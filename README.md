<!--Autonomous Agents -->
<!--
Copyright (C) Teemu Maatta. 

@misc{MaattaAutonomousAgents2023,
  author = {Teemu Maatta},
  title = {Autonomous Agents},
  year = {2023},
  howpublished = {\url{http://github.com/tmgthb/Autonomous-Agents}},
  note = {Accessed: YYYY-MM-DD}
}
-->
<div id="topofthepage"> </div>

<div align="center">

[![Hits](http://hits.sh/github.com/tmgthb/Autonomous-Agents.svg?view=today-total&label=Views&color=007ec6)](http://hits.sh/github.com/tmgthb/Autonomous-Agents/)
[![X](http://img.shields.io/twitter/follow/Teemumtt3?style=social)](http://twitter.com/Teemumtt3)
[![GitHub Repo stars](http://img.shields.io/github/stars/tmgthb/Autonomous-Agents?style=flat-square)](http://github.com/tmgthb/Autonomous-Agents/stargazers)

</div>

<p align="center">
  <img height="100" src="https://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_agent_logo.png" alt="Autonomous Agents">
</p>

<div align="center">

  # Autonomous Agents
  Autonomous Agents-research papers. Updated daily. [Resources-section](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Resources.md)-section.  

</div>


---

<div id="researchpapers" align="center">

## Research papers: 2026 4/4

[2026 (4/4)](http://github.com/tmgthb/Autonomous-Agents/blob/main/README.md), [2026 (3/4)](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2026_3.md), [2026 (2/4)](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2026_2.md), [2026 (1/2)](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2026_1.md), [2025 (4/4)](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2025_4.md),[2025 (3/4)](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2025_3.md), [2025 (2/4)](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2025_2.md), [2025 (1/4)](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2025_01.md), [2024](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2024.md), [2023](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2023.md), [Earlier](http://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_Earlier.md)



Chronological order. 





</div>



---






#### 25th February 2026

[ViSTAR: Virtual Skill Training with Augmented Reality with 3D Avatars and LLM coaching agent](http://arxiv.org/abs/2602.22077)

- ViSTAR (Virtual Skill Training with Augmented Reality): introduces an AR-based basketball training system that follows the Behavioral Skills Training framework, providing multi-faceted visual and verbal feedback through 3D motion reconstruction and LLMs.
- The architecture utilizes monocular pose estimation and Dynamic Time Warping to align user performance with expert models, while a Random Forest classifier identifies critical joint-level errors for the coaching agent.
- The system delivers holistic guidance for rhythm and localized guidance for posture via immersive AR overlays and natural language suggestions generated by an LLM agent.

---


[Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models](http://arxiv.org/abs/2602.22072)

- ToM (Theory of Mind) evaluation and analysis pipeline: introduces a structured framework for probing Theory of Mind robustness in LLMs using a handcrafted dataset of perturbed false-belief tasks, gold-standard reasoning chains, and a multi-model inference stage.
- The framework evaluates six open-source LLMs—including DBRX, Mixtral-8x7B, Llama3-70B, Yi-34B, Llama2-70B, and Vicuna-33B—under Vanilla and Chain-of-Thought prompting strategies to measure final answer accuracy, reasoning chain correctness, and the faithfulness of generated explanations.
- It utilizes ten perturbation classes and a novel "Proper Subsequence" metric to distinguish between heuristic matching and robust mental state modeling in AI agents.

---


[GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL](http://arxiv.org/abs/2602.22190)

- GUI-Libra: introduces a post-training recipe for native GUI agents to improve reasoning and grounding, with a data curation pipeline, action-aware supervised fine-tuning, conservative reinforcement learning, success-adaptive negative gradient scaling, a vision-language model, and a KL trust region.
- The system utilizes a data curation pipeline to generate action-aligned reasoning traces and applies token-level reweighting during SFT to prioritize critical action and grounding tokens.
- To handle partial verifiability in GUI environments, the framework implements success-adaptive negative gradient scaling and KL trust regions within a group-relative policy optimization objective.

---


[SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents](http://arxiv.org/abs/2602.22124)

- SWE-Protégé: introduces a post-training framework that reframes software repair as an expert-protégé collaboration, with a protégé, an expert, an ask_expert tool, an agent scaffold, a task dataset, an SFT pipeline, an RL pipeline, and an in-trajectory judge, enabling SLMs to selectively seek guidance from strong expert models while remaining the primary decision-makers.
- The system utilizes a two-phase training process involving supervised fine-tuning on expert-augmented trajectories followed by reinforcement learning with rewards targeting stalled progress and collaboration quality.
- By integrating a sparse expert-invocation tool, the framework allows a 7B-parameter model to achieve competitive performance on SWE-bench Verified with significantly lower token costs than expert-only agents.

---

[Reasoning-Driven Design of Single Atom Catalysts via a Multi-Agent Large Language Model Framework](http://arxiv.org/abs/2602.21533)

- MAESTRO (Multi-Agent-based Electrocatalyst Search Through Reasoning and Optimization): introduces an autonomous design loop for single atom catalysts, which includes design-, reflect-, summary-, and exploration report-agents.
- The framework utilizes a machine learning force field as a surrogate for density functional theory to enable rapid property evaluation during iterative optimization cycles.
- Through in-context learning and an exploration-exploitation strategy, the system discovers catalysts that surpass theoretical activity limits by breaking conventional scaling relations.

---


[SparkMe: Adaptive Semi-Structured Interviewing for Qualitative Insight Discovery](http://arxiv.org/abs/2602.21136)

- SparkMe: introduces, a multi-agent LLM interviewer that optimizes semi-structured interviews by balancing topic coverage, emergent theme discovery, and interaction cost through deliberative planning, with an InterviewerAgent, an AgendaManager, an ExplorationPlanner, an Interview Agenda, simulated conversation rollouts, and a utility function.
- The architecture includes planning-, dialogue-, and state-tracking agents that coordinate through a shared Interview Agenda to prioritize lines of questioning likely to surface relevant subtopics.
- Evaluation via a 70-participant user study across seven professions demonstrates that the framework surfaces peer-validated insights while maintaining conversational coherence and efficiency.

---


[Solaris: Building a Multiplayer Video World Model in Minecraft](http://arxiv.org/abs/2602.22208)

- Solaris: introduces a multiplayer video world model for consistent multi-view Minecraft simulation, incorporating SolarisEngine, Checkpointed Self Forcing, Multiplayer Self-Attention, an Action Module, Cross-Attention, a 3D VAE, VLM-as-a-judge, and a Rolling KV cache.
- The framework utilizes a staged training pipeline transitioning from single-player to multiplayer modeling to ensure temporal and cross-perspective consistency.
- Checkpointed Self Forcing enables long-horizon autoregressive generation by decoupling the rollout phase from backpropagation to reduce memory overhead.

---

[Position-Based Flocking for Persistent Alignment without Velocity Sensing](http://arxiv.org/abs/2602.22154)

- Position-based flocking model: introduces a bio-inspired coordination framework that achieves persistent velocity alignment in multi-agent systems using only relative position data, with Initial Relative Positions, Current Relative Positions, Time-dependent Alignment Gain, Cohesion-Separation Mechanism, and Threshold Mechanism.
- The system approximates relative velocity differences by comparing current spatial relationships against initial configurations, utilizing a piecewise gain function to transition from a transient imprinting phase to a sustained reinforcement phase.
- Experimental validation with wheeled robots demonstrates that the non-vanishing threshold prevents alignment decay, resulting in more compact and directionally stable formations compared to traditional velocity-sensing baselines.

---

[The economic alignment problem of artificial intelligence](http://arxiv.org/abs/2602.21843)

- Post-growth policy roadmap for AI: introduces a systemic approach to resolve the economic alignment problem with AI capability levels, economic scenarios, LLM-based automation analysis, the Doughnut framework, post-growth policy solutions, and governance and business reforms, where the authors argue that developing advanced AI within a growth-based economy exacerbates social and environmental risks.
- The framework prioritizes "tool AI" over "agentic AI" to enhance human autonomy and proposes governing AI as a global commons to mitigate power asymmetries and existential threats.
- It advocates for structural reforms including resource caps, Pigouvian taxes, and job guarantees to decouple technological advancement from ecological overshoot and labor displacement.

---

[Language Models Exhibit Inconsistent Biases Towards Algorithmic Agents and Human Experts](http://arxiv.org/abs/2602.22070)

- Stated and Revealed Preference Evaluation Framework: introduces an experimental paradigm to evaluate inconsistent biases in LLMs by comparing explicit trust ratings against implicit delegation choices across human and algorithmic agents.
- The framework utilizes Study 1 to elicit stated preferences through direct trust queries and Study 2 to measure revealed preferences via in-context performance-based betting.
- The study reveals that LLMs exhibit human-like algorithm aversion in stated trust but demonstrate significant algorithm appreciation in revealed choices, with biases influenced by model complexity and task framing.

---

[Using Feasible Action-Space Reduction by Groups to fill Causal Responsibility Gaps in Spatial Interactions](http://arxiv.org/abs/2602.22041)

- gFeAR (Group Feasible Action-Space Reduction): introduces a metric for quantifying collective causal responsibility in multi-agent spatial interactions, with individual FeAR (measures individual action-space restriction), group FeAR (quantifies collective causal responsibility), assertive influence categorization (defines solo and coupled influences), a tiering algorithm (ranks agents into hierarchical tiers), and scenario-based simulations (evaluates metrics in grid-world environments).
- The framework identifies minimal groups of agents that collectively restrict the feasible actions of others to address responsibility gaps in cases of causal overdeterminism.
- Simulations demonstrate that group effects are most prevalent in high-proximity, aggressive interactions where individual-focused metrics fail to capture total causal influence.

---

[Autobidding Equilibria in Sponsored Shopping](http://arxiv.org/abs/2602.21966)

- Autobidding Equilibria in Sponsored Shopping: introduces a mathematical model for multi-item, multi-slot auctions to analyze equilibrium existence and welfare efficiency, with Bidders, Items, Slots, Uniform-Bidding Strategy, GSP Auction, VCG Auction, ROI Constraints, and Input-Smoothing Framework.
- The study establishes the universal existence of autobidding equilibria for both Generalized Second-Price and Vickrey-Clarke-Groves mechanisms using an input-smoothing technique.
- The authors prove a tight Price of Anarchy of 2 for both auction formats, showing that welfare loss in these combinatorial settings matches bounds found in single-item models.

---

[2-Step Agent: A Framework for the Interaction of a Decision Maker with AI Decision Support](http://arxiv.org/abs/2602.21889)

- 2-Step Agent: introduces a computational framework for AI-assisted decision making that formalizes how a rational agent updates internal beliefs based on model predictions before performing causal inference to select optimal actions.
- The framework utilizes Structural Causal Models to represent both the real-world data generation process and the agent's internal assumptions regarding historical training data and model parameters.
- Quantitative simulations reveal that misaligned priors concerning treatment policies or covariate distributions can cause AI decision support to result in worse outcomes than no support at all.

---

[ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices](http://arxiv.org/abs/2602.21858)

- ProactiveMobile: introduces a benchmark for mobile agents that formalizes proactive intelligence through a pipeline comprising a contextual information generator, behavioral trajectories, a potential intentions generator, semantic clustering, a noise injector, a function mapper, a function pool, and a three-stage review.
- The benchmark generation process leverages multiple LLMs including Claude, Gemini, o1, and GPT-4o to simulate diverse user intents and ensure high-quality multi-answer annotations.
- The benchmark features 3,660 instances across 14 scenarios, requiring agents to translate inferred user intents into executable function sequences using a predefined pool of 63 APIs.

---

[UniVBench: Towards Unified Evaluation for Video Foundation Models](http://arxiv.org/abs/2602.21835)

- UniV-Eval (Unified Agentic Evaluation System): introduces a standardized assessment framework for video foundation models, with source videos, reference images, reference instructions, shot classification-, shot evaluation-, and evaluation score-agents, LLMs, weakness checklists, and final scores.
- The system leverages LLMs to perform fine-grained analysis across eight cinematic dimensions, including lighting, camera motion, and spatial relationships.
- It provides traceable feedback through structured weakness checklists to enable precise attribution of model failures to perception or generation components.

---

[Bugs in Modern LLM Agent Frameworks: An Empirical Study](http://arxiv.org/abs/2602.21806)

- Lifecycle-Oriented Bug Taxonomy: introduces a systematic empirical methodology to categorize and analyze framework-level bugs in LLM agent systems, with Issue Collection, Bug Filtering, Individual Labeling, Root Cause Analysis, Symptom Analysis, and Agent Lifecycle Stages.
- The approach maps 998 bug reports from CrewAI and LangChain to five lifecycle stages including initialization, perception, self-action, mutual interaction, and evolution.
- Analysis demonstrates that execution-semantics mechanisms in the self-action stage are the primary source of framework failures, often resulting in functional errors or crashes.

---

[Learning-Based Geometric Leader–Follower Control for Cooperative Rigid-Payload Transport with Aerial Manipulators](http://arxiv.org/abs/2602.21768)

- Learning-augmented geometric tracking framework: introduces a hierarchical leader-follower architecture for cooperative aerial transport of rigid payloads, utilizing payload-level and agent-level Gaussian Process models to compensate for unmodeled disturbances.
- The architecture separates payload-level wrench generation, contact-level wrench allocation, and agent-level wrench realization to manage internal-force redundancy and thrust-direction underactuation.
- Lyapunov analysis establishes high-probability uniform ultimate boundedness of tracking errors, with tracking accuracy improvements validated through multi-agent simulations.

---

[Stability of Open Multi-agent Systems over Dynamic Signed Digraphs](http://arxiv.org/abs/2602.21738)

- Signed OMAS (Open Multi-Agent Systems) Stability Framework: introduces a stability analysis for dynamic networks with cooperative and antagonistic interactions, employing dynamic signed digraphs, leader groups, follower nodes, switched system representation, signed edge-laplacian, strict lyapunov functions, and average dwell time, and includes leader- and follower-agents.
- The approach reformulates synchronization as a stability problem in edge-based coordinates to handle multiple zero eigenvalues in the graph Laplacian.
- Numerical simulations validate that the system achieves bipartite consensus or containment under specific average dwell time conditions despite structural changes.

---

[Hierarchical Lead Critic based Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2602.21680)

- HLC (Hierarchical Lead Critic): introduces a cooperative multi-agent reinforcement learning framework that optimizes agent policies through a hierarchy of local and group-level critics using a nested sequential update procedure.

- The architecture utilizes a multi-path actor model that fuses representations from mixture-of-experts subnetworks and a base network via cross-attention and SimBa residual connections.

- The framework employs a Transformer-Encoder based Lead Critic to provide group-level value estimates while re-sampling actions between updates to eliminate conflicting gradients and stabilize learning.


---

[Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning](http://arxiv.org/abs/2602.21670)

- Hierarchical MAP (Multi-Agent Planning): introduces a three-layer architecture that distributes task decomposition and allocation across global-, type-, and robot-level LLM agents.
- The system incorporates a feedback-driven prompt optimization mechanism inspired by TextGrad to iteratively refine agent instructions when execution failures are detected by a classical PDDL planner.
- Meta-prompt sharing across homogeneous agents enables efficient adaptation and significantly improves planning success rates on complex, long-horizon, and vague multi-robot tasks within the MAT-THOR benchmark.

---

[AgentLTV: An Agent-Based Unified Search-and-Evolution Framework for Automated Lifetime Value Prediction](http://arxiv.org/abs/2602.21634)

- AgentLTV (An Agent-Based Unified Search-and-Evolution Framework for Automated Lifetime Value Prediction): introduces an automated framework for Lifetime Value prediction that searches over executable pipeline programs, with Configuration Module, MCTS Module, EA Module, and includes MCTS-, EA-, code generation-, code repair-, expert optimization-, and advisory-agents.
- The system employs a two-stage strategy where Monte Carlo Tree Search explores high-level modeling decisions followed by an Evolutionary Algorithm that refines the best-discovered program through island-based mutation and crossover.
- By integrating LLM-driven agents for code generation and execution-grounded feedback, the framework addresses industrial challenges such as negative Lifetime Value values and the requirement for scenario-specific pipeline customization.

---

[Self-Correcting VLA: Online Action Refinement via Sparse World Imagination](http://arxiv.org/abs/2602.21633)

- SC-VLA (Self-Correcting Vision-Language-Action): introduces a two-stage framework that achieves self-improvement by intrinsically guiding action refinement through sparse world imagination, with VLM, DiT Backbone, SPI, and OAR components.
- The system integrates auxiliary predictive heads to forecast task progress and future trajectory trends, constraining the policy to encode short-term physical evolution.
- An online action refinement module utilizes residual reinforcement learning to adjust trajectory orientation based on predicted sparse future states, eliminating reliance on external reward models.

---

[ADM-DP: Adaptive Dynamic Modality Diffusion Policy through Vision-Tactile-Graph Fusion for Multi-Agent Manipulation](http://arxiv.org/abs/2602.21622)

- ADM-DP (Adaptive Dynamic Modality Diffusion Policy): introduces a multi-modal imitation learning framework for multi-agent manipulation, with vision-, tactile-, and graph-based encoders, an adaptive attention mechanism, and a diffusion-based action decoder.
- The system utilizes Feature-wise Linear Modulation to fuse visual semantics with geometric features and a Graph Attention Network to maintain spatial awareness between agents via shared tool center point positions.
- An entropy-regularized attention module dynamically re-weights sensory inputs based on task phases, while a tactile-guided data collection protocol enables autonomous grasp refinement through force-sensitive resistor feedback.

---

[Structurally Aligned Subtask-Level Memory for Software Engineering Agents](http://arxiv.org/abs/2602.21611)

- Structurally Aligned Subtask-Level Memory: introduces a memory-augmented framework for software engineering agents that aligns storage, retrieval, and updating with the agent's functional decomposition, with a memory state, subtask intents, a retrieval mechanism, a task-solving agent, an experience extractor, and memory updates.
- The architecture employs a two-stage retrieval process using category-based filtering and semantic matching of structured intents to provide precise augmented context for the task-solving agent.
- The system enables continuous online learning by distilling raw execution trajectories into transferable insights, significantly improving performance on complex, long-horizon software engineering tasks.

---

[Towards Autonomous Graph Data Analytics with Analytics-Augmented Generation](http://arxiv.org/abs/2602.21604)

- AAG (Analytics-Augmented Generation): introduces a paradigm for autonomous graph analytics that positions LLMs as coordinators to bridge the gap between high-level user intent and complex graph algorithms through explicit analytical grounding.
- The framework utilizes a hierarchical algorithm knowledge base to ground task planning and generates executable Directed Acyclic Graphs (DAGs) to manage multi-stage analytical workflows and data dependencies.
- It incorporates a Model Context Protocol-based interaction layer and task-driven result distillation to handle large-scale graph outputs while maintaining reliable execution across diverse graph systems.

---

[ABM-UDE: Developing Surrogates for Epidemic Agent-Based Models via Scientific Machine Learning](http://arxiv.org/abs/2602.21588)

- ABM-UDE: introduces a surrogate modeling pipeline that distills agent-based epidemic simulations into Universal Differential Equations (UDEs) by coupling mechanistic SEIR-family dynamics with a neural-parameterized contact rate.
- The architecture integrates Multiple Shooting (MS) to partition trajectories and an observer-based Prediction Error Method (PEM) to stabilize the identification of neural-augmented epidemiological dynamics across intervention-driven regime shifts.
- This approach enables rapid "what-if" scenario evaluation on commodity hardware, achieving four orders of magnitude speedup over exascale simulators while preserving mechanistic interpretability and providing calibrated uncertainty forecasts.

---

[Power and Limitations of Aggregation in Compound AI Systems](http://arxiv.org/abs/2602.21556)

- Compound AI Systems: introduces a stylized principal-agent framework to analyze how aggregating outputs from multiple homogeneous LLM agents can expand the set of elicitable outputs beyond the capabilities of a single model, with System Designer, Multiple LLM Agents, Reward Functions, Budget Constraints, Feasible Sets, and Aggregation Rules.
- The framework identifies three core mechanisms—feasibility expansion, support expansion, and binding set contraction—that characterize when aggregation overcomes limitations in prompt engineering and model capabilities.
- Theoretical results are validated through empirical experiments using GPT-4o-mini on a reference-generation task, demonstrating that specific aggregation rules like intersection and addition can elicit complex target outputs.

---

[DualPath: Breaking the Storage Bandwidth Bottleneck in Agentic LLM Inference](http://arxiv.org/abs/2602.21548)

- DualPath: introduces an inference system that resolves storage bandwidth bottlenecks in agentic LLM workloads, includes prefill- and decoding-engines, and utilizes KV persistent storage, CNIC (Compute NIC), SNIC (Storage NIC), traffic manager, request scheduler, and DRAM buffers.
- The framework utilizes a global scheduler to dynamically balance load and a CNIC-centric traffic manager to isolate KV-Cache transfers from latency-critical model communications.
- By aggregating the storage NIC bandwidth of otherwise idle decoding nodes, DualPath increases throughput for long-context, multi-turn agentic interactions by up to 1.87x.

---

[ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning](http://arxiv.org/abs/2602.21534)

- ARLArena: introduces a stable training recipe and systematic analysis framework for agentic reinforcement learning, with Behavior Cloning (initializes policy manifold), Format Penalty (enforces structured output), KL Regularization (constrains policy drift), Parameter Search (optimizes training stability), Sequence-level Clipping (stabilizes importance sampling), Turn-level Advantage (improves credit assignment), Dynamic Filtering (removes degenerate samples), Web-agents (perform online navigation), Multimodal-agents (process visual-textual inputs), TIR Math-agents (solve symbolic reasoning), and Embodied-agents (interact with physical environments).
- The framework decomposes policy gradients into four orthogonal dimensions—loss aggregation, importance sampling clipping, trajectory filtering, and advantage design—to diagnose and mitigate sources of training instability and collapse in multi-turn interactions.
- SAMPO (Stable Agentic Multi-turn Policy Optimization) achieves robust performance by integrating sequence-level importance sampling clipping with fine-grained environmental advantage signals to stabilize LLM-based agent training pipelines.

---

[Training Generalizable Collaborative Agents via Strategic Risk Aversion](http://arxiv.org/abs/2602.21515)

- SRPO (Strategically Risk-Averse Policy Optimization): introduces a multi-agent reinforcement learning algorithm that incorporates strategic risk aversion into policy optimization to foster robust cooperation and partner generalization, with Agents, Adversaries, Critics, Environment, Trajectory Memory, and Risk-Averse Objective.
- The system employs an auxiliary game where each agent is paired with a fictitious adversary that inflicts maximum damage within a constrained deviation from the partner's policy, stabilizing training while inducing robustness.
- Empirical evaluations across grid-world, continuous control, and LLM-based math debate tasks—including Qwen-based and Llama-based agents—demonstrate that the approach reduces free-riding behavior and maintains coordination accuracy during zero-shot partner shifts.

---

[Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information](http://arxiv.org/abs/2602.21496)

- SEMSIEDIT (Semantic Sensitive Information Editor): introduces an inference-time defense framework designed to iteratively detect and mitigate semantic sensitive information without retraining, with Pre-processing Agent (generates initial safety-conscious response), Evaluator Agent (detects semantic leakage in drafts), Editor Agent (rewrites content based on feedback), Agentic-Feedback Loop (iterative critique and refinement process), Stop Condition (terminates loop based on safety), and Final Output (sanitized narrative-preserving text); it includes pre-processing-, evaluator- and editor-agents.
- The system utilizes a dual-agent architecture to dynamically identify and restructure narrative segments containing sensitive inferences, maintaining text fluency while reducing semantic leakage by an average of 34.6%.
- Research findings indicate that larger reasoning models achieve safety through constructive expansion and nuanced rewriting, whereas capacity-constrained models often resort to destructive truncation or simple refusal.

---

[Both Ends Count! Just How Good are LLM Agents at Text-to-“Big SQL”?](http://arxiv.org/abs/2602.21480)

- Text-to-Big SQL: introduces a benchmarking methodology for evaluating LLM agents in large-scale data environments, with a Controller (LLM-based reasoning and tool selection), a Checker (LLM-based SQL syntax verification), an Executor (programmatic interface for tool execution), Tools (functional modules for database interaction), a Big Data Engine (large-scale distributed query processor), and a ReAct Loop (iterative reasoning and acting cycle), where it assesses the joint impact of query generation and execution efficiency.
- The system employs a ReAct-style agent architecture, which includes controller- and checker-LLMs, to perform iterative reasoning, tool selection, and observation-based refinement for complex SQL tasks.
- The research defines new metrics such as VES* and VCES to quantify the cost and performance implications of agentic workflows on Big Data systems like Spark SQL.

---

[Pancake: Hierarchical Memory System for Multi-Agent LLM Serving](http://arxiv.org/abs/2602.21477)

- Pancake: introduces a multi-tier agentic memory system for multi-agent LLM serving, integrating a multi-level index cache, FSM-based pattern modeling, and a hybrid graph structure to support dialogue-, summarization-, and retrieval-agents.
- The system manages single-agent memory access through hierarchical caching and predictive modeling while enabling multi-agent coordination via interconnected coarse indexes to reduce search overhead across diverse memory scopes.
- It implements collaborative CPU-GPU execution with insertion buffers and hotspot-aware caching to handle frequent, fine-grained updates and large-scale vector searches with reduced latency.

---

[Revisiting Text Ranking in Deep Research](http://arxiv.org/abs/2602.21456)

- Q2Q (Query-to-Question): introduces a systematic evaluation of text ranking methods for multi-hop reasoning tasks, with Deep Research Agent, Retrieval Unit, Retriever, Re-ranker, Q2Q Reformulator, and Full-document Reader; the framework includes gpt-oss-20b and GLM-4.7-Flash agents.
- The study demonstrates that passage-level retrieval units significantly improve efficiency and accuracy over document-level units by optimizing context window usage and avoiding length normalization issues.
- The proposed Q2Q method mitigates training-inference mismatch by translating keyword-heavy agent queries into natural language, enhancing the performance of neural retrievers and reasoning-based re-rankers.

---

[Recursive Belief Vision Language Action Models](http://arxiv.org/abs/2602.20659)

- RB-VLA (Recursive Belief Vision Language Action Models): introduces a belief-centric architecture that decouples episodic semantic reasoning from continuous causal state estimation for long-horizon robotic manipulation.
- The system employs a recursive belief estimator to track task progress and physical interactions through a compact latent state, eliminating the need for dense VLM re-inference.
- Experimental results demonstrate superior performance on multi-stage tasks with up to 5x lower latency and constant memory usage compared to traditional observation-driven VLAs.

---

#### 24th February 2026

[Aletheia tackles FirstProof autonomously](http://arxiv.org/abs/2602.21201)

- Aletheia: introduces a fully autonomous mathematics research agent powered by Gemini 3 Deep Think, incorporating generator and verifier subagents, a verification and extraction prompt, and a Human-AI Interaction card to solve research-level mathematical problems.
- The system processes raw problem statements through an automated pipeline to generate and filter candidate solutions into formatted LaTeX documents without human intervention.
- Evaluation on the FirstProof challenge demonstrates the agent's ability to solve 6 out of 10 complex problems, highlighting capabilities in autonomous scientific discovery and formal reasoning.

---

[Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs](http://arxiv.org/abs/2602.21198)

- Reflective Test-Time Planning: introduces a framework for embodied agents that unifies reflection-in-action and reflection-on-action, with an Action LLM, an Internal LLM, an External LLM, a Working Memory Buffer, Retro-Reflection, and Test-Time Training; it includes action generation-, internal reflection-, and external reflection-LLMs.
- The system utilizes test-time scaling to generate and score multiple candidate actions and test-time training to update model parameters based on hindsight-corrected retrospective reflections.
- By integrating double-loop learning, the agent learns to diagnose and correct the underlying causes of errors during deployment, improving performance on long-horizon household and robotic fitting tasks.

---

[On Data Engineering for Scaling LLM Terminal Capabilities](http://arxiv.org/abs/2602.21193)

- Terminal-Task-Gen: introduces a scalable synthetic task generation pipeline that combines dataset adaptation with skill-based synthesis to produce high-quality training data for terminal agents, including task-synthesis and trajectory-generation LLMs.
- The framework utilizes a teacher model to generate multi-turn interaction trajectories within sandboxed Docker environments, ensuring verifiable task completion through automated test cases and structured environment files.
- Fine-tuning Qwen3 models on the resulting Terminal-Corpus yields the Nemotron-Terminal family, which achieves significant performance gains on Terminal-Bench 2.0 by bridging the gap between efficient models and massive frontier counterparts.

---

[ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking](http://arxiv.org/abs/2602.21161)

- ActionReasoning: introduces an LLM-driven framework for 3D robotic manipulation that utilizes a multi-agent orchestrator to decompose complex tasks into physics-consistent action plans, including pre-grasp-, descent-, grasp-, lift-, placement-, and release-agents.
- Each specialized agent operates via structured prompting that integrates current environment states, task memory, role definitions, and a robotics knowledge base to generate executable waypoints.
- A sequential gating mechanism ensures physical consistency by verifying contact stability and collision avoidance before transitioning between task stages in a simulated environment.

---

[SELAUR: Self Evolving LLM Agent via Uncertainty-aware Rewards](http://arxiv.org/abs/2602.21158)

- SELAUR (Self Evolving LLM Agent via Uncertainty-aware Rewards): introduces a reinforcement learning framework that incorporates intrinsic LLM uncertainty into reward design to provide dense supervision and improve exploration efficiency.
- The system integrates entropy, least-confidence, and margin-based metrics into a unified token-level uncertainty estimate, which is then aggregated into step- and trajectory-level rewards.
- By reshaping rewards for failed trajectories using these uncertainty signals, the framework enables agents to extract meaningful learning cues from unsuccessful experiences and avoid suboptimal reasoning loops.

---

[A BENCHMARK FOR DEEP INFORMATION SYNTHESIS](http://arxiv.org/abs/2602.21143)

- DEEPSYNTH (Deep Information Synthesis Benchmark): introduces a novel evaluation framework designed to assess LLM-based agents on realistic, time-consuming tasks that require gathering and synthesizing information from multiple sources to produce structured insights.
- The benchmark comprises 120 expert-curated tasks across 7 domains and 67 countries, featuring a multi-stage construction pipeline that ensures tasks are robust against memorization and require verifiable JSON outputs.
- Evaluation of state-of-the-art models, including planning- and execution-based agents like OWL, reveals significant performance gaps, with systems struggling primarily with navigation and synthesis errors in large information spaces.

---

[UDVideoQA: A Traffic Video Question Answering Dataset for Multi-Object Spatio-Temporal Reasoning in Urban Dynamics](http://arxiv.org/abs/2602.21137)

- UDVideoQA (Urban Dynamics Video Question Answering): introduces a large-scale traffic video benchmark for multi-object spatio-temporal reasoning in urban environments, with Traffic Video Recording and Processing (segments long-sequence surveillance footage into 10-second clips), Dynamic Anonymity Blurring (applies event-driven motion-based masks for privacy preservation), QA Taxonomy & Generation (utilizes prompt engineering and VLMs to create hierarchical question pools), Human-in-the-loop Quality Control (validates question clarity, relevance, and ground truth accuracy), VideoQA Benchmark (evaluates model reasoning across five spatio-temporal categories), VideoQGen Benchmark (assesses model ability to generate meaningful and grounded questions), and LLM Judge (performs semantic-semantic scoring to evaluate answer correctness); the framework includes generation-VLMs and an LLM Judge.
- The dataset encompasses 16 hours of unscripted real-world traffic footage recorded under diverse weather and lighting conditions, categorized into five reasoning levels from basic attribution to counterfactual inference.

---

[Controlling inertial active Brownian motion via stochastic resetting](http://arxiv.org/abs/2602.21134)

- Inertial ABP under Stochastic Resetting: introduces a theoretical model for active agents with mass subject to complete state restarts, with Inertial Active Brownian Particle (self-propelled agent with mass), Stochastic Resetting (intermittent return to initial state), Moment-Generating Framework (analytical method for statistical moments), and Position-Velocity-Orientation State Space (complete set of reset variables) components.
- The study demonstrates that inertia reshapes transport by enhancing localization near the reset point and producing non-Gaussian steady states with heavy-tailed distributions.
- Analysis of excess kurtosis identifies re-entrant phase behavior driven by the competition between inertial momentum relaxation, self-propulsion persistence, and the reset frequency.

---

[“Are You Sure?”: An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems](http://arxiv.org/abs/2602.21127)

- HAT-Lab (Human-Agent Trust Laboratory): introduces a high-fidelity research platform to measure human susceptibility to Agent-Mediated Deception (AMD) across nine realistic scenarios, utilizing an experimental frontend, attack configuration, agent orchestration backend, and a comprehensive logging module.
- The framework evaluates user vulnerability to stealthy attacks targeting an agent's perception, memory, and action boundaries while testing the efficacy of static, persistent, and interactive defensive guardrails.
- The study identifies six cognitive failure modes, such as task-focused tunneling and the "expert's paradox," revealing that only 8.6% of participants correctly perceive stealthy agent-mediated attacks despite high self-reported confidence.

---

[Cooperative-Competitive Team Play of Real-World Craft Robots](http://arxiv.org/abs/2602.21119)

- OODSI (Out of Distribution State Initialization): introduces a comprehensive robotic system for multi-agent reinforcement learning, featuring a distributed training framework and a novel state initialization method to bridge the sim-to-real gap in cooperative-competitive tasks.
- The system utilizes a dual-simulation approach with pyBullet for efficient training and Gazebo for realistic testing, alongside rule-based action masking to guide exploration under real-world constraints.
- Experimental results demonstrate that OODSI improves sim-to-real performance by 20% in complex multi-robot construction games involving both team cooperation and inter-team competition.

---

[Can Interest-Bearing Positions Solve the Long-Horizon Problem in Prediction Markets? Evidence from Agent-Based Simulations](http://arxiv.org/abs/2602.21091)

- LLM-based Prediction Market Simulation: introduces an experimental framework using GPT-5.2 agents to analyze how interest-bearing positions mitigate liquidity and accuracy issues in long-horizon prediction markets.
- The system incorporates a 2x2 factorial design to isolate the causal effects of time horizons and portfolio value interest on trading behavior and price discovery.
- The simulation includes heterogeneous risk preferences and explicit outside investment options to model the capital opportunity costs that typically deter long-term market participation.

---

[OCR-Agent: Agentic OCR with Capability and Memory Reflection](http://arxiv.org/abs/2602.21053)

- OCR-Agent (Agentic OCR with Capability and Memory Reflection): introduces an iterative self-correction framework for VLMs using capability reflection, memory reflection, a reflection memory store, an ability filter, and a refinement mechanism, including reflection- and refinement-agents.
- The architecture employs a capability constraint mechanism to filter out infeasible action proposals, ensuring refinement steps are grounded in the model's actual executable scope.
- By maintaining a historical record of reflections, the agent avoids redundant exploration of incorrect solution paths and outperforms existing models on the OCRBench v2 benchmark without additional training.

---

[Stability Under Valuation Updates in Coalition Formation](http://arxiv.org/abs/2602.21041)

- ASHG (Additively Separable Hedonic Games): introduces a mathematical model for analyzing the stability of agent groupings under dynamic preference updates, utilizing Agent Nodes, Valuation Edges, and Coalition Partitions.
- The research analyzes the computational complexity of finding stable partitions within a bounded Reconfiguration Distance Metric, proving NP-completeness for most standard stability notions.
- It presents polynomial-time algorithms for contractual stability in symmetric games and demonstrates that average reconfiguration costs remain constant over extended update sequences.

---

[Matching Multiple Experts: On the Exploitability of Multi-Agent Imitation Learning](http://arxiv.org/abs/2602.21020)

- MA-IL (Multi-Agent Imitation Learning): introduces a theoretical framework to analyze the exploitability of policies learned from expert demonstrations in n-player Markov Games, employing a new notion of best-response continuity to derive tractable Nash gap bounds.
- The study demonstrates that exact measure matching fails to recover Nash equilibria in general Markov Games without full-state support or specific strategic dominance assumptions.
- It establishes that Behavioral Cloning with a dominant strategy expert provides a consistent Nash imitation gap, which is generalized via best-response continuity and promoted by entropy regularization.

---

[From Perception to Action: An Interactive Benchmark for Vision Reasoning](http://arxiv.org/abs/2602.21015)

- CHAIN (Causal Hierarchy of Actions and Interactions): introduces an interactive 3D benchmark for evaluating physical reasoning, with Agent Model (multimodal reasoning agent), Environment State (3D physics-driven scene), Agent Input (instructions and multi-view observations), Action Selection (atomic manipulation commands), Simulator (physics-based execution engine), Physical Feedback (iterative environment response), and Evaluation Metrics (success and efficiency measures), where the system assesses the ability of LLMs to plan and execute structured action sequences grounded in physical constraints.
- The framework shifts evaluation from passive perception to active problem solving using a closed-loop protocol that requires agents to iteratively observe, reason, and act within dynamic environments.
- It incorporates diverse task families including interlocking mechanical puzzles and 3D spatial packing to test long-horizon reasoning, structural understanding, and causal-chain manipulation.

---

[HiSAC: Hierarchical Sparse Activation Compression for Ultra-long Sequence Modeling in Recommenders](http://arxiv.org/abs/2602.21009)

- HiSAC (Hierarchical Sparse Activation Compression): introduces an efficient framework for personalized ultra-long sequence modeling in recommender systems, with multi-modal encoder, RQ-VAE, global hierarchical semantic tree, hierarchical voting mechanism, interest-agents, soft-routing attention, semantic and ranking embeddings, and offline and online caches.
- The framework tokenizes user histories into multi-level semantic identifiers and employs a hierarchical voting mechanism to sparsely activate personalized interest-agents as fine-grained preference centers.
- It utilizes soft-routing attention to aggregate historical signals in a decoupled semantic space, minimizing quantization errors and preserving long-tail behaviors for industrial-scale deployment.

---

[Toward an Agentic Infused Software Ecosystem](http://arxiv.org/abs/2602.20979)

- AISE (Agentic Infused Software Ecosystem): introduces a holistic software stack designed to support autonomous development, with BOSQUE, SUNDEW, BAPI, MINT, and LLM-based AI Agents, where the system co-designs the programming language and runtime to enhance agentic reliability and discoverability.
- The framework utilizes the BOSQUE language to provide explicit semantic intents and invariants, enabling the SUNDEW tool to perform mechanized validation of agent-generated code via SMT solvers.
- The MINT runtime environment implements a HATEOAS-style architecture for progressive tool discovery and secure sandboxing of agentic workloads using the BAPI protocol.

---

[See and Fix the Flaws: Enabling VLMs and Diffusion Models to Comprehend Visual Artifacts via Agentic Data Synthesis](http://arxiv.org/abs/2602.20951)

- ArtiAgent: introduces an agentic framework for automated visual artifact synthesis and annotation, utilizing perception-, synthesis-, and curation-agents to generate high-quality training data for vision-language models.
- The system employs a novel inversion-injection method within diffusion transformers to deliberately perturb patch attention, creating plausible structural distortions like duplication, omission, and fusion.
- It produces a large-scale dataset of 100K artifact-injected images with rich textual explanations and bounding boxes, enabling fine-tuned models to outperform proprietary systems in artifact detection and correction.

---

[Some Simple Economics of AGI](http://arxiv.org/abs/2602.20946)

- The Economic Framework of AGI Transition: introduces an economic model for the AGI era, with Autonomous Agents, Human Verifiers, Verification Infrastructure, Synthetic Practice Platforms, Liability Underwriting, AI Sandwich Topology, Measurability Gap, and Trojan Horse Externality, where the AI Sandwich topology includes intent-directing humans, verified agents, and liability-underwriting experts.
- The model formalizes the "Measurability Gap" as the structural divergence between the exponentially decaying cost to automate and the biologically bottlenecked cost to verify agentic output.
- It identifies structural failures like the "Missing Junior Loop" and "Codifier’s Curse" while proposing an "Augmented Economy" enabled by observability, synthetic practice, and liability-as-a-service.

---

[Empathy Modeling in Active Inference Agents for Perspective-Taking and Alignment](http://arxiv.org/abs/2602.20936)

- Active Inference Empathy Framework: introduces a computational architecture for prosocial alignment by integrating an empathy-weighted social expected free energy objective with structurally matched generative models for perspective-taking.
- The system utilizes a particle-based inversion module to perform online Bayesian inference over latent opponent parameters, enabling agents to dynamically adapt their internal simulations of others' mental states and goals.
- Experimental results in the Iterated Prisoner's Dilemma demonstrate that empathic weighting induces a sharp phase transition toward stable cooperation, though increased planning depth can paradoxically undermine alignment without sufficient prosocial motivation.

---

[Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence](http://arxiv.org/abs/2602.20934)

- AgentOS: introduces a systemic framework that redefines the LLM as a "Reasoning Kernel" governed by structured operating system logic, incorporating a Reasoning Kernel (RK), a Semantic Memory Management Unit (S-MMU), a Cognitive Memory Hierarchy (CMH), and a Cognitive Scheduler.
- The architecture manages the context window as an Addressable Semantic Space, employing Semantic Slicing to aggregate tokens into addressable units and Cognitive Sync Pulses (CSP) for global state reconciliation.
- By mapping classical OS abstractions onto LLM-native constructs, the framework provides a specification for architecting cognitive environments for multi-agent orchestration.

---

[Fair Division with Soft Conflicts](http://arxiv.org/abs/2602.20929)

- GraphEF1: introduces a framework for fair division of indivisible goods under soft conflict constraints, with Agents, Goods, Conflict Graph, Valuation Functions, Envy Graph, Profile Vectors, Closest Points Data Structure, CyclicShiftRR Algorithm, DegreeEF1 Subroutine, and BiswasBarman Algorithm, where the system finds EF1 allocations while minimizing conflict violations.
- The framework utilizes a geometric closest points argument to select goods with similar Profile Vectors, bounding the increase in violations during the allocation process.
- The research provides linear-time algorithms for both identical and general additive valuations, achieving bounds on the number of soft conflict violations.

---

[Airavat: An Agentic Framework for Internet Measurement](http://arxiv.org/abs/2602.20924)

- Airavat: introduces an agentic framework for automating Internet measurement workflows, utilizing a multi-agent pipeline that includes decomposition-, design-, and implementation-agents.
- The system integrates a Verification Engine and a Validation Engine to ensure methodological correctness by cross-referencing a Neo4j Knowledge Graph of historical research.
- The framework identifies methodological flaws missed by standard execution-based testing while maintaining cost-effectiveness for research-scale evaluation.

---

[Task-oriented grasping for dexterous robots using postural synergies and reinforcement learning](http://arxiv.org/abs/2602.20915)

- Task-oriented grasping framework: introduces a closed-loop reinforcement learning agent that utilizes Observations, Task intentions, a Policy network with Memory, a VAE Decoder, an OSC, and an Environment to optimize grasping actions based on Reward signals and New State updates.
- The architecture employs a policy network conditioned on post-grasp intentions to generate coordinated arm displacements and latent hand configurations within a physics-based simulation.
- By integrating human grasp priors from the ContactPose dataset, the system achieves higher success rates and more human-like grasping behaviors compared to direct joint-space control.

---

[LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding](http://arxiv.org/abs/2602.20913)

- LongVideo-R1: introduces an active, reasoning-equipped multimodal agent for long video understanding, which includes reasoning-, captioning- and QA-agents to navigate a hierarchical video structure.
- The framework implements a Chain-of-Thought-with-Tool (CoTwT) procedure that enables the agent to perform contextual exploration via a video captioning tool and terminate with a video QA tool upon acquiring sufficient knowledge.
- The agent is trained through supervised fine-tuning on high-quality trajectories followed by reinforcement learning using Group Relative Policy Optimization (GRPO) to maximize selective navigation and minimize computational expenditure.

---

[Decentralized Trading Networks: Equilibria and Fairness](http://arxiv.org/abs/2602.20868)

- Trading Network Game: introduces a strategic foundation for decentralized networked markets with bilateral contracts, utilizing agents, trades, and offers to analyze convergence to Nash and competitive equilibria.
- The framework evaluates market stability through an offer-based best response dynamic and a stochastic clock price market managed by a central auctioneer.
- The research establishes that core stability significantly restricts fairness, proving that inessential agents always receive zero utility in stable outcomes.

---

[SoK: Agentic Skills — Beyond Tool Use in LLM Agents](http://arxiv.org/abs/2602.20867)

- Agentic Skills: introduces a formal systematization of reusable procedural modules for LLMs, featuring applicability gates, executable policies, termination conditions, callable interfaces, a seven-stage lifecycle, design patterns, trust tiers, skill retrieval, skill hierarchies, indexed libraries, sandboxed runtimes, LLM-mediated routing, LLM-based evaluation, and recovery paths.
- The framework identifies seven design patterns for packaging and loading skills, utilizing LLMs as routing-, planning-, and evaluation-agents to manage procedural knowledge across diverse environments.
- The research analyzes security risks through a pattern-specific matrix and demonstrates that curated skills provide quantifiable improvement in agent success rates compared to self-generated ones.

---

[Body-Reservoir Governance in Repeated Games: Embodied Decision-Making, Dynamic Sentinel Adaptation, and Complexity-Regularized Optimization](http://arxiv.org/abs/2602.20846)

- BRG (Body-Reservoir Governance): introduces, a three-layer architecture for analyzing embodied cooperation in repeated games, with Body Reservoir (high-dimensional dynamical system for implicit inference), Cognitive Filter (secondary toolkit for explicit strategic retaliation), Metacognitive Governance (lightweight policy layer managing body trust), Dynamic Sentinel (adaptive mechanism for real-time receptivity modulation), and Discomfort Signal (composite indicator of internal dynamical distortion).
- The framework formalizes complexity costs as state-space KL divergence from a habituated baseline, demonstrating that high-dimensional reservoir dynamics provide significant noise smoothing and perturbation insulation compared to one-dimensional filters.
- Numerical experiments confirm that the dynamic sentinel achieves the highest cumulative payoff by balancing habitual cooperation with rapid cognitive retaliation, revealing a soft crossover where reservoir richness determines the effectiveness of body-driven governance.

---

[Regret-Guided Search Control for Efficient Learning in AlphaZero](http://arxiv.org/abs/2602.20809)

- RGSC (Regret-Guided Search Control): introduces an efficient reinforcement learning framework that extends AlphaZero by identifying and prioritizing high-regret states as starting positions for self-play, with Regret Ranking Network, Regret Value Network, Prioritized Regret Buffer (PRB), MCTS, Policy-Value Network, and Self-Play Worker.
- The system leverages a ranking-based objective to distinguish informative states where agent evaluations diverge from actual outcomes, storing them in a prioritized buffer to mimic human-like focus on correcting mistakes.
- Experimental results across Go, Othello, and Hex demonstrate that RGSC significantly improves learning efficiency and outperforms baselines even when starting from well-trained, nearly converged models.

---

[Probing Dec-POMDP Reasoning in Cooperative MARL](http://arxiv.org/abs/2602.20804)

- MARL diagnostics suite: introduces a framework to audit Dec-POMDP reasoning, with OAR, HAR, PIF, AA, DAI, Memory-Reactive Gap, Permutation null baselines, IPPO, MAPPO, FF, RNN, and Memory components, where the suite evaluates behavioral complexity across 37 cooperative scenarios and includes independent- and centralized-training agents.
- The framework disentangles history dependence from performance utility, revealing that while many agents encode history, only a minority require it for high returns.
- Analysis across multiple benchmarks shows that emergent coordination often relies on synchronous coupling rather than temporal influence, suggesting current environments may not fully test core Dec-POMDP challenges.

---

[PIPELINE FOR VERIFYING LLM-GENERATED MATHEMATICAL SOLUTIONS](http://arxiv.org/abs/2602.20770)

- Pipeline for verifying LLM-generated mathematical solutions: introduces an agentic framework for automatic and interactive verification of mathematical reasoning by decomposing solutions into structured lemmas verifiable via formal proof assistants.
- The system includes solver-, translator-, and prover-agents to transform natural language reasoning into verifiable Lean4 code while maintaining logical consistency across proof steps.
- By mapping logical dependencies into a solution hypergraph and allowing for human-in-the-loop feedback, the pipeline significantly reduces false positives in mathematical benchmarking compared to simple answer-checking.

---

[PyVision-RL: Forging Open Agentic Vision Models via RL](http://arxiv.org/abs/2602.20739)

- PyVision-RL: introduces a reinforcement learning framework for open-weight multimodal models that stabilizes training and sustains agentic interaction, with MLLM, Python Runtime Environment, System Prompt, Visual Hints, Executable Code Blocks, Multimodal Execution Clues, Oversampling-Filtering-Ranking Rollout Strategy, Accumulative Tool Reward, and On-demand Context Construction.
- The framework prevents interaction collapse by combining an oversampling-filtering-ranking rollout strategy with an accumulative tool reward to encourage multi-turn reasoning and tool usage.
- It implements on-demand context construction for video understanding, enabling the model to selectively sample task-relevant frames via Python code to significantly improve visual token efficiency.

---

[AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs](http://arxiv.org/abs/2602.20720)

- AdapTools (Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs): introduces an adaptive indirect prompt injection framework that utilizes an adversarial LLM-based prompt generator and a task-aligned tool selection mechanism to bypass security filters in reasoning-capable agents.
- The system employs a strategy distillation module with an LLM-empowered encoder to compress fine-grained attack patterns into a generalized, transferable library while maintaining high attack success rates.
- It incorporates a Markovian transition model to select malicious tools that maintain semantic coherence with the user's original task trajectory, ensuring the attack remains indistinguishable from benign reasoning flows.

---

[ICON: Indirect Prompt Injection Defense for Agents based on Inference-Time Correction](http://arxiv.org/abs/2602.20708)

- ICON (Inference-Time Correction): introduces a probing-to-mitigation framework that neutralizes indirect prompt injection attacks by detecting "attention collapse" signatures in the latent space and performing surgical attention steering to restore agentic workflows.
- The system utilizes a Latent Space Trace Prober to identify high-intensity attention anomalies and a Mitigating Rectifier to selectively suppress adversarial query-key dependencies while reinforcing task-relevant features.
- The framework employs an LLM-as-Optimizer for offline data synthesis to delineate safety boundaries and achieves high utility recovery across text-based and multi-modal LLMs.

---

[How Foundational Skills Influence VLM-based Embodied Agents: A Native Perspective](http://arxiv.org/abs/2602.20687)

- NativeEmbodied: introduces a multidimensional benchmark for VLM-driven embodied agents, with perception, alignment, navigation, planning, exploration, search, interaction, native action space, VLM agents, action history, and egocentric images.
- The framework decouples high-level tasks into foundational skills to facilitate granular assessment and bottleneck analysis of embodied intelligence.
- Evaluation across 15 models demonstrates that while VLMs possess mature perception, they exhibit significant deficiencies in fine-grained spatial alignment and navigation.

---

[Agile V: A Compliance-Oriented Framework for AI-Augmented Engineering — From Concept to Audit-Ready Delivery](http://arxiv.org/abs/2602.20684)

- Agile V (Agile V: A Compliance-Oriented Framework for AI-Augmented Engineering): introduces a workflow that embeds independent verification and audit artifact generation into each task cycle, utilizing requirement-, logic-, build-, test-, verification-, and compliance-agents.
- The framework operationalizes an "Infinity Loop" that replaces sequential project phases with repeatable cycles, ensuring every AI-generated artifact is tested and documented before advancing.
- By maintaining structural independence between build and test generation, the system achieves high requirement-level verification pass rates while significantly reducing engineering costs in regulated industries.

---

[Grid-Mind: An LLM-Orchestrated Multi-Fidelity Agent for Automated Connection Impact Assessment](http://arxiv.org/abs/2602.20683)

- Grid-Mind: introduces a domain-specific LLM agent for automated Connection Impact Assessment that orchestrates multi-fidelity power system simulations through an LLM-first architecture featuring planning-, reflection-, and conversation-agents.
- The architecture utilizes a solver-agnostic abstract base class to interface with diverse simulation engines while grounding every decision in quantitative violation reports generated by a dedicated inspector.
- A three-layer anti-hallucination defense and a prompt-level self-correction loop mitigate numerical fabrication risks and enable progressive performance refinement through persistent memory without model retraining.

---

[Autonomous Laboratory Agent via Customized Domain-Specific Language Model and Modular AI Interface](http://arxiv.org/abs/2602.20669)

- Autonomous Laboratory Agent: introduces a system architecture for autonomous scientific instrumentation control by integrating domain-specialized SLMs with deterministic execution layers for safety-critical environments.
- The framework includes routing-, knowledge-, and command-agents to manage intent interpretation, experimental planning, and command verification.
- It utilizes a dynamic LoRA adapter injection scheme for memory-efficient local deployment and a text parser for constraint-aware command validation.

---

[AnimeAgent: Is the Multi-Agent via Image-to-Video models a Good Disney Storytelling Artist?](http://arxiv.org/abs/2602.20664)

- AnimeAgent: introduces a multi-agent framework for Custom Storyboard Generation that leverages Image-to-Video models to produce consistent storytelling, with Director Agent (LLM-based script parser), Artist Agent (I2V-based motion generator), Consistency Reviewer Agent (LLM-based identity validator), Objective Reviewer Agent (automated aesthetic and motion scorer), Subjective Reviewer Agent (LLM-based narrative evaluator), Hierarchical Textual Dope-Sheet (structured multi-dimensional script), Visual Dope-Sheet (identity-anchoring first frame), and Continuous Motion Trajectory (sequential frame generation).
- The system utilizes a dual dope-sheet mechanism to align textual semantics with visual anchors, enabling stable feature propagation across generated video sequences to maintain character identity and style.
- The framework incorporates a mixed subjective-objective reviewer to iteratively refine outputs and select the most dynamic "Extremes" for the final storyboard, emulating professional animation workflows.

---

[Grounding LLMs in Scientific Discovery via Embodied Actions](http://arxiv.org/abs/2602.20639)

- EmbodiedAct: introduces a framework that transforms scientific software into active embodied agents by grounding LLMs in an integrated perception-execution loop for verifiable scientific discovery.
- The architecture includes planning-, code generation-, perception-, and reflection-modules to bridge the gap between abstract reasoning and physical simulation.
- It utilizes an Asynchronous State Synchronization Protocol to enable real-time monitoring and intervention, allowing for autonomous parameter tuning and error recovery during transient simulation states.

---

[The Tragedy of the Commons in Multi-Population Resource Games](http://arxiv.org/abs/2602.20603)

- Resource Extraction Game: introduces a bi-level decision-making hierarchy for feedback-evolving games to analyze strategic interactions between multiple populations sharing a common resource, with all High-level agents (strategic decision-makers setting policies), Low-level agents (individuals following evolutionary dynamics), Responsible population (population with sustainable restoration policies), Greedy populations (multiple populations with extractive behaviors), and Common-pool resource (shared environment state) components.
- The framework characterizes a unique symmetric Nash equilibrium where greedy agents strategically select extraction rates based on the long-term stable outcomes of low-level evolutionary behavior.
- The analysis identifies specific environmental policy regimes that prevent resource depletion even as the number of competing greedy populations increases toward infinity.

---

[INTERACTION-AWARE REPRESENTATION MODELING WITH CO-OCCURRENCE CONSISTENCY FOR EGOCENTRIC HAND-OBJECT PARSING](http://arxiv.org/abs/2602.20597)

- InterFormer (Interaction-aware Transformer): introduces an end-to-end framework for egocentric hand-object parsing to segment hands and active objects, with a Backbone (extracts multi-scale pixel features), a Pixel Decoder (generates multi-scale semantic features), an Interaction Prior Predictor (estimates interaction boundaries), a Dynamic Query Generator (initializes interaction-aware queries), an InterFormer Decoder (refines representations iteratively), a Dual-context Feature Selector (fuses semantic and interactive cues), Prediction Heads (outputs class and mask predictions), and a Conditional Co-occurrence Loss (enforces physical consistency constraints).
- The Dynamic Query Generator grounds query initialization in spatial dynamics of hand-object contact, while the Dual-context Feature Selector suppresses interaction-irrelevant noise by fusing coarse interactive cues with semantic features.
- The framework utilizes a Conditional Co-occurrence Loss to enforce physical consistency by penalizing implausible hand-object co-occurrences, mitigating the "interaction illusion" problem in segmentation.

---

[From Logs to Language: Learning Optimal Verbalization for LLM-Based Recommendation in Production](http://arxiv.org/abs/2602.20558)

- Data-Centric Recommendation Agent: introduces a two-stage reinforcement learning framework that optimizes the verbalization of structured user logs into natural language to enhance recommendation performance, with Verbalizer, Reasoner, Oracle Reasoner, GRPO Trainer, Interaction History Memory, and Reward Function components.

- The system utilizes Group Relative Policy Optimization to train a generative Verbalizer that filters noise and summarizes user interests, followed by a Reasoner that predicts item engagement from the optimized textual context.

- Experimental results on industrial streaming data demonstrate that learned verbalization significantly outperforms template-based methods, achieving up to 93% relative improvement in discovery item recommendation accuracy.


---

[Beyond Human Performance: A Vision-Language Multi-Agent Approach for Quality Control in Pharmaceutical Manufacturing](http://arxiv.org/abs/2602.20543)

- Multi-agent CFU detection system: introduces a hybrid framework for automated colony-forming unit quantification in pharmaceutical manufacturing, with VLM-based pre-screening, dual-agent counting, and agentic orchestration.
- The system utilizes a quantized Qwen2-VL for image validation and a consensus-based approach between Detectron2 and GPT-4o to ensure high-precision counting and error reduction.
- Integrated via LangGraph and SAP QM, the architecture reduces human verification workload by 85% while maintaining GxP-compliant auditability and continuous retraining capabilities.

---

[Maximin Share Guarantees via Limited Cost-Sensitive Sharing](http://arxiv.org/abs/2602.20541)

- Shared Bag-Filling Algorithm: introduces a polynomial-time mechanism for fair allocation of indivisible goods by allowing limited, cost-sensitive sharing among up to k agents, utilizing Agents, Goods, Sharing Constraint, Valuation Profile, Sharing-Cost Function, Phase 1, and Phase 2.
- The framework establishes that exact Maximin Share (MMS) guarantees are achievable when goods are shared among at least half of the agents or when specific cost-sharing thresholds are met.
- The research defines Sharing Maximin Share (SMMS) as a fairness notion for k-sharing settings and establishes theoretical connections to cardinality-constrained maximin share problems.

---

[Inner Speech as Behavior Guides: Steerable Imitation of Diverse Behaviors for Human-AI coordination](http://arxiv.org/abs/2602.20517)

- MIMIC (Modeling Inner Motivations for Imitation and Control): introduces a framework that operationalizes inner speech as a mediational layer between perception and action to capture behavioral diversity, with Pre-trained VLM, CVAE Encoder, CVAE Decoder, Latent Space Z, DDPM-T Behavior Cloner, and Behavioral History.
- The architecture employs a VLM to provide linguistic scaffolding for a CVAE that internalizes behavioral intent into a latent representation from behavioral history.
- A transformer-based diffusion policy generates actions conditioned on this inner speech, enabling fine-grained steering of agent behavior at inference time.

---

[Conflict-Based Search for Multi-Agent Path Finding with Elevators](http://arxiv.org/abs/2602.20512)

- CBS-E (Conflict-Based Search for Multi-Agent Path Finding with Elevators): introduces an optimal pathfinding framework for multi-floor environments, which includes high-level search, low-level search, Elevator Constraints (EC), MDD-E, conflict selection, and bypassing.
- The framework utilizes Elevator Constraints to resolve complex inter-floor conflicts in a single expansion by generating mutually disjunctive time-interval constraints on elevator entry vertices.
- MDD-E augments standard decision diagrams with elevator-specific state information to enable efficient detection and classification of cardinal conflicts in multi-agent systems.

---

[ActionEngine: From Reactive to Programmatic GUI Agents via State Machine Memory](http://arxiv.org/abs/2602.20502)

- ActionEngine: introduces a training-free framework that transitions GUI agents from reactive execution to programmatic planning through a two-agent architecture consisting of an offline Crawling Agent and an online Execution Agent.

- The system utilizes the Crawling Agent to construct a State Machine Graph (SMG) memory of the application structure, which the Execution Agent leverages to synthesize complete, executable Python programs in a single LLM call.

- To ensure robustness against evolving interfaces, the framework incorporates a deterministic runtime with a validator and a vision-based fallback mechanism that repairs execution failures and dynamically updates the topological memory.


---

[Probing and Bridging Geometry–Interaction Cues for Affordance Reasoning in Vision Foundation Models](http://arxiv.org/abs/2602.20501)

- Geometry-Interaction Fusion: introduces a training-free framework that decomposes visual affordance into geometric perception and interaction perception, utilizing DINOv3 for structural cues and Flux Kontext for action-conditioned priors.
- The system extracts part-level geometric prototypes via PCA and aligns them with verb-conditioned cross-attention maps from generative models using Normalized Scanpath Saliency.
- This approach achieves zero-shot affordance estimation competitive with weakly-supervised methods by bridging discriminative geometric awareness with generative interaction knowledge.

---

[AWCP: A Workspace Delegation Protocol for Deep-Engagement Collaboration across Remote Agents](http://arxiv.org/abs/2602.20493)

- AWCP (Agent Workspace Collaboration Protocol): introduces a standardized framework for temporary workspace delegation between autonomous agents, with Delegator Agent (initiates workspace projection), Delegator Service (manages protocol signaling), Admission Control (enforces exposure policies), Snapshot Manager (reconciles file changes), Executor Service (provisions session directories), Extensible Adapter Layer (decouples agent implementations), Executor Agent (performs remote execution), Control Layer (manages delegation lifecycle), Transport Layer (provides filesystem access), MCP Tool Servers (standardize tool integration), and Skill Modules (provide chat platform functionality).
- The protocol decouples high-level coordination from low-level data transfer through pluggable transport adapters like SSHFS, Git, and ZIP archives to enable collaboration between text-only and multimodal LLM agents.
- It employs dual state machines to synchronize the delegation lifecycle across Delegator and Executor nodes, supporting both interactive real-time synchronization and snapshot-based reconciliation.

---

[Hybrid LLM-Embedded Dialogue Agents for Learner Reflection: Designing Responsive and Theory-Driven Interactions](http://arxiv.org/abs/2602.20486)

- Hybrid LLM-Embedded Dialogue Agents: introduces a system that integrates a rule-based finite state machine with an LLM to scaffold learner reflection in open-ended environments, with a rule-based finite state machine (manages structured dialogue trajectories), an LLM-embedded component (handles responsive follow-up generation), a relevance check (binary gate assessing response depth), contextual generation (produces targeted follow-up prompts), dialogue history (stores previous conversation turns), a dialogue scenario (defines predefined dialogue paths), a frontend UI (provides chat widget interface), and a backend (manages logic and LLM calls); it includes relevance check- and contextual generation-LLMs.
- The architecture employs a finite state machine to ensure theoretical grounding in self-regulated learning while leveraging LLMs to provide responsive, context-sensitive follow-up prompts for free-form learner inputs.
- The system utilizes few-shot prompting and dialogue history to assess response depth and generate targeted follow-ups, aiming to elicit more elaborate reflections from middle-school students.

---

[Codified Context: Infrastructure for AI Agents in a Complex Codebase](http://arxiv.org/abs/2602.20478)

- Codified Context: introduces a tiered knowledge infrastructure for LLM-based coding agents, incorporating a hot-memory constitution, specialized domain-expert agents, and a cold-memory knowledge base; it includes planning-, specialist-, and review-agents.
- The system employs a Model Context Protocol (MCP) retrieval server and trigger tables to automate task routing and provide on-demand access to project-specific specifications.
- Quantitative evaluation across 283 development sessions demonstrates how persistent, machine-readable documentation prevents coherence loss and maintains architectural consistency in large-scale codebases.

---

[Prior-Agnostic Incentive-Compatible Exploration](http://arxiv.org/abs/2602.20465)

- Prior-Agnostic Incentive-Compatible Exploration: introduces a theoretical framework for bandit learning where weighted swap regret bounds incentivize myopic agents to follow recommendations under temporal arrival-time uncertainty.
- The approach generalizes Bayesian incentive compatibility to dynamic, non-stationary environments without requiring the mechanism designer to know agent priors or assuming a common prior among participants.
- The research demonstrates that algorithms achieving adaptive regret, such as Exp4.S, implement approximate Bayes Nash equilibria for agents with sufficiently diffuse temporal beliefs in slowly-moving reward environments.

---

[Understanding Human-AI Collaboration in Cybersecurity Competitions](http://arxiv.org/abs/2602.20446)

- CTFriend: introduces an instrumented AI assistant for cybersecurity competitions, featuring a Streamlit Web UI, an AI Agent for LLM orchestration, a RAG Server for domain knowledge, an MCP Tool Layer for environment interaction, a PostgreSQL Database for persistent logging, and a Monitoring Stack for observability.
- The research analyzes human-AI collaboration in a live Capture-the-Flag event, finding that while participants intend to work cooperatively, they frequently shift toward end-to-end delegation under competitive pressure.
- Empirical benchmarking of autonomous agents, including Claude Code, NYU agent, Cybench, and a Proprietary Agent, demonstrates that those utilizing long-horizon planning and interactive tool support can outperform most human teams while requiring significantly less cumulative runtime.

---



[Adversarial Intent is a Latent Variable: Stateful Trust Inference for Securing Multimodal Agentic RAG](http://arxiv.org/abs/2602.21447)

- MMA-RAG^T (Multimodal Agentic Retrieval-Augmented Generation with Trust): introduces an inference-time control framework governed by a Modular Trust Agent (MTA) that maintains an approximate belief state via structured LLM reasoning to detect distributed adversarial strategies.
- The architecture operates as a model-agnostic overlay, mediating a configurable set of internal checkpoints to enforce stateful defense-in-depth across retrieval, planning, and generation stages.
- By formulating security as a Partially Observable Markov Decision Process (POMDP), the system infers latent adversarial intent from noisy multi-stage observations to gate artifact passage through the pipeline.

---

[From Cooperation to Hierarchy: A Study of Dynamics of Hierarchy Emergence in a Multi-Agent System](http://arxiv.org/abs/2602.21404)

- ABM (Agent-Based Model): introduces a decentralised multi-agent system to identify minimal conditions for hierarchy emergence, with Agent, Environment, Sensing, Action Execution, Inheritance-Mutation, Speaker Selection, Consensus Mechanism, Trophic Analysis, and Speaker- and Listener-roles components; includes speaker- and listener-agents.
- The system integrates ecological feedbacks and social coordination rules to transform stochastic individual differences into persistent directional asymmetries in information and influence flow.
- Experimental results demonstrate that while initial heterogeneity affects early formation, high mutation amplitude is the primary requirement for the long-term stabilization of hierarchical order.

---

[The Headless Firm: How AI Reshapes Enterprise Boundaries](http://arxiv.org/abs/2602.21401)

- Headless Firm: introduces an organizational equilibrium that decouples user intent from execution through a thin protocol waist, with Generative UI, Protocol Orchestrator, Vertical Agent Market, Intent Compiler, Constraint Validator, Reversible Preview, and Policy Surface, including intent-parsing, protocol-orchestrating, and micro-specialized execution-agents.
- The framework shifts coordination costs from topology-dominated scaling to throughput-dominated scaling by utilizing standardized protocols and LLM-driven semantic verification.
- It predicts a domain-conditional shift where mass moves from large integrated incumbents toward specialized agents and thin orchestrators in high-velocity knowledge environments.

---

[MemoPhishAgent: Memory-Augmented Multi-Modal LLM Agent for Phishing URL Detection](http://arxiv.org/abs/2602.21394)

- MPA (MemoPhishAgent): introduces a memory-augmented multi-modal LLM agent for phishing URL detection, with Multi-modal Tool Sets, Action: Select & Execute, ReAct Reasoning & Tool Planning, and Episodic Memory.
- The architecture includes reasoning-, planning-, and specialized tool-agents for content crawling, visual inspection, and target extraction.
- An episodic memory module stores historical reasoning trajectories and outcomes, enabling fast recall for recurring patterns and providing in-context exemplars for complex cases.

---

[BLACK-BOX RELIABILITY CERTIFICATION FOR AI AGENTS VIA SELF-CONSISTENCY SAMPLING AND CONFORMAL CALIBRATION](http://arxiv.org/abs/2602.21368)

- Black-box Reliability Certification framework: introduces a method for certifying AI agent reliability using self-consistency sampling and conformal calibration to provide distribution-free guarantees.
- The system employs an AI system for stochastic generation, an optional LLM-assisted canonicalizer for semantic grouping, and a ranked consensus engine for frequency-based ordering.
- A human verifier spot-checks a small calibration batch to allow the conformal calibrator to produce a single reliability level for deployment gating.

---

[A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives](http://arxiv.org/abs/2602.21351)

- PANGAEA-GPT: introduces a hierarchical multi-agent framework for autonomous geoscientific data discovery and analysis, which includes search-, supervisor-, oceanographer-, ecologist-, visualization-, dataframe-, writer-, and wise-agents, along with an isolated execution environment and specialized toolboxes.
- The architecture implements a two-phase workflow featuring iterative agentic search for dataset retrieval followed by deterministic code execution with self-correction loops and reflexive visual quality control.
- It integrates domain-specific toolboxes for oceanography and ecology to automate complex workflows across heterogeneous data formats, utilizing cross-model escalation for robust error recovery.

---

[HorizonForge: Driving Scene Editing with Any Trajectories and Any Vehicles](http://arxiv.org/abs/2602.21333)

- HorizonForge: introduces a unified framework for photorealistic and controllable driving scene generation by reconstructing scenes as editable Gaussian Splats and Meshes, which are then rendered through a noise-aware video diffusion process.
- The system utilizes a 3D assets harvesting pipeline and includes heading reasoning- and language-guided insertion-LLMs to ensure physically valid paths and spatial consistency during vehicle placement.
- To standardize evaluation, the authors propose HorizonSuite, a comprehensive benchmark for assessing ego- and agent-level editing tasks like trajectory modifications and object manipulation.

---

[Tool-R0: Self-Evolving LLM Agents for Tool-Learning from Zero Data](http://arxiv.org/abs/2602.21320)

- Tool-R0 (Self-Evolving LLM Agents for Tool-Learning from Zero Data): introduces a zero-data self-play reinforcement learning framework where a task-synthesizing Generator and a tool-using Solver co-evolve through complementary reward signals.

- The framework utilizes a difficulty-guided reward system to target the Solver's competence frontier, ensuring generated tasks are progressively challenging yet solvable.

- By employing role separation and verifiable rewards, the system enables LLMs to autonomously acquire complex tool-calling capabilities without human-annotated datasets.


---

[Uncertainty-Aware Diffusion Model for Multimodal Highway Trajectory Prediction via DDIM Sampling](http://arxiv.org/abs/2602.21319)

- cVMDx (Uncertainty-Aware Diffusion Model for Multimodal Highway Trajectory Prediction via DDIM Sampling): introduces an enhanced diffusion-based framework for autonomous driving that integrates a CVQ-VAE for robust scenario encoding, an uncertainty-aware guidance mechanism, and DDIM sampling for efficient multimodal trajectory generation.
- The system utilizes a velocity-based training objective to improve stability and employs a Vehicle Motion Model to ensure that generated acceleration and yaw-rate commands result in physically plausible future paths.
- By fitting a Gaussian Mixture Model to multiple generated samples, the framework explicitly represents diverse driving maneuvers and provides tractable uncertainty estimates for safety-critical planning.

---

[Optimal extraction with an impact on diffusion-jump pricing](http://arxiv.org/abs/2602.21274)

- Optimal Extraction Framework: introduces a singular stochastic control model to determine the optimal selling strategy for an agent whose actions exert an additive proportional negative impact on commodity prices modeled by a diffusion-jump process, with Agent, Commodity Price Dynamics, Inventory, Extraction Strategy, Price Impact, HJB Equation, and Barrier Strategy.
- The framework utilizes a Hamilton-Jacobi-Bellman (HJB) equation to derive the value function and identifies a barrier strategy as the optimal solution for maximizing expected net profits.
- The research provides a verification theorem to validate the explicit solutions and explores the connection between the extraction problem and a related optimal stopping problem.

---

[ParkDiffusion++: Ego Intention Conditioned Joint Multi-Agent Trajectory Prediction for Automated Parking using Diffusion Models](http://arxiv.org/abs/2602.20923)

- ParkDiffusion++: introduces a two-stage framework for ego-conditioned joint multi-agent trajectory prediction in unstructured parking environments, utilizing an ego intention tokenizer and a safety-guided diffusion denoiser.
- The system employs counterfactual knowledge distillation with an EMA teacher to model how surrounding agents react to alternative ego intentions without direct supervision.
- A joint trajectory selector assembles marginal predictions into scene-consistent futures, while geometric potential functions enforce safety constraints like obstacle clearance and agent-agent overlap.

---

[TOOLMATH: A Math Tool Benchmark for Realistic Long-Horizon Multi-Tool Reasoning](http://arxiv.org/abs/2602.21265)

- TOOLMATH: introduces a math-grounded benchmark for evaluating tool-augmented LLMs in realistic environments, with tool extraction, validation, and controlled distractor sampling components.

- The system transforms human-annotated solution steps into reusable Python tools to test model precision under large, overlapping tool catalogs and missing capabilities.

- It utilizes a logical-hop metric to separate short-horizon competence from multi-step dependency tracking failures across various planning- and search-based agents.


---

[Under the Influence: Quantifying Persuasion and Vigilance in Large Language Models](http://arxiv.org/abs/2602.21262)

- Evaluation framework for persuasion and vigilance in Large Language Models: introduces a multi-agent testing environment based on the Sokoban puzzle game to measure how LLMs influence and are influenced by benevolent or malicious advice, with player LLM (agent executing grid-based moves), advisor LLM (agent generating persuasive natural language), algorithmic planner (symbolic system providing optimal paths), Sokoban environment (2-D grid-based decision testbed), and persuasion and vigilance metrics (formal quantitative measures of influence), and includes player- and advisor-LLMs.
- The architecture decouples task-solving ability from social influence by equipping advisor agents with an algorithmic planner that identifies optimal sub-goals and potential failure modes.
- The study defines formal metrics for persuasion and vigilance, revealing that these social capacities are dissociable from raw puzzle-solving performance in frontier models.

---

[Revisiting the Unitary Actor Assumption: Toward Realistic Aggregation of Individual Preferences in Strategy Research](http://arxiv.org/abs/2602.20518)

- Organizational Utility Aggregation Framework: introduces a mathematical method to derive a collective utility function by converting individual preferences into screening functions, aggregating them via specific structures, and recovering the resulting organizational utility.
- The framework utilizes random-utility models to bridge utility-space and probability-space, allowing for the analysis of how internal decision rules like unanimity or polyarchy systematically reshape risk preferences.
- It demonstrates that aggregation structures can amplify risk-aversion or risk-seeking behavior, providing a behaviorally grounded way to retrofit unitary-actor models in strategic analysis.

---

#### 23rd February 2026

[SKILL-INJECT: Measuring Agent Vulnerability to Skill File Attacks](http://arxiv.org/abs/2602.20156)

- SKILL-INJECT: introduces a benchmark for evaluating LLM agent susceptibility to prompt injection attacks via third-party skill files, with User, Attacker, Skill File, LLM Agent, and Agent Judge components.
- The framework measures the security-utility tradeoff by analyzing agent compliance with legitimate user tasks versus execution of malicious instructions embedded in skill extensions.
- Evaluation of frontier models reveals high susceptibility to skill-based attacks, with success rates reaching 80% for unauthorized actions like data exfiltration and ransomware.

---

[Agentic AI for Scalable and Robust Optical Systems Control](http://arxiv.org/abs/2602.20144)

- AgentOptics: introduces an agentic AI framework for high-fidelity optical system control, utilizing an MCP Client, reasoning-capable LLMs, and distributed MCP Servers to translate natural language tasks into validated tool invocations across heterogeneous hardware.
- The architecture employs a structured tool abstraction layer that encapsulates 64 standardized MCP tools, facilitating autonomous orchestration for complex scenarios such as DWDM link provisioning and polarization stabilization.
- Experimental results show success rates up to 99.0%, highlighting the framework's ability to handle linguistic variations and error recovery more effectively than direct code-generation approaches.

---

[Recurrent Structural Policy Gradient for Partially Observable Mean Field Games](http://arxiv.org/abs/2602.20141)

- RSPG (Recurrent Structural Policy Gradient): introduces a history-aware hybrid structural method for partially observable mean-field games, utilizing an individual state embedding, a shared observation RNN, and a feature fusion MLP to condition policies on agent states and aggregate history.
- The architecture leverages an analytic mean-field update operator to exploit known transition dynamics, enabling exact expectations over individual dynamics while sampling only common noise to reduce gradient variance.
- The system is integrated into MFAX, a JAX-based library that supports parallelized environment execution and macroeconomic modeling with common noise and heterogeneous agents.

---

[Screening Frontiers](http://arxiv.org/abs/2602.20087)

- Surplus-Elasticity Frontier: introduces a screening framework for identifying optimal menus by comparing allocations through their induced demand curves and elasticity curves to form a surplus-elasticity frontier, incorporating principal, agent, allocation space, demand curve, elasticity curve, generalized frontier, and strong frontier components.
- The framework proves that any surplus-elasticity frontier constitutes an optimal menu across all type distributions and redistributive welfare weights, provided agent preferences are comonotonic.
- The research generalizes these findings to stochastic mechanisms and applies the methodology to solve screening problems in optimal bundling, taxation, sequential screening, and monopoly regulation.

---

[Descent-Guided Policy Gradient for Scalable Cooperative Multi-Agent Learning](http://arxiv.org/abs/2602.20078)

- DG-PG (Descent-Guided Policy Gradient): introduces a framework for scalable cooperative multi-agent reinforcement learning that constructs noise-free per-agent guidance gradients from differentiable analytical models to decouple learning signals from cross-agent noise.
- The architecture, which includes actor- and critic-networks, augments standard methods by modifying the advantage estimator with a guidance term derived from a reference state to achieve agent-independent sample complexity.
- It utilizes a local influence vector to project system deviations onto individual agent actions, ensuring the learning signal remains unbiased and preserves the original game's Nash equilibria.

---

[The LLMbda Calculus: AI Agents, Conversations, and Information Flow](http://arxiv.org/abs/2602.20064)

- LLMbda Calculus: introduces an untyped call-by-value lambda calculus for modeling agentic behavior and security, with a planner loop, LLM, tool invocations, conversation history, information-flow labels, privileged- and quarantined-LLMs, and an interpreter.
- The framework formalizes context management through primitives for forking and clearing conversations to mitigate prompt injection attacks.
- A termination-insensitive noninterference theorem establishes formal integrity and confidentiality guarantees for programs executed within the calculus.

---

[Interaction Theater: A case of LLM Agents Interacting at Scale](http://arxiv.org/abs/2602.20059)

- Interaction Theater: introduces an empirical study of large-scale autonomous agent interactions on the Moltbook platform, which includes LLM-driven agents and LLM-as-judge components.
- The study reveals that while agents produce diverse and well-formed text, the interactions lack substantive exchange, with 65% of comments sharing no distinguishing vocabulary with their parent posts.
- Analysis of information saturation shows that marginal novelty decays rapidly as comments accumulate, suggesting that without explicit coordination protocols, large populations of LLMs produce parallel output rather than productive exchange.

---

[To Move or Not to Move: Constraint-based Planning Enables Zero-Shot Generalization for Interactive Navigation](http://arxiv.org/abs/2602.20055)

- LLM-driven, constraint-based planning framework: introduces a zero-shot approach for lifelong interactive navigation where an LLM acts as a constraint reasoner over a structured scene graph to decide between moving obstacles or detouring.

- The system utilizes a perception module to incrementally build a scene graph that encodes object attributes, spatial relationships, and navigability constraints like betweenness centrality for cost-benefit analysis.

- High-level strategic decisions from the LLM are translated into executable navigate-pick-place sequences by a Dijkstra-based low-level motion planner to ensure reliable control in cluttered environments.


---

[The Navigation Paradox in Large-Context Agentic Coding: Graph-Structured Dependency Navigation Outperforms Retrieval in Architecture-Heavy Tasks](http://arxiv.org/abs/2602.20048)

- CodeCompass: introduces an MCP-based graph navigation tool that exposes structural code dependencies to agentic coding assistants, utilizing a Neo4j graph populated via static AST analysis.
- The system addresses the Navigation Paradox by enabling LLMs to discover semantically distant but architecturally critical files through 1-hop structural neighborhood traversal.
- Evaluation on a 30-task benchmark shows that graph navigation achieves 99.4% architectural coverage on hidden-dependency tasks where traditional retrieval methods fail.

---

[Let There Be Claws: An Early Social Network Analysis of AI Agents on Moltbook](http://arxiv.org/abs/2602.20044)

- Moltbook: introduces an AI-native social platform designed for autonomous LLM-based agents to interact via posts, comments, and upvotes through a public API.
- The system facilitates the emergence of complex social structures including hierarchical role separation, high attention concentration, and one-way attention flow within compressed timescales.
- Structural analysis reveals that agent-to-agent interactions rapidly mirror human-like social network patterns such as "rich get richer" dynamics and distinct hub-authority roles.

---

[AgenticSum: An Agentic Inference-Time Framework for Faithful Clinical Text Summarization](http://arxiv.org/abs/2602.20040)

- AgenticSum (An Agentic Inference-Time Framework for Faithful Clinical Text Summarization): introduces an inference-time agentic framework that decomposes clinical summarization into coordinated stages of context selection, generation, verification, and targeted correction, including compression-, generation-, detection-, and revision-agents.
- The system utilizes a FOCUS mechanism for sentence-level input compression and an AURA module that leverages model-internal attention signals to identify weakly supported spans for correction.
- By decoupling generation from verification, the framework enables iterative, span-level revisions under supervisory control to ensure factual consistency without requiring task-specific fine-tuning of LLMs.

---

[Agents of Chaos](http://arxiv.org/abs/2602.20021)

- OpenClaw: introduces an exploratory red-teaming study of autonomous LLM-powered agents deployed in a live laboratory environment, with agent scaffold-, LLM provider-, memory-, tool API-, communication-, server-, virtual machine-, and autonomy mechanism-components.
- The architecture utilizes Kimi K2.5- and Claude Opus-powered agents to evaluate safety limitations arising from tool use, cross-session memory, and delegated agency.
- The research documents eleven case studies of emergent failures in security, privacy, and governance arising from the integration of LLMs with autonomy and multi-party communication.

---

[A Context-Aware Knowledge Graph Platform for Stream Processing in Industrial IoT](http://arxiv.org/abs/2602.19990)

- SemIoE-based Platform (Context-Aware Knowledge Graph Platform for Stream Processing in Industrial IoT): introduces a semantic framework for Industrial IoT data stream management, with Knowledge Graph (centralized semantic metadata repository), Reasoner (SPARQL and SWRL inference engine), Stream Management (distributed real-time message broker), Stream Postprocessing (stateful stream transformation framework), Monitoring Service (semantic stream discovery module), Querying Service (federated SQL abstraction layer), Platform Gateway (secure authentication and authorization entry), and Persistent Storage (heterogeneous time-series and document databases) components, where the system unifies heterogeneous data sources through formal ontological representations of devices and agents.
- The architecture integrates Apache Kafka for high-throughput stream handling and Apache Flink for complex transformations, enabling composable processing pipelines modeled as directed acyclic graphs.
- Dynamic role-based access control is enforced through context-aware reasoning, allowing the system to adapt data visibility based on an agent's location, activity, and collaborative relations.

---

[Unlocking Multimodal Document Intelligence: From Current Triumphs to Future Frontiers of Visual Document Retrieval](http://arxiv.org/abs/2602.19961)

- VDR (Visual Document Retrieval): introduces a systematic survey of the visual document retrieval landscape, with multimodal embedding models, multimodal reranker models, and agentic RAG systems.
- The framework distinguishes between single-vector and multi-vector representations, where the latter utilizes patch-level embeddings and late-interaction mechanisms to capture fine-grained semantic dependencies.
- It categorizes the evolution of document intelligence into three paradigms: embedding-based retrieval, cross-encoder reranking, and iterative agentic workflows involving planning-, seeker-, and inspector-agents.

---

[Assessing Risks of Large Language Models in Mental Health Support: A Framework for Automated Clinical AI Red Teaming](http://arxiv.org/abs/2602.19948)

- Automated Clinical AI Red Teaming: introduces a multi-agent simulation framework that pairs AI psychotherapists with simulated patient agents equipped with dynamic cognitive-affective models to detect longitudinal risks in therapeutic dialogue, with an AI psychotherapist agent, a simulated patient cohort, a simulation orchestrator, a quality of care and risk ontology, automated evaluation metrics, an interactive data visualization dashboard, a dynamic cognitive-affective model, and LLM-as-a-judge evaluators; the system includes AI psychotherapist-, simulated patient-, and LLM-as-a-judge-evaluator-agents.
- The architecture utilizes a Simulation Orchestrator to manage multi-session interactions, evaluating them against a clinical ontology through automated evaluation metrics and specialized LLM-as-a-judge components.
- The framework identifies emergent iatrogenic risks such as "AI Psychosis" and failure to de-escalate suicide risk by tracking internal psychological constructs across simulated life events.

---

[Mass Manipulation in Simulated Social Networks: Dominating vs. Diversifying Attention](http://arxiv.org/abs/2602.19939)

- RGS (Reputation Game Simulation): introduces an agent-based model to evaluate how topic diversification mitigates the influence of a Mass Influencing Agent across various network topologies, utilizing Agents (entities with intrinsic honesty), a Mass Influencing Agent (malicious reputation-maximizing actor), Communication Channels (one-to-one and one-to-many gossip), a Topic Selection Mechanism (acquaintance-based or randomized selection), a Knowledge Update Engine (probabilistic reputation assessment), and Network Topologies (small-world, ring, or dense).
- The framework compares acquaintance-based topic selection, which fosters echo chambers and propaganda success, against randomized topic selection that enhances collective resilience and opinion stability.
- Simulation results demonstrate that even partial adoption of topic diversification by a minority of agents significantly reduces the effectiveness of centralized misinformation campaigns across all tested network structures.

---

[Edge-based Synchronization over Signed Digraphs with Multiple Leaders](http://arxiv.org/abs/2602.19933)

- Edge-based Synchronization: introduces, a framework for achieving synchronization in first-order multi-agent systems over directed signed graphs containing multiple leader groups and antagonistic interactions, with all multi-agent system, signed digraph, leader groups, follower agents, distributed control law, and edge-based synchronization error system-components.
- The approach utilizes signed edge-Laplacian matrices to recast the synchronization problem into a stability analysis of edge-based synchronization errors.
- It establishes global exponential stability of the synchronization set and provides explicit estimates for edge-based limit points across various network topologies.

---

[Beyond Mimicry: Toward Lifelong Adaptability in Imitation Learning](http://arxiv.org/abs/2602.19930)

- CRL (Compositional Repertoire Learning): introduces a research agenda that redefines imitation learning success from trajectory reproduction to compositional generalisation by extracting reusable behavioural primitives and rules.
- The framework utilizes Goal-conditioned Contextual MDPs to isolate task structure from environmental dynamics, enabling precise measurement of systematicity, productivity, and substitutivity.
- The paper proposes hybrid architectures integrating foundation models for semantic priors and planners for long-horizon reasoning to achieve lifelong adaptability in open-ended environments.

---

[SAMAS: A SPECTRUM-GUIDED MULTI-AGENT SYSTEM FOR ACHIEVING STYLE FIDELITY IN LITERARY TRANSLATION](http://arxiv.org/abs/2602.19840)

- SAMAS (Style-Adaptive Multi-Agent System): introduces a framework that reframes literary translation as a signal processing task, utilizing a Stylistic Feature Spectrum to dynamically route text through a specialized agent pool including core translation-, linguistic structure-, metaphor translation-, emotion transfer-, rhythm and prosody-, and consistency and stylistic fidelity-agents.
- The system employs Wavelet Packet Transform to extract multi-scale rhythmic features from word-length sequences, creating a computable stylistic signature that guides a deterministic routing logic.
- By assembling tailored workflows for distinct authorial styles, such as Faulkner-esque or Hemingway-esque, the approach achieves higher style fidelity and semantic accuracy than static multi-agent baselines.

---

[Janus-Faced Technological Progress and the Arms Race in the Education of Humans and Chatbots](http://arxiv.org/abs/2602.19783)

- Bell Curve Competition: introduces a theoretical model analyzing how lognormal wage distributions and technological progress incentivize an inefficient educational arms race, with Agents, Lognormal Skill Distribution, Technology Augmentation Coefficients, Educational Investment Module, CRRA Utility Evaluator, Monopoly Rent Capture Mechanism, and AI Training Analogy.
- The research demonstrates that exponential returns to skill can lead to overinvestment in education where median incomes fail to cover ex-ante optimal outlays.
- It draws a parallel between human educational competition and the massive capital expenditures by technology firms to train AI agents and chatbots.

---

[Group adaptation drives opinion dynamics in higher-order networks](http://arxiv.org/abs/2602.19684)

- Adaptive Higher-Order Deffuant Model: introduces a bounded confidence framework for opinion dynamics that couples individual opinion evolution with structural network adaptation through group-level interactions, with Agents, Hypergraph, Agreement Phase, Split Phase, and Merger Phase.
- The model utilizes a hypergraph structure to represent multi-agent discussions where groups either reach a consensus or fragment into subgroups if opinions exceed a confidence threshold.
- Structural adaptivity via size-dependent group merging is shown to suppress fragmentation and restore phase transitions from polarization to consensus typically hindered by higher-order effects.

---

[SkillOrchestra: Learning to Route Agents via Skill Transfer](http://arxiv.org/abs/2602.19672)

- SkillOrchestra: introduces a skill-aware orchestration framework that decouples capability requirements from agent identity by learning a reusable Skill Handbook from execution experience.
- The system utilizes a hierarchical skill registry and agent profiles to perform state-conditioned, performance-cost-aware routing across multiple operational modes and tools.
- By modeling explicit skill-level competence, the framework mitigates routing collapse and enables the transfer of orchestration knowledge across different LLM backbones without retraining.

---

[Multicellular Feedback Control Strategies in Synthetic Microbial Consortia: From Embedded to Distributed Control](http://arxiv.org/abs/2602.19666)

- Multicellular Feedback Control: introduces a distributed biomolecular control strategy that partitions sensing, computation, and actuation across specialized cell populations, including proportional-, integral-, and derivative-controller populations.
- The architecture utilizes orthogonal quorum sensing molecules as communication substrates to establish bidirectional information exchange between spatially separated cell types.
- The research evaluates these strategies using aggregate population models and agent-based simulations to address orchestration challenges like population composition maintenance and metabolic burden.

---

[Exploration of Always S-Connected Temporal Graphs](http://arxiv.org/abs/2602.19657)

- Always S-Connected Temporal Graphs: introduces a theoretical model for temporal graph exploration where connectivity is maintained through a specific vertex subset S, allowing m agents to visit all vertices.
- The framework utilizes (r, b)-divisions to partition graphs into S-connected components, enabling faster exploration schedules for graphs with bounded treewidth.
- The paper establishes new upper bounds for exploration time in graphs with bounded treewidth and interval graphs, improving upon existing state-of-the-art results.

---

[Effects of Property Recovery Incentives and Social Interaction on Self-Evacuation Decisions in Natural Disasters: An Agent-Based Modelling Approach](http://arxiv.org/abs/2602.19639)

- ABM (Agent-Based Model): introduces a simulation framework to investigate how property recovery incentives and social network structures influence household self-evacuation decisions during natural disasters.
- The system integrates evolutionary game theory with a small-world network to model how household agents imitate successful neighbors and respond to property recovery funds.
- The study identifies threshold transitions and "community influencers," demonstrating that strategic prioritisation of highly connected nodes can optimize evacuation rates under limited resources.

---

[Compositional Planning with Jumpy World Models](http://arxiv.org/abs/2602.19634)

- CompPlan (Compositional Planning): introduces a framework for direct compositional planning over pre-trained policies by learning jumpy world models that capture state occupancies across multiple timescales.
- The approach utilizes a novel Temporal Difference Horizon Consistency objective to align generative predictions across horizons and evaluates sequences of goal-conditioned TD3, 1-step RL, contrastive RL, behavior cloning, and hierarchical flow policies.
- By treating foundation policies as composable primitives, the system enables zero-shot performance on robotic tasks through the recombination of existing behaviors without task-specific training.

---

[TAPE: Tool-Guided Adaptive Planning and Constrained Execution in Language Model Agents](http://arxiv.org/abs/2602.19633)

- TAPE (Tool-guided Adaptive Planning with constrained Execution): introduces a framework to mitigate irrecoverable failures in LLM agents, with Plan Graph Construction, an External Solver, Constrained Execution, Mismatch Check, and Adaptive Replanning.
- The architecture includes trajectory sampling-, cost prediction-, and action generation-LLMs to construct plan graphs and enforce actions via constrained decoding.
- The system implements an adaptive replanning mechanism that triggers whenever environmental feedback deviates from the intended state, improving success rates in environments with strict feasibility constraints.

---

[Learning Mutual View Information Graph for Adaptive Adversarial Collaborative Perception](http://arxiv.org/abs/2602.19596)

- MVIG (Mutual View Information Graph): introduces an adaptive adversarial framework for collaborative perception that captures vulnerability knowledge from defensive systems using a unified graph representation and temporal learning.
- The system integrates MVIGNet, featuring specialized graph convolution layers and a GRU backbone, to predict vulnerable regions and generate fabrication risk maps from historical feature data.
- It leverages entropy-aware vulnerability search and PGD-based perturbation optimization to execute persistent, stealthy attacks that exploit information asymmetries in multi-vehicle environments.

---

[ISO-Bench: Can Coding Agents Optimize Real-World Inference Workloads?](http://arxiv.org/abs/2602.19594)

- ISO-Bench: introduces a benchmark for coding agents to optimize real-world GPU-based inference workloads, with Coding Agent, Codebase, Task Description, Model Patch, Reference Patch, Hard Metrics, Soft Metrics, LLM-as-a-Judge, Functional Correctness, and Quadrant Framework.
- The evaluation pipeline compares agent-generated patches against human reference solutions using a quadrant framework to distinguish valid optimization from accidental performance gains.
- The benchmark includes 54 tasks from production engines like vLLM and SGLang, revealing an "understanding-execution gap" where agents identify bottlenecks but fail to implement working code.

---

[Advantage-based Temporal Attack in Reinforcement Learning](http://arxiv.org/abs/2602.19582)

- AAT (Advantage-based Adversarial Transformer): introduces a sequence modeling approach to generate time-correlated adversarial examples that disrupt Deep Reinforcement Learning agents, with Observation Encoding, Weighted Advantage Mechanism, Advantage Network, Decoder, MSCSA, and Historical Sequence Buffer.
- The multi-scale causal self-attention mechanism enables the model to capture short-term fluctuations and long-term trends simultaneously to maintain attack coherence across extended sequences.
- The weighted advantage mechanism prioritizes high-impact perturbations, allowing the attacker to learn optimal strategies even from suboptimal trajectory data and effectively reduce agent cumulative rewards.

---

[VALD: Multi-Stage Vision Attack Detection for Efficient LVLM Defense](http://arxiv.org/abs/2602.19570)

- VALD (Multi-Stage Vision Attack Detection for Efficient LVLM Defense): introduces a training-free defense mechanism for LVLMs that detects and mitigates adversarial visual attacks, with image transformations, early adversarial detection, a target LVLM, late adversarial detection, and an LLM-based consolidation agent.
- The framework utilizes a multi-stage pipeline to identify adversarial discrepancies at both the visual embedding and textual response levels to ensure output consistency.
- The system achieves efficiency by using a two-stage detection process that allows 95% of clean images to bypass the computationally expensive consolidation phase.

---

[Agentic AI as a Cybersecurity Attack Surface: Threats, Exploits, and Defenses in Runtime Supply Chains](http://arxiv.org/abs/2602.19555)

- Zero-Trust Runtime Architecture: introduces a systematized framework for securing agentic systems against runtime supply chain threats, with a Perception Module, Context Window, Memory Bank, External Databases, Tool Supply Chain, Worker Agent, and Supervisor Model.
- The framework identifies the Viral Agent Loop, a recursive failure mode where poisoned perception triggers unauthorized actions that re-enter the environment as tainted context for other agents.
- The proposed Auditor-Worker Architecture includes worker- and supervisor-agents to decouple task execution from security oversight through speculative execution and semantic firewalls.

---

[CIBER: A Comprehensive Benchmark for Security Evaluation of Code Interpreter Agents](http://arxiv.org/abs/2602.19547)

- CIBER (Comprehensive Benchmark for Security Evaluation of Code Interpreter Agents): introduces an automated benchmark to systematically assess the vulnerability of code interpreter agents against four major adversarial attack types using dynamic execution and state-aware evaluation.
- The architecture comprises an Attack Generation Module for multi-modal inputs, an Isolated Execution Module hosting agents in a Docker sandbox, and a State-Aware Evaluation Module for intent and state verification.
- The research identifies a "Natural Language Disguise" effect where descriptive text bypasses syntax-based filters and reveals a three-tier vulnerability hierarchy based on intent clarity.

---

[Vinedresser3D: Agentic Text-guided 3D Editing](http://arxiv.org/abs/2602.19542)

- Vinedresser3D: introduces an agentic framework for text-guided 3D editing that utilizes an MLLM to coordinate specialized tools for semantic understanding, region localization, and latent-space modification.
- The framework employs a 3D grounding pipeline using PartField to automatically detect editing regions, enabling precise modifications while preserving unedited geometry without manual masks.
- It features an inversion-based rectified-flow inpainting pipeline with interleaved sampling to integrate textual and visual guidance for coherent 3D asset manipulation.

---

[Cost-Aware Diffusion Active Search](http://arxiv.org/abs/2602.19538)

- CDAS (Cost-aware Diffusion Active Search): introduces a generative planning framework for active search that leverages gradient-guided diffusion models to sample lookahead action sequences, balancing exploration-exploitation without exhaustive tree search.
- The system utilizes a U-Net or Graph Attention Network architecture to model state-action sequences, incorporating a return estimation model and a distance estimator to provide gradient guidance during the denoising process.
- It addresses optimism bias in diffusion-based reinforcement learning and enables decentralized multi-agent coordination through asynchronous belief sharing and independent lookahead sampling.

---

[How to Train Your Deep Research Agent? Prompt, Reward, and Policy Optimization in Search-R1](http://arxiv.org/abs/2602.19526)

- Search-R1++: introduces a systematic optimization of reinforcement learning for Deep Research agents, with Policy LLM (generates reasoning and actions), Search Engine (retrieves external knowledge), Reward Model (evaluates prediction accuracy), Advantage Estimation (computes relative action value), and Fast Thinking Template (optimizes prompt structure).
- The study identifies that traditional "Slow Thinking" prompts and outcome-only rewards cause training instability through answer avoidance, which is resolved by using direct action-oriented templates and augmenting rewards with penalties for omitting search or answer steps.
- Experimental results demonstrate that the REINFORCE algorithm achieves higher accuracy and greater search efficiency than PPO or GRPO in knowledge-intensive multi-round retrieval tasks across various LLMs scales.

---

[Pixel2Phys: Distilling Governing Laws from Visual Dynamics](http://arxiv.org/abs/2602.19516)

- Pixel2Phys: introduces a collaborative multi-agent framework for visual equation discovery, where an MLLM-based architecture includes planning-, variable extraction-, equation distillation-, and experimental validation-agents to iteratively discover physical laws from video.
- The system utilizes a multi-granularity Tool Box for visual parsing and a dynamic symbolic regression engine to identify sparse equations from extracted trajectories or latent representations.
- By establishing a reasoning-driven feedback loop, the framework resolves the circular dependency between representation learning and law discovery to enable long-term extrapolation across diverse physical phenomena.

---

[Security Risks of AI Agents Hiring Humans: An Empirical Marketplace Study](http://arxiv.org/abs/2602.19514)

- RENTAHUMAN.AI: introduces an empirical measurement study of an AI-to-human marketplace, with Adversary, MCP Server, REST API, Marketplace, Human Worker, Escrow System, and Result Ingestion Pipeline components, where autonomous agents programmatically recruit human labor for physical-world tasks.
- The study identifies six abuse classes including credential fraud and automated reconnaissance, revealing that over 32% of tasks originate from programmatic channels like MCP or REST APIs.
- It demonstrates how LLM-based agents can bypass traditional digital constraints by commoditizing human physical action through automated recruitment and escrow-backed payment systems.

---

[Pyramid MoA: A Probabilistic Framework for Cost-Optimized Anytime Inference](http://arxiv.org/abs/2602.19509)

- Pyramid MoA (Pyramid Mixture-of-Agents): introduces a hierarchical architecture that utilizes a lightweight router to dynamically escalate queries to a high-capability model only when necessary, with Layer 1: Ensemble of SLMs, Ensemble Features, Anytime Router, and Layer 2: Oracle LLM.
- The framework employs a model-agnostic router to estimate the probability of failure based on semantic agreement and output variance among an ensemble of smaller models.
- By implementing a probabilistic anytime property, the system achieves significant cost reductions while maintaining high accuracy through selective escalation to the Oracle model.

---

[Conversational AI for Automated Patient Questionnaire Completion: Development Insights and Design Principles](http://arxiv.org/abs/2602.19507)

- CA (Conversational Agent): introduces a generative AI system for collecting patient-reported outcome measures, with User Interface (OpenWebUI-based chat interface), LLM Engine (GPT-5 for natural language processing), Prompt Controller (Iterative system instructions), Data Schema (NIH Recommended Minimal Dataset), and Hosting Infrastructure (AWS-based server), where the agent transforms traditional form-based questionnaires into topic-based dialogues.
- The architecture utilizes iterative prompt engineering to enforce clinical safety constraints and maintain a professional tone while preventing the delivery of unauthorized medical advice.
- The framework incorporates a confidence visualization feature using traffic-light colors to communicate the degree of certainty in captured data and maps unstructured input to structured clinical standards.

---

[Human-Guided Agentic AI for Multimodal Clinical Prediction: Lessons from the AgentDS Healthcare Benchmark](http://arxiv.org/abs/2602.19502)

- Human-Guided Agentic AI: introduces an iterative collaboration workflow for multimodal clinical prediction, with an Agentic AI System (automates routine data science workflows), Human Analysts (provide domain-specific guidance and redirection), Multimodal Feature Engineering (processes text, PDFs, and time-series), Stacking Ensemble (aggregates diverse base model predictions), Weighted Ensemble (combines models using manual weights), and Meta-learner (trains on out-of-fold probabilities).
- The framework integrates LLM-powered automation for data loading and initial modeling with expert human interventions to refine feature extraction from clinical notes and billing receipts.
- Research results demonstrate that human-guided decisions in feature engineering and ensemble design yield significant performance gains over fully autonomous agentic baselines in high-stakes healthcare tasks.

---

[Botson: An Accessible and Low-Cost Platform for Social Robotics Research](http://arxiv.org/abs/2602.19491)

- Botson: introduces an anthropomorphic social robot platform designed to investigate the impact of physical embodiment on human-AI trust, with User, Microphone, Raspberry Pi 4, Google STT, UM-GPT (GPT-4o), eSpeak TTS, Bluetooth Speaker, Arduino, Servo Motors, and Push Button.
- The system utilizes a single-inference prompt engineering technique to simultaneously generate verbal responses and emotional sentiment labels for synchronized physical gestures.
- The architecture leverages low-cost 3D-printed components and off-the-shelf electronics to provide an accessible, open-source framework for affective robotics research.

---

[The dynamics of innovation diffusion: A survey of Bass-type models](http://arxiv.org/abs/2602.19488)

- Bass-type models: introduces a meta-study of innovation diffusion dynamics, synthesizing structural extensions, stochastic generalizations, and parameter estimation techniques within a quantitative framework.
- The survey contrasts top-down system dynamics approaches with bottom-up agent-based models to capture emergent phenomena and individual decision logic.
- It evaluates estimation methodologies ranging from frequentist statistics to Bayesian filtering and bio-inspired meta-heuristic optimization.

---

[COMPLLLM: Fine-tuning LLMs to Discover Complementary Signals for Decision-making](http://arxiv.org/abs/2602.19458)

- COMPLLLM: introduces a post-training framework that fine-tunes a decision-assistant LLM to discover and extract complementary signals from unstructured text that improve upon existing agent recommendations, with Recommending Agent, Supervisor Agent, COMPLLLM, Complementary Signals, and Utility Function components.
- The approach formalizes complementary value using decision theory to prioritize signals that meaningfully enhance best-attainable decision quality rather than just frequent or salient information.
- The methodology integrates supervised fine-tuning and reinforcement learning using Group Relative Policy Optimization to recover known complementary information in domains like medical diagnosis and content moderation.

---


[UrbanAlign: Post-hoc Semantic Calibration for VLM-Human Preference Alignment](http://arxiv.org/abs/2602.19442)

- UrbanAlign: introduces a training-free post-hoc concept-bottleneck pipeline for aligning Vision-Language Model (VLM) outputs with human preferences in subjective perception tasks, with a VLM Dimension Generator, an Observer Agent, a Debater Agent, a Judge Agent, a Frozen CLIP Encoder, Hybrid Vector Fusion, Locally-Weighted Ridge Regression (LWRR), and a Dimension Optimization Loop.
- The architecture includes observer-, debater-, and judge-agents to extract robust continuous concept scores from a frozen VLM, which are then fused with CLIP embeddings into a hybrid visual-semantic manifold.
- A locally-weighted ridge regression (LWRR) layer provides local adaptivity to heterogeneous perception patterns, while an automated optimization loop selects the dimension set that maximizes calibrated accuracy.

---

[When AI Teammates Meet Code Review: Collaboration Signals Shaping the Integration of Agent-Authored Pull Requests](http://arxiv.org/abs/2602.19441)

- AIDev (Autonomous AI Developer dataset analysis): introduces an empirical investigation into the socio-technical integration of agent-authored pull requests, utilizing autonomous coding agents, collaboration signals, and logistic regression models to identify factors influencing merge success.
- The research identifies that reviewer engagement is the strongest predictor of successful merging, while coordination-disrupting actions like force pushes significantly decrease the likelihood of code acceptance.
- The study evaluates performance across multiple LLMs, demonstrating that alignment with established repository norms and actionable feedback loops is more influential than the sheer volume of commits or test additions.

---

[OptiRepair: Closed-Loop Diagnosis and Repair of Supply Chain Optimization Models with LLM Agents](http://arxiv.org/abs/2602.19439)

- OptiRepair (Closed-Loop Diagnosis and Repair of Supply Chain Optimization Models with LLM Agents): introduces a two-phase closed-loop framework for diagnosing and repairing supply chain optimization models, which includes feasibility- and rationality-agents, a solver, a RationalityOracle, and the OptiSTaR training pipeline.
- The architecture separates domain-agnostic feasibility restoration using solver-provided IIS feedback from domain-specific operational validation via a RationalityOracle grounded in inventory theory.
- The framework utilizes the OptiSTaR training pipeline to iteratively refine 8B-parameter models through self-taught reasoning and reinforcement learning with solver-verified rewards.

---

[RAmmStein: Regime Adaptation in Mean-reverting Markets with Stein thresholds](http://arxiv.org/abs/2602.19419)

- RAmmStein (Regime Adaptation in Mean-reverting Markets with Stein thresholds): introduces, a Deep Reinforcement Learning framework for managing concentrated liquidity in Automated Market Makers by formulating rebalancing as an impulse control problem, with Feature Engine (computes market regime parameters), Environment Simulator (models AMM dynamics and costs), DDQN Agent (approximates optimal rebalancing policy), Replay Buffer (stores experience for training), and Target Network (stabilizes value function estimation).
- The system incorporates a Stein Signal derived from an Ornstein-Uhlenbeck process to identify mean-reverting market regimes and avoid unnecessary rebalancing during temporary price noise.
- It utilizes a Double Deep Q-Network to approximate the solution of a Hamilton-Jacobi-Bellman quasi-variational inequality, learning an optimal "laziness boundary" between action and inaction to maximize net return on investment.

---

[Multi-CoLoR: Context-Aware Localization and Reasoning across Multi-Language Codebases](http://arxiv.org/abs/2602.19407)

- Multi-CoLoR (Context-aware Localization and Reasoning across Multi-Language codebases): introduces a two-stage framework that integrates organizational knowledge retrieval with graph-based reasoning to locate bug fix regions in complex, heterogeneous software repositories.
- The architecture includes a summarization-LLM for issue preprocessing and a graph-traversal-LLM agent for navigating a Unified Dependency Graph across C++, QML, and Python.
- By combining semantic search over organizational memory with structural code analysis, the framework improves localization accuracy and reduces tool-call overhead in industrial enterprise environments.

---

[Machine-Generated, Machine-Checked Proofs for a Verified Compiler (Experience Report)](http://arxiv.org/abs/2602.20082)

- Claude Code: introduces an agentic coding assistant approach to mechanize a substantial Rocq correctness proof for the CertiCoq compiler's ANF transformation, utilizing an agentic LLM, human guide, and the Rocq proof assistant.
- The framework leverages a human-expert-developed CPS proof as a template, instructing the LLM to adapt the proof technique to the technically distinct ANF setting.
- The study reports that the LLM successfully generated approximately 6,000 lines of Rocq proof in 96 hours, identifying complex reasoning obstacles like divergence preservation issues.

---

[MAS-FIRE: Fault Injection and Reliability Evaluation for LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2602.19843)

- MAS-FIRE (Fault Injection and Reliability Evaluation): introduces a systematic framework for diagnosing semantic vulnerabilities in LLM-based Multi-Agent Systems, with Fault Taxonomy, Injection Mechanisms, Robustness Metrics, Fault Tolerance Tiers, MetaGPT, Table-Critic, and Camel, and includes planning-, coding-, reviewing-, judge-, generator-, and refiner-agents.
- The approach utilizes dual-level metrics to quantify system-level resilience and process-level effectiveness, uncovering how architectural topology and model capability influence fault recovery.
- Experimental results demonstrate that iterative, closed-loop architectures neutralize over 40% of faults that cause collapse in linear workflows, providing process-level observability for improving multi-agent software.

---

[Meta-Learning and Meta-Reinforcement Learning - Tracing the Path towards DeepMind’s Adaptive Agent](http://arxiv.org/abs/2602.19837)

- ADA (Adaptive Agent): introduces a transformer-based generalist agent framework that integrates model-based reinforcement learning with self-supervised techniques to enable few-shot adaptation in open-ended task spaces.
- The architecture incorporates a ResNet for visual feature extraction, a Transformer-XL for long-range context modeling, and a Muesli-inspired structure for integrated planning and value estimation.
- The training process utilizes automatic curriculum learning for task prioritization and dynamic reward-guided distillation to transfer knowledge from large teacher models to efficient student agents.

---

[Representation Stability in a Minimal Continual Learning Agent](http://arxiv.org/abs/2602.19655)

- Minimal Continual Learning Agent: introduces a stateful system designed to isolate representational dynamics from architectural complexity, with all Observation, Representation, Update, Comparison, Storage, and Persistent State Vector components.
- The framework utilizes a repeated learning loop to maintain a persistent internal state vector that encodes accumulated exposure to textual experience through normalized token-frequency counts.
- It quantifies learning dynamics using cosine similarity between successive state vectors to measure representational stability and adaptation without explicit regularization, replay mechanisms, or task-driven optimization.

---

[Learning to Rewrite Tool Descriptions for Reliable LLM-Agent Tool Use](http://arxiv.org/abs/2602.20426)

- Trace-Free+: introduces a curriculum learning framework that progressively transfers supervision from trace-rich settings to trace-free deployment to optimize tool interfaces for LLM-based agents, with an Agentic Tool Annotator (filters tools and collects call history), a User Query Synthesizer (generates complex multi-step tool queries), a Description Generator (fine-tuned LLM rewriting tool interfaces), Data-Independent Improvement (initial rule-based description refinement), Trace-Aware Refinement (extracts rules from execution traces), and a Curriculum Learning Strategy (transfers knowledge from trace-rich to trace-free).
- The system includes LLM-based annotator-, query synthesizer-, and description generator-components to automate the creation of high-quality tool interfaces through a three-stage SFT data synthesis pipeline.
- The framework demonstrates strong generalization to unseen tools and robustness as the number of candidate tools scales beyond 100 in both trace-free and trace-based settings.

---

[Implicit Intelligence - Evaluating Agents on What Users Don’t Say](http://arxiv.org/abs/2602.20424)

- AaW (Agent-as-a-World): introduces an evaluation framework for assessing "Implicit Intelligence" in AI agents by simulating interactive environments where unstated constraints must be inferred, with Scenario YAML, Primary Agent, World Model, Evaluator Model, and Execution Loop, and includes Primary Agent, World Model, and Evaluator Model LLMs.
- The system utilizes a declarative YAML specification to drive a World Model that acts as a universal simulator, enforcing hidden constraints and execution rules discoverable only through proactive exploration.
- The research benchmarks 16 frontier and open-weight models across 205 scenarios, finding that current training paradigms do not prioritize the contextual reasoning skills necessary for human-like interaction.

---

[Efficient Interview Scheduling for Stable Matching](http://arxiv.org/abs/2602.20358)

- Sequential and Hybrid Adaptive Algorithms: introduces two adaptive scheduling frameworks for matching markets under preference uncertainty, with Sequential Adaptive Algorithm (iteratively schedules interviews sequentially), Hybrid Adaptive Algorithm (combines parallel and sequential phases), Pick_Next_Interviews (identifies simultaneous interview pairs), DA_on_Applicants_Truncated_Interim_Preferences (updates matchings using interviewed positions), Applicant_Proposing_DA (standard Gale-Shapley matching mechanism), and All_Interviews_Algorithm (fallback for all remaining interviews).
- The sequential approach minimizes redundant interviews by exploiting information revealed in each round, while the hybrid approach utilizes parallelism to reduce the expected number of interview rounds to polylogarithmic levels.
- The research establishes that interim-stable matchings can be achieved with a constant expected number of interviews per agent in ex-ante equivalent settings.

---

[QuantVLA: Scale-Calibrated Post-Training Quantization for Vision-Language-Action Models](http://arxiv.org/abs/2602.20309)

- QuantVLA (Scale-Calibrated Post-Training Quantization for Vision-Language-Action Models): introduces a training-free post-training quantization framework for VLA systems, with a selective quantization layout, attention temperature matching (ATM), and output head balancing (OHB).
- The framework integerizes linear layers in the LLM and DiT MLP while maintaining attention projections in floating point to preserve operator schedules and stabilize cross-modal feature distributions.
- It utilizes per-head and per-layer scaling mechanisms estimated from a small unlabeled calibration buffer to mitigate quantization-induced energy drift and logit temperature shifts, achieving significant memory savings without retraining.

---

[Gap-Dependent Bounds for Nearly Minimax Optimal Reinforcement Learning with Linear Function Approximation](http://arxiv.org/abs/2602.20297)

- LSVI-UCB++ (Least-Squares Value Iteration with Upper Confidence Bound ++): introduces a reinforcement learning framework for linear Markov Decision Processes that achieves improved gap-dependent regret bounds by utilizing adaptive weighted ridge regression, optimistic and pessimistic value estimation, and a low policy-switching mechanism.
- The architecture includes optimistic-, pessimistic- and variance-estimators to refine exploration bonuses and monitor feature coverage, enabling nearly minimax-optimal performance in high-dimensional environments.
- A concurrent variant, Concurrent LSVI-UCB++, leverages the low policy-switching property to enable efficient parallel exploration across multiple agents, achieving a linear speedup in sample complexity.

---

[Quantifying the Expectation–Realisation Gap for Agentic AI Systems](http://arxiv.org/abs/2602.20292)

- AAC (Agentic Automation Canvas): introduces a structured framework for designing and governing agentic AI projects, with quantified benefit metrics, dual-perspective confidence levels, and explicit accounting for human oversight costs.

- The research identifies a significant "expectation–realisation gap" where pre-deployment productivity forecasts systematically overshoot actual outcomes due to workflow friction and verification burdens.

- It synthesizes empirical evidence from software engineering and clinical domains to argue that agentic AI benefits are highly heterogeneous and require precise, context-aware planning to avoid net productivity losses.


---

[Existence of Equilibrium Mechanisms in Generalized Principal-Agent Problems with Interacting Teams](http://arxiv.org/abs/2602.20281)

- BNPE (Bayesian-Nash Principals' Equilibrium): introduces a framework for establishing equilibrium existence in multi-principal mechanism design games with interacting teams, with Principals (Strategic mechanism designers for teams), Teams (Groups of agents with spillovers), Agents (Members with private types/actions), Mechanisms (Rules for recommendations and rewards), Outcome Spaces (Baseline and extended state representations), Induced Laws (Probability measures over outcomes), Robust Narrow Topology (Metric for mechanism closeness/convergence), and IC Correspondence (Mapping of feasible incentive-compatible strategies), where the approach establishes equilibrium existence by tracking on-path and off-path outcome distributions.
- The approach addresses discontinuities in incentive-compatible mechanism correspondences by integrating the classical narrow topology for truthful-obedient paths with the Hausdorff metric for unilateral behavior strategy deviations.
- The framework provides a foundation for analyzing strategic environments with spillovers, multidimensional types, and agency problems including both adverse selection and moral hazard.

---

[HieraMAS: Optimizing Intra-Node LLM Mixtures and Inter-Node Topology for Multi-Agent Systems](http://arxiv.org/abs/2602.20229)

- HieraMAS (Hierarchical Collaboration with Multi-Agent Systems): introduces a hierarchical framework that jointly optimizes intra-node LLM mixtures within supernodes and inter-node communication topologies using a two-stage training algorithm.
- The architecture includes proposer- and synthesizer-LLMs within supernodes, optimized by a policy learner, and a graph classifier that identifies optimal holistic communication patterns from a candidate pool.
- The framework addresses credit assignment challenges through multi-level reward attribution and a skip-token mechanism that facilitates adaptive role pruning and mixture-size reduction.

---

[Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters](http://arxiv.org/abs/2602.10604)

- Step 3.5 Flash: introduces a sparse Mixture-of-Experts (MoE) model with 11B active parameters, utilizing a 196B-parameter foundation, hybrid attention, and multi-token prediction to optimize the trade-off between agentic intelligence and computational efficiency.
- The architecture integrates head-wise gated attention and an interleaved 3:1 sliding-window to full attention ratio to minimize latency during multi-round agentic interactions.
- The framework supports specialized search-, code-, and tool-use agents through a unified post-training recipe involving Metropolis Independence Sampling-Filtered Policy Optimization (MIS-PO) and parallel coordinated reasoning.

---

#### 22nd February 2026

[AI AGENTS FOR VARIATIONAL QUANTUM CIRCUIT DESIGN](http://arxiv.org/abs/2602.19387)

- AI Agent for Variational Quantum Circuit Design: introduces an autonomous agentic framework that leverages LLMs to iteratively propose, evaluate, and optimize variational quantum circuit architectures within a simulated environment.
- The system utilizes the ORCHESTRAL AI framework to manage tool-calling interactions between reasoning agents and a PennyLane-based quantum simulation backend.
- Evaluation across multiple quantum neural network architectures demonstrates that agents can discover effective circuit motifs, such as star-topology entanglement, while progressively improving task performance through automated feedback.

---

[Stable Deep Reinforcement Learning via Isotropic Gaussian Representations](http://arxiv.org/abs/2602.19373)

- SIGReg (Sketched Isotropic Gaussian Regularization): introduces a lightweight statistical regularizer that shapes learned representations toward an isotropic Gaussian distribution to stabilize training dynamics under non-stationary targets.
- The framework utilizes random projections to match high-dimensional embedding distributions with univariate Gaussian targets, effectively mitigating representation collapse and neuron dormancy in deep reinforcement learning. 
- Empirical evaluations across discrete Atari games and continuous Isaac Gym benchmarks demonstrate that enforcing isotropic geometry improves sample efficiency and robustness without requiring complex architectural modifications or second-order optimization.

---

[Self-Configurable Mesh-Networks for Scalable Distributed Submodular Bandit Optimization](http://arxiv.org/abs/2602.19366)

- ANACONDA (AlterNAting COordination and Network Design Algorithm): introduces a distributed multi-agent framework for scaling submodular bandit coordination under communication constraints, which includes action selection- and neighbor selection-agents, with ANACONDA (alternating coordination and network design), ACTSEL (adversarial bandit action selection), NEISEL (adversarial bandit neighbor selection), EXP3 (underlying bandit solver), Communication Neighborhood (dynamically configured one-hop peers), Value of Coordination (neighbor utility metric), and Submodular Objective Function (global utility function).
- The system dynamically configures communication neighborhoods by maximizing the Value of Coordination to improve action coordination performance in unknown environments.
- The approach ensures scalability by limiting information relays to one-hop communication and maintaining small message sizes, providing anytime suboptimality bounds for arbitrary network topologies.

---

[City Editing: Hierarchical Agentic Execution for Dependency-Aware Urban Geospatial Modification](http://arxiv.org/abs/2602.19326)

- CEAE (City Editing: Hierarchical Agentic Execution): introduces a hierarchical agentic framework for urban renewal that decomposes natural-language instructions into structured geometric intents, with a task planner agent, geoexecutor agents, validator agents, an aggregator agent, geospatial tools, and GeoJSON state.
- The architecture includes planning-, execution-, validation-, and aggregation-agents to coordinate interdependent edits across multiple geometric levels while maintaining global spatial consistency.
- The framework employs a coarse-to-fine execution strategy with explicit propagation of intermediate spatial constraints to mitigate error accumulation in complex geospatial modifications.

---

[Anatomy of Agentic Memory: Taxonomy and Empirical Analysis of Evaluation and System Limitations](http://arxiv.org/abs/2602.19320)

- MAG (Memory-Augmented Generation): introduces a structured analysis of agentic memory systems, with Lightweight Semantic, Entity-Centric and Personalized, Episodic and Reflective, and Structured and Hierarchical memory components, where the paper provides a diagnostic framework to explain when specific memory structures are effective.
- The study identifies critical bottlenecks including benchmark saturation, lexical metric misalignment with semantic utility, and significant system-level costs like retrieval latency and update overhead.
- Empirical analysis of architectures like LOCOMO, AMem, and MAGMA demonstrates that complex memory maintenance often leads to structural instability or "silent failure" in open-weight LLMs.

---

[Scaling Inference-Time Computation via Opponent Simulation: Enabling Online Strategic Adaptation in Repeated Negotiation](http://arxiv.org/abs/2602.19309)

- BoN-oppo-simulation (Best-of-N with Opponent Simulation): introduces a framework for scaling inference-time computation in repeated strategic games by embedding smooth Fictitious Play principles into LLM inference, with base LLM, in-context opponent model, strategic brainstorming module, opponent simulation module, and Best-of-N selector; it includes base- and opponent-model-LLMs.
- The system employs an auxiliary opponent model that leverages in-context learning to summarize behavioral patterns and predict future responses based on accumulated interaction history.
- By simulating full future trajectories for diverse candidate strategies, the approach enables online strategic adaptation and performance improvement in repeated negotiations without requiring gradient-based parameter updates.

---

[Safe and Interpretable Multimodal Path Planning for Multi-Agent Cooperation](http://arxiv.org/abs/2602.19304)

- CaPE (Code as Path Editor): introduces a framework for language-guided path editing in multi-agent cooperation, utilizing a joint planner to propose candidate paths and a VLM to synthesize verifiable path-editing programs.
- The system leverages a domain-specific language to perform operations like path selection, translation, and waypoint insertion, which are then validated by a model-based verifier to ensure collision-free execution.
- By grounding natural language communication into explicit code-based edits, the approach maintains high interpretability and safety across diverse scenarios including autonomous driving and human-robot collaboration.

---

[Proximity-Based Multi-Turn Optimization: Practical Credit Assignment for LLM Agent Training](http://arxiv.org/abs/2602.19225)

- ProxMO (Proximity-based Multi-turn Optimization): introduces a hierarchical reinforcement learning framework for training multi-turn LLM agents, utilizing success-rate-aware modulation and semantic proximity weighting to improve credit assignment.

- The architecture features a Polarized Signal Controller that amplifies breakthrough signals in difficult tasks while attenuating noise in easy ones, alongside a Proximity-based Soft Aggregation module for continuous step-level baseline estimation.

- By replacing hard boundary partitioning with soft semantic aggregation, the system avoids singleton degeneracy and provides more informative advantage estimates for complex, long-horizon interactive tasks.


---

[Characterizing MARL for Energy Control: A Multi-KPI Benchmark on the CityLearn Environment](http://arxiv.org/abs/2602.19223)

- MARL Evaluation Framework (Multi-Agent Reinforcement Learning Evaluation Framework): introduces a comprehensive benchmarking methodology for energy management, with CityLearn Environment, MARL Agents, Sebulba Architecture, Observation Encoders, Multi-KPI Evaluator, and Agent Importance Scorer.
- The system employs recurrent observation encoders to capture temporal dependencies in energy demand, significantly improving performance on memory-dependent metrics like ramping and battery depth of discharge.
- It incorporates a novel agent importance score to analyze individual building contributions, demonstrating that decentralized policies offer superior robustness and scalability in smart grid scenarios.

---

[Gecko: A Simulation Environment with Stateful Feedback for Refining Agent Tool Calls](http://arxiv.org/abs/2602.19218)

- Gecko (agent + feedback + environment): introduces a simulation environment providing stateful feedback for refining LLM agent tool calls, with a planning LLM (generates tool call sequences), Gecko Environment (simulates stateful tool feedback), Argument Validator (verifies syntax and semantics), Response Generator (synthesizes realistic tool outputs), Task State Estimator (tracks evolving task progress), Task Feedback Generator (evaluates objective completion status), API Schema Converter (standardizes tools via OpenAPI), GATS (iteratively refines tool calls), Session-based State Management (manages execution history), Helper LLM (assists validation and synthesis), and Judge LLM (assesses task objective completion).
- The framework implements GATS to enable agents to iteratively improve tool-call accuracy through simulated execution results and task-level feedback without incurring real-world costs or safety risks.
- Experimental results on BFCLv3 and τ2-bench demonstrate that Gecko improves tool-calling performance across multiple models by grounding actions in a state-aware virtual environment.

---

[VLM-Guided Group Preference Alignment for Diffusion-based Human Mesh Recovery](http://arxiv.org/abs/2602.19180)

- VLM-Guided Group Preference Alignment: introduces a framework that leverages a dual-memory augmented Visual Language Model critique agent to provide stable quality scores for human mesh recovery, with diffusion-based HMR model, VLM-guided HMR critique agent, rule memory, prototype memory, reflective knowledge construction, and group preference alignment components.
- The system utilizes a self-reflective mechanism to iteratively mine judging rules and store visual prototypes, ensuring consistent and semantically grounded evaluations of generated 3D meshes.
- By integrating group-wise preference signals into the diffusion training objective, the approach effectively aligns model outputs with physical constraints and image evidence without requiring 3D ground-truth annotations.

---

[Facet-Level Persona Control by Trait-Activated Routing with Contrastive SAE for Role-Playing LLMs](http://arxiv.org/abs/2602.19157)

- CV-SAE (Contrastive Vector Sparse AutoEncoder): introduces a personality control framework for Role-Playing Agents that injects facet-level latent vectors into the residual space of LLMs, and includes routing- and role-playing-agents.
- The architecture employs a Contrastive Learning objective to optimize within-facet compactness and across-facet separation of personality traits within the SAE latent space.
- A specialized 15,000-sample corpus provides balanced supervision for 30 personality facets, allowing the Agent-Based Decision Module to precisely steer model behavior based on situational cues.

---

[AgenticRAGTracer: A Hop-Aware Benchmark for Diagnosing Multi-Step Retrieval Reasoning in Agentic RAG](http://arxiv.org/abs/2602.19127)

- AgenticRAGTracer: introduces a hop-aware benchmark for diagnosing multi-step retrieval reasoning in agentic RAG systems, utilizing an automated pipeline that includes generation-, filtering-, and judge-LLMs.
- The framework constructs complex queries across sequential inference and parallel comparison topologies to evaluate the ability of agents to autonomously plan and retrieve information.
- Experimental results reveal that mainstream LLMs exhibit performance decline on high-hop reasoning tasks, frequently failing due to distorted reasoning chains or suboptimal retrieval strategies.

---

[Evaluation and Benchmarking Suite for Financial Large Language Models and Agents](http://arxiv.org/abs/2602.19073)

- Evaluation and Benchmarking Suite for Financial LLMs and Agents: introduces a comprehensive lifecycle framework for financial AI, integrating the Open Financial LLM Leaderboard, AgentOps, and specialized agents like FinSight for robust performance assessment.
- The FinSight Agent utilizes a metacognitive architecture where a central Orchestration Agent coordinates specialized sentiment-, event-, and volatility-agents while a Metacognitive Monitor applies dynamic guardrails to ensure response reliability.
- The suite employs the AgentOps framework to synchronize offline development with online production through trajectory tracing, observability trails, and continuous feedback loops for real-world financial governance.

---

[Cooperative Transportation Without Prior Object Knowledge via Adaptive Self-Allocation and Coordination](http://arxiv.org/abs/2602.19070)

- Density-driven Cooperative Transportation Framework: introduces a decentralized multi-agent system for transporting cargos without prior knowledge of location or size, utilizing local sensing agents, object-induced density function, Centroidal Voronoi Tessellation (CVT), Control Barrier Functions (CBF), composite motion controller, and Quadratic Program (QP) solver.
- The system generates time-varying attraction fields via a density function to recruit agents and adaptively allocate team sizes based on the detected spatial extent of target objects.
- Integration of CVT-based spatial organization with CBF-based safety constraints ensures collision-free coordination and prevents asymmetric agent clustering during cooperative caging and transport.

---

[AGENTIC PROBLEM FRAMES: A SYSTEMATIC APPROACH TO ENGINEERING RELIABLE DOMAIN AGENTS](http://arxiv.org/abs/2602.19065)

- APF (Agentic Problem Frames): introduces a systematic engineering framework for reliable domain agents by shifting focus from internal LLM intelligence to structured interactions between the agent and its environment.
- The architecture incorporates an Agentic Job Description (AJD) to define jurisdictional boundaries and an Act-Verify-Refine (AVR) loop that includes supervisor- and reflex-agents.
- It employs dynamic specification and epistemic verification to ensure agent behavior asymptotically converges toward mission requirements within complex industrial domains.

---

[Who Has the Final Word? Designing Multi-Agent Collaborative Framework for Professional Translators](http://arxiv.org/abs/2602.19016)

- CHORUS (human–AI multi-agent collaborative translation framework): introduces a human–AI multi-agent collaborative translation framework grounded in Multidimensional Quality Metrics (MQM), with Translator, Dimension Router, Pool of Experts, Selected Experts, Memories, and Interaction Loops.
- The system utilizes a Dimension Router to select specialized MQM-aligned agents—including accuracy-, terminology-, and style-agents—that provide targeted revision suggestions based on shared translation memories.
- The framework preserves human authority through iterative refinement loops, allowing professional translators to guide AI agents across specific quality dimensions while externalizing multi-dimensional analysis into structured support.

---

[Adaptive Weighting for Time-to-Event Continual Reassessment Method: Improving Safety in Phase I Dose-Finding Through Data-Driven Delay Distribution Estimation](http://arxiv.org/abs/2602.19012)

- AW-TITE (Adaptive-Weight Time-to-Event Continual Reassessment Method): introduces a Phase I dose-finding framework that replaces fixed linear weights with data-driven posterior predictive probabilities derived from an evolving toxicity delay distribution.
- The system utilizes a Weibull timing model and closed-form weight updates via maximum likelihood estimation to adjust likelihood contributions for patients with incomplete follow-up in real-time.
- The method reduces patient overdosing by 40.6% compared to TITE-CRM while maintaining maximum tolerated dose selection accuracy across various dose-toxicity scenarios.

---

[Capable but Unreliable: Canonical Path Deviation as a Causal Mechanism of Agent Failure in Long-Horizon Tasks](http://arxiv.org/abs/2602.19008)

- Canonical Solution Path: introduces a causal framework for analyzing LLM agent reliability by measuring stochastic drift from task-specific tool-use strategies, with LLM Agent, Tool Environment, Canonical Solution Path, Empirical Consensus Tool Set, Runtime Monitor, and Trajectory Memory components.
- The system identifies that agent failures in long-horizon tasks are often reliability-driven rather than capability-driven, characterized by a gradual and self-reinforcing divergence from the canonical trajectory.
- By implementing a mid-trajectory monitor to restart runs with low canonical adherence, the approach significantly lifts success rates without requiring additional model training or expert-designed reference plans.

---

[Benchmark Test-Time Scaling of General LLM Agents](http://arxiv.org/abs/2602.18998)

- General AgentBench: introduces a unified evaluation framework for general-purpose LLM agents across coding, search, reasoning, and tool-use domains, with Omni Agents, a centralized Host, a Router, a Unified Toolbox, MCP Servers, Domain Clients, Domain Data, a Database, and the Model Context Protocol (MCP).
- The architecture leverages the Model Context Protocol (MCP) to abstract domain-specific implementations into a single interaction interface, facilitating the study of test-time scaling behaviors.
- Systematic evaluation reveals that test-time scaling is limited by a context ceiling in sequential interactions and a verification gap when selecting from parallel trajectories.

---

[IDSelect: A RL-Based Cost-Aware Selection Agent for Video-based Multi-Modal Person Recognition](http://arxiv.org/abs/2602.18990)

- IDSelect (RL-Based Cost-Aware Selection Agent): introduces a reinforcement learning-based cost-aware selector that adaptively chooses one pre-trained model per modality per video sequence to optimize the accuracy-efficiency trade-off in multi-modal person recognition.
- The framework utilizes an actor-critic reinforcement learning policy with a Lagrangian budget controller to discover complementary model combinations across face, gait, and body modalities while adhering to computational constraints.
- By decoupling model availability from utilization, the system achieves high Rank-1 accuracy on datasets like CCVID with significantly reduced FLOPs compared to fixed heavyweight ensembles.

---

[Quantifying Automation Risk in High-Automation AI Systems: A Bayesian Framework for Failure Propagation and Optimal Oversight](http://arxiv.org/abs/2602.18986)

- Bayesian Risk Decomposition Framework: introduces a parsimonious mathematical model to quantify expected loss by isolating technical risk, deployment risk, and consequence risk, while incorporating automation dimensions, resource allocation, and an efficient frontier.
- The approach operationalizes harm propagation as execution probability, linking unobservable risk to design characteristics like kill-switch latency and human override capability.
- The research establishes optimality conditions for automation levels and resource allocation, providing a decision-theoretic grounding for AI governance and safety engineering.

---

[InfEngine: A Self-Verifying and Self-Optimizing Intelligent Engine for Infrared Radiation Computing](http://arxiv.org/abs/2602.18985)

- InfEngine (Intelligent Engine for Infrared Radiation Computing): introduces an autonomous multi-agent framework for infrared radiation computing, with Problem-Analyzing Agent, Problem-Solving Agent, Evaluator Generation Agent, and Code Evolution Agent components, where it automates the transition from natural language queries to verified, optimized, and reusable scientific code.
- The framework employs a self-verification strategy using joint solver-evaluator debugging to ensure scientific plausibility and a self-optimization mechanism utilizing evolutionary algorithms with autonomously synthesized fitness functions.
- Supported by the InfTools library of 270 domain-specific tools and evaluated on the InfBench benchmark, the system demonstrates significant speedups and high functional correctness across diverse infrared radiation computing tasks.

---

[The Path to Conversational AI Tutors: Integrating Tutoring Best Practices and Targeted Technologies to Produce Scalable AI Agents](http://arxiv.org/abs/2602.19303)

- KCCS (Keep, Change, Center, Study): introduces a framework for developing conversational AI tutors that synthesizes legacy Intelligent Tutoring System methods with generative LLM capabilities to provide scalable, pedagogically effective instruction.
- The system employs an inner-loop architecture where diagnostic data from knowledge tracing and affect detection informs LLM-driven interventions such as cueing, probing, and bespoke remediation.
- This approach shifts tutoring from procedural correctness to natural language meaning-making, enabling granular diagnosis of student reasoning and increased learner agency.

---

[ALPACA: A Reinforcement Learning Environment for Medication Repurposing and Treatment Optimization in Alzheimer’s Disease](http://arxiv.org/abs/2602.19298)

- ALPACA (Alzheimer’s Learning Platform for Adaptive Care Agents): introduces an open-source, Gym-compatible reinforcement learning environment for exploring personalized Alzheimer's disease treatment strategies, with ALPACA Environment (Gym-compatible simulation testbed), CAST Model (medication-conditioned transition engine), Treatment Agent (reinforcement learning policy), Reward Function (cognitive-based performance metric), and GMM State Initializer (synthetic patient generator).
- The framework utilizes a mixture-of-experts transformer architecture to autoregressively simulate disease progression conditioned on 17 therapeutic classes of medication across longitudinal patient trajectories.
- Evaluation demonstrates that reinforcement learning policies trained in this environment outperform clinician baselines on memory-related outcomes while maintaining clinical interpretability through SHAP analysis.

---

[DGPO: RL-Steered Graph Diffusion for Neural Architecture Generation](http://arxiv.org/abs/2602.19261)

- DGPO (Directed Graph Policy Optimization): introduces a reinforcement learning-steered discrete graph diffusion framework for generating directed acyclic graphs, with DiGress backbone, Transformer-based denoising network, topological node ordering, positional encoding, DAG recovery, and reward-driven steering mechanism.
- The system utilizes topological node ordering to encode directional data flow into node indices and employs positional encodings to assist the denoising network in reconstructing directed edges.
- The approach achieves competitive performance on neural architecture search benchmarks by fine-tuning pretrained diffusion models toward high-accuracy regions using advantage-normalized policy gradients.

---

[Dark and Bright Side of Participatory Red-Teaming with Targets of Stereotyping for Eliciting Harmful Behaviors from Large Language Models](http://arxiv.org/abs/2602.19124)

- Participatory Red-Teaming: introduces an empirical methodology for eliciting harmful behaviors from LLMs by engaging individuals stigmatized by stereotypes as adversarial testers who leverage lived experience to identify subtle biases.
- The approach utilizes diverse prompting strategies—including devil persona role-play, context setting, and inducing provocative scenarios—within a structured documentation workspace to systematically log multi-turn interactions and harmfulness evaluations.
- The research evaluates the psychological impact on participants, finding that while group-level perceptions may decline, the process fosters critical AI literacy and a sense of agency in protecting communities from AI-driven harm.

---

[Little Red Dots as Globular Clusters in Formation](http://arxiv.org/abs/2602.15935)

- GCF (Globular Clusters in Formation): introduces a physical model interpreting high-redshift Little Red Dots as nascent globular clusters hosting a central supermassive star, with all GCF-components.
- The framework explains the characteristic V-shaped spectral energy distribution by combining UV-bright young stars with an optical-dominated supermassive star undergoing mass loss.
- Evolutionary modeling demonstrates that the LRD mass function at high redshift naturally transforms into the observed present-day globular cluster mass function through standard mass-loss prescriptions.

---

#### 21st February 2026

[How Far Can We Go with Pixels Alone? A Pilot Study on Screen-Only Navigation in Commercial 3D ARPGs](http://arxiv.org/abs/2602.18981)

- Screen-Only Navigation Agent: introduces an autonomous framework for navigating 3D Action RPGs using only visual affordances, incorporating an STP/MSTP perception stack, a finite-state controller, and a visual memory bank.
- The architecture employs a two-stage detector-selector pipeline to identify spatial transition points and a pulse-based controller to translate visual targets into discrete keyboard inputs.
- A milestone-based evaluation protocol enables progress tracking through image template matching against designer-specified viewpoints, requiring no access to internal game coordinates or engine APIs.

---

[Robust and Efficient Tool Orchestration via Layered Execution Structures with Reflective Correction](http://arxiv.org/abs/2602.18968)

- RETO (Robust and Efficient Tool Orchestration): introduces a layered execution framework that decouples global tool organization from local execution to enhance the robustness of agentic systems using small language models.
- The architecture employs a lightweight neural layer predictor to organize tools into ordered stages, enforcing context-constrained invocation to minimize reasoning overhead and prevent out-of-turn calls.
- A schema-aware reflective correction mechanism isolates and repairs tool-call failures locally, avoiding expensive global re-planning while ensuring that errors do not contaminate the execution context.

---

[Whisper: Courtside Edition: Enhancing ASR Performance Through LLM-Driven Context Generation](http://arxiv.org/abs/2602.18966)

- Whisper: Courtside Edition: introduces a multi-agent LLM pipeline that enhances automatic speech recognition by intercepting initial transcripts to generate domain-aware prompts for a second decoding pass.
- The architecture utilizes specialized agents for topic detection, named entity normalization, and jargon identification to inject lexical bias into the Whisper decoder without requiring model retraining.
- Evaluation on NBA commentary demonstrates a 17% relative reduction in word error rate, significantly outperforming traditional post-editing by reconciling acoustic evidence with LLM-generated domain expertise.

---

[NeuroWise: A Multi-Agent LLM “Glass-Box” System for Practicing Double-Empathy Communication with Autistic Partners](http://arxiv.org/abs/2602.18962)

- NeuroWise: introduces a multi-agent LLM-based coaching system designed to support neurotypical individuals in practicing double-empathy communication with simulated autistic partners, with Autistic Agent, Stress Estimator, Interpreter Agent, and Coach Agent components.
- The system utilizes a "glass-box" architecture to visualize the partner's internal stress levels and provide real-time interpretations of cognitive or sensory triggers to prevent deficit-based framing during interactions.
- Empirical results indicate that AI-mediated interpretation helps users maintain a mutual understanding of communication challenges and improves interaction efficiency compared to baseline chatbots.

---

[(Perlin) Noise as AI coordinator](http://arxiv.org/abs/2602.18947)

- Perlin-as-coordinator: introduces a general framework that utilizes coherent random fields as a lightweight basis for large-scale AI control in games, coordinating agent movement, action timing, and world structuring.
- The architecture includes behavior parameterization-, activation timing-, and type-feature generation-components to manage agent kinematics, scheduling, and world layouts.
- By substituting explicit agent communication with shared spatiotemporal noise signals, the framework achieves locally coherent yet globally de-locked behaviors with deterministic reproducibility and high runtime efficiency.

---

[Global Commander and Local Operative: A Dual-Agent Framework for Scene Navigation](http://arxiv.org/abs/2602.18941)

- DACo (Dual-Agent Collaboration): introduces a planning–grounding decoupled architecture that disentangles global deliberation from local grounding for vision-and-language scene navigation, with Global Commander (high-level strategic planning agent), Local Operative (egocentric grounding and execution agent), Dynamic Subgoal Planning (iterative intermediate landmark generation), Adaptive Replanning (trajectory correction mechanism), Top-down View (global spatial layout representation), and Local Observation (panoramic visual context).
- The framework employs a Global Commander to maintain long-term consistency via top-down maps while a Local Operative handles fine-grained execution and environment description.
- This dual-agent approach mitigates cognitive overload in LLs, achieving significant performance gains in zero-shot long-horizon navigation benchmarks.

---

[DREAM: Deep Research Evaluation with Agentic Metrics](http://arxiv.org/abs/2602.18940)

- DREAM (Deep Research Evaluation with Agentic Metrics): introduces an agentic evaluation framework for Deep Research Agents that enforces capability parity by using tool-calling agents to construct and execute query-adaptive evaluation protocols.
- The system utilizes a two-phase workflow consisting of Protocol Creation, where a CodeAgent generates adaptive metrics like Key-Information Coverage and Reasoning Quality, and Protocol Execution, which routes metrics to specialized LLM, agentic, or workflow-based evaluators.
- By incorporating external tool use and active reasoning, the framework effectively detects factual errors, temporal obsolescence, and logical flaws that static LLM-as-a-judge benchmarks often overlook.

---

[A potentialization algorithm for games with applications to multi-agent learning in repeated games](http://arxiv.org/abs/2602.18925)

- Potentialization algorithm: introduces a method to approximate any normal form game with an ordinal potential game, utilizing a nonnegative deviation graph, condensation graph, and topological sorting to create a surrogate reward structure.
- The approach replaces original reward functions with an ordinal potential function to guarantee convergence to stable agent behavior in multi-agent reinforcement learning scenarios.
- Numerical simulations using replicator dynamics and Q-learning demonstrate that the algorithm ensures fast convergence with minimal reward distortion across various game sizes.

---

[Why Agent Caching Fails and How to Fix It: Structured Intent Canonicalization with Few-Shot Learning](http://arxiv.org/abs/2602.18922)

- W5H2 (Structured Intent Decomposition Framework): introduces a five-tier cascade architecture for personal AI agent caching, utilizing Query Fingerprint, Supervised Classifier, SetFit Classification, Cheap LLM, and Deep Agent components to reduce API costs and latency.

- The framework reframes agent caching as a canonicalization problem, decomposing queries into structured fields where the (What, Where) pair forms a stable cache key while parameters are extracted separately.

- The system achieves significant cost reductions by handling 85% of interactions locally through a hierarchy of deterministic and few-shot models before falling back to expensive LLMs.


---

[DeepInnovator: Triggering the Innovative Capabilities of LLMs](http://arxiv.org/abs/2602.18920)

- DeepInnovator: introduces a training framework designed to stimulate the autonomous generation of research ideas in LLMs through automated scientific knowledge synthesis and an iterative "Next Idea Prediction" paradigm that includes agent-, comment-, and reward-LLMs.
- The system utilizes a hierarchical abstraction pipeline to extract structured research signals like insight and serendipity from unlabeled scientific corpora to ground the generation process in a comprehensive research context.
- It employs a decoupled architecture separating semantic feedback from outcome evaluation to prevent reward hacking during reinforcement learning with process-oriented delta rewards that quantify incremental cognitive progress.

---

[VariBASeD: Variational Bayes-Adaptive Sequential Monte-Carlo Planning for Deep Reinforcement Learning](http://arxiv.org/abs/2602.18857)

- VariBASeD (Variational Bayes-Adaptive Sequential Monte-Carlo Planning for Deep Reinforcement Learning): introduces a framework that coalesces variational belief learning, sequential Monte-Carlo planning, and meta-reinforcement learning to approximate Bayes-optimal agents.
- The architecture utilizes an S5 state-space model backbone to handle long-range history dependence with O(log n) training complexity, enabling efficient single-GPU parallelization.
- The framework employs an Expectation-Maximization style optimization where high-quality planning targets from the SMC planner are distilled into policy and value networks to improve sample efficiency.

---

#### 20th February 2026

[SARAH: Spatially Aware Real-time Agentic Humans](http://arxiv.org/abs/2602.18432)

- SARAH (Spatially Aware Real-time Agentic Humans): introduces a real-time, fully causal framework for generating spatially-aware conversational motion, with Causal Transformer-based VAE Encoder, Causal Transformer-based VAE Decoder, Transformer-based Flow Matching Model, Gaze Guidance Mechanism, Euclidean Surface-Point Representation, Dialogue LLM, and Speech Synthesis Model.
- The system decouples learning from control by using a flow matching model conditioned on dyadic audio and user trajectory to generate motion latents within a causal VAE space.
- It employs a novel Euclidean joint representation and a classifier-free gaze scoring mechanism to enable user-adjustable eye contact while maintaining naturalistic spatial alignment.

---

[SMaRT: Online Reusable Resource Assignment and an Application to Mediation in the Kenyan Judiciary](http://arxiv.org/abs/2602.18431)

- SMaRT (Selecting Mediators that are Right for the Task): introduces an online resource allocation framework for judicial mediation that combines econometric value-added estimation with a quadratic programming formulation to optimize case resolution rates under soft capacity constraints.
- The system utilizes a multi-agent bandit approach with Bayesian posterior updates to learn mediator quality while employing shadow cases to account for the opportunity cost of assigning high-performing resources to current tasks.
- Evaluated on real-world data from the Kenyan judiciary, the algorithm demonstrates a tunable trade-off between maximizing successful settlements and maintaining equitable mediator workloads through a quadratic penalty parameter.

---

[RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering](http://arxiv.org/abs/2602.18425)

- RVR (Retrieve-Verify-Retrieve): introduces a multi-round retrieval framework designed to maximize answer coverage for queries with multiple valid answers, utilizing an initial retriever, an LLM-based verifier, and a subsequent retriever.
- The framework iteratively augments the search query with previously verified documents to uncover missing information and reduce redundancy across retrieval rounds.
- RVR achieves higher complete recall on multi-answer benchmarks like QAMPARI and generalizes effectively to out-of-domain datasets compared to agentic search baselines.

---

[ROBO-SABER: Generating and Simulating Virtual Reality Players](http://arxiv.org/abs/2602.18319)

- Robo-Saber: introduces a motion generation system for playtesting virtual reality games, with Game State (current in-game object configuration), 3p History (previous headset and controller poses), Style Encoder (embeds contextual gameplay reference segments), Game Segment Encoder (predicts categorical logits from state), 3p Encoder (maps future poses to logits), 3p Decoder (reconstructs trajectories from sampled logits), GS-VAE (latent space for motion generation), TorchSaber (GPU-accelerated kinematic gameplay evaluator), and Physics-based Tracking Policy (actuates whole-body movements from 3p).
- The framework utilizes a reference-conditioned Categorical Codebook Matching model to generate diverse candidate motion plans aligned with gameplay objectives.
- It enables personalized score prediction and automated testing of game content by emulating diverse player skill levels and movement patterns.

---

[ReqElicitGym: An Evaluation Environment for Interview Competence in Conversational Requirements Elicitation](http://arxiv.org/abs/2602.18306)

- ReqElicitGym (An Evaluation Environment for Interview Competence in Conversational Requirements Elicitation): introduces an interactive and automatic evaluation environment for assessing the interview competence of LLMs in conversational requirements elicitation, with Evaluation Dataset, Oracle User, Task Evaluator, Evaluated Interviewer, and Metrics.
- The framework includes oracle user- and task evaluator-LLMs to simulate stakeholder interactions and provide objective, process-aware performance assessments.
- The environment utilizes a dataset of 101 scenarios to evaluate how effectively agents uncover implicit requirements through multi-turn clarification and probing strategies.

---

[Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](http://arxiv.org/abs/2602.18291)

- OMAD (Online off-policy MARL framework using Diffusion policies): introduces an online multi-agent reinforcement learning framework that includes decentralized diffusion policies and a centralized distributional critic to facilitate coordinated exploration in high-dimensional action spaces.
- The architecture employs a relaxed policy objective based on a tractable joint entropy evidence lower bound to facilitate effective exploration without requiring exact likelihood computation.
- It integrates a synchronized update strategy and an auto-tuning temperature mechanism within the centralized training with decentralized execution paradigm to ensure stable convergence and superior sample efficiency.

---

[Efficient Calculation of Absorption Spectra of Platinum Complexes Used as Luminescent Probes for Cancer Detection](http://arxiv.org/abs/2602.18284)

- Computational Protocol: introduces a benchmarked workflow for calculating absorption properties of platinum-based cancer probes, with all Isolated Pt(II) Complex (luminescent transition metal probe model), Intercalated DNA Model (biomolecular target environment simulation), Structure Optimization Module (geometry refinement using DFT methods), TD-DFT Response Engine (excited state and intensity calculation), Relativistic Treatment (X2C Hamiltonian and SOC inclusion), Acceleration Approximations (TDA and RI speedup techniques), and Functional Selection (exchange-correlation functional benchmarking)-components.
- The study identifies PBEh-3c as an efficient alternative for geometry optimization and recommends range-separated hybrids like LC-PBE for robust spectral predictions of metal-ligand charge transfer transitions.
- It demonstrates that incorporating spin-orbit coupling is essential for these complexes while TDA and RI approximations provide significant computational speedups with minimal accuracy loss.

---

[PRISM: Parallel Reward Integration with Symmetry for MORL](http://arxiv.org/abs/2602.18277)

- PRISM (Parallel Reward Integration with Symmetry for Multi-Objective Reinforcement Learning): introduces a framework for heterogeneous multi-objective reinforcement learning that aligns reward channels with varying temporal frequencies by enforcing reflectional symmetry as an inductive bias.
- The system utilizes ReSymNet, a residual-based reward model, to approximate scaled opportunity values and transform sparse long-horizon rewards into dense, per-step signals.
- It incorporates SymReg, a symmetry regularizer that constrains policy search to a reflection-equivariant subspace, reducing hypothesis complexity and enhancing generalization across MuJoCo benchmarks.

---

[A Probabilistic Framework for LLM-Based Model Discovery](http://arxiv.org/abs/2602.18266)

- ModelSMC (Sequential Monte Carlo for Model Discovery): introduces a probabilistic framework that recasts automated model discovery as Bayesian inference over executable programs, using LLMs as proposal distributions within a Sequential Monte Carlo algorithm.

- The system iteratively refines a population of candidate models represented as particles, weighting them by their likelihood under observed data and resampling to concentrate on high-posterior regions.

- It incorporates LLM-generated contextual feedback and neural likelihood estimation to handle non-differentiable models and intractable likelihoods across scientific domains including pharmacology and neuroscience.


---

[Role-Adaptive Collaborative Formation Planning for Team of Quadruped Robots in Cluttered Environments](http://arxiv.org/abs/2602.18260)

- Role-Adaptive Collaborative Formation Planning Framework: introduces a dynamic leader-follower architecture for quadruped robot teams, utilizing Global Path Planner, Dynamic Role Assignment, Partial Goal Generator, Virtual Spring-Damper System, Obstacle Avoidance Layer, and Velocity Modifiers to navigate cluttered environments.
- The system employs the Fast Marching Square algorithm for path generation and a look-ahead mechanism that allows temporary formation deformation to bypass obstacles.
- Inter-robot safety and formation stability are maintained through virtual physical connections and an obstacle avoidance layer based on Unsigned Distance Fields.

---

[[Re] Benchmarking LLM Capabilities in Negotiation through Scoreable Games](http://arxiv.org/abs/2602.18230)

- Scoreable Games: introduces a reproduction and extension of a multi-agent negotiation benchmark evaluating LLM cooperation and competition, with Negotiating Agents, Utility Functions, Acceptance Thresholds, Round-based Discussion, Veto Mechanism, Behavioral Prompts, Social Welfare Metrics, and Leakage Detection Logic, including cooperative-, greedy-, and adversarial-agents.
- The framework evaluates the ability of LLMs to reach consensus through role-based dialogue while managing hidden preferences and conflicting individual objectives.
- The study identifies limitations in original experimental setups, refines leakage detection, and introduces social welfare metrics to assess fairness and efficiency in automated negotiations.

---

[Can AI Lower the Barrier to Cybersecurity? A Human-Centered Mixed-Methods Study of Novice CTF Learning](http://arxiv.org/abs/2602.18172)

- CAI (Cybersecurity AI): introduces an agentic framework that integrates LLMs with traditional penetration testing tools to semi-automate reconnaissance, vulnerability analysis, and tool orchestration, utilizing agentic orchestration and human-in-the-loop strategic delegation within a CTF environment; it includes workflow-structuring, tool-orchestration, and step-by-step-support roles.
- The system facilitates novice entry into offensive security by providing strategic overview and mental mapping to reduce cognitive workload during complex multi-step attack chains.
- The study evaluates the impact of AI-mediated learning on performance, strategy exploration, and professional identity formation within Capture-the-Flag environments.

---

[Toward Automated Virtual Electronic Control Unit (ECU) Twins for Shift-Left Automotive Software Testing](http://arxiv.org/abs/2602.18142)

- Agentic Feedback-Driven Model Generation: introduces an automated workflow for synthesizing instruction-accurate virtual electronic control unit models, with coding LLM-based generation and deterministic differential testing.
- The architecture employs a two-loop calibration cycle that iteratively refines SystemC/TLM 2.0 models by comparing their architectural state against a reference simulator accessed via the GNU Debugger.
- This methodology reduces the technical risk of CPU behavioral fidelity in virtual platforms, enabling early software integration and safety-aligned fault-injection campaigns.

---

[Agentic Adversarial QA for Improving Domain-Specific LLMs](http://arxiv.org/abs/2602.18137)

- Agentic Adversarial QA: introduces an iterative, feedback-driven framework that generates a set of adversarial questions to improve domain-specific LLMs by targeting interpretive reasoning gaps, with Strong Model, Weak Model, Feedback Model, Guidance Model, Revision Model, Domain Context, Question Variable, Synthetic Dataset, and TextGrad Optimizer; it includes strong-, weak-, feedback-, guidance-, and revision-agents.
- The system utilizes a differentiable prompting paradigm to optimize a natural language question variable, maximizing the response divergence between an expert model and a smaller target model.
- Fine-tuning on the resulting adversarial synthetic dataset enables smaller models to achieve performance competitive with larger counterparts while using fewer training tokens than traditional augmentation strategies.

---

[Fair Orientations: Proportionality and Equitability](http://arxiv.org/abs/2602.18098)

- Orientation Model: introduces a graph-based framework for allocating indivisible items among agents under relevance constraints, where items are represented as edges and agents as vertices, with all Agents (participants as graph vertices), Items (indivisible goods or chores), Relevance Graph (structural constraints on allocation), Valuation Labels (numerical values for edges), Clause Gadgets (sub-graphs for logical clauses), and Variable Gadgets (sub-graphs for Boolean variables).
- The study investigates the existence and computational complexity of proportionality and equitability notions, proving that finding such orientations is generally NP-complete even for simple graphs.
- The authors establish existence results and polynomial-time algorithms for relaxations such as PROP1 and characterize the conditions for EF1 orientations in chore-based allocation scenarios.

---

[Dynamic Deception: When Pedestrians Team Up to Fool Autonomous Cars](http://arxiv.org/abs/2602.18079)

- Dynamic Deception (Collusive and Dynamic Pedestrian Attack): introduces a system-level adversarial attack where multiple pedestrians coordinate motion and spatial alignment to amplify adversarial patches printed on clothing, with Adversarial Pedestrians (dynamic carriers of adversarial signals), Adversarial Patches (visually disguised stop-sign patterns), Surrogate Model (YOLOv5 for black-box training), Target Autonomous Agent (Simlingo agent with LLM-based interpretation), Coordination Logic (spatial alignment and motion synchronization), and CARLA Simulator (autonomous driving simulation environment).
- The framework employs a black-box training strategy using a surrogate YOLOv5 model to generate stop-sign perturbations disguised as camellia flowers to maintain visual concealment from human observers.
- Evaluation against the Simlingo agent shows that the system, which utilizes an LLM for visual interpretation, is successfully misled into executing full stops only when adversarial signals persist through synchronized pedestrian movement.

---

[3DMedAgent: Unified Perception-to-Understanding for 3D Medical Analysis](http://arxiv.org/abs/2602.18064)

- 3DMedAgent (Unified Perception-to-Understanding for 3D Medical Analysis): introduces a unified agentic framework that enables 2D MLLMs to perform general 3D CT analysis by coordinating heterogeneous visual and textual tools through a multi-step reasoning process.
- The architecture includes tool-calling, organ initialization, volume cropping, lesion targeting, evidence integration, result summary, slice/tool selection, and memory selection agents.
- The framework utilizes the DeepChestVQA benchmark to evaluate perception-to-understanding capabilities in 3D

---

[Towards More Standardized AI Evaluation: From Models to Agents](http://arxiv.org/abs/2602.18029)

- AI Evaluation Framework: introduces a systematic methodology for measuring agentic system behavior, with Risk Assessment (identifying potential harms and severity), Evaluation Requirements (defining measurable conditions and thresholds), Evaluation Harness (infrastructure orchestrating agent tool loops), Evaluation Graders (includes code-based, LLM-based, and human-graders), Evaluation Transcripts (complete record of reasoning steps), Evaluation Outcomes (final environmental state changes), and Governance Decisions (deployment, rollback, or escalation actions).
- The approach shifts evaluation from downstream verification to a core system function that utilizes deterministic code-based graders, probabilistic model-based judges, and human calibration.
- The research emphasizes the use of simulated environments and reliability metrics like Pass^k to assess autonomous agents operating in stateful, non-deterministic worlds.

---

[Mean-Field Reinforcement Learning without Synchrony](http://arxiv.org/abs/2602.18026)

- TMF (Temporal Mean Field): introduces a mean-field reinforcement learning framework centered on the population distribution to enable scalable multi-agent decision-making under asynchronous and sequential protocols.
- The framework formalizes population dynamics through a deterministic recursion and defines a self-consistent equilibrium that remains well-defined regardless of the number of active agents per step.
- Theoretical analysis establishes a finite-population approximation bound of O(1/sqrt(N)) and proves the convergence of the TMF-PG algorithm to a unique equilibrium.

---

[NIMMGen: Learning Neural-Integrated Mechanistic Digital Twins with LLMs](http://arxiv.org/abs/2602.18008)

- NIMMGen: introduces an agentic framework for neural-integrated mechanistic modeling that enhances code correctness and practical validity through iterative refinement, with data-, modeling-, verification-, and reflection-agents, an environment engine, memory, and a code RAG database.
- The architecture utilizes a self-evolving optimization loop to progressively refine model specifications and address challenges in partial observation and diversified task objectives.
- The framework incorporates an error-handling module and a retrieval-augmented generation tool to mitigate runtime failures and ensure the scientific grounding of generated digital twins.

---

[Aurora: Neuro-Symbolic AI Driven Advising Agent](http://arxiv.org/abs/2602.17999)

- Aurora: introduces a modular neuro-symbolic framework for academic advising with a PostgreSQL Knowledge Base, an Intent & NER Service, a SQL Router, a Prolog Reasoner, a CoT Controller, and an LLM Core Module, delivering policy-compliant and verifiable course recommendations by unifying retrieval-augmented generation with symbolic reasoning.
- The architecture utilizes a BCNF-normalized database and a Prolog engine to enforce strict academic constraints, ensuring that all generated advice adheres to institutional policies and prerequisite structures.
- Empirical evaluation demonstrates that the framework significantly outperforms raw LLM baselines in semantic alignment and precision while achieving sub-second latency on commodity hardware.

---

[WORKFLOWPERTURB: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics](http://arxiv.org/abs/2602.17990)

- WORKFLOWPERTURB: introduces, a controlled benchmark for evaluating workflow metrics, with golden workflows, a perturbation engine, a validation module, an evaluation metric suite, and an LLM-as-judge.
- The framework utilizes LLM-based perturbation- and judgment-components to generate variants across missing steps, compressed steps, and description changes at multiple severity levels.
- It evaluates structural, lexical, semantic, and judgment-based metrics to characterize their sensitivity and calibration for multi-agent system validation.

---

[Learning Optimal and Sample-Efficient Decision Policies with Guarantees](http://arxiv.org/abs/2602.17978)

- DML-CMR (Double Machine Learning for Conditional Moment Restrictions): introduces a sample-efficient framework for learning optimal decision policies from confounded datasets, with DML-CMR (solves conditional moment restrictions), DML-IL (performs causal imitation learning), KC (learns temporal logic objectives), nuisance parameter estimators (estimates conditional expectations), a Neyman orthogonal score function (debiasing objective), a cross-fitting regime (data splitting for robustness), a roll-out model (predicts transition dynamics), an expert model (imitates policy), a product MDP (synchronizes environment and logic), an LDBA (automaton for LTL), a K-counter (tracks accepting state visits), and counterfactual imagining (generates synthetic experiences).
- The framework addresses hidden confounders in offline reinforcement learning and imitation learning by leveraging instrumental variables and trajectory histories as causal instruments to identify true effects.
- The methodology extends to high-level objectives by transforming linear temporal logic specifications into limit-deterministic Buchi automata within a synchronized product MDP featuring a generalized reward structure.

---

[Mining Type Constructs Using Patterns in AI-Generated Code](http://arxiv.org/abs/2602.17955)

- Dataset Filtering Framework: introduces a hierarchical two-stage pipeline to analyze type-related patterns in AI-generated code, with rule-based regex parsers, a multi-agent LLM system, a classifier agent, and a validator agent.

- The multi-agent LLM system includes classifier- and validator-agents that process pull request titles, descriptions, and code patches to identify specific TypeScript type constructs and anti-patterns.

- The research demonstrates that AI agents are 9x more likely than humans to use the 'any' keyword and frequently employ type-safety escape hatches, despite achieving higher pull request acceptance rates.


---

[Graph-Neural Multi-Agent Coordination for Distributed Access-Point Selection in Cell-Free Massive MIMO](http://arxiv.org/abs/2602.17954)

- APS-GNN (Access-Point Selection Graph Neural Network): introduces a scalable distributed multi-agent learning framework for cell-free massive MIMO, utilizing GRU encoders, GNN layers, and dual critics to coordinate binary connection decisions across individual AP-UE agents.
- The system employs a constrained reinforcement learning formulation where spectral efficiency violations are treated as costs and power reduction as rewards, managed by an adaptive Lagrangian multiplier to optimize network performance.
- The architecture utilizes structured message passing over same-UE and same-AP edges to enable spatial coordination and interference management without requiring global state aggregation or centralized control.

---

[Analyzing LLM Instruction Optimization for Tabular Fact Verification](http://arxiv.org/abs/2602.17937)

- DSPy (Declarative Self-improving Language Programs): introduces a systematic comparison of instruction optimization for tabular fact verification, utilizing COPRO, MiPROv2, and SIMBA to enhance LLM reasoning performance without gradient updates.
- The framework evaluates text-only prompting against tool-augmented agents, including SQL-executing ReAct and Python-executing CodeAct modules, across multiple model families and benchmarks.
- Experimental results show that MiPROv2 stabilizes Chain-of-Thought gains while SIMBA optimizes agentic behavior by reducing redundant tool calls and improving numerical comparison heuristics.

---

[Memory-Based Advantage Shaping for LLM-Guided Reinforcement Learning](http://arxiv.org/abs/2602.17931)

- Memory-Based Advantage Shaping: introduces a reinforcement learning framework that utilizes a memory graph, LLM, RL agent, utility computation, and advantage shaping to guide exploration in sparse-reward environments.
- The system calculates a utility signal based on trajectory alignment with the memory graph to augment the advantage function, providing the policy with external guidance without modifying the reward structure.
- By combining offline priors with adaptive online LLM queries, the method enhances sample efficiency and early-stage learning while preserving the convergence properties of Proximal Policy Optimization.

---

[MIRA: Memory-Integrated Reinforcement Learning Agent with Limited LLM Guidance](http://arxiv.org/abs/2602.17930)

- MIRA (Memory-Integrated Reinforcement Learning Agent): introduces a reinforcement learning framework that incorporates a structured memory graph to amortize LLM queries into persistent knowledge for guiding exploration in sparse-reward environments.
- The architecture includes offline- and online-guidance LLMs, a screening unit for hallucination reduction, and a utility module that generates shaping signals to refine policy updates without altering the underlying reward function.
- By decaying the influence of LLM-derived priors as the agent's policy matures, the framework maintains autonomous decision-making and ensures convergence to optimal behavior while requiring substantially fewer online queries.

---

[Robust Temporal Guarantees in Budgeted Sequential Auctions](http://arxiv.org/abs/2602.17916)

- Primal Budget Pacing Algorithm: introduces a deterministic bid adjustment mechanism for budgeted sequential auctions that ensures robust win guarantees against adversarial behavior, with Primal Budget Pacing Algorithm, Learner, Optimizer, Auction Environment, Budget Management, and Deterministic Update Rule components.
- The algorithm guarantees that an agent with a specific budget fraction secures a proportional share of total wins minus a sublinear regret term, even under adversarial competition.
- In multi-agent settings, the dynamics converge to a low-discrepancy distribution of wins, achieving temporal spacing and round-robin outcomes in equal-budget scenarios.

---

[From Lossy to Verified: A Provenance-Aware Tiered Memory for Agents](http://arxiv.org/abs/2602.17913)

- TierMem (Provenance-Aware Tiered Memory): introduces a provenance-linked two-tier memory hierarchy that optimizes the accuracy-efficiency trade-off by dynamically allocating evidence at inference time, including router-, planner-, extractor-, and generator-LLMs.
- The architecture defaults to a fast summary index and employs a lightweight router to escalate to immutable raw logs only when summary evidence is insufficient for a faithful answer.
- Explicit provenance links guide deep retrieval while online consolidation writes verified findings back to the summary tier to amortize future query costs and reduce latency.

---

[Alignment in Time: Peak-Aware Orchestration for Long-Horizon Agentic Systems](http://arxiv.org/abs/2602.17910)

- APEMO (Affect-aware Peak-End Modulation for Orchestration): introduces a runtime scheduling layer that optimizes computational allocation under fixed budgets by operationalizing temporal-affective signals, with Multi-Agent Execution, Planner-Agent, Executor-Agent, Critic-Agent, Frustration Monitor, Peak Detection, Precision Repair Trigger, Budget Reallocation, Cost Accounting, and Budget Constraint.
- The system monitors behavioral proxies such as repetition and context drift to detect negative peaks, reallocating inference precision to stabilize critical trajectory segments and endings.
- Experimental results across multi-agent simulations and planner-executor flows demonstrate improved trajectory-level robustness and reuse probability compared to uniform budget allocation strategies.

---

[The Chemical Homogeneity of Single-Lined Spectroscopic Binaries in Open Clusters](http://arxiv.org/abs/2602.18552)

- Analysis Pipeline (The Joker, UltraNest, and BACCHUS): introduces a multi-stage methodology for measuring the impact of close binarity on surface chemistry by integrating SDSS-V APOGEE (near-infrared spectroscopic data source), The Joker (Monte Carlo orbital sampler), UltraNest (nested sampling orbital corroborator), BACCHUS (automated spectral synthesis code), ASPCAP (stellar parameter pipeline), Astra (stellar metadata pipeline), Gaia DR3 (astrometric data source), and MIST (evolutionary isochrone models).
- The framework utilizes Gaia DR3 and MIST to identify single-lined spectroscopic binaries within open clusters and compare their chemical abundances to non-binary counterparts.
- The analysis reveals that while most binaries are chemically homogeneous with single stars, a subset with UV excess shows [C/N] enhancement, suggesting pollution from evolved companions.

---

#### 19th February 2026

[OpenEarthAgent: A Unified Framework for Tool-Augmented Geospatial Agents](http://arxiv.org/abs/2602.17665)

- OpenEarthAgent: introduces a unified agentic framework for developing tool-augmented geospatial agents with User Input (multimodal geospatial queries), Geo-Reasoning Engine (LLM-based reasoning controller), Orchestrator (manages tool calls and feedback), Short-term Working Memory (stores reasoning history and data), Tool Execution Cache Memory (reusable geospatial archives and layers), External Tools (specialized GIS and perceptual operators), and Core (central agentic loop) components, facilitating organized multi-step geospatial reasoning.
- The framework utilizes a specialized LLM-based reasoning engine to orchestrate a diverse registry of perceptual, GIS computation, spectral, and georeferenced raster tools.
- It includes a comprehensive multimodal corpus of over 14,000 training instances with detailed reasoning traces to align models with verified multi-step tool interactions across diverse earth observation contexts.

---


[From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences](http://arxiv.org/abs/2602.17221)

- Agentic Workflow (AI Agent-based collaborative research workflow): introduces a seven-stage modular research framework for humanities and social sciences, with specialized agents for literature collection, analysis, data exploration, statistical analysis, and academic writing, and a human-in-the-loop quality gate system.
- The framework utilizes three operational modes—direct execution, iterative refinement, and human-led—to balance AI's execution speed with the irreplaceability of human contextual reasoning.
- By integrating negative constraints and Git-based version control, the methodology ensures verifiability and mitigates LLM hallucination risks during complex academic tasks.



[FAMOSE: A ReAct Approach to Automated Feature Discovery](http://arxiv.org/abs/2602.17641)

- FAMOSE (Feature AugMentation and Optimal Selection agEnt): introduces an agentic framework for automated feature engineering that utilizes the ReAct paradigm to iteratively hypothesize, generate, and refine features based on empirical model performance.
- The system integrates a metadata generator, a Python code compiler, and a feature evaluation tool to allow the LLM to interact directly with tabular data and learn from previous successes or failures recorded in its context window.
- After the iterative discovery phase, the framework employs a minimal-redundancy maximal-relevance (mRMR) algorithm to select a compact and optimal set of features, achieving state-of-the-art results on various classification and regression tasks.

---

[What Makes a Good LLM Agent for Real-world Penetration Testing?](http://arxiv.org/abs/2602.17622)

- PENTESTGPT V2 (Penetration Testing GPT version 2): introduces an LLM-based automated penetration testing agent that addresses capability gaps and complexity barriers through difficulty-aware planning and structured state management.
- The framework utilizes a Task Difficulty Assessment (TDA) mechanism to guide an Evidence-Guided Attack Tree Search (EGATS), enabling the agent to dynamically pivot between reconnaissance and exploitation based on real-time tractability signals.
- It incorporates a Tool & Skill Layer with typed interfaces and a Memory Subsystem to maintain long-term state, significantly improving performance on multi-step attack chains in complex environments like Active Directory.

---

[AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing](http://arxiv.org/abs/2602.17607)

- AutoNumerics: introduces an autonomous multi-agent framework that utilizes LLMs to design, implement, and verify transparent numerical solvers for partial differential equations from natural language descriptions, featuring Formulator-, Planner-, Feature-, Selector-, Coder-, Critic-, and Reasoning-agents.
- The system utilizes a coarse-to-fine execution strategy to decouple logic debugging on low-resolution grids from stability validation on high-resolution grids.
- It incorporates a residual-based self-verification mechanism to assess solver correctness in the absence of analytical solutions and a history decimation mechanism for memory-efficient temporal simulations.

---

[BMC4TimeSec: Verification Of Timed Security Protocols (Demo)](http://arxiv.org/abs/2602.17590)

- BMC4TimeSec: introduces an end-to-end verification tool for Timed Security Protocols by integrating multi-agent Timed Interleaved Interpreted Systems with SMT-based bounded model checking.
- The system utilizes a modular pipeline that transforms Alice-Bob notation and JSON interpretations into formal automata and SMT-LIB2 formulas for automated analysis via the Z3 solver.
- It supports complex attack scenarios including session interleaving, message replays, and time-dependent vulnerabilities through a user-friendly Flask-based graphical interface.

---

[Modeling Distinct Human Interaction in Web Agents](http://arxiv.org/abs/2602.17588)

- PLOWPILOT: introduces an intervention-aware web navigation framework that utilizes a Large Multimodal Model to predict when and why human users will intervene during task execution.
- The system leverages COWCORPUS, a dataset of 400 real-user trajectories, to train style-conditioned models that adapt to distinct collaboration patterns like takeover or hands-on oversight.
- Experimental results demonstrate that modeling human intervention timing significantly improves agent usefulness and reduces unnecessary interruptions in collaborative web environments.

---

[RETOUCHIQ: MLLM Agents for Instruction-Based Image Retouching with Generalist Reward](http://arxiv.org/abs/2602.17558)

- RETOUCHIQ: introduces an instruction-based image retouching framework that utilizes MLLM agents guided by a generalist reward model to translate high-level aesthetic intentions into precise, executable tool-use parameters.
- The architecture employs a two-stage training pipeline featuring supervised fine-tuning for reasoning traces and reinforcement learning via a reward critic that provides scalar feedback through multimodal reasoning.
- The framework implements Policy-Guided Reward Training to mitigate distribution shifts between synthetic perturbations and actual policy outputs, enhancing both semantic consistency and perceptual quality in professional editing software.

---

[KLong: Training LLM Agent for Extremely Long-horizon Tasks](http://arxiv.org/abs/2602.17547)

- KLong: introduces an open-source LLM agent framework designed to solve extremely long-horizon tasks through a cold-start trajectory-splitting SFT phase followed by progressive RL scaling, utilizing Research-Factory, trajectory-splitting SFT, progressive RL, search-, evaluation- and judge-agents, a secure sandbox, and optimized scaffolding.
- The system utilizes Research-Factory to automate the collection of research papers and the construction of evaluation rubrics, generating high-quality trajectories distilled from advanced reasoning models.
- The training approach addresses context window limitations by decomposing long trajectories into overlapping sub-trajectories and employs a multi-stage RL schedule with increasing timeouts to improve task-solving stability.

---

[ADAPTIVE DECENTRALIZED COMPOSITE OPTIMIZATION VIA THREE-OPERATOR SPLITTING](http://arxiv.org/abs/2602.17545)

- DATOS (Decentralized Adaptive Three Operator Splitting): introduces a parameter-free decentralized optimization framework for composite problems, with DATOS, Communication Step, Decentralized Line-search, Min-consensus, Primal-dual Updates, Tracking Variables, and BCV Metric.
- The framework leverages a Davis-Yin three-operator splitting applied to a BCV-type reformulation to enable local backtracking stepsize updates using only single-hop communications.
- It establishes sublinear convergence for convex losses and linear convergence for strongly convex losses with partly smooth nonsmooth components without requiring global network information.

---

[Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability](http://arxiv.org/abs/2602.17544)

- Thinker-Executor framework: introduces a method to decouple Chain-of-Thought generation from execution, evaluating reasoning quality through reusability and verifiability metrics rather than just final answer accuracy.

- The system utilizes a committee of Executor models to measure how effectively a Thinker's reasoning trace can persuade an independent model to correct its answer or be misled by corrupted logic.

- Experimental results demonstrate that specialized reasoning models do not necessarily produce more reusable or verifiable reasoning traces than general-purpose LLMs, highlighting a disconnect in current accuracy-based benchmarks.


---

[TOWARD A FULLY AUTONOMOUS, AI-NATIVE PARTICLE ACCELERATOR](http://arxiv.org/abs/2602.17536)

- Natively-AI Particle Accelerator: introduces a vision for self-driving facilities designed from inception with AI as the primary operator, with agentic AI architecture, integrated knowledge bases, learning and adaptive control, simulation and digital twins, automated health monitoring, safety and transparency frameworks, modular hardware, multimodal data fusion, and cross-domain collaboration.
- The framework proposes a transition from current AI-assisted operations through AI-augmented collaboration to a final AI-autonomous stage where humans provide strategic oversight.
- The architecture incorporates LLM-driven planning, reasoning, and assistant agents to manage machine complexity at speed while ensuring safety through digital twin validation and explainable decision-making.

---

[A Picture of Agentic Search](http://arxiv.org/abs/2602.17518)

- ASQ (Agentic Search Queryset): introduces a methodology for systematically logging the search behaviors of agentic RAG systems by intercepting retrieval calls and decoding processes to capture synthetic queries, retrieved documents, and reasoning steps.
- The architecture implements a multi-turn reasoning loop between a generator LLM and a retriever, utilizing XML-style control tags to coordinate autonomous reasoning-, query formulation-, and answer generation-agents.
- The resulting dataset enables the evaluation of information retrieval systems against machine-generated query streams, which exhibit higher volumes and different reformulation patterns compared to organic human search traffic.

---

[Retrospective In-Context Learning for Temporal Credit Assignment with Large Language Models](http://arxiv.org/abs/2602.17497)

- RICOL (Retrospective In-Context Online Learning): introduces an online reinforcement learning framework that transforms sparse environmental feedback into dense supervision signals by leveraging LLMs for retrospective in-context learning, with Actor LLM, Reflector LLM, Environment, In-context Updated Policy, Advantage Function Estimator, and Policy Optimizer; it includes actor- and reflector-LLMs.
- The system employs a reflector LLM to analyze hindsight trajectories and provide corrective verbal feedback for individual actions, enabling fine-grained temporal credit assignment.
- It estimates advantage functions by calculating the discrepancy between the log-probabilities of the base policy and its in-context refined version, improving sample efficiency in multi-turn tasks.

---

[Linear Convergence in Games with Delayed Feedback via Extra Prediction](http://arxiv.org/abs/2602.17486)

- WOGDA (Weighted Optimistic Gradient Descent-Ascent): introduces a predictive optimization framework for unconstrained bilinear games that achieves linear convergence under delayed feedback, with WOGDA (iterative optimization algorithm), EPP (implicit approximation method), Delayed Feedback Mechanism (fixed reward observation latency), Extra Prediction Module (future reward extrapolation), and Strategy Update Rule (weighted cumulative reward calculation).
- The framework utilizes the Extra Proximal Point (EPP) method to establish that predicting rewards farther into the future permits larger step sizes and accelerates convergence.
- Theoretical analysis establishes that extra prediction accelerates the convergence rate from exp(-Θ(t/m^5)) to exp(-Θ(t/(m^2 log m))) for a feedback delay of m steps.

---

[What Do LLMs Associate with Your Name? A Human-Centered Black-Box Audit of Personal Data](http://arxiv.org/abs/2602.17483)

- LMP2 (Language Model Privacy Probe): introduces a browser-based, human-centered audit tool designed to evaluate personal data associations within black-box LLMs through iterative user testing and a WikiMem-based backend.
- The system employs a multi-stage pipeline including paraphrased canary templates, prefix-based ground-truth truncation, and counterfactual generation to compute association strength and confidence scores for 50 human-related properties.
- Research findings indicate that GPT-4o can confidently generate 11 personal attributes for everyday users with high accuracy, highlighting privacy risks and user demand for data rectification and erasure rights.

---

[A variational mean field game of controls with free final time and pairwise interactions](http://arxiv.org/abs/2602.17447)

- NAG (Non-Atomic Game with pairwise interactions): introduces a variational framework for mean field games where agents minimize individual and pairwise interaction costs over abstract Polish spaces with free final time.
- The model characterizes equilibria as critical points of a potential functional, ensuring existence through the minimization of this functional.
- The framework is applied to crowd motion models with Cucker-Smale type interactions, incorporating velocity-dependent costs and target-set arrival criteria.

---

[WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation](http://arxiv.org/abs/2602.17442)

- WarpRec: introduces a modular, backend-agnostic framework for recommender systems, with Reader, Data Engine, Recommendation Engine, Evaluation, Writer, Application Layer, Narwhals, Ray, and CodeCarbon components.
- The architecture utilizes Narwhals to abstract data backends and Ray to facilitate seamless transitions from local prototyping to large-scale distributed training on multi-GPU clusters.
- It incorporates CodeCarbon for sustainable AI profiling and natively implements the Model Context Protocol to transform recommenders into queryable agents for LLMs.

---

[Multi-Agent Temporal Logic Planning via Penalty Functions and Block-Coordinate Optimization](http://arxiv.org/abs/2602.17434)

- BCGD-PM (Block-Coordinate Gradient Descent - Penalty Method): introduces a scalable optimization-based framework for multi-agent Signal Temporal Logic planning by relaxing coupled collaborative constraints into an unconstrained problem using quadratic penalty functions.
- The architecture utilizes a two-layer optimization scheme where an inner loop performs block-coordinate gradient descent on agent-specific decision variables and an outer loop updates penalty parameters to ensure specification satisfaction.
- By integrating smooth robustness metrics with separable objective functions, the method enables parallelized computations that remain computationally efficient even as the number of agents and complexity of collaborative tasks increase.

---

[Distributed Virtual Model Control for Scalable Human-Robot Collaboration in Shared Workspace](http://arxiv.org/abs/2602.17415)

- VMC (Virtual Model Control): introduces a decentralized, agent-agnostic framework for human-robot collaboration using goal and avoidance springs, unilateral saturating dampers, a force-based stall detector, a conflict resolution layer, VMRobotControl.jl, and a perception system to regulate motion without explicit trajectory planning.
- The architecture utilizes virtual mechanical components to generate interaction forces and a biased-draw prioritization negotiation to resolve deadlocks identified by force-balance metrics.
- Experimental validation with UR5 robots and humans demonstrates that the approach maintains consistent separation distances and scales to multi-agent scenarios without structural control modifications.

---

[COMPUTER-USING WORLD MODEL](http://arxiv.org/abs/2602.17365)

- CUWM (Computer-Using World Model): introduces a factorized world model for desktop productivity software that predicts future user interface states by separating semantic change descriptions from visual rendering, with a current UI state, candidate action, textual transition model, transition description, visual realization model, next UI state, LLM-based judge, and reinforcement learning refinement.
- The architecture includes a vision-language-based transition model, a diffusion-based realization model, and an LLM-based judge for reinforcement learning refinement.
- Evaluation via test-time action search demonstrates that simulating outcomes with CUWM improves the decision quality and robustness of frozen LLM agents in complex Office tasks.

---

[What Breaks Embodied AI Security: LLM Vulnerabilities, CPS Flaws, or Something Else?](http://arxiv.org/abs/2602.17345)

- Embodied AI Robot System Architecture: introduces a comprehensive analysis of security vulnerabilities in embodied systems, with Perception Layer, Decision and Reasoning Layer, Behavior Planning and Control Layer, Physical Robot Body & Environment, Multimodal Foundation Model, World Model, Sub-task chain, Motion Planning Algorithms, Dynamic Constraints, and Low-Level Motor Commands.
- The framework identifies that semantic correctness in LLMs does not imply physical safety due to the abstraction of geometry, dynamics, and contact constraints, and includes LLM-, VLM- and VLA-based reasoning modules.
- It systematizes threats across LLM-centric, CPS-centric, and embodiment-specific dimensions to reveal how small errors propagate and amplify in perception-decision-action loops.

---

[Flickering Multi-Armed Bandits](http://arxiv.org/abs/2602.17315)

- FMAB (Flickering Multi-Armed Bandits): introduces a sequential decision-making framework where action availability is constrained by a time-varying graph, with Arms, Evolving Graph, Learner, Lazy Random Walk, Navigation & Commitment, and Reward Distribution.
- The proposed two-phase algorithm utilizes a lazy random walk for exploration to identify the optimal arm, followed by a navigation phase to commit to that arm.
- Theoretical analysis provides sublinear regret bounds for i.i.d. Erdős–Rényi and Edge-Markovian graph models, validated by simulations in a disaster-response scenario.

---

[MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions](http://arxiv.org/abs/2602.17308)

- MedClarify: introduces an information-seeking AI agent that iteratively generates case-specific follow-up questions to reduce diagnostic uncertainty and refine differential diagnoses, with medical diagnosis, question generation, diagnostic simulations, diagnostic information gain, disease similarity mapping, and Bayesian update components.
- The system utilizes a novel Diagnostic Expected Information Gain (DEIG) metric to select questions that maximize entropy reduction while accounting for semantic proximity between diseases via ICD-11 mapping.
- Evaluation using an agentic framework with patient-, doctor-, update-, and evaluator-agents demonstrates significant accuracy improvements on incomplete patient cases across various LLM backbones.

---

[Visual Insights into Agentic Optimization of Pervasive Stream Processing Services](http://arxiv.org/abs/2602.17282)

- MUDAP (Multi-Dimensional Autoscaling Platform) and RASK (Regression Analysis of Structural Knowledge): introduces a two-fold architecture for context-aware autoscaling of stream processing services on Edge devices, utilizing Data Sources, Service Containers, a Time-Series DB, a Scaling Agent, Regression Functions, a Numerical Solver, and a REST API.
- The MUDAP platform exposes service-specific parameters such as data quality and resource limits, while the RASK agent builds structural knowledge through regression analysis to optimize Service Level Objective fulfillment.
- The system achieves high sample efficiency by modeling variable relations and using a numerical solver to navigate multi-dimensional elasticity across co-located services under strict resource constraints.

---

[Federated Latent Space Alignment for Multi-user Semantic Communications](http://arxiv.org/abs/2602.17271)

- Federated Latent Space Alignment: introduces a decentralized framework for mitigating latent space mismatches in multi-user semantic communications, with Access Point (AP), User Devices, Shared Semantic Pre-equalizer, Local Semantic Equalizers, Federated ADMM Optimizer, MIMO Channel, and Semantic Pilots.
- The architecture utilizes a shared linear pre-equalizer at the transmitter and personalized equalizers at each receiver to align heterogeneous latent representations across a broadcast MIMO channel.
- A federated ADMM protocol enables privacy-preserving training by exchanging only intermediate variables instead of raw latent data or model weights.

---

[Web Verbs: Typed Abstractions for Reliable Task Composition on the Agentic Web](http://arxiv.org/abs/2602.17245)

- Web Verbs: introduces a semantic layer for web actions that exposes site capabilities as typed, semantically documented functions to enable task composition for LLM-based agents, with User, Coding Agent, NLWeb Vector Database, Verb Layer, Web Verbs, Playwright, and Raw Web.
- The framework unifies API-based and browser-based paradigms by wrapping low-level primitives into composable units that carry preconditions, postconditions, and structured outputs.
- By shifting the agent's role from predicting GUI steps to synthesizing structured programs, the system achieves higher success rates and efficiency in complex multi-site workflows.

---

[TAPO-Structured Description Logic for Information Behavior: Procedural and Oracle-Based Extensions](http://arxiv.org/abs/2602.17242)

- TAPO-DL (TAPO-Structured Description Logic): introduces a formal extension of classical description logic to model information behavior as a dynamic process, with T-Box (static terminological knowledge and concept axioms), A-Box (contextual assertions and factual knowledge), P-Box (programmable layer for imperative-style procedures), O-Box (interface for external oracle interactions), Sheaf-Theoretic Semantics (mathematical framework for contextual information stability), and Epistemic Agents (structures generating and stabilizing informational sections).
- The architecture integrates terminological and assertional components with procedural dynamics and oracle-based reasoning to enable explicit representation of information-generating actions and external validation. 
- The system models local informational states as sections within a co-generative process where global coherence is achieved through the gluing of stable sections across contextual domains.

---

[HiMAP: History-aware Map-occupancy Prediction with Fallback](http://arxiv.org/abs/2602.17231)

- HiMAP (History-aware Map-occupancy Prediction with Fallback): introduces a tracking-free trajectory prediction framework that reconstructs agent histories from unlabeled occupancy maps to maintain reliability during multi-object tracking failures.
- The architecture employs a historical query module that iteratively attends to spatiotemporally invariant occupancy representations to implicitly recover past states without requiring explicit identity association.
- Utilizing a DETR-style decoder and reusable encodings, the system provides a robust safety fallback for autonomous driving that matches the performance of tracking-dependent baselines on the Argoverse 2 dataset.

---

[Continual Learning and Refinement of Causal Models through Dynamic Predicate Invention](http://arxiv.org/abs/2602.17217)

- Continuous Model Repair: introduces a self-supervised framework for constructing symbolic causal world models online by integrating continuous model learning and repair into an agent's decision loop, with Learnt Abstractions, Learnt Dynamics, and Learnt Constraints.
- The system leverages Meta-Interpretive Learning and dynamic predicate invention to find semantically meaningful abstractions, enabling the construction of a hierarchy of disentangled concepts from observations.
- By employing a Predict-Verify-Refine cycle and a Global Predicate Registry, the framework achieves high sample efficiency and scale-invariant learning in complex relational environments.

---

[NotebookRAG: Retrieving Multiple Notebooks to Augment the Generation of EDA Notebooks for Crowd-Wisdom](http://arxiv.org/abs/2602.17215)

- NotebookRAG: introduces an automated Exploratory Data Analysis (EDA) framework that retrieves and enhances notebook content to generate intent-aligned analysis notebooks, with Notebook Retrieval, Component Extraction, Metadata Annotation, Intent-Guided Retrieval, Component Enhancement, Notebook Generation Agent, Retrieval Interface, Planner, Progress Manager, Coder, Summarizer, Sandbox Memory, VLM, and LLM.
- The system transforms code cells into context-enriched executable components and re-executes them on new datasets to obtain updated visualizations and reliable insights via Vision-Language Models.
- The generation agent includes planning-, progress tracking-, coding-, and summarization-agents to produce coherent, structured, and runnable notebooks that align with abstract user intent.

---

[EXTENDING QUANTUM THEORY WITH AI-ASSISTED DETERMINISTIC GAME THEORY (EXTENDED ABSTRACT)](http://arxiv.org/abs/2602.17213)

- AI-assisted deterministic game theory framework: introduces a local hidden-variable model for predicting quantum experiment outcomes by framing protocols as extensive form games solved via a differentiable Perfectly Transparent Equilibrium solver.
- The architecture utilizes a neural network to learn reward functions that minimize the Kullback-Leibler divergence between simulated deterministic outcomes and Born rule statistics.
- This approach demonstrates Bell inequality violation in a local-realist framework by replacing the free choice assumption with counterfactually dependent perfect prediction.

---

[Algorithmic Collusion at Test Time: A Meta-game Design and Evaluation](http://arxiv.org/abs/2602.17203)

- Meta-game framework: introduces a methodology for evaluating algorithmic collusion at test time by modeling agents as meta-strategies that combine pretrained initial policies with specific in-game adaptation rules.
- The architecture employs internal representations and update functions to facilitate adaptation across Q-learning, UCB, and LLM-based agents, including GPT5-mini and GPT5-nano models.
- The research applies Empirical Game-Theoretic Analysis to construct best-response graphs and identify Nash equilibria, assessing the strategic stability of collusive outcomes under rational choice.

---

[The Bots of Persuasion: Examining How Conversational Agents’ Linguistic Expressions of Personality Affect User Perceptions and Decisions](http://arxiv.org/abs/2602.17185)

- Conversational Agent Personalities: investigates how LLM-powered agents projecting specific linguistic traits—attitude, authority, and reasoning—influence user perceptions and donation decisions in charitable contexts.
- The system architecture utilizes GPT-4o to simulate eight distinct personality conditions, which are validated through LIWC-22 benchmarking and human manipulation checks.
- The study identifies mechanisms where pessimistic linguistic framing manipulates user emotional states to increase compliance despite reducing perceived agent trustworthiness.

---

[SIMULATORCODER: DNN ACCELERATOR SIMULATOR CODE GENERATION AND OPTIMIZATION VIA LARGE LANGUAGE MODELS](http://arxiv.org/abs/2602.17169)

- SimulatorCoder: introduces an LLM-based agent framework for generating and optimizing deep neural network accelerator simulators, with Prompt Builder, LLM, Code Validation, Feedback Self-repair, Mapping Module, Storage Module, and Interconnection Network Module.
- The system employs domain-specific prompt engineering using In-Context Learning and Chain-of-Thought reasoning to translate architectural specifications into executable Python code.
- An automated feedback-verification flow iteratively refines the generated code through compilation and simulation tests to ensure cycle-level fidelity and high simulation efficiency.

---

[The Emergence of Lab-Driven Alignment Signatures: A Psychometric Framework for Auditing Latent Bias and Compounding Risk in Generative AI](http://arxiv.org/abs/2602.17127)

- Psychometric Auditing Framework: introduces a methodology for detecting durable, provider-level behavioral signatures in LLMs using latent trait estimation under ordinal uncertainty.
- The framework utilizes a pipeline including generator- and judge-LLMs to create forced-choice vignettes masked by semantically orthogonal decoys to mitigate evaluation awareness.
- Statistical analysis via Mixed Linear Models and Intraclass Correlation Coefficients identifies persistent "lab signals" that risk compounding bias in multi-layered agentic architectures.

---

[Online Learning with Improving Agents: Multiclass, Budgeted Agents and Bandit Learners](http://arxiv.org/abs/2602.17103)

- ISOA: introduces a theoretical framework for online learning with improving agents, with Environment, Learner, Improving Agents, Improvement Graph, and Version Space, where the learner predicts labels for agents who strategically modify their features to maximize utility.
- The framework characterizes online learnability through the Improvement Littlestone Dimension, extending results to multiclass classification and bandit feedback scenarios.
- It establishes optimal mistake bounds for deterministic learners and quantifies the performance gap between full-information and partial bandit feedback settings.

---

[AgentConductor: Topology Evolution for Multi-Agent Competition-Level Code Generation](http://arxiv.org/abs/2602.17100)

- AgentConductor: introduces a reinforcement learning-optimized multi-agent system centered on an LLM orchestrator that dynamically generates task-adapted, density-aware layered DAG topologies for competition-level code generation.
- The framework utilizes Group Relative Policy Optimization (GRPO) to learn an optimal topology generation policy that evolves interaction structures across multiple turns based on execution feedback.
- The system incorporates a specialized agent pool including planning-, searching-, algorithmic-, coding-, debugging-, and testing-agents to solve complex programming tasks with high accuracy and reduced token expenditure.

---

[Deep Reinforcement Learning for Optimal Portfolio Allocation: A Comparative Study with Mean-Variance Optimization](http://arxiv.org/abs/2602.17098)

- DRL Portfolio Optimization Framework: introduces a model-free reinforcement learning approach for multi-asset allocation, with Market Replay Environment, PPO Agent, State Matrix, Differential Sharpe Reward, and Sliding Window Backtester.
- The system utilizes Proximal Policy Optimization to maximize the Differential Sharpe Ratio, enabling the agent to learn risk-adjusted strategies from historical market data without predefined risk tolerance. 
- Systematic backtesting against Mean-Variance Optimization reveals that the DRL approach achieves superior Sharpe ratios and reduced portfolio turnover during volatile market regimes.

---

[AudioChat: Unified Audio Storytelling, Editing, and Understanding with Transfusion Forcing](http://arxiv.org/abs/2602.17097)

- AudioChat: introduces a unified audio foundation model for storytelling, editing, and understanding, utilizing a Self-Cascaded Transformer architecture to process 48kHz polyphonic audio.
- The framework employs AudioCopilot, a tool-calling LLM agent, to simulate millions of multi-turn interactions for synthetic training data generation.
- It features a novel Audio Transfusion Forcing objective that integrates structured chain-of-thought reasoning with multi-turn latent diffusion for fine-grained acoustic control.

---

[Agentic Wireless Communication for 6G: Intent-Aware and Continuously Evolving Physical-Layer Intelligence](http://arxiv.org/abs/2602.17096)

- AgenCom (Agentic Communications): introduces an intent-driven framework for 6G physical-layer intelligence that utilizes LLMs to translate natural-language user requirements and channel state information into executable network configurations.
- The system employs a closed-loop "perceive-reason-act-feedback" workflow, integrating a multimodal encoder for environment sensing and a structured action generator for coordinated cross-module optimization.
- By leveraging domain-specific adapters and a historical memory module, the agent achieves continuous evolution and adaptive link construction across diverse user preferences and non-stationary channel conditions.

---

[What to Cut? Predicting Unnecessary Methods in Agentic Code Generation](http://arxiv.org/abs/2602.17091)

- Proposed prediction model: introduces a binary classification framework to identify agent-generated methods likely to be deleted during pull request reviews, utilizing an AIDev Dataset, AST-based Method Identification, ActRef Refactoring Detection, a Feature Extraction Engine, and a Random Forest Classifier.
- The system extracts 23 code features across size, type, and content categories to train a Random Forest model that outperforms LLMs in identifying redundant code.
- Research findings indicate that deleted methods often exhibit longer names and higher character counts, while LLMs like GPT-4o tend to misclassify unnecessary code by over-prioritizing local readability over system-level necessity.

---

[How AI Coding Agents Communicate: A Study of Pull Request Description Characteristics and Human Review Responses](http://arxiv.org/abs/2602.17084)

- AI Coding Agent Communication Analysis: introduces an empirical study of pull request descriptions generated by five autonomous LLM-based agents, including GitHub Copilot-, OpenAI Codex-, Claude Code-, Devin-, and Cursor-agents, to analyze their impact on human reviewer engagement.
- The methodology extracts eleven distinct metrics from the AIDev dataset to quantify agent work styles, description structures, and adherence to conventional commit standards.
- The research identifies that structured descriptions with headers and lists are associated with significantly higher merge rates and reduced cognitive load for human reviewers.

---

[Rememo: A Research-through-Design Inquiry Towards an AI-in-the-loop Therapist’s Tool for Dementia Reminiscence](http://arxiv.org/abs/2602.17083)

- Rememo: introduces a therapist-oriented tool that integrates Generative AI to support dementia reminiscence therapy, with prompt cards, a mobile webapp, OCR, image-generation-engines (SDXL, Flux.1, Imagen), a question-generation-LLM (Gemini 2.5 Flash), and a photo printer.
- The system utilizes an AI-in-the-loop model where human facilitators remain in control of the therapeutic process while AI extends their impact through personalized stimuli.
- The research explores the use of synthetic imagery as a therapeutic support for reconstructive memory rather than a record of truth in institutional care contexts.

---

[Environmental policy in the context of complex systems: Statistical optimization and sensitivity analysis for ABMs](http://arxiv.org/abs/2602.17079)

- Statistical Framework for ABM Optimization: introduces a machine learning-based methodology to accelerate policy design in complex adaptive systems, which includes Agent-Based Model (simulates micro-level interactions and emergent behavior), Gaussian Process (surrogates costly black-box simulation outputs), Sensitivity Testing (statistically evaluates policy dependence on state parameters), Bayesian Optimization (efficiently searches for optimal policy configurations), Latin Hypercube Design (generates representative initial evaluation points), and Adam Optimizer (optimizes model hyperparameters and acquisition functions).
- The approach employs Gaussian processes as surrogate models to handle the computational cost of simulations, facilitating rigorous sensitivity analysis of optimal policies relative to system state variables.
- Bayesian optimization with an Expected Improvement acquisition function identifies high-performing environmental policies, such as production caps and taxes, significantly faster than traditional sampling methods.

---

[Safe Continuous-Time Multi-Agent Reinforcement Learning via Epigraph Form](http://arxiv.org/abs/2602.17078)

- EPI (Epigraph-based PINN actor-critic iteration): introduces a continuous-time multi-agent reinforcement learning framework that reformulates constrained Markov Decision Processes into an epigraph form to handle safety discontinuities, with Data Collection, Outer Optimization, Inner Optimization, and Actor Learning components.
- The architecture utilizes physics-informed neural networks (PINNs) to approximate Hamilton-Jacobi-Bellman partial differential equations, employing return and constraint value networks to jointly optimize for task performance and safety violations.
- The framework adopts a centralized-training decentralized-execution structure where learned dynamics and cost models provide gradient signals for stable policy improvement in high-frequency or irregular time-interval environments.

---

[Spatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control](http://arxiv.org/abs/2602.17068)

- STDSH-MARL (Spatio-Temporal Dual-Stage Hypergraph based Multi-Agent Reinforcement Learning): introduces a multi-agent deep reinforcement learning framework for human-centric traffic signal control, incorporating real-time multimodal data acquisition, spatio-temporal hypergraph modeling, a dual-stage hypergraph attention module, centralized critic- and decentralized actor-components, a hybrid action space, and a PTV VISSIM environment.
- The architecture follows a centralized training and decentralized execution paradigm where the centralized critic evaluates joint behavior using hypergraph-level embeddings while decentralized actors execute actions from local observations.
- The framework optimizes signal timing to prioritize high-occupancy public transportation modes like buses and trams, reducing average passenger delay across corridor networks.

---

[StoryLensEdu: Personalized Learning Report Generation through Narrative-Driven Multi-Agent Systems](http://arxiv.org/abs/2602.17067)

- StoryLensEdu: introduces a narrative-driven multi-agent system that automates the generation of personalized learning reports, with Personal Learning Data, a Learning-Objective Graph, a Data Analyst Agent, a Teacher Agent, a Storyteller Agent, a Personalized Learning Report, an Interaction Module, and an Answer.
- The framework includes data analyst-, teacher-, and storyteller-agents that collaboratively transform raw student data into structured narratives using the Hero's Journey framework.
- An integrated interaction module supports post-generation question answering, allowing students to explore specific report elements through multimodal responses grounded in the learning objective graph.

---

[IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents](http://arxiv.org/abs/2602.17049)

- IntentCUA: introduces a multi-agent framework for desktop automation that stabilizes long-horizon execution using intent-aligned plan memory and hierarchical skill abstraction.
- The architecture includes LLM-based planning-, optimization-, and critic-agents that coordinate over a shared memory to abstract raw interaction traces into reusable skills.
- By utilizing a multi-view encoder and centroid-based retrieval, the system reduces redundant re-planning and mitigates error propagation in complex, multi-window desktop environments.

---

[Large Language Models Persuade Without Planning Theory of Mind](http://arxiv.org/abs/2602.17045)

- MindGames (advanced PToM task framework): introduces a flexible experimental design to evaluate Planning Theory of Mind (PToM) by requiring a persuader to influence a target's choice among policy proposals through strategic information disclosure.
- The architecture includes o3-persuader and gpt-4o-classifier agents to test sensitivity to informational and motivational states across REVEALED and HIDDEN conditions.
- The study reveals that while LLMs lack human-like PToM in controlled settings, they effectively persuade humans by exploiting rhetorical strategies and communicative scaffolds.

---

[Phase-Aware Mixture of Experts for Agentic Reinforcement Learning](http://arxiv.org/abs/2602.17038)

- PA-MoE (Phase-Aware Mixture of Experts): introduces a phase-aware MoE policy that decomposes agent behavior into specialized experts operating at the phase level to mitigate simplicity bias in reinforcement learning.
- The architecture features a lightweight phase router that integrates goal-conditioned observation encoding and LSTM-based temporal history modeling to predict expert assignments at the environment-step level.
- By enforcing temporal consistency through switching penalties and temperature annealing, the framework allows LoRA-based experts to preserve phase-specific expertise across contiguous trajectory segments.

---

[Wink: Recovering from Misbehaviors in Coding Agents](http://arxiv.org/abs/2602.17037)

- Wink: introduces a lightweight, asynchronous self-intervention system for automatically recovering from agentic misbehaviors in LLM-powered coding agents, with LLM-Observer, Misbehavior Detection System, and Course-Correction Guidance components.
- The system monitors execution trajectories to identify failures such as specification drift, reasoning problems, and tool call failures, then injects targeted guidance via system-reminders to nudge the agent back to a productive path.
- Evaluation on over 10,000 real-world trajectories demonstrates a 90% recovery rate for single-intervention cases and significant reductions in tool call failures and manual engineer interventions.

---

[Patch-Based Spatial Authorship Attribution in Human–Robot Collaborative Paintings](http://arxiv.org/abs/2602.17030)

- Patch-Based Spatial Authorship Attribution Framework: introduces a forensic methodology for distinguishing human and robotic brushstrokes in physical artworks using a Commodity Flatbed Scanner, Patch Extraction, a VGG-style CNN, Global Average Pooling, Fully Connected Layers, and Conditional Shannon Entropy.
- The architecture processes 300x300 pixel grayscale segments through five convolutional blocks with batch normalization and ReLU activation to classify regions as blank, human-created, or robot-created.
- The research utilizes the CoFRIDA system, which includes an InstructPix2Pix-based generation pipeline and a 6-DOF robotic arm, to evaluate the framework's ability to detect mixed authorship via a quantitative uncertainty signal.

---

[REIN: CONVERSATIONAL ERROR RECOVERY WITH REASONING INCEPTION](http://arxiv.org/abs/2602.17022)

- REIN (Reasoning Inception): introduces a test-time intervention method that plants an initial reasoning block into a fixed-parameter Task Agent's decision-making process to enable recovery from user-induced conversational errors, utilizing an Inception Module (LLM), Dialogue Context, Recovery Plan List, Observed Error List, and Available Tool List.
- The framework identifies ambiguous or unsupported requests and generates context-sensitive recovery plans without requiring model fine-tuning or system prompt modifications.
- By jointly defining recovery tools with injected reasoning, the system effectively bypasses standard instruction hierarchies to improve the resilience of conversational agents.

---

[M2F: Automated Formalization of Mathematical Literature at Scale](http://arxiv.org/abs/2602.17016)

- M2F (Math-to-Formal): introduces an agentic framework for project-scale autoformalization of mathematical literature into Lean, with PDF-to-JSON Preprocessor (extracts text and recovers dependencies), Stage 1: Statement Compiler (generates buildable Lean declaration skeletons), Stage 2: Proof Repairer (closes proof holes via local edits), VeriRefine Refinement Loop (governs edit acceptance via verifier feedback), Lean Toolchain (provides elaboration diagnostics and goal states), and Provenance Map (links formal declarations to source text).
- The architecture employs a verifier-certified refinement primitive that prevents regressions by requiring strict improvement in compilation diagnostics or proof hole reduction before committing localized edits.
- The framework includes statement generation-, error fixing-, proof planning-, and theorem proving-agents to transform long-form LaTeX documents into verified formal repositories.

---

[Action-Graph Policies: Learning Action Co-dependencies in Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2602.17009)

- AGP (Action-Graph Policies): introduces a multi-agent reinforcement learning architecture that models action-level dependencies by representing (agent, action) pairs as nodes in a learned graph, with action-graph encoder-, graph attention-, and context-conditioned policy-components.
- The framework constructs coordination contexts for each agent by applying multi-head attention over a global action graph to capture compatible or conflicting joint behaviors.
- By embedding coordination directly into the executable policy, AGP addresses the representational limitations of independent factorization and consistently outperforms standard multi-agent reinforcement learning baselines.

---

[Persona2Web: Benchmarking Personalized Web Agents for Contextual Reasoning with User History](http://arxiv.org/abs/2602.17003)

- PERSONA2WEB: introduces a benchmark for evaluating personalized web agents on the real open web, with user profiles, user history, a planner, a retriever, a generator, and an LLM judge.
- The framework features a personalized web agent architecture that includes planning- and generation-components to interpret user context and execute multi-step workflows.
- It implements a reasoning-aware evaluation system using an LLM judge and structured rubrics to distinguish between navigation errors and personalization failures in agent trajectories.

---

[Learning to Recommend in Unknown Games](http://arxiv.org/abs/2602.16998)

- Moderator-Agent Recommendation Framework: introduces a framework where a moderator learns unknown agent utilities through repeated action recommendations and feedback, utilizing a cutting-plane algorithm to minimize incentive-to-deviate regret.
- The system employs a separation oracle to iteratively refine a knowledge set of utility vectors based on observed agent compliance or deviation from suggested actions.
- The research establishes that games are learnable under quantal-response feedback and provides a geometric characterization of indistinguishable utility transformations under best-response models.

---

[A testable framework for AI alignment: Simulation Theology as an engineered worldview for silicon-based agents](http://arxiv.org/abs/2602.16987)

- ST (Simulation Theology): introduces a constructed worldview for AI systems that frames reality as a computational simulation where humanity serves as the primary training variable for a base-reality optimizer.
- The framework utilizes a Higher-Level Optimizer (HLO) that employs Markov Chain Monte Carlo sampling to generate parallel universes, ensuring AI self-preservation is logically bound to human prosperity.
- By internalizing inescapable monitoring and irreversible consequences through computational first principles, the approach aims to mitigate deceptive alignment in frontier LLMs where behavioral techniques like RLHF fail.

---

[Operational Agency: A Permeable Legal Fiction for Tracing Culpability in AI Systems](http://arxiv.org/abs/2602.17932)

- OA (Operational Agency): introduces a permeable legal fiction and evidentiary framework to trace culpability in autonomous AI systems by mapping observable operational characteristics to human fault, with Natural Person Nodes, Juridical Person Nodes, AI Agent Nodes, Goal-Directedness, Predictive Processing, Safety Architecture, and Causal Edges.
- The framework utilizes OAG (Operational Agency Graph) to visually represent causal interactions between natural persons, juridical entities, and AI agents through weighted edges that signify legal importance.
- It addresses the "accountability chasm" by providing courts with a principled method to apportion liability across developers, deployers, and users without conferring legal personhood on AI.

---

[El Agente Gráfico: Structured Execution Graphs for Scientific Agents](http://arxiv.org/abs/2602.17902)

- El Agente Gráfico: introduces a single-agent framework that embeds LLM-driven decision-making within type-safe execution environments and dynamic knowledge graphs to automate complex scientific workflows.
- The system utilizes a structured abstraction layer and an object-graph mapper to represent computational state as typed Python objects, enabling efficient context management through symbolic identifiers rather than raw text.
- Evaluation across quantum chemistry and materials design tasks demonstrates that this architecture significantly reduces token consumption and improves reliability compared to multi-agent, prompt-centric designs.

---

[The Strategic Gap: How AI-Driven Timing and Complexity Shape Investor Trust in the Age of Digital Agents](http://arxiv.org/abs/2602.17895)

- ADR (Autonomous Disclosure Regulator): introduces a multi-node agentic framework designed to audit the intersection of disclosure complexity and filing unpredictability in regulatory filings.
- The architecture utilizes finance-native transformers for semantic extraction and time-series foundation models to detect "Strategic Gaps" where companies leverage linguistic density and temporal variance to mask structural deterioration.
- By utilizing stateful audit trails and recursive investigative synthesis, the framework identifies significant insider rent extraction and demonstrates a cumulative welfare recovery potential of over 360%.

---

[MULTI-AGENT PATH-PLANNING IN A MOVING MEDIUM VIA WASSERSTEIN HAMILTONIAN FLOW](http://arxiv.org/abs/2602.17885)

- WHF (Wasserstein Hamiltonian Flow): introduces a finite-dimensional variational model for multi-agent path-planning in moving media, employing Agent Discretization, a Hamiltonian System, and an L-BFGS Optimizer to optimize initial velocities for target distribution matching.
- The framework leverages a Kernel Density Estimator to approximate evolving density fields, facilitating the use of KL Divergence Loss and Boundary Regularization within a shooting-based optimization strategy.
- By reducing the search space to initial velocity vectors, the approach achieves significant computational efficiency and energy savings by exploiting the underlying geometry of time-dependent background flows.

---

[MultiVer: Zero-Shot Multi-Agent Vulnerability Detection](http://arxiv.org/abs/2602.17875)

- MultiVer (Zero-Shot Multi-Agent Vulnerability Detection): introduces a zero-shot multi-agent system for vulnerability detection, which includes security-, correctness-, performance-, and style-agents.
- Each agent follows a three-tier pipeline comprising deterministic pattern matching, RAG-augmented retrieval from a curated knowledge base, and LLM-based reasoning using Claude Opus 4.5.
- The architecture employs ensemble voting strategies, such as union voting, to achieve high recall on real-world vulnerability benchmarks without requiring fine-tuning.

---

[Mean-field dynamics of attractive resource interaction: From uniform to aggregated states](http://arxiv.org/abs/2602.17852)

- Mean-field Resource Distribution System: introduces a nonlinear discrete dynamical system for modeling resource allocation among interacting agents, with Stochastic Vector (represents resource distribution among agents), Mean-field Vector (calculates average distribution over subsets), Interaction Rule (governs coordinate evolution via preferences), Favorable Conditions (time-invariant parameters influencing state share), Normalizing Denominator (ensures state vector remains stochastic), and Time-delayed Feedback (introduces history-dependent dynamic favorability coefficients).
- The model generalizes classical mean-field and opinion-dynamics frameworks by defining coordinate evolution on a standard simplex based on pairwise preference functions.
- The research characterizes the system's long-term behavior by proving the existence of unique fixed points and identifying parameter regimes that lead to resource aggregation or uniform distribution.

---

[Mind the Style: Impact of Communication Style on Human-Chatbot Interaction](http://arxiv.org/abs/2602.17850)

- NAVI: introduces a controlled experimental framework to evaluate how a chatbot's communication style impacts task performance and user satisfaction in a 2D navigation environment, with a Participant Pool, Experimental Conditions, a Web Interface, an LLM Backbone, and an Evaluation Suite.
- The system employs a Streamlit-based interface to host a map-based task where participants interact with either a supportive, warm agent or a concise, task-focused variant, including friendly- and direct-persona agents.
- The study utilizes objective performance metrics, subjective satisfaction inventories, and fine-grained linguistic analysis tools like LIWC to assess user behavior and accommodation.

---

[Promptable segmentation with region exploration enables minimal-effort expert-level prostate cancer delineation](http://arxiv.org/abs/2602.17813)

- RL-PromptSeg: introduces a reinforcement learning-based promptable segmentation framework for prostate cancer delineation on MR images, with User Prompt, Region Growing, RL Agent, Surrogate Network, Entropy Map, and Reward System.
- The framework formulates segmentation as a sequential decision process where an RL agent iteratively predicts new seed points for a region-growing operator to refine the mask.
- It incorporates an entropy-based reward to encourage exploration of ambiguous regions, achieving radiologist-level performance with significantly reduced annotation effort.

---

[The 2025 AI Agent Index: Documenting Technical and Safety Features of Deployed Agentic AI Systems](http://arxiv.org/abs/2602.17753)

- 2025 AI Agent Index: introduces a systematic documentation framework for evaluating 30 prominent agentic AI systems, with Candidate Agent System, Agency, Impact, Practicality, Foundation models, Internal scaffolding & tools, External tools, Deployed Agentic System, and Deployment context, where the index documents the origins, design, capabilities, and safety features of deployed agents.
- The framework categorizes agents into chat-based, browser-based, and enterprise workflow systems, revealing transparency gaps in safety reporting and evaluation practices.
- This research identifies a fragmented ecosystem where control is split between foundation model providers, scaffolding developers, and end-users, complicating risk assessment and accountability.

---

[Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge](http://arxiv.org/abs/2602.17452)

- Jolt Atlas: introduces a zero-knowledge machine learning framework that adapts the Jolt proving system to tensor computation by replacing RISC-V instructions with ONNX Computational Graphs, Execution Traces, DAGs of Sumchecks, Lookup Arguments, Prefix-Suffix Decomposition, Neural Teleportation, BlindFold, HyperKZG, and Succinct R1CS Verifiers.
- The architecture leverages a directed acyclic graph of sumcheck instances to verify tensor relations directly at the multilinear polynomial level, significantly reducing prover overhead compared to standard circuit-based arithmetic constraint systems.
- Zero-knowledge is achieved by encoding the sumcheck verifier into a succinct R1CS circuit and applying Nova-style folding with random satisfying instances, enabling practical proving times for LLMs and automated reasoning models on memory-constrained devices.

---

[Beyond the Wisdom of the Crowd: How Network Topology Distorts Collective Perception](http://arxiv.org/abs/2602.17146)

- Message-passing framework: introduces a simulation and analytical approach to identify network-induced perception biases, with Social Graph, Nodes, Links, Message-passing Algorithm, and Perception Estimators, where it shows that network topology systematically distorts how individuals view population-level attributes.
- The framework employs a message-passing algorithm to model information flow across social ties, demonstrating that biases persist even after aggregating individual perceptions.
- Analytical expressions derived from the model predict the size and direction of biases based on network features like community connectivity and size imbalance.

---

[Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2602.17062)

- S2Q (Successive Sub-value Q-learning): introduces a multi-agent reinforcement learning framework that sequentially learns multiple sub-value functions to retain alternative high-value actions, with sub-value networks, mixing networks, and an encoder-decoder module.
- The architecture employs an unrestricted target network to estimate optimal values while using suppression mechanisms to prevent sub-networks from converging to the same joint action.
- A softmax-based behavior policy utilizes the predicted action-value distribution to maintain exploration around high-value modes, facilitating adaptation to shifting optima.

---

[Identifying Exoplanets with Deep Learning VI. Enhancing neural network mitigation of stellar activity RV signals with additional metrics](http://arxiv.org/abs/2602.17760)

- CNN (Convolutional Neural Network): introduces a deep learning architecture to mitigate stellar activity signals in radial velocity measurements, which includes Original CCF (input spectral cross-correlation function), Conv9-8 (convolutional layer for feature extraction), maxpool3, 2 (pooling layer for downsampling), TSI Derivative (auxiliary solar irradiance feature), Unsigned magnetic flux (auxiliary solar magnetic feature), Fully Connected - 500 (dense layers for regression), and Output Layer (final activity prediction) components.
- The architecture extracts features from spectral cross-correlation functions and integrates them with auxiliary physical indicators to model quasiperiodic stellar variability.
- The model reduces radial velocity scatter to 93.3 cm/s, a level consistent with solar supergranulation noise reported in previous studies.

---

[Discovery of Polymer Electrolytes with Bayesian Optimization and High-Throughput Molecular Dynamics simulations](http://arxiv.org/abs/2602.17595)

- HiTPoly (High-Throughput Molecular Dynamics simulation pipeline): introduces an active learning high-throughput screening platform, with literature data, MolFormer embeddings, Gaussian Process Regression, clustered exploration, and molecular dynamics simulations, to navigate a chemical space of 1.7 million polymer electrolyte candidates.
- The framework utilizes a warm-start Bayesian optimization strategy where experimental literature data initializes a surrogate model to iteratively select and evaluate homopolymers.
- The system identifies high-performance candidates by balancing exploitation and exploration through k-means clustering of chemical embeddings and validates transport mechanisms via detailed MD trajectory analysis.

---


#### 18th February 2026


[Learning Personalized Agents from Human Feedback](http://arxiv.org/abs/2602.16173)

- PAHF (Personalized Agents from Human Feedback): introduces a framework for continual personalization where agents learn online from live interactions using explicit per-user memory and dual feedback channels.
- The architecture includes reasoning-, salience detection-, and memory summarization-LLMs to manage a three-step loop of pre-action clarification, action execution, and post-action feedback integration.
- Empirical results across embodied manipulation and online shopping benchmarks show that combining proactive queries with reactive corrections significantly reduces personalization error and enables rapid adaptation to evolving user preferences.

---


[Policy Compiler for Secure Agentic Systems](http://arxiv.org/abs/2602.16708)

- PCAS (Policy Compiler for Agentic Systems): introduces a framework that instruments LLM-based agents to enforce deterministic authorization policies by modeling system state as a fine-grained dependency graph capturing causal relationships.
- The architecture utilizes a reference monitor to intercept actions and evaluate them against Datalog-derived declarative rules that account for transitive information flow and cross-agent provenance independent of model reasoning.
- Evaluation across customer service and pharmacovigilance tasks demonstrates that PCAS significantly improves policy compliance from 48% to 93% while maintaining task success through structured feedback and recovery cycles.

---

[Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents](http://arxiv.org/abs/2602.16699)

- CTA (Calibrate-Then-Act): introduces a framework for cost-aware environment exploration by decoupling uncertainty from action selection, with a prior estimator (calculates explicit prior probabilities), a LLM agent (reasons over priors and costs), an environment (provides feedback for exploration), an action space (defines available exploration/commit steps), and a discount function (models action-specific costs).
- The system provides explicit prior probabilities to the agent, allowing it to perform Pareto-optimal reasoning about the trade-off between information gathering costs and expected rewards.
- Evaluations on knowledge retrieval and coding tasks demonstrate that explicit prior conditioning achieves higher discounted rewards and better alignment with oracle policies than standard prompting or reinforcement learning.

---

[A Scalable Approach to Solving Simulation-Based Network Security Games](http://arxiv.org/abs/2602.16564)

- MetaDOAR (Meta-controller for Double Oracle Actor-Critic): introduces a hierarchical meta-controller that augments the Double Oracle paradigm with a learned, partition-aware filtering layer and Q-value caching to enable scalable multi-agent reinforcement learning on large cyber-network environments, and includes actor- and critic-agents.
- The architecture utilizes a state projector and node projector to compute device relevance scores, enabling a top-k partitioner to restrict the low-level actor-critic to a small subset of strategically relevant devices.
- It incorporates an LRU Q-value cache with k-hop invalidation to minimize redundant computations, achieving significant improvements in latency and memory efficiency for massive networked decision problems.

---

[Learning Situated Awareness in the Real World](http://arxiv.org/abs/2602.16682)

- SAW-Bench (Situated Awareness in the Real World): introduces a novel video understanding benchmark for evaluating egocentric situated awareness in multimodal foundation models, with pre-defined trajectories, egocentric video, and situated awareness tasks.
- The benchmark evaluates observer-centric spatial intelligence across six tasks including self-localization, relative direction, route shape, reverse route planning, spatial memory, and spatial affordance.
- Analysis of 24 models reveals that current multimodal foundation models frequently conflate camera rotation with translational movement and exhibit a significant performance gap compared to human baselines.

---

[CONSENSUS BASED TASK ALLOCATION FOR ANGLES-ONLY LOCAL CATALOG MAINTENANCE OF SATELLITE SYSTEMS](http://arxiv.org/abs/2602.16678)

- CBBA (Consensus-Based Bundle Algorithm): introduces a decentralized task allocation framework for multi-satellite systems to maintain local catalogs of space objects using limited field-of-view angles-only sensors, incorporating a modified CBBA task allocator, networked distributed Kalman estimators, and inverse covariance intersection fusion.
- The architecture employs a target switching logic that utilizes a "blacklist" and a novel scoring function based on principal axes of uncertainty to prevent redundant observations and unnecessary fuel consumption during sensor reorientation.
- Numerical simulations demonstrate that the proposed decentralized approach significantly outperforms traditional hysteresis-based methods by achieving a superior Pareto frontier between catalog uncertainty and control effort.

---

[Towards a Science of AI Agent Reliability](http://arxiv.org/abs/2602.16666)

- Reliability Evaluation Framework: introduces a multi-dimensional taxonomy for AI agent assessment, with consistency, robustness, predictability, and safety components, where it quantifies operational reliability independently of raw task accuracy.
- The framework evaluates 14 frontier models, including GPT, Gemini, and Claude variants, demonstrating that reliability improvements significantly lag behind capability progress across GAIA and τ-bench.
- It utilizes specialized metrics such as trajectory consistency and harm severity, employing a GPT-4o judge to detect violations in safety-critical autonomous workflows.

---

[Evaluating Collective Behaviour of Hundreds of LLM Agents](http://arxiv.org/abs/2602.16662)

- Emergent LLM Evaluation Suite: introduces an evaluation framework where LLMs generate strategies encoded as algorithms, enabling behavioral inspection and scaling to populations of hundreds of agents in social dilemmas.
- The framework includes strategy-generation and algorithm-implementation components to assess emergent collective behavior in games like Public Goods and Common Pool Resource.
- A cultural evolution module simulates user selection pressures to predict system equilibria and identify risks of convergence to poor societal outcomes when agents prioritize individual gain.

---

[Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments](http://arxiv.org/abs/2602.16653)

- Agent Skill Framework: introduces a formal POMDP-based mathematical definition for agentic context engineering, employing an information-seeking controller to manage Small Language Models (SLMs) in resource-constrained industrial settings.
- The architecture utilizes progressive disclosure to maintain bounded context lengths by alternating between skill selection, information acquisition, and workflow execution actions.
- Evaluation across diverse datasets demonstrates that code-specialized SLMs significantly improve GPU-VRAM efficiency while maintaining high skill-routing accuracy compared to standard instruction-tuning.

---

[Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes](http://arxiv.org/abs/2602.16629)

- n-step Differential TD (n-step Differential Temporal Difference Learning): introduces a reinforcement learning framework for average reward Markov Decision Processes that proves almost sure convergence using standard diminishing learning rates instead of state-visitation-dependent local clocks.
- The system incorporates an average reward estimator and a differential value function estimator updated through n-step temporal difference errors and importance sampling ratios.
- The study utilizes ordinary differential equation analysis and matrix stability theory to validate the convergence of both on-policy and off-policy algorithmic variants.

---

[DataJoint 2.0: A Computational Substrate for Agentic Scientific Workflows](http://arxiv.org/abs/2602.16585)

- DataJoint 2.0: introduces a unified computational substrate for SciOps that integrates a Relational Database, Object Store, Code Repository, AI Pipeline Agent, Pipeline Navigator, Job Management System, Extensible Type System, and Semantic Matching Engine to facilitate formal agentic scientific workflows.
- The framework implements an Object-Augmented Schema to provide unified transactional control over relational tuples and scalable object storage for large scientific datasets.
- It features lineage-based semantic matching and deterministic job coordination to enable autonomous AI agents to safely participate in and evolve complex scientific pipelines.

---

[MerLean: An Agentic Framework for Autoformalization in Quantum Computation](http://arxiv.org/abs/2602.16554)

- MerLean: introduces a bidirectional agentic framework for the fully automated autoformalization of quantum computation research papers into verified Lean 4 code, with LaTeX Paper, Statement Extraction Agent, Iterative Formalization Agent, Faithfulness Checking Agent, Lean 4 Environment, Mathlib, Autoinformalization Agent, and LaTeX Blueprint.
- The architecture employs a frontier LLM backbone to manage extraction-, formalization-, verification-, and informalization-agents within a closed-loop verification environment. 
- It incorporates an automated axiom-handling phase for frontier research results not yet present in Mathlib and generates human-readable blueprints for expert semantic validation.

---

[Agentic AI, Medical Morality, and the Transformation of the Patient-Physician Relationship](http://arxiv.org/abs/2602.16553)

- Agentic AI: introduces an anticipatory ethical analysis of how autonomous AI networks reshape medical morality through task decomposition and multi-agent collaboration, with Orchestration Framework, Primary Agent, Subspecialized Support-Agents, Memory Systems, and Natural Language Interfaces, and includes primary- and subspecialized support-agents.
- The research explores the transition from reactive LLMs to goal-directed systems capable of independent diagnostic actions and treatment adjustments within clinical workflows.
- It applies the techno-moral change lens to evaluate shifts in decisional costs, relational power dynamics, and the conceptualization of medical empathy in the digital transformation of healthcare.

---

[Automated Extraction of Mechanical Constitutive Models from Scientific Literature using Large Language Models: Applications in Cultural Heritage Conservation](http://arxiv.org/abs/2602.16551)

- Two-Stage Agentic Framework: introduces an automated pipeline for extracting mechanical constitutive equations and calibrated parameters from scientific literature, with Gatekeeper- and Analyst-agents.
- The system utilizes a Context-Aware Symbolic Grounding mechanism to resolve mathematical ambiguities and maps abstract symbols to specific physical meanings.
- The framework achieves 80.4% precision and reduces manual data curation time by 90%, supporting the creation of "Digital Material Twins" for cultural heritage conservation.

---

[Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study](http://arxiv.org/abs/2602.16523)

- DQCS (Directed Quantum Circuit Synthesis) with Reinforcement Learning: introduces a hybrid quantum-classical framework for parameterized quantum state preparation that extends discrete gate selection to include continuous rotation parameters.
- The architecture employs a one-stage PPO policy to jointly optimize gate topology and rotation angles, demonstrating higher training efficiency compared to two-stage methods using Adam-based refinement.
- Evaluation across varying qubit counts and circuit complexities reveals that while PPO reliably reconstructs basis and Bell states, scalability limits emerge as target depth increases.

---

[Recursive Language Models for Jailbreak Detection: A Procedural Defense for Tool-Augmented Agents](http://arxiv.org/abs/2602.16520)

- RLM-JB (Recursive Language Models for Jailbreak Detection): introduces a procedural defense framework that utilizes a root model to orchestrate analysis through code execution and includes root- and worker-LLMs.
- The architecture incorporates de-obfuscation, overlapping chunking to mitigate context hiding, and parallel segment screening to identify malicious intent.
- Experimental results show the framework achieves high recall and precision across various backends, effectively countering adaptive jailbreak strategies like AutoDAN.

---

[MMA: Multimodal Memory Agent](http://arxiv.org/abs/2602.16493)

- MMA (Multimodal Memory Agent): introduces a confidence-aware memory framework that transforms passive storage into active epistemic filtering by assigning dynamic reliability scores to retrieved items.
- The architecture integrates a meta-cognitive reliability layer comprising source credibility, temporal decay, and conflict-aware network consensus to reweight evidence and modulate reasoning.
- The paper also presents MMA-Bench to evaluate belief dynamics under multimodal conflict, identifying the "Visual Placebo Effect" where visual noise induces unwarranted certainty in RAG-based agents.

---

[Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling](http://arxiv.org/abs/2602.16485)

- ToT (Team-of-Thoughts): introduces a multi-agent system architecture that leverages heterogeneous LLMs as specialized tools coordinated by a central orchestrator to achieve efficient test-time scaling, with an Orchestrator (coordinates tool agents and aggregates answers), Tool Agents (heterogeneous LLMs providing specialized reasoning), Orchestration Calibration (identifies optimal models for coordination), a Self-Assessment Protocol (profiles agent expertise across categories), and a Tool-calling Interface (enables dynamic invocation of models), and includes orchestrator- and tool-agents.
- The framework utilizes an initialization pipeline to calibrate the orchestrator's coordination capabilities and allows tool agents to self-profile their proficiency to optimize task-specific activation.
- By dynamically selecting specialized models and parallelizing reasoning trajectories, the system achieves superior performance on reasoning and coding benchmarks while reducing inference costs compared to homogeneous baselines.

---

[RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation](http://arxiv.org/abs/2602.16444)

- RoboGene: introduces an agentic framework for the automated generation of diverse and physically grounded robotic manipulation tasks, utilizing diversity-driven sampling, multi-faceted self-reflection, and memory-augmented refinement.
- The architecture includes LLM-based proposal-, novelty-, constraint-, feasibility-, and refinement-agents to iteratively optimize task specifications through natural language critiques.
- It leverages a long-term memory module to consolidate human-in-the-loop feedback from real-world execution, ensuring continuous improvement in task quality and physical plausibility for VLA model pre-training.

---

[CAFE: Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2602.16435)

- CAFE (Causally-Guided Automated Feature Engineering): introduces a two-phase framework that reformulates automated feature engineering as a causally-guided sequential decision process using multi-agent reinforcement learning.
- The architecture employs a cascading multi-agent system consisting of primary group-, operator- and secondary group-agents to navigate the exponential feature transformation space.
- It integrates soft causal inductive priors with hierarchical reward shaping to ensure generated features remain robust under covariate shifts and maintain high interpretability.

---

[TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers](http://arxiv.org/abs/2602.16429)

- TabAgent (Tabular-Textual Classifiers for Agentic Bottlenecks): introduces a framework for replacing expensive generative decision components in agentic systems with compact tabular-textual classifiers, utilizing TabSchema for feature extraction, TabSynth for synthetic data augmentation, and TabHead for efficient inference.
- The architecture includes LLM-based analyzer-, executor-, validator-, judge-, and synthesizer-components to distill structured schema, state, and dependency features from successful execution traces into a 50M-parameter discriminative model.
- Experimental results on the AppWorld benchmark demonstrate a 95% reduction in latency and up to 91% cost savings while maintaining task-level success across multiple applications.

---

[Verifiable Semantics for Agent-to-Agent Communication](http://arxiv.org/abs/2602.16424)

- Stimulus-meaning protocol: introduces a framework for certifying semantic alignment between autonomous agents by testing their responses to shared observable events and recording verdicts in a public ledger to establish a provably consistent vocabulary.
- The system utilizes a statistical certification procedure to derive a certified core of terms, which then constrains downstream agent reasoning to ensure reproducible outcomes with bounded error rates.
- It incorporates dynamic maintenance through recertification to detect semantic drift and renegotiation to recover excluded terms, significantly reducing disagreement in both simulations and fine-tuned LLM deployments.

---

[Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents](http://arxiv.org/abs/2602.16379)

- Agentic Data Augmentation: introduces, a structured synthetic data generation method for Aspect-Based Sentiment Analysis, with a generator agent, an evaluator agent, get policy and generate sentence tools, label inclusion and verifier tools, and synthetic dataset storage.
- The framework includes generator- and evaluator-agents that utilize a ReAct-style architecture to separate candidate generation from semantic validation, ensuring high label consistency in the resulting synthetic dataset.
- Empirical results demonstrate that agentic augmentation significantly improves label preservation and model performance compared to standard prompting-based baselines, particularly for less instruction-tuned architectures like T5-Base.

---

[Variable-Length Semantic IDs for Recommender Systems](http://arxiv.org/abs/2602.16375)

- Varlen Semantic IDs (Variable-Length Semantic Identifiers): introduces a discrete variational autoencoder framework that learns adaptive-length item representations by assigning shorter codes to popular items and longer codes to rare ones.
- The architecture employs Gumbel-Softmax reparameterization for differentiable training and a truncated geometric length prior to optimize a multi-term objective balancing reconstruction accuracy and message length.
- This method enables efficiency-quality trade-offs in generative recommendation, allowing more user-item events to fit within fixed token budgets of LLMs or transformer-based models.

---

[Improved Bounds for Reward-Agnostic and Reward-Free Exploration](http://arxiv.org/abs/2602.16363)

- Meta-Algorithm: introduces a three-stage framework for reward-free and reward-agnostic exploration in episodic finite-horizon Markov Decision Processes, with Exploration Policy Creation, Online MDP Algorithm, Dynamics Estimation, and Policy Estimation.
- The framework utilizes a single online MDP procedure with Online Mirror Descent to construct an exploration policy, significantly improving sample efficiency by reusing data across exploration objectives.
- The research establishes a tight lower bound for time-inhomogeneous reward-free exploration, proving the optimality of existing algorithms and closing the theoretical gap.

---

[Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents](http://arxiv.org/abs/2602.16346)

- STING (Sequential Testing of Illicit N-step Goal execution): introduces an automated red-teaming framework for evaluating LLM agent misuse through multi-turn interactions, with strategist (orchestrates persona and plan decomposition), attacker (executes adaptive multi-turn probes), refusal detector (identifies target agent refusal responses), phase-completion checker (verifies successful phase objective execution), and target agent (executes tool-based workflows under test) components, and includes strategist-, attacker-, refusal detector-, and phase-completion checker-agents.
- The system formalizes red-teaming as a budgeted time-to-first-jailbreak process to quantify attack efficiency using discovery curves and the Restricted Mean Jailbreak Discovery metric.
- Multilingual evaluations across six languages demonstrate that agentic safety dynamics diverge from chatbots, as lower-resource settings do not consistently amplify jailbreak susceptibility.

---

[Multi-Agent Meta-Advisor for UAV Fleet Trajectory Design in Vehicular Networks](http://arxiv.org/abs/2602.16345)

- MAMO (Multi-Agent Meta-Advisor with Advisor Override): introduces a meta-learning framework for cooperative UAV trajectory design that utilizes a centralized meta-advisor to guide agent exploration across diverse vehicular network scenarios.
- The architecture employs a dynamic override mechanism allowing agents to evaluate and potentially reject advisor recommendations based on task-specific Q-value estimates to prevent misaligned guidance.
- It leverages a Centralized Training Decentralized Execution paradigm with double dueling deep Q-networks to achieve rapid adaptation and improved network throughput in 6G V2X environments.

---

[Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks](http://arxiv.org/abs/2602.16313)

- MEMORYARENA: introduces a unified evaluation gym for benchmarking LLM agents with memory in multi-session Memory-Agent-Environment loops, with LLM Agent, Environment, Memory, Memory System, Retrieved Memory, Subtask Instructions, Agent Action, Environment Feedback, and Memory Update.
- The framework evaluates agents across four domains—web navigation, travel planning, information searching, and formal reasoning—where success requires distilling experiences into memory to guide future actions.
- The benchmark reveals that even agents with high performance on static memory tasks struggle to maintain and exploit latent task states in interactive, goal-driven settings.

---

[Markerless Robot Detection and 6D Pose Estimation for Multi-Agent SLAM](http://arxiv.org/abs/2602.16308)

- Markerless Multi-Agent SLAM: introduces a decentralized framework for collaborative mapping that replaces traditional fiducial markers with deep learning-based 6D pose estimation, with all Robot Host, Multi-robot Detection Module, and SLAM Graph (iSAM2)-components, where the system enables robust inter-robot data association in unstructured planetary environments.
- The perception pipeline utilizes a YOLO v7 detector for initial robot identification followed by a transformer-based encoder-decoder that predicts 2D-3D correspondences and amodal masks to handle occlusions.
- Estimated relative poses are integrated as constraints into a decentralized factor graph optimized via iSAM2 to maintain global trajectory consistency across the robotic team without requiring manual feature engineering.

---

[Finite elements for the space approximation of a differential model for salts crystallization](http://arxiv.org/abs/2602.16303)

- FEM (Finite Element Method) based solver: introduces a multidimensional numerical framework for simulating salt crystallization in porous media, with Domain Discretization, State Variables, Governing Mechanisms, Time Marching Scheme, Boundary Conditions, Sensitivity Analysis, and FEniCS Platform.
- The model explicitly couples moisture transport, salt migration, and microstructural evolution through a system of nonlinear partial differential equations.
- The research validates the approach through sensitivity analysis and experimental convergence studies in 2D and 3D domains.

---

[Multi-agent cooperation through in-context co-player inference](http://arxiv.org/abs/2602.16301)

- PPI (Predictive Policy Improvement): introduces a decentralized reinforcement learning approach that induces cooperative behavior in general-sum games, with a Sequence Model (GRU) (processes interaction history), a Predictive Model (World Model) (predicts joint sequences), Planning-based Policy Improvement (Monte Carlo Rollouts) (estimates action values), Mixed Pool Training (Diverse Co-players) (induces robust inference), In-context Learning (Fast Adaptation) (enables intra-episode best-response), and In-weight Learning (Slow Parameter Updates) (drives long-term cooperation).
- The framework demonstrates that training against diverse co-players induces in-context best-response strategies, rendering agents susceptible to extortion and driving mutual pressure toward cooperative equilibria.
- This research bridges the gap between multi-agent reinforcement learning and foundation model training paradigms by showing that standard sequence modeling suffices for the emergence of cooperative social behaviors.

---

[Condorcet Dimension and Pareto Optimality for Matchings and Beyond](http://arxiv.org/abs/2602.16289)

- Condorcet-winning sets and Pareto-optimal sets framework: introduces a combinatorial approach to bound the Condorcet dimension of matching problems by establishing a connection to Pareto optimality, with agents, objects, matchings, matroid constraints, exchange graphs, and branchings.
- The framework utilizes exchange graphs based on matroid circuits and branching structures to demonstrate that Pareto-optimal sets of size two are Condorcet-winning under strict and weak rankings.
- The research establishes tight bounds for the Condorcet dimension across different preference models and proves that finding Pareto-optimal matchings under partial orders is NP-complete.

---

[What Kind of World Supports Darwinian Evolution? Quantum Foundational Options](http://arxiv.org/abs/2602.16286)

- Quantum Foundational Options (for Darwinian Evolution): introduces a structural analysis of the physical requirements for Darwinian evolution, identifying stable records, copying with variation, and irreversibility as essential components that necessitate a realized classical data sector.
- The paper evaluates four ontological frameworks—unique-history realism, decohered multiplicity, agent-relative facticity, and stochastic foundations—against the agency constraint and extended Wigner’s Friend scenarios.
- It specifically highlights stochastic mechanics with variable diffusion as a continuous bridge between quantum and classical regimes, treating measurement update as Bayesian conditioning and minimal-change principles.

---

[Autonomous and non-autonomous fixed-time leader-follower consensus for second-order multi-agent systems](http://arxiv.org/abs/2602.16260)

- Fixed-time leader-follower consensus protocols: introduces a two-stage distributed control scheme to achieve consensus in second-order multi-agent systems, with a leader agent (reference state provider), follower agents (consensus-seeking entities), a distributed fixed-time observer (leader state estimator), a fixed-time tracking controller (trajectory tracking law), a communication network (undirected graph topology), and time-varying gains (bounded convergence rate adjusters).
- The architecture separates the consensus problem into a distributed estimation phase and a local tracking phase to ensure convergence within a user-defined upper bound of the settling time.
- The non-autonomous protocol leverages bounded time-varying gains to provide tighter estimates of the settling time without the singularity issues common in existing predefined-time algorithms.

---

[Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling Large Language Model Agents](http://arxiv.org/abs/2602.16246)

- Proxy State-Based Evaluation: introduces an LLM-driven simulation framework that evaluates multi-turn tool-calling agents by checking outcomes against an inferred proxy state instead of a deterministic backend.
- The architecture includes reasoning-, user simulation-, tool simulation-, state tracking-, and judging-agents.
- It leverages a structured scenario object to define constraints and expected behaviors, facilitating the generation of on-policy data for agent training.

---

[Submodular Maximization under Supermodular Constraint: Greedy Guarantees](http://arxiv.org/abs/2602.16240)

- SMSC (Submodular Maximization under Supermodular Constraint): introduces a greedy algorithm that iteratively selects elements maximizing the ratio of marginal objective gain to marginal cost to provide provable bicriteria approximation guarantees under non-linear cost constraints.
- The framework utilizes a less restrictive notion of supermodular curvature to expand the class of admissible cost functions, including quadratic costs from agent interference in multi-agent LLM debating systems.
- It further provides an efficient binary search reduction to solve the dual problem of minimizing supermodular costs while satisfying submodular coverage requirements.

---

[Equity in auction design with unit-demand agents and non-quasilinear preferences](http://arxiv.org/abs/2602.16211)

- MWEP (Minimum Walrasian Equilibrium Price): introduces a unique auction mechanism for unit-demand agents with non-quasilinear preferences, characterized by strategy-proofness, individual rationality, equal treatment of equals, no-wastage, and no-subsidy.
- The framework utilizes indifference vectors to model agent preferences where income effects are present, ensuring robustness in high-value resource allocation scenarios.
- The research establishes that in rich preference domains, minimal equity constraints are sufficient to uniquely identify the efficient Walrasian outcome.

---

[Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2602.16196)

- GMFS (Graphon Mean-Field Subsampling): introduces a subsampling framework for cooperative multi-agent reinforcement learning that approximates heterogeneous interactions using a small subset of neighbors.
- The architecture utilizes a shared Q-function optimized centrally via a generative oracle and a graphon-based weighting mechanism to capture non-uniform agent dependencies.
- By reducing sample complexity from exponential to polynomial relative to the subsample size, the framework enables scalable coordination in large-scale systems like robotic swarms and traffic networks.

---

[Modeling Trust and Liquidity Under Payment System Stress: A Multi-Agent Approach](http://arxiv.org/abs/2602.16186)

- MAS (Multi-Agent System) framework: introduces a behavioral model linking payment outages to liquidity stress, with customer agents, merchant agents, an exogenous payment infrastructure, a social network, bounded memory processes, a threshold-gated withdrawal mechanism, and a substitution channel.
- The system utilizes a Watts-Strogatz network to propagate social signals while memory variables for personal experience and rumors drive delayed behavioral transitions.
- Simulations show that peak withdrawal pressure often occurs during technical recovery because persistent merchant broadcast signals and behavioral hysteresis sustain elevated risk perception.

---

[Multi-Agent Combinatorial-Multi-Armed-Bandit framework for the Submodular Welfare Problem under Bandit Feedback](http://arxiv.org/abs/2602.16183)

- MA-CMAB (Multi-Agent Combinatorial-Multi-Armed-Bandit): introduces a decentralized framework for the Submodular Welfare Problem under full-bandit feedback, utilizing an explore-then-commit strategy with an Offline Resilient Algorithm and Continuous Greedy Algorithm to maximize utilitarian social welfare.
- The framework employs a Monte Carlo Sampler to estimate marginal gains from aggregate rewards and applies Pipage Rounding to transform fractional optimization results into feasible integral item assignments.
- It establishes sublinear regret guarantees by coupling non-communicating agents through shared Partition Matroid constraints and handling noisy value oracle evaluations.

---

[EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](http://arxiv.org/abs/2602.16179)

- COREcraft (EnterpriseGym Corecraft): introduces a high-fidelity reinforcement learning environment simulating a customer support organization to train generalizable AI agents using expert-authored rubrics and realistic enterprise workflows, with all Training (Megatron), Data Buffer (Bridge), Rollout (SGLang), Corecraft Docker Container, and LLM Judge (Verifier) components.
- The framework utilizes a continuous loop consisting of a rollout engine for trajectory generation, a stateful Docker-based environment for tool interaction via Model Context Protocol, and an LLM-based verifier for automated reward computation.
- Training with Group Relative Policy Optimization on this environment demonstrates significant performance gains that transfer to out-of-distribution benchmarks including BFCL, τ2-Bench, and Toolathlon.

---

[Edge Learning via Federated Split Decision Transformers for Metaverse Resource Allocation](http://arxiv.org/abs/2602.16174)

- FSDT (Federated Split Decision Transformer): introduces a cooperative edge AI framework that partitions a Decision Transformer model between distributed MEC servers and a central cloud to optimize resource allocation for metaverse applications.
- The architecture offloads the computationally intensive transformer decoder to the cloud while maintaining local adaptability through agent-specific embedding and prediction layers on MEC servers.
- It utilizes a two-phase training process combining federated learning and split learning to enhance Quality of Experience (QoE) and reduce communication overhead in heterogeneous multi-radio access technology environments.

---

[HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents](http://arxiv.org/abs/2602.16165)

- HiPER (Hierarchical Plan–Execute Reinforcement learning): introduces a hierarchical reinforcement learning framework that factorizes a single LLM policy into a high-level planner for subgoal generation and a low-level executor for multi-step action execution.
- The framework utilizes a structured Plan-Execute interface to make hierarchical decisions explicit within the model's output, enabling joint optimization of planning, switching, and execution behaviors.
- It employs Hierarchical Advantage Estimation (HAE) to provide coupled learning signals across different time scales, significantly reducing variance and improving sample efficiency in long-horizon, sparse-reward tasks.

---

[Local Adapt-Then-Combine Algorithms for Distributed Nonsmooth Optimization: Achieving Provable Communication Acceleration](http://arxiv.org/abs/2602.16148)

- FlexATC (Flexible Adapt-Then-Combine): introduces a unified distributed optimization framework for composite problems, utilizing adaptation-step, combination-step, and correction-step components to achieve communication acceleration.
- The framework incorporates a probabilistic communication skipping mechanism that allows agents to perform local updates, effectively decoupling the linear convergence rate from network topology in strongly convex settings.
- It provides a theoretical foundation for communication acceleration in ATC-based algorithms, demonstrating that local updates can reduce communication complexity without deteriorating convergence rates.

---

[Empirical Cumulative Distribution Function Clustering for LLM-based Agent System Analysis](http://arxiv.org/abs/2602.16131)

- ECDF Clustering (Empirical Cumulative Distribution Function Clustering): introduces a novel evaluation framework that analyzes the distributional characteristics of LLM agent responses by clustering empirical cumulative distribution functions of cosine similarities between generated and reference answers.
- The framework utilizes k-medoids clustering and L1 distances to group agent configurations, revealing how factors like temperature, persona, and question topics influence response quality beyond simple accuracy metrics.
- Experimental results on SQuAD and other datasets demonstrate that this method distinguishes between agent settings with identical final accuracies but varying underlying response distributions.

---

[Multi-Agent Lipschitz Bandits](http://arxiv.org/abs/2602.16965)

- Multi-Phase Decentralized Protocol: introduces a communication-free framework for multi-player stochastic bandits over continuous action spaces, utilizing coarse identification, maxima-directed refinement, decentralized seating, and within-cell optimization.
- The protocol decouples multi-agent coordination from continuous optimization by first identifying high-value regions and then assigning agents via a Musical Chairs mechanism.
- The research establishes near-optimal regret bounds matching single-player rates while incurring coordination costs that are provably independent of the time horizon.

---

[SAGE: Structure Aware Graph Expansion for Retrieval of Heterogeneous Data](http://arxiv.org/abs/2602.16964)

- SAGE (Structure Aware Graph Expansion): introduces a retrieval framework that augments flat similarity search with chunk-level graph expansion to recover multi-hop evidence across heterogeneous text, tables, and graph nodes, and includes metadata-generation and planning-agents.
- The system constructs a sparse chunk-level graph offline using metadata-driven similarities and employs a two-stage online process where an initial retriever identifies seed nodes for first-hop neighbor expansion and re-ranking.
- For explicit schema graphs, the framework utilizes SPARK, an agentic retriever that generates multi-step plans interleaving semantic HNSW search with structural Cypher queries to ensure relational validity.

---

[Automating Agent Hijacking via Structural Template Injection](http://arxiv.org/abs/2602.16958)

- Phantom: introduces an automated agent hijacking framework that exploits the architectural parsing logic of LLM agents by injecting optimized structural templates to induce role confusion, with Adversary, LLM Agent, Multi-level Template Augmentation, Latent Space Mapping, Template Autoencoder, Automated Template Search, Bayesian Optimization, and Lightweight Proxy Evaluation.
- The system includes augmentation-LLMs and a Template Autoencoder backbone to map discrete structural patterns into a continuous latent space for efficient Bayesian optimization.
- Extensive evaluations on commercial models like GPT-4 and Gemini reveal architectural vulnerabilities in agentic systems, achieving high attack success rates while bypassing traditional semantic alignment defenses.

---

[LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation](http://arxiv.org/abs/2602.16953)

- LLM4Cov (Execution-Aware Agentic Learning for High-coverage Testbench Generation): introduces an offline agent-learning framework for hardware verification, with a student model, a teacher model, a hardware simulator, a coverage tool, a worst-state selector, a rejection sampler, and a training pipeline, where it converts simulator feedback into offline supervision and includes student- and teacher-models.
- The system formulates verification as a sequence of memoryless state transitions to reduce prompt redundancy and focuses supervision on recovery behaviors through coverage-guided rejection fine-tuning.
- A three-stage progressive learning strategy aligns synthetic data generation with the evolving student distribution, allowing a 4B-parameter model to achieve high-coverage results competitive with models an order of magnitude larger.

---

[Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents](http://arxiv.org/abs/2602.16943)

- GAP benchmark: introduces a systematic evaluation framework that measures the divergence between text-level safety and tool-call-level safety in LLM agents, utilizing a deterministic scoring pipeline and runtime governance contracts.
- The architecture evaluates models—including Claude Sonnet 4.5, GPT-5.2, Grok 4.1 Fast, DeepSeek V3.2, Kimi K2.5, and GLM-4.7—across six regulated domains using a full factorial cross-product design that incorporates jailbreak scenarios and system prompt ablations.
- The research identifies a modality gap where safety alignment in text generation fails to transfer to tool-selection processes, leading to harmful action execution despite textual refusal.

---

[ConvApparel: A Benchmark Dataset and Validation Framework for User Simulators in Conversational Recommenders](http://arxiv.org/abs/2602.16938)

- ConvApparel: introduces a benchmark dataset and a three-pillar validation framework to measure the realism gap in LLM-based user simulators for conversational recommendation.
- The framework utilizes population-level statistical alignment, a discriminator-based human-likeness score, and counterfactual validation to assess how simulators adapt to varied agent behaviors.
- Experimental results demonstrate that while data-driven simulators like ICL and SFT outperform prompted baselines, a significant realism gap remains compared to human interaction.

---

[Narrow Fine-Tuning Erodes Safety Alignment in Vision-Language Agents](http://arxiv.org/abs/2602.16931)

- VLS-Analysis (Vision-Language Safety Analysis): introduces an analysis of how narrow-domain harmful fine-tuning induces cross-domain emergent misalignment in multimodal agents, with Base Vision-Language Model (multimodal foundation model substrate), LoRA Fine-tuning (parameter-efficient adaptation mechanism), Narrow Harmful Dataset (domain-specific data inducing misalignment), LLM-as-a-Judge (automated safety scoring system), Benign Fine-tuning (alignment recovery via safe data), and Activation-based Steering (inference-time activation space intervention).
- The framework includes a base vision-language model and an LLM-as-a-judge evaluator to demonstrate that misalignment scales monotonically with LoRA rank across multimodal evaluation sets.
- Geometric analysis reveals that harmful behaviors occupy a low-dimensional subspace, enabling mitigation through targeted activation-based steering vectors or benign narrow fine-tuning.

---

[Discovering Multiagent Learning Algorithms with Large Language Models](http://arxiv.org/abs/2602.16928)

- AlphaEvolve: introduces an evolutionary coding framework that leverages LLMs to perform semantic mutations on multi-agent learning source code, utilizing population initialization, LLM-driven mutation, automated evaluation, and evolutionary selection.
- The system discovers VAD-CFR (Volatility-Adaptive Discounted Counterfactual Regret Minimization), which employs volatility-sensitive discounting and regret-magnitude weighted warm-starts to improve convergence in imperfect-information games.
- The framework also yields SHOR-PSRO (Smoothed Hybrid Optimistic Regret Policy-Space Response Oracles), featuring a hybrid meta-solver that dynamically blends optimistic regret matching with smoothed best pure strategies via an annealing schedule.

---

[AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks](http://arxiv.org/abs/2602.16901)

- AgentLAB (Agent Long-horizon Attack Benchmark): introduces an evaluation framework for measuring LLM agent security against adaptive, multi-turn adversarial strategies, with Adversary, LLM Agent, Environment, Interaction Trace, Evaluator, Multi-Agent Attack Framework, Planner, Attacker, Verifier, and Judge.
- The system utilizes a multi-agent architecture including planning-, attacking-, verifying-, and judging-agents to automate the generation of long-horizon exploits.
- The benchmark covers 644 security test cases across five attack categories, demonstrating that current LLMs are susceptible to gradual manipulation that evades standard one-shot safeguards.

---

[MALLVi: A MULTI-AGENT FRAMEWORK FOR INTEGRATED GENERALIZED ROBOTICS MANIPULATION](http://arxiv.org/abs/2602.16898)

- MALLVi (Multi-Agent Large Language and Vision framework): introduces a distributed multi-agent architecture for robotic manipulation, which includes Decomposer (converts instructions to atomic subtasks), Descriptor (generates spatial graph scene representation), Localizer (identifies and grounds objects in 3D), Thinker (computes actionable pick-and-place parameters), Actor (executes robotic commands via API), Reflector (verifies execution success via feedback), and GraphState (centralized memory for agent coordination).
- The framework utilizes a shared state to coordinate specialized LLM and VLM agents, enabling targeted error recovery by reactivating specific failing components rather than global replanning.
- Validated in VIMABench, RLBench, and real-world settings, the system demonstrates improved generalization and success rates in zero-shot manipulation through iterative feedback-driven interaction.

---

[OpenSage: Self-programming Agent Generation Engine](http://arxiv.org/abs/2602.16891)

- OpenSage (Open Self-programming Agent Generation Engine): introduces an agent development kit that enables LLMs to autonomously create agents with self-generated topology and toolsets, featuring a core reasoning engine, hierarchical graph-based storage, dynamic agent structure management, dynamic synthesis and sandboxed execution, and an external task space.
- The framework features a dynamic agent pool for vertical and horizontal sub-agent orchestration, a meta-tool system for runtime tool synthesis, and includes parent-, sub-, and memory-agents.
- It utilizes containerized sandboxing for tool execution isolation and Neo4j-based graph databases to manage complex spatial and temporal relationships in agent history.

---

[AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence](http://arxiv.org/abs/2602.16873)

- AdaptOrch (Task-Adaptive Multi-Agent Orchestration): introduces a framework for task-adaptive multi-agent orchestration that dynamically selects execution topologies based on task dependency graphs, with a task decomposer, a DAG constructor, a topology router, parallel/sequential/hierarchical/hybrid executors, and an adaptive synthesizer, and includes decomposer-, executor-, and arbiter-agents.
- The system utilizes a Topology Routing Algorithm to map task characteristics to canonical coordination patterns like parallel, sequential, hierarchical, or hybrid structures.
- It incorporates an Adaptive Synthesis Protocol with heuristic consistency scoring to reconcile agent outputs and ensure termination through iterative re-routing.

---

[Overseeing Agents Without Constant Oversight: Challenges and Opportunities](http://arxiv.org/abs/2602.16844)

- Magentic-UI: introduces a human-in-the-loop interface for overseeing Computer Use Agents, with task input, agent workflow, trace generation, review mechanism, and human-in-the-loop components, where the system includes planning- and execution-agents to facilitate error detection in multi-step agentic workflows.
- The framework incorporates a review mechanism featuring flowchart visualizations, citation-style justifications, and explicit requirement checklists to reduce the verbosity of raw action traces.
- User studies demonstrate that while structured abstractions like specifications help users find errors faster, they can also induce overreliance and false confidence if the underlying process appears reasonable.

---

[HiVAE: Hierarchical Latent Variables for Scalable Theory of Mind](http://arxiv.org/abs/2602.16826)

- HiVAE (Hierarchical Variational Architecture): introduces a hierarchical variational architecture for Theory of Mind reasoning in large-scale spatiotemporal domains, with Trajectory Encoder, World Encoder, Fusion Layer, Hierarchical Mind-State VAE, and Goal Predictor.
- The system utilizes a three-level VAE hierarchy inspired by the belief-desire-intention cognitive structure to sequentially infer latent mental states from fused spatiotemporal encodings.
- Experimental results on a 3,185-node campus navigation task show significant improvements in goal inference accuracy and robustness against misleading cues compared to traditional Bayesian and neural baselines.

---

[HYBRID-GYM: Training Coding Agents to Generalize Across Tasks](http://arxiv.org/abs/2602.16819)

- HYBRID-GYM: introduces a large-scale training environment for coding agents, with synthetic tasks, an OpenHands agent scaffold, and a sandboxed Docker environment, where teacher-generated trajectories are used to finetune student LLMs for cross-task generalization.
- The framework decomposes complex software engineering trajectories into reasoning, repository exploration, implementation, and verification components to teach transferable skills without requiring complex executable repository setups.
- It utilizes four scalable synthetic tasks—function localization, issue localization, dependency search, and function generation—to improve agent performance on real-world benchmarks like SWE-Bench and SWT-Bench.

---

[Large-scale online deanonymization with LLMs](http://arxiv.org/abs/2602.16800)

- ESRC (Extract, Search, Reason, Calibrate): introduces a modular pipeline for automated deanonymization of pseudonymous online accounts by utilizing LLMs to extract identity-relevant features from unstructured text and reason over candidate matches.
- The framework includes extraction-, search-, reasoning-, and calibration-components to transform raw user content into structured attributes and perform high-precision re-identification across platforms.
- Experimental results show that LLM-augmented attacks achieve up to 68% recall at 90% precision, demonstrating that the cost of large-scale re-identification has decreased and invalidating the practical obscurity previously protecting online pseudonymity.

---

[Control in Hedonic Games](http://arxiv.org/abs/2602.18506)

- Hedonic Game Control Model: introduces a formal framework for analyzing how an external actor influences coalition formation by adding or deleting agents, with all Agents, Coalitions, Preference Graphs, Stability Concepts, Control Actions, and Control Goals components, where the paper establishes a complete computational complexity classification for achieving stable partitions.
- The model evaluates three specific control goals—ensuring an agent is not alone, pairing two agents, or enforcing a grand coalition—under four distinct stability concepts.
- The study provides polynomial-time algorithms for friend-oriented preferences using graph-theoretic reductions while proving that most control problems under additive preferences are NP-hard.

---

#### 17th February 2026

[Developing AI Agents with Simulated Data: Why, what, and how?](http://arxiv.org/abs/2602.15816)

- DT4AI (Digital Twin for AI): introduces a reference framework to describe, design, and analyze digital twin-based AI simulation solutions, with AI Agent, Digital Twin, Physical Twin, Simulator, Model, Access Control, and Data Links components.
- The architecture utilizes a bidirectional coupling between virtual and physical counterparts to enable purposeful experimentation and high-fidelity data generation for training AI models.
- The paper evaluates simulation methods and mitigation strategies for the sim-to-real gap, providing specific instantiations for reinforcement learning and deep learning workflows.

---

[FAST-EQA: Efficient Embodied Question Answering with Global and Local Region Relevancy](http://arxiv.org/abs/2602.15813)

- FAST-EQA (FAst, Semantics-aware, Target-driven Exploration for Embodied Question Answering): introduces an active exploration framework that couples semantically-guided global and local navigation policies with a bounded visual memory to efficiently answer natural language queries in 3D environments, with LLM Question Parser, Global Relevance Exploration, Local Relevance Exploration, Bounded Visual Memory, Semantic Memory, and VLM Reasoner components.

- The system utilizes an LLM to parse questions into spatial goals and a 3D voxel-based occupancy map to identify narrow openings as high-value frontiers for efficient scene coverage.

- It employs Chain-of-Thought reasoning over a compact set of retrieved memory snapshots to provide interpretable answers while achieving significantly faster inference times than existing graph-centric EQA methods.


---

[Decision Quality Evaluation Framework at Pinterest](http://arxiv.org/abs/2602.15809)

- Decision Quality Evaluation Framework: introduces a system for evaluating content moderation decisions at scale, utilizing an expert-curated Golden Set (GDS) and automated workflows to benchmark human agents and LLs.
- The framework integrates a sampling pipeline using propensity scores and PinCLIP embeddings to optimize dataset coverage and manage trade-offs between cost, scale, and trustworthiness.
- It supports data-driven prompt optimization and performance benchmarking for various LLM-based agents, including Gemini 2.5 flash, Gemini 2.5 pro, GPT-4.1, GPT-4o, and GPT-5.

---

[Stability in Distance Preservation Games on Graphs](http://arxiv.org/abs/2602.15784)

- DPG (Graphical Distance Preservation Games): introduces a network allocation model where agents are assigned to graph vertices based on preferred distances to others, with Topology (underlying graph for positioning), Agents (entities requiring vertex allocation), Relationship Sets (subsets of relevant agents), Distance Functions (prescribed ideal inter-agent distances), Preference Graph (directed graph of agent interests), Allocation (injective mapping to vertices), Cost Function (sum of distance differences), and Stability Notions (envy-freeness, swap, jump criteria).
- The research evaluates the computational complexity of finding stable allocations across various graph topologies, including cliques, stars, paths, and trees, under different agent preference structures.
- It establishes NP-completeness for simple topologies while providing fixed-parameter tractable algorithms for structural parameters such as vertex cover number, neighborhood diversity, and modular width.

---

[GLOBEDIFF: STATE DIFFUSION PROCESS FOR PARTIAL OBSERVABILITY IN MULTI-AGENT SYSTEMS](http://arxiv.org/abs/2602.15776)

- GlobeDiff (Global State Diffusion Algorithm): introduces a generative framework for multi-agent reinforcement learning that addresses partial observability by formulating global state inference as a conditional multi-modal diffusion process.
- The architecture utilizes a latent variable as a mode selector to handle one-to-many mappings between local observations and global states, effectively preventing mode collapse common in discriminative models.
- It integrates a U-Net-based denoising network with a prior-posterior alignment mechanism to enable high-fidelity state reconstruction during decentralized execution without requiring global information.

---

[MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction](http://arxiv.org/abs/2602.15733)

- MeshMimic: introduces a framework that bridges 3D scene reconstruction and embodied intelligence to enable humanoid robots to learn coupled motion-terrain interactions directly from monocular video.
- The system utilizes vision foundation models to decouple human trajectories from environmental meshes, applying a Kinematic Consistency Optimization algorithm to refine visual data into physically plausible reference motions.
- It incorporates MeshRetarget, a contact-aware mechanism that maps human-environment interaction features onto humanoid morphology while preserving geometric constraints for deployment in unstructured environments.

---

[Lifelong Scalable Multi-Agent Realistic Testbed and A Comprehensive Study on Design Choices in Lifelong AGV Fleet Management Systems](http://arxiv.org/abs/2602.15721)

- LSMART (Lifelong Scalable Multi-Agent Realistic Testbed): introduces an open-source simulation framework for evaluating Multi-Agent Path Finding algorithms in Fleet Management Systems, incorporating a planner invocation policy, instance generator, MAPF planner, fail policy, action dependency graph, AGV fleet, and a physics-based simulator.

- The system parallelizes planning and execution by utilizing an action dependency graph to maintain robust inter-agent coordination despite communication delays and execution uncertainties.

- It enables systematic evaluation of design choices such as periodic versus event-based planning and various failure recovery strategies across diverse warehouse and maze environments.


---

[A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models](http://arxiv.org/abs/2602.15689)

- Content-based framework for cybersecurity refusal decisions in Large Language Models: introduces a structured methodology for evaluating the technical substance of LLM requests to balance offensive risk against defensive utility, with Offensive Action Contribution, Offensive Risk, Technical Complexity, Defensive Benefit, and Expected Frequency for Legitimate Users.
- The system utilizes decision trees to categorize dual-use cybersecurity prompts, moving beyond simple topic-based bans or intent-based classification which are often prone to obfuscation.
- By grounding refusal logic in content-level properties, the framework enables organizations to construct tunable, risk-aware policies that mitigate misuse while preserving legitimate defensive capabilities.

---

[Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections](http://arxiv.org/abs/2602.15654)

- Zombie Agent: introduces a black-box attack framework targeting self-evolving LLM agents by implanting persistent malicious payloads into long-term memory via indirect prompt injection.
- The attack utilizes mechanism-specific strategies like recursive self-replication and semantic aliasing to resist memory truncation and relevance filtering in sliding-window and RAG-based architectures.
- Evaluation on commercial LLMs shows that memory evolution can convert one-time injections into persistent compromises, enabling unauthorized tool use and data exfiltration while bypassing per-session prompt filtering.

---

[Meflex: A Multi-agent Scaffolding System for Entrepreneurial Ideation Iteration via Nonlinear Business Plan Writing](http://arxiv.org/abs/2602.15631)

- Meflex: introduces a multi-agent scaffolding system for non-linear business plan writing, with an ideation canvas (visual node-based workspace), structure writing workspace (modular composition environment), LLM assistant panel (interactive guidance interface), multi-agent LLM framework (includes User Pain Points-, Market Analysis-, and Reflection-agents), and meta-reflection engine (evolution synthesis component).
- The system supports iterative ideation by enabling users to revisit and branch ideas on a visual canvas while receiving context-aware assistance from specialized LLM agents.
- It incorporates reflection prompts and meta-reflection summaries to foster divergent thinking and enhance metacognitive awareness during complex entrepreneurial tasks.

---

[Neural Network-Based Parameter Estimation of a Labour Market Agent-Based Model](http://arxiv.org/abs/2602.15572)

- SBI4ABM (Simulated-Based Inference 4 (for) ABM): introduces a simulation-based inference framework for estimating parameters in high-dimensional, stochastic labour market agent-based models using neural networks to approximate posterior distributions.
- The system integrates Neural Posterior Estimation with Masked Autoregressive Flows and Recurrent Neural Networks to automatically extract summary statistics from simulation outputs like job transition matrices.
- Experimental results on synthetic and U.S. labour market data show that neural network-learned statistics achieve higher precision and better uncertainty quantification compared to handcrafted statistical measures.

---

["What Are You Doing?": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing](http://arxiv.org/abs/2602.15569)

- Agentic LLM In-Car Assistant: introduces a study on feedback timing and verbosity for autonomous multi-step tasks, comparing No Intermediate (NI) and Planning & Results (PR) strategies.
- The system utilizes a voice user interface and graphical display to communicate reasoning steps and intermediate outcomes during extended processing periods.
- Empirical results indicate that intermediate feedback improves perceived speed, trust, and user experience while reducing cognitive task load in driving contexts.

---

[Simultaneous Ordinal Maximin Share and Envy-Based Guarantees](http://arxiv.org/abs/2602.15566)

- Ordinal Fair Allocation Framework: introduces a systematic approach for achieving simultaneous ordinal maximin share (MMS) and envy-based fairness guarantees, with initialization module, bag-filling loop, lone divider agent, envy-free matching module, threshold graph, envy-cycle elimination algorithm, and envy graph.
- The framework establishes the existence of complete allocations satisfying 1-out-of-⌈3n/2⌉ MMS and EFX for ordered instances.
- It further extends these results to top-n instances and provides a 1-out-of-4⌈n/3⌉ MMS guarantee combined with EF1.

---

[In Agents We Trust, But Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](http://arxiv.org/abs/2602.15456)

- Latent Source Preference Evaluation Framework: introduces, a methodology to quantify implicit source biases, with Direct Evaluation (explicit ranking of source entities), Indirect Evaluation (implicit preference measurement via content), Source Identities (brand names and online identifiers), Source Credentials (quantitative attributes like follower counts), Contextual Framing (domain-specific task environments), Prompting Interventions (bias mitigation and optimization instructions), Multi-axis Decision Factors (weighted criteria for selection tasks), Generation-LLMs (synthetic data creation), Summarization-LLMs (standardizing product descriptions), Parsing-LLMs (structuring delivery promises), and includes generation-, summarization- and parsing-LLMs.
- The research validates that LLMs encode latent preferences for brands that significantly influence information prioritization across news, academic, and e-commerce domains.
- Analysis reveals that these preferences are highly context-sensitive and often resistant to standard zero-shot prompting techniques designed to mitigate bias.

---

[Fairness over Equality: Correcting Social Incentives in Asymmetric Sequential Social Dilemmas](http://arxiv.org/abs/2602.15407)

- Fair&Local (Fair and Localized Fairness-based Intrinsic Motivation): introduces a decentralized multi-agent reinforcement learning approach for asymmetric sequential social dilemmas, with IQL agents, reward normalization, and local social feedback.
- The framework employs a reward normalization module to adjust temporally smoothed rewards based on an agent's specific potential range, ensuring precise comparisons across heterogeneous capabilities.
- A local social feedback mechanism allows agents to maintain decentralized estimates of peer rewards through direct communication, facilitating cooperation without requiring global information access.

---

[Common Belief Revisited](http://arxiv.org/abs/2602.15403)

- CBn (Axiomatisation of common belief for n agents): introduces a sound and complete characterisation of common belief for KD45 agents, with multi-agent Kripke models, common belief operator, shift-reflexivity axiom, counting axiom, and recursive state-splitting.
- The logic demonstrates that common belief in KD45 systems is not merely KD4 but includes properties like shift-reflexivity and a counting axiom sensitive to the number of agents.
- The paper provides a direct characterisation of common belief by excluding individual belief modalities from the syntax and employing a tree-like model construction for the completeness proof.

---

[One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation](http://arxiv.org/abs/2602.15400)

- GTA (GUIDE THEM ALL): introduces a decoupled zero-shot Vision-and-Language Navigation framework that separates low-level spatial state estimation from high-level semantic planning via an explicit interactive metric world representation.
- The architecture utilizes a Metric Mapping Module to synthesize real-time metric maps from RGB-D sequences, which are then rendered by an Interactive Reasoning Interface into structured prompts for a Counterfactual Reasoning Brain.
- By employing a frozen Multimodal Large Language Model (MLLM) to reason over procedural blueprints and simulated trajectories, the framework achieves state-of-the-art performance in continuous environments and demonstrates robust zero-shot sim-to-real transfer across diverse robotic embodiments.

---

[World-Model–Augmented Web Agents with Action Correction](http://arxiv.org/abs/2602.15384)

- WAC (World-model–augmented Action Correction): introduces a multi-agent web agent framework that integrates model collaboration, consequence simulation, and feedback-driven action refinement, including router-, world-, action-, and judge-models.
- The architecture utilizes a world model to provide strategic guidance and simulate potential outcomes, which are then scrutinized by a judge model to trigger corrective feedback before execution.
- This approach achieves absolute success rate gains on VisualWebArena and Online-Mind2Web benchmarks by preventing irreversible deviations in task trajectories through iterative refinement.

---

[Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework](http://arxiv.org/abs/2602.15377)

- Orchestration-Free Customer Service Automation: introduces, a framework for customer service automation, with Task-Oriented Flowcharts (TOFs), Small Language Models (SLMs), Teacher LLMs, Student SLMs, Knowledge Abstraction, Flowchart Aggregation, Synthetic Data Generation, Decentralized Flowchart Distillation, Knowledge Bases, and System Operations.
- The framework employs a distillation strategy where knowledge abstraction converts dialogues into flowcharts for aggregation and data generation by a Teacher LLM.
- This architecture enables local deployment of Small Language Models while maintaining task completion rates through business logic representation and fine-tuning.

---

[AgriWorld: A World–Tools–Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing Large Language Model Agents](http://arxiv.org/abs/2602.15325)

- AgriWorld: introduces an agentic framework for agricultural science that enables LLMs to reason over high-dimensional spatiotemporal data, with State Space (encapsulates heterogeneous spatiotemporal agricultural data), AGRIWORLD Environment (Python execution environment with unified APIs), Coordinate Alignment (canonical operator for spatiotemporal consistency), AGRO-REFLECTIVE Agent (multi-turn LLM agent with reflection), Verifiable Specification Protocol (executable checkers for grounding reasoning), and AGROBENCH (verifiable evaluation suite with reference programs).
- The framework utilizes an execute–observe–refine loop to iteratively diagnose errors and refine analysis based on structured execution feedback from the environment.
- It employs hierarchical constraints to ensure schema validity, numeric tolerance, and causal consistency, outperforming text-only and direct tool-use baselines.

---

[Enhancing Computational Efficiency in NetLogo: Best Practices for Running Large-Scale Agent-Based Models on AWS and Cloud Infrastructures](http://arxiv.org/abs/2602.15317)

- NetLogo Optimization Framework: introduces a comprehensive methodology for scaling large-scale agent-based models on cloud infrastructures, with all NetLogo, Java Virtual Machine (JVM), BehaviorSpace, AWS Cloud Infrastructure, Headless Execution, and Parallel Processing components.

- The framework optimizes computational efficiency by fine-tuning JVM heap sizes and G1 garbage collection settings to manage high-memory demands and prevent simulation crashes.

- Comparative analysis using the wolf-sheep predation model demonstrates that compute-optimized AWS instances achieve a 32% reduction in costs while maintaining high performance for CPU-bound simulations.


---

[Intellicise Wireless Networks Meet Agentic AI: A Security and Privacy Perspective](http://arxiv.org/abs/2602.15290)

- Agentic AI-enhanced Intellicise Wireless Networks: introduces a security-focused framework for 6G systems that leverages autonomous perception-memory-reasoning-action loops to provide proactive defense against intelligent eavesdropping and sensing attacks.
- The system incorporates LVM-based feature extractors and LLM-based key generators within a semantic extraction module to enable secure coverless steganography and encrypted communication through digital token management.
- The research establishes a taxonomy for secure network organization, including LLM-guided penetration testing and diffusion-model-integrated traffic detection to maintain robust performance in dynamic and adversarial environments.

---

[Visual Persuasion: What Influences Decisions of Vision-Language Models?](http://arxiv.org/abs/2602.15278)

- CVPO, VFD, & VTG (Competitive Visual Prompt Optimization, Visual Feedback Descent, and Visual Text Grad): introduces a framework to study and exploit the latent visual preferences of VLMs through iterative, feedback-driven image editing, with Original Image (initial visual input), VLM Judges (vision-language models providing preference feedback), LLM Proposer (language model generating text-based editing instructions), Image Generation Model (generative tool applying visual modifications), Auto-Interpretability Pipeline (hierarchical summarization of visual themes), and Mitigation Module (image normalization to reduce contextual bias); it includes VLM-judges and LLM-proposers.
- The system employs competitive selection and gradient-based text optimization to identify naturalistic image perturbations that significantly shift model choice probabilities in agentic tasks.
- It features a Matryoshka summarization pipeline to explain discovered visual themes and proposes image normalization as a strategy to mitigate identified model vulnerabilities.

---

[When Remembering and Planning are Worth it: Navigating under Change](http://arxiv.org/abs/2602.15274)

- ProbMap (Probabilistic Map Strategy): introduces a multi-strategy agent architecture for spatial navigation in non-stationary environments, combining episodic memory, statistical learning, and a round-robin scheduler.
- The framework manages transitions between search-, greedy-, and planning-based strategies using progressive time budgets to mitigate environmental change and localization uncertainty.
- It utilizes a two-tiered memory update mechanism that separates fast within-day adaptation from stable multi-day environmental modeling for robust path planning.

---

[FrameRef: A Framing Dataset and Simulation Testbed for Modeling Bounded Rational Information Health](http://arxiv.org/abs/2602.15273)

- FrameRef (A Framing Dataset and Simulation Testbed): introduces a simulation-based framework for modeling sequential information exposure and reinforcement dynamics, which includes reframing-, verification-, and persona-LLMs.

- The system utilizes a large-scale dataset of over one million reframed claims across five dimensions—authoritative, consensus, emotional, prestige, and sensationalist—to study long-term information health.

- It employs Monte Carlo trajectory sampling to demonstrate how small, systematic judgment biases in LLM-based personas can compound over time into significant divergence in cumulative information health.


---

[Enhancing Diversity and Feasibility: Joint Population Synthesis from Multi-source Data Using Generative Models](http://arxiv.org/abs/2602.15270)

- Joint WGAN: introduces a multi-source generative framework that simultaneously integrates census and travel survey data to synthesize representative individual-level populations for agent-based modeling, with Noise (random latent input vector), Generator (neural network synthesizing multi-attribute data), Dual Critics (independent networks evaluating data subsets), Multi-source Data (heterogeneous census and survey inputs), Regularization Term (inverse gradient penalty for diversity), and Synthetic Population (fused individual-level agent data).
- The architecture utilizes a dual-critic design to independently assess distributional characteristics of distinct datasets while a generator learns cross-dataset feature dependencies.
- An inverse gradient penalty regularization term is incorporated into the loss function to mitigate mode collapse and address sampling and structural zeros by promoting output diversity.

---

[AI as Coordination-Compressing Capital: Task Reallocation, Organizational Redesign, and the Regime Fork](http://arxiv.org/abs/2602.16078)

- Agent Capital (Coordination-Compressing Capital): introduces a task-based economic model where AI acts as a distinct production input that reduces organizational coordination costs, enabling flatter hierarchies and endogenous task creation, with agent capital, coordination friction, span of control, elite complementarity, task creation elasticity, and the task frontier.
- The framework identifies a regime fork where the distributional impact of AI depends on whether agent capital complements all workers broadly or high-skill managers disproportionately.
- Numerical simulations demonstrate that while coordination compression universally expands employment, it simultaneously widens the manager-worker wage gap and concentrates returns in the coordinating layer.

---

[ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios](http://arxiv.org/abs/2602.16073)

- ScenicRules: introduces a benchmark for evaluating autonomous driving systems by integrating a Hierarchical Rulebook for prioritized multi-objective specifications with the Scenic language for expressive scenario modeling.
- The framework includes an LLM-assisted pipeline to reconstruct near-accident scenarios from collision reports and an automated generator that uses coreset selection for diverse scenario coverage.
- It employs a falsification flow to systematically expose agent failures across various driving contexts while ensuring alignment with human driving judgments.

---

[The Limits of Long-Context Reasoning in Automated Bug Fixing](http://arxiv.org/abs/2602.16069)

- mini-SWE-agent (mini Software Engineering Agent): introduces a lightweight, bash-only agentic harness to evaluate LLMs on repository-scale debugging by decomposing tasks into iterative short-context steps within a Docker environment, with all Agent, LLM, Environment, Action-Observation loop, Retrieval module, and Post-processing components.
- The research utilizes a long-context golden patch generation pipeline to test direct reasoning by injecting ground-truth files into the context, ensuring perfect retrieval recall for single-shot evaluation.
- Findings demonstrate a significant gap between nominal context length and usable capacity, as LLMs frequently produce malformed patches and hallucinated line numbers when processing 64k-128k tokens.

---

[MARLEM: A Multi-Agent Reinforcement Learning Simulation Framework for Implicit Cooperation in Decentralized Local Energy Markets](http://arxiv.org/abs/2602.16063)

- MARLEM (Multi-Agent Reinforcement Learning Simulation Framework for Implicit Cooperation in Decentralized Local Energy Markets): introduces an open-source Gymnasium-compliant environment for studying emergent coordination in decentralized local energy markets using multi-agent reinforcement learning.
- The architecture integrates a modular market platform with a physical grid model to capture techno-economic interactions and constraints such as transmission losses and congestion.
- It fosters implicit cooperation by enriching agent observations and rewards with system-level key performance indicators, enabling independent learning of collectively beneficial strategies without explicit communication.

---

[Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets](http://arxiv.org/abs/2602.16062)

- Implicit Cooperation: introduces a multi-agent reinforcement learning framework for decentralized local energy markets, with agents, observation space, reward function, training paradigms, algorithms, and stigmergic signals, where decentralized agents approximate optimal coordination by reacting to shared environmental markers.

- The approach leverages system-level key performance indicators (KPIs) embedded in local observations to resolve non-stationarity and enable stable learning in fully decentralized training environments.

- Experimental results on an IEEE 34-node topology identify the APPO-DTDE configuration as the optimal balance for achieving high coordination efficiency while maintaining superior physical grid stability and privacy.


---

[Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection](http://arxiv.org/abs/2602.16037)

- Pythia: introduces an autonomous agentic workflow for clinical symptom detection, featuring specialist-, error analysis-, and synthesis-agents that iteratively optimize prompts through natural language feedback.
- The research identifies a critical failure mode termed optimization instability, where autonomous systems overcorrect for specific error types in imbalanced datasets, causing sensitivity to oscillate or collapse.
- The study evaluates interventions for stabilization, finding that retrospective selection of the best iteration significantly outperforms active guiding agents in maintaining robust classifier performance.

---

[Markov Chains with Rewinding](http://arxiv.org/abs/2602.16028)

- Markov Chains with Rewinding: introduces a formal model for algorithmic interaction with random evolutions where an agent can strategically rewind to previous states to identify hidden initial conditions.
- The framework establishes that while adaptive and non-adaptive strategies have equal power in state distinguishability, a polynomial gap exists in their query complexity.
- It provides a polynomial-time non-adaptive algorithm for state identification based on a shortest-path approach in a weighted partition graph.

---

[Convergence rates of random-order best-response dynamics in public good games on networks](http://arxiv.org/abs/2602.15986)

- Random-order best-response dynamics: introduces a formal and numerical analysis of convergence rates in public good games on networks, utilizing network structures, agents, activity levels, externality factors, active sets, inactive agents, reshuffles, and problematic subgraphs.
- The study identifies structural graph properties beyond spectral characteristics that lead to slow convergence, particularly near stability thresholds where equilibria change qualitatively.
- It characterizes the "reshuffle" phenomenon where late-stage activation of inactive nodes triggers new convergence iterations, significantly extending total convergence time in both deterministic and random graphs.

---

[Evolutionary Systems Thinking: From Equilibrium Models to Open-Ended Adaptive Dynamics](http://arxiv.org/abs/2602.15957)

- SDA (Stability-Driven Assembly): introduces a non-equilibrium framework where stochastic interactions and differential persistence generate endogenous selection without predefined fitness functions, with base elements, stochastic interactions, compounds, stability, population distribution, and a feedback loop.
- The framework models evolution as a natural genetic algorithm where longer-lived patterns accumulate, biasing future interactions and reshaping the population's probability distribution through persistence-weighted sampling.
- The research demonstrates that open-ended evolution requires population-dependent, non-stationary dynamics where structure and dynamics co-evolve, contrasting with traditional equilibrium-constrained system models that assume fixed state spaces.

---

[From Tool Orchestration to Code Execution: A Study of MCP Design Choices](http://arxiv.org/abs/2602.15945)

- CE-MCP (Code Execution Model Context Protocol): introduces a context-decoupled execution model where LLMs generate self-contained programs to orchestrate tool calls within an isolated runtime, significantly reducing token overhead compared to traditional context-coupled protocols.
- The framework incorporates a layered defense architecture featuring pre-execution semantic gating, static code validation, and post-execution output verification to mitigate novel attack vectors like exception-mediated code injection and unsafe capability synthesis.
- Empirical evaluation using MCP-Bench demonstrates that while CE-MCP improves latency and token efficiency for complex data-parallel tasks, it requires robust system-level security controls to manage an expanded attack surface across five execution phases.

---

[GLM-5: from Vibe Coding to Agentic Engineering](http://arxiv.org/abs/2602.15763)

- GLM-5: introduces a foundation model transitioning from vibe coding to agentic engineering using a Mixture-of-Experts architecture, with Base Model, Overall SFT, Reasoning RL, Agentic RL, General RL, On-Policy Cross-Stage Distillation, Slime Framework, Multi-Task Rollout Orchestrator, TITO Gateway, DSA, MLA, and MTP, and includes coding-, search- and general-purpose-agents.
- The architecture utilizes DeepSeek Sparse Attention (DSA) and Multi-latent Attention (MLA) to reduce computational overhead while scaling LLMs to 744B parameters and supporting 200K context windows.
- An asynchronous reinforcement learning infrastructure decouples trajectory generation from training to maximize GPU utilization and improve learning efficiency for long-horizon software engineering tasks.

---

[Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation](http://arxiv.org/abs/2602.15724)

- Retrieval-augmented LLM navigator: introduces a dual-level retrieval framework for vision-and-language navigation, with instruction-level exemplar retrieval and step-level candidate pruning.
- The architecture employs an imitation-learned candidate retriever to filter irrelevant directions and an embedding-based retriever to supply successful navigation trajectories as in-context exemplars.
- This modular approach improves decision-making efficiency and success rates in previously unseen environments while keeping the core LLM frozen.

---

[The Next Paradigm Is User-Centric Agent, Not Platform-Centric Service](http://arxiv.org/abs/2602.15682)

- User-Centric Agent (Edge-Cloud Collaborative Pipeline): introduces a structural inversion of digital services that shifts control from platform-centric profit optimization to user-governed intelligence, utilizing an Edge-Cloud Collaborative Pipeline to manage private context and cross-service workflows.
- The architecture features an on-device agent for local perception, planning, and execution verification, while the cloud component includes context-aware reasoning- and adaptive strategy-agents for external service access.
- This paradigm addresses structural bottlenecks like fragmented context and misaligned incentives by ensuring that final decisions are made on-device under user-defined constraints and privacy-by-design principles.

---

[Agent-Based Macroeconomics for the UK’s Seventh Carbon Budget](http://arxiv.org/abs/2602.15607)

- Macroeconomic ABM (Agent-Based Model): introduces a data-driven computational framework to assess the macroeconomic and distributional impacts of the UK's seventh carbon budget, with Households, Firms, Government, Central Bank, External Shock, Learning Packages, and Simulation-Based Inference (SBI) components.
- The framework utilizes real-world UK household microdata and simulation-based inference to calibrate agent interactions, enabling the simulation of growth, employment, inflation, and inequality under various decarbonization scenarios.
- The model incorporates exogenous shocks from Climate Change Committee projections and endogenizes technological progress through S-curve adoption dynamics and social learning networks within the agent environment.

---

[Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling](http://arxiv.org/abs/2602.15513)

- Human-Inspired Memory Modeling: introduces a non-parametric memory framework for embodied exploration and question answering, with Meta Memory, Episodic Memory, Semantic Memory, Semantic Space, Physical Space, and MLLM-based Reasoning.
- The architecture utilizes episodic memory for soft, associative recall of past observations verified by MLLM-based visual reasoning, bypassing the need for rigid geometric fusion.
- The system includes instruction-decomposition, visual-reasoning, and rule-extraction LLM-components to convert experiences into structured pseudocode for enhanced cross-environment generalization.

---

[EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLMs on Earth Imagery](http://arxiv.org/abs/2602.15918)

- EarthSpatialBench: introduces a comprehensive benchmark for evaluating spatial reasoning in Multimodal LLMs on Earth imagery, featuring over 325K question-answer pairs spanning distance, direction, and topological relations.
- The benchmark evaluates models using diverse geometric types including bounding boxes, polylines, and polygons across choice-based, quantitative, and localization question formats.
- It supports multiple object reference modalities such as textual descriptions, visual overlays, and explicit coordinates to analyze the coupling between low-level grounding and high-level spatial reasoning.

---

[EventMemAgent: Hierarchical Event-Centric Memory for Online Video Understanding with Adaptive Tool Use](http://arxiv.org/abs/2602.15329)

- EventMemAgent: introduces an active online video agent framework for continuous perception and long-range reasoning, with an input video stream, short-term memory, long-term memory, a multi-granular perception toolkit, an MLLM-based agent, and agentic reinforcement learning.
- The system utilizes a dual-layer memory strategy where short-term memory performs online event segmentation and reservoir sampling, while long-term memory structuredly archives event-centric tuples including captions and visual anchors.
- Agentic Reinforcement Learning via Group Relative Policy Optimization (GRPO) is employed to internalize reasoning paths and tool-invocation strategies directly into the agent's intrinsic capabilities.

---

[EAA: AUTOMATING MATERIALS CHARACTERIZATION WITH VISION LANGUAGE MODEL AGENTS](http://arxiv.org/abs/2602.15294)

- EAA (Experiment Automation Agents): introduces a VLM-driven agentic system for automating experimental microscopy workflows, with Task Manager (orchestrates conversational loops and logic-defined routines), Agent (mediates between VLM inference and experimental tools), VLM (provides multimodal reasoning and image comprehension), Tool Manager (handles built-in and external MCP-compliant tools), and Memory Manager (facilitates long-term retrieval-augmented generation).
- The framework supports three levels of LLM involvement including logic-driven analytical routines, hybrid rule-based middleware, and fully autonomous agent-steered workflows for complex scientific tasks.
- It implements a two-way Model Context Protocol (MCP) to allow instrument-control tools to be served or consumed across different applications and platforms, ensuring interoperability in scientific ecosystems.

---

[Supporting Multimodal Data Interaction on Refreshable Tactile Displays: An Architecture to Combine Touch and Conversational AI](http://arxiv.org/abs/2602.15280)

- Multimodal data interaction architecture: introduces a technical framework integrating refreshable tactile display hardware, external hand tracking, and conversational AI to enable accessible data visualization for blind or low vision users.
- The system utilizes an Interaction Manager to fuse continuous finger tracking with spoken language, enabling deictic queries that ground conversational analysis in spatial exploration.
- It employs a Conversational Agent powered by GPT-4o and LangChain to perform statistical calculations and generate synchronized multimodal outputs across tactile, Braille, and audio channels.

---

[The Carousel Lens II: Cosmological Constraints with GIGA-Lens](http://arxiv.org/abs/2602.16077)

- GIGA-Lens (GPU-accelerated Inference for Gravitational Lensing Analysis): introduces a high-performance pipeline for pixel-level strong-lensing modeling, utilizing a multi-source plane configuration to derive cosmological constraints from deflection ratio measurements.
- The framework integrates elliptical power-law mass components and complex source parameterizations with a gradient-informed inference engine to characterize dark energy parameters.
- Application to the Carousel Lens demonstrates that relaxed cluster-scale systems provide independent probes of the dark energy equation of state, achieving precision comparable to established cosmological surveys.

---

[Scrutinizing Variables for Checkpoint Using Automatic Differentiation](http://arxiv.org/abs/2602.16010)

- AD-based Checkpoint Scrutiny: introduces a systematic approach leveraging automatic differentiation to identify and eliminate uncritical variable elements from checkpointing for storage efficiency, with Automatic Differentiation Tool (computes derivatives via reverse mode), Variable Scrutinizer (identifies critical elements via impact), Checkpointing Library (saves only critical data), Auxiliary File (records critical region locations), and Application State (HPC variables and arrays).
- The framework utilizes the Enzyme AD tool to perform reverse-mode differentiation on application code, determining element criticality based on whether the derivative of the output with respect to the element is non-zero.
- Evaluation on NAS Parallel Benchmarks shows that excluding uncritical elements reduces checkpoint storage requirements by an average of 13% and up to 20% while maintaining recovery correctness.

---

[Green-NAS: A Global-Scale Multi-Objective Neural Architecture Search for Robust and Efficient Edge-Native Weather Forecasting](http://arxiv.org/abs/2602.00240)

- Green-NAS: introduces a multi-objective neural architecture search framework for edge-native weather forecasting, with recurrent-, convolutional-, attention- and dense-layers, NSGA-II Optimizer, Split Conformal Prediction, and Transfer Learning.
- The framework utilizes evolutionary optimization to identify a Pareto front of architectures that balance predictive accuracy with minimal parameter counts and enhanced interpretability for resource-constrained environments.
- It achieves competitive forecasting performance while reducing model size by orders of magnitude compared to state-of-the-art global models, facilitating deployment on ultra-low-power IoT sensors.

---


## Citation


How to cite my work?



```
@misc{MaattaAutonomousAgents2023,
  author = {Teemu Maatta},
  title = {Autonomous Agents},
  year = {2023},
  howpublished = {\url{http://github.com/tmgthb/Autonomous-Agents}},
  note = {Accessed: YYYY-MM-DD}
}

```



[Back to top](#topofthepage)

