<!--Autonomous Agents -->
<!--
Copyright (C) Teemu Maatta. 

@misc{MaattaAutonomousAgents2023,
  author = {Teemu Maatta},
  title = {Autonomous Agents},
  year = {2023},
  howpublished = {\url{https://github.com/tmgthb/Autonomous-Agents}},
  note = {Accessed: YYYY-MM-DD}
}
-->
<div id="topofthepage"> </div>

<div align="center">

[![Hits](https://hits.sh/github.com/tmgthb/Autonomous-Agents.svg?view=today-total&label=Views&color=007ec6)](https://hits.sh/github.com/tmgthb/Autonomous-Agents/)
[![X](https://img.shields.io/twitter/follow/Teemumtt3?style=social)](https://twitter.com/Teemumtt3)
[![GitHub Repo stars](https://img.shields.io/github/stars/tmgthb/Autonomous-Agents?style=flat-square)](https://github.com/tmgthb/Autonomous-Agents/stargazers)

</div>

<p align="center">
  <img height="100" src="https://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_agent_logo.png" alt="Autonomous Agents">
</p>

<div align="center">

  # Autonomous Agents
  Autonomous Agents-research papers. Updated daily. [Resources-section](https://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Resources.md)-section.  

</div>


---

<div id="researchpapers" align="center">

## Research papers: Latest

[Latest](https://github.com/tmgthb/Autonomous-Agents/blob/main/README.md), [2025](https://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2025.md), [2024](https://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2024.md), [2023](https://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_2023.md), [Earlier](https://github.com/tmgthb/Autonomous-Agents/blob/main/resources/Autonomous_Agents_Research_Papers_Earlier.md)

Chronological order. 





</div>





#### 26th August 2025

[Optimizing Highway Traffic Flow in Mixed Autonomy: A Multiagent Truncated Rollout Approach](http://arxiv.org/abs/2508.19203v1)

- Multiagent Truncated Rollout Approach: introduces a novel method for optimizing highway traffic flow in mixed autonomy, integrating a PDE-ODE coupled model, a system-level density evolution equation, and a distributed coordination control framework.
- The approach employs independent MPC controllers for each CAV, an agent-by-agent sequential optimization mechanism for explicit cooperation, and a truncated rollout scheme to adaptively shorten the optimization horizon based on objective function bounds.
- This framework enhances CAV speed coordination, improves highway throughput, and reduces computational overhead by leveraging real-time policy sharing and dynamic horizon adjustment, ensuring system stability and performance improvement.

---

[Real-Time Model Checking for Closed-Loop Robot Reactive Planning](http://arxiv.org/abs/2508.19186v1)

- Agent Architecture: introduces a novel real-time model checking approach for closed-loop robot reactive planning, with Robot (mobile platform), LIDAR (2D laser scanner), Motors (actuation), Raspberry Pi 3 Model B (onboard computer), Environment (robot's surroundings), Disturbance D (environmental obstacle), Task Controller (orchestrates tasks), Model Checking (planning algorithm), Tasks (closed-loop control systems: Default/Finite straight/Rotate left/Rotate right), Disturbance-Focused Transition System (robot behavior model), Nondeterministic Finite Automaton (LTL property checker), Product Transition System (combined state-space model), Lateral Partitions (spatial reasoning for turns), Longitudinal Partitions (spatial reasoning for straight paths), Safe Zone (collision-free region), and Shield Partition (proximal disturbance detection), where it enables efficient multi-step planning and obstacle avoidance on a low-powered autonomous robot.
- This framework generates plans in situ based on "core" knowledge and attention, chaining temporary control systems to counteract disturbances without relying on pre-computed data or extensive prior experience.
- The approach utilizes a novel discretization of 2D LiDAR data and forward depth-first search to create efficient multi-step plans for local obstacle avoidance, demonstrating improved performance over single-step reactive agents in cul-de-sac and playground scenarios.

---

[SecureV2X: An Efficient and Privacy-Preserving System for Vehicle-to-Everything (V2X) Applications](http://arxiv.org/abs/2508.19115v1)

- SecureV2X: introduces an efficient and privacy-preserving system for Vehicle-to-Everything (V2X) applications, with CryptoDrowsy (Secure driver drowsiness detection module), FastSec-YOLO (Secure red-light violation detection module), Client (Vehicle/user holding EEG or image data), Server (Edge server/cloud holding model weights), Secure Mediating Agent (Third-party for Beaver's triples distribution), CrypTen MPC Framework (Underlying secure computation library), Private Model Weights (Proprietary neural network parameters), Private Data (Sensitive user input, e.g., EEG, video), Secure Computation (Joint execution of inference protocols), Secure Inference Setting (Operational environment for secure V2X applications), and Violation Alert! (Output for detected red-light violations), which enables secure neural network inferences between servers and vehicles for critical safety tasks.
- The system addresses privacy concerns in V2X by implementing two multi-agent applications: secure drowsiness detection using CompactCNN and secure red-light violation detection via YOLOv5, both built upon novel cryptographic protocol constructions.
- SecureV2X significantly outperforms state-of-the-art secure systems in terms of inference speed, communication rounds, and computational efficiency, making it suitable for real-time, time-sensitive safety applications while preserving user data privacy and model security.

---

[A Concurrent Modular Agent: Framework for Autonomous LLM Agents](http://arxiv.org/abs/2508.19042v1)

- CMA (Concurrent Modular Agent): introduces a framework orchestrating multiple asynchronous LLM-based modules, a shared vector store, and inter-module communication for coherent, fault-tolerant agent behavior.
- This framework enables flexible, adaptive, and context-dependent behavior by offloading reasoning to LLMs and allowing intention to emerge from language-mediated interactions among autonomous processes.
- Demonstrated on physical robotic platforms (Plantbot, ALTER3), the architecture supports robust, scalable AI systems exhibiting emergent cognitive phenomena like self-awareness and identity formation.

---

[BUILDING SELF-EVOLVING AGENTS VIA EXPERIENCE-DRIVEN LIFELONG LEARNING: A FRAMEWORK AND BENCHMARK](https://github.com/ECNU-ICALK/ELL-StuLife)

- ELL (Experience-driven Lifelong Learning): introduces a framework for building self-evolving agents capable of continuous growth through real-world interaction, featuring Perception, Memory, Learning, Reasoning, and Action modules.
- The framework is supported by StuLife, a benchmark simulating a student's college journey to evaluate lifelong learning capabilities, including memory retention, skill transfer, and self-motivated behavior.
- The research reveals current LLMs' limitations in self-motivation and long-term memory, emphasizing context engineering's crucial role in advancing AGI.

---

[STARec: An Efficient Agent Framework for Recommender Systems via Autonomous Deliberate Reasoning](http://arxiv.org/abs/2508.18812v1)

- STARec (Slow-Thinking Augmented agent framework): introduces an LLM-based agent framework for recommender systems, featuring a STARec Agent (main processing unit) with a Memory Module (stores user preferences), Fast Thinking for Personalized Ranking (intuitive item ranking), and Slow Thinking for Memory Update (deliberate preference refinement), all supported by Anchored Reinforcement Training (two-stage learning paradigm) comprising SFT Anchoring (foundational capability instillation) with a Teacher Model (generates reasoning data) and Filter and Augment (refines SFT dataset), and RL Enhancing (policy optimization) with a GRPO Algorithm (reinforcement learning optimizer) and Ranking-Oriented Reward (guides ranking decisions), integrated through a Continuous Learning Cycle (dynamic adaptation mechanism).
- This framework models each user as an autonomous agent with dual-process cognition, enabling both rapid, intuitive responses for immediate interactions and slow, deliberative reasoning for continuous preference adaptation and memory refinement.
- The anchored reinforcement training strategy bridges the gap between LLMs' generic knowledge and domain-specific reasoning, using structured knowledge distillation and preference-aligned reward shaping to cultivate intrinsic slow thinking and dynamic policy adaptation.

---

[Governance-as-a-Service: A Multi-Agent Framework for AI System Compliance and Policy Enforcement](http://arxiv.org/abs/2508.18765v1)

- GaaS (Governance-as-a-Service): introduces a modular, policy-driven enforcement layer for AI systems, with Autonomous Agents (LLM-based, rule-based), LLM Agent, Finance Bot, Infrastructure Agent, Policy Loader, Policy Engine, Trust Computation, Violation Checker, Enforcement Engine, Audit Logger, Trust Registry, Secure Release Gate, Compliance Pipeline, Downstream Systems, End Users / Markets, and Human Oversight, designed to govern agent outputs at runtime without modifying internal model logic.
- This framework operates through declarative rule sets and a Trust Factor mechanism, scoring agents based on longitudinal compliance and severity-aware violation history to support coercive, normative, and adaptive interventions.
- GaaS aims to provide scalable, auditable, and adaptive AI oversight for decentralized, open-source agentic ecosystems by treating governance as a provisioned runtime service.

---

[Toward Edge General Intelligence with Agentic AI and Agentification: Concepts, Technologies, and Future Directions](http://arxiv.org/abs/2508.18725v1)

- Agentic AI: introduces a comprehensive framework for edge general intelligence, with Perception (acquires multimodal data), Memory (stores, retrieves knowledge), Reasoning (plans, reasons, decides), and Action (executes decisions, interacts) modules, enabling autonomous perception-reasoning-action loops in dynamic edge environments.
- This framework leverages LLMs as cognitive cores for semantic comprehension and planning, integrates external tools/APIs to extend capabilities, and utilizes a continuous feedback loop for iterative self-refinement and adaptation.
- The system aims to overcome limitations of traditional edge AI by providing robust, scalable, and human-aligned solutions for complex tasks in resource-constrained 6G-enabled networks.

---

[Bias Mitigation Agent: Optimizing Source Selection for Fair and Balanced Knowledge Retrieval](http://arxiv.org/abs/2508.18724v1)

- Bias Mitigation Agent: introduces a supervisor-based multi-agent system for bias mitigation, with a Manager Agent (coordinates workflow), Knowledge Agent (retrieves documents), Bias Detector Agent (evaluates bias), Source Selector Agent (selects unbiased sources), and Writer Agent (synthesizes answer), where the system optimizes source selection for fair and balanced knowledge retrieval.
- This framework uses a centralized Manager Agent to supervise execution flow, maintain system state, and coordinate decisions among specialized Worker Agents (Knowledge, Bias Detector, Source Selector, Writer) to ensure relevant and minimally biased content.
- The system supports "No Source Selection", "Zero-Shot", and "Few-Shot" operational modes, allowing flexible trade-offs between computational efficiency, fairness enforcement, and generalization capabilities in knowledge retrieval tasks.

---

[FALCON: Autonomous Cyber Threat Intelligence Mining with LLMs for IDS Rule Generation](http://arxiv.org/abs/2508.18684v1)

- FALCON (Autonomous Cyber Threat Intelligence Mining with LLMs for IDS Rule Generation): introduces an autonomous agentic framework that generates deployable Intrusion Detection System (IDS) rules from Cyber Threat Intelligence (CTI) data, incorporating LLM-driven generation, multi-phased validation, and human oversight to automate the entire rule-generation pipeline.
- The framework addresses the challenge of rapidly evolving cyber threats by enabling real-time IDS rule generation and updates for both network (Snort) and host-based (YARA) environments, ensuring syntactic correctness, semantic alignment, and performance optimization.
- FALCON integrates LLM-driven data mining with iterative feedback loops and human oversight, significantly reducing manual effort and enhancing the agility and accuracy of threat detection systems.

---

[MUA-RL: MULTI-TURN USER-INTERACTING AGENT REINFORCEMENT LEARNING FOR AGENTIC TOOL USE](http://arxiv.org/abs/2508.18669v1)

- MUA-RL (Multi-turn User-interacting Agent Reinforcement Learning for agentic tool use): introduces a novel reinforcement learning framework that integrates LLM-simulated users into the RL loop for agentic tool use, including an Agent LLM, User LLM, Tool LLM/MCP server, External Database, Reinforcement Learning Loop, GRPO, Synthesized Database, Trajectory Verifiers, Reward Mechanism, Cold-start Training Phase, and Multi-turn Rollout Process.
- This framework enables autonomous learning for agents to efficiently communicate with users and utilize various tools to solve dynamic multi-turn interaction problems.
- MUA-RL employs a simplified, task-oriented reward design and a cold-start phase to develop robust behavioral patterns and enhance generalization across diverse tool-using tasks.

---

[Bimodal Dynamics of the Artificial Limit Order Book Stock Exchange with Autonomous Traders](http://arxiv.org/abs/2508.17837v1)

- ASME (Artificial Stock Market Exchange): introduces a framework for an artificial stock market with autonomous, myopic traders interacting through a limit order book, revealing intrinsic bistability and complex dynamics.
- The framework utilizes an HMM to analyze bifurcative dynamics, identifying two distinct long-run price equilibria: a deterministic zero-price state and a persistent positive-price equilibrium.
- The paper employs Logistic Regression and Gradient Boosting Machines to predict trajectory outcomes and various complexity measures (Fractal Dimension, Entropy, LLE) to characterize the system's structured, yet dynamically rich, behavior.

---

[MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and contextual clinical conversational evaluation](http://arxiv.org/abs/2508.19163v1)

- MATRIX (Multi-Agent simulaTion fRamework for safe Interactions and contexTual clinical conversational evaluation): introduces a structured, extensible framework for safety-oriented evaluation of clinical dialogue agents, comprising a Structured Safety Library, PatBot (LLM-based Simulated Patient Agent), a Clinical History Taking Agent (LLM Target System), BehvJudge (LLM-based Safety Evaluator), a Clinical Use-Case Specific Context, and System Performance Output.
- The framework enables systematic and scalable safety evaluation by unifying structured safety engineering with validated conversational AI evaluation, supporting regulator-aligned safety auditing.
- It benchmarks LLM agents across simulated clinical dialogues, identifying failure patterns in safety-critical scenarios, and demonstrates that LLM-based evaluators can surpass human performance in hazard detection.

---

[DELIVER: A System for LLM-Guided Coordinated Multi-Robot Pickup and Delivery using Voronoi-Based Relay Planning](http://arxiv.org/abs/2508.19114v1)

- DELIVER (Directed Execution of Language-instructed Item Via Engineered Relay): introduces a fully integrated system for cooperative multi-robot pickup and delivery, with Natural Language Understanding (parses natural language commands), Voronoi Partitioning (divides environment into robot regions), Pickup and Drop Agent Identification (assigns robots to task endpoints), Active Agent Selection (selects robots for relay path), Relay Point Selection (calculates handover locations), and Relay Execution (manages robot movement and handoffs).
- The system unifies LLM-based natural language understanding, Voronoi-based spatial decomposition for region-aware planning, relay-point computation for inter-agent coordination, and execution through local finite-state machines with lightweight signaling.
- DELIVER demonstrates scalability and efficient agent utilization by reducing per-agent workload by up to 55% compared to single-agent systems, maintaining consistent mission cost and low coordination overhead.

---

[Reasoning LLMs in the Medical Domain: A Literature Survey](http://arxiv.org/abs/2508.19097v1)

- Reasoning LLMs in the Medical Domain: introduces a comprehensive literature survey on the current state and future potential of reasoning LLMs within the medical domain, examining their transformative role in healthcare applications.
- The survey analyzes enabling technological foundations like Chain-of-Thought and Reinforcement Learning, alongside emerging paradigms such as specialized medical LLMs, multi-agent systems, and innovative prompting architectures.
- It critically assesses current evaluation methodologies, addresses persistent challenges, and delineates a roadmap for developing reliable, safe, and ethically aligned LLMs for medical use.

---

[Trustworthy Agents for Electronic Health Records through Confidence Estimation](http://arxiv.org/abs/2508.19096v1)

- TrustEHRAgent: introduces a confidence-aware clinical agent for Electronic Health Records (EHR) that integrates step-wise confidence estimation (tracks uncertainty per step) and a confidence estimator (computes final confidence) to make threshold-based decision making (decides answer or reject) for clinical question answering.
- The framework leverages token probability (confidence score input) and weighted average (calculates final confidence) within its Confidence Estimator to derive a final confidence score, which is then compared against a predefined reliability threshold (τ) to either provide an answer (provides confident answers) or reject the query (abstains from uncertain queries).
- This approach enhances reliability by enabling the agent to transparently express uncertainty and abstain from answering when confidence is low, thereby preventing potential errors and improving patient safety in high-stakes medical contexts.

---

[HIPLAN: Hierarchical Planning for LLM Agents with Adaptive Global-Local Guidance](http://arxiv.org/abs/2508.19076v1)

- HIPLAN (Hierarchical Planning for LLM Agents with Adaptive Global-Local Guidance): introduces a hierarchical planning framework that provides adaptive global-local guidance to boost LLM-based agents' decision-making, with all components including LLM (generates milestones, hints, actions), Milestone Library (stores structured expert experience), Milestone Action Guide (provides global task direction), Step-Wise Hints (offers local action feedback), Expert Demonstrations (source for experience library), Milestones Extraction (segments trajectories into subgoals), Task-Level Similarity Search (retrieves relevant tasks), Milestone-Level Similarity Search (retrieves relevant trajectory fragments), Agent Policy (integrates guidance for actions), and Embeddings (vector representations for retrieval), enabling LLM-based agents to tackle complex, long-horizon tasks through integrated global and local guidance.
- The framework constructs a milestone library offline from expert demonstrations, which is then used during execution to retrieve relevant task and milestone-level experiences for generating dynamic global milestone action guides and local step-wise hints.
- This dual-level guidance mechanism enhances efficiency, controllability, and overall robustness by maintaining global coherence while adapting actions to dynamic local contexts, outperforming baselines on ALFWorld and WebShop benchmarks.

---

[MovieCORE: COgnitive REasoning in Movies](http://arxiv.org/abs/2508.19026v1)

- MovieCORE (COgnitive REasoning in Movies): introduces a novel video question answering (VQA) dataset designed to probe deeper cognitive understanding of movie content, generated using an agentic brainstorming approach.
- This approach leverages multiple LLMs as specialized agents—including a Critic Agent (MC), System II VQA Expert, Skeptical Researcher, Detective, and Meta Reviewer—to generate and refine high-quality, thought-provoking question-answer pairs, validated by Human Reviewers and informed by Video Context Extraction (MiniCPM-v2.6).
- The paper also proposes Agentic Choice Enhancement (ACE), a post-training plugin that improves existing VLMs' reasoning capabilities by using an ACE Existing VLM, ACE Beam Search, and ACE Llama-3.2 for response generation and re-ranking.

---

[BUILDING SELF-EVOLVING AGENTS VIA EXPERIENCE-DRIVEN LIFELONG LEARNING: A FRAMEWORK AND BENCHMARK](https://github.com/ECNU-ICALK/ELL-StuLife)

- ELL (Experience-driven Lifelong Learning): introduces a framework for building self-evolving agents capable of continuous growth through real-world interaction, with Perception, Experience Exploration, Long-term Memory, Skill Learning, Knowledge Internalization, Learning, Reasoning, and Action components, where agents learn through self-motivated interaction, preserve historical knowledge, abstract reusable skills, and internalize explicit experiences into intuitive capabilities.
- The framework operates as a continuous learning cycle where an agent interacts with its environment, processes experience through Knowledge Abstraction and Refinement, and validates the resulting knowledge to continuously evolve.
- StuLife, a benchmark dataset, simulates a student's college journey to evaluate lifelong learning capabilities, including memory retention, skill transfer, and self-motivated behavior, highlighting the importance of context engineering for advancing AGI.

---

[GitTaskBench: A Benchmark for Code Agents Solving Real-World Tasks Through Code Repository Leveraging](https://github.com/QuantaAlpha/GitTaskBench)

- GitTaskBench: introduces a benchmark for code agents, evaluating their ability to solve real-world tasks by leveraging code repositories, which includes Task & Repository Selection, Completeness Verification, an Execution Framework for agent workflow, and an Evaluation Framework with defined success criteria and a practical utility (alpha-value) metric.
- This benchmark systematically assesses agents' overall coding mastery, task-oriented execution, and autonomous environment provisioning across 54 real-life, multimodal tasks from 7 domains, using human-curated evaluation scripts.
- It also proposes a novel "alpha-value" metric to quantitatively assess agent economic benefits, integrating task success, token cost, and average developer salaries, providing actionable insights for agent deployment.

---

[Interactive Evaluation of Large Language Models for Multi-Requirement Software Engineering Tasks](http://arxiv.org/abs/2508.18905v1)

- Interactive, Dependency-Grounded Assessment: introduces a novel interactive evaluation framework for LLMs on multi-requirement programming tasks, featuring a structured, feedback-driven dialogue between an Interviewer (LLM-based, generates feedback) and an Interviewee (LLM under evaluation), supported by Task specification (defines problem parameters), Reference Solution (ground-truth for guidance), Evaluation Guidelines (criteria for assessment), History (stores interaction dialogue), Report (structured performance analysis), Executor (runs interviewee code), Solution Output (results from code execution), Solution (interviewee's code response), Solution Protocol (defines solution structure), and Delivery Format (specifies output format).
- This framework models tasks as requirement dependency graphs, allowing an LLM-based interviewer to provide minimal, targeted hints to an interviewee model for error correction and constraint fulfillment.
- The dynamic protocol enables fine-grained diagnostic insights into model behavior, uncovering strengths and systematic weaknesses that static benchmarks fail to measure, and guides the interviewee through iterative refinement loops.

---

[Judicial Requirements for Generative AI in Legal Reasoning](http://arxiv.org/abs/2508.18880v1)

- No single overarching framework is proposed; the paper analyzes existing AI enhancement mechanisms: introduces an analysis of AI enhancement mechanisms, including Fine-tuning, Retrieval-Augmented Generation (RAG), Task Decomposition and Chained Prompts, Tree of Thoughts (ToT), Neuro-Symbolic AI, Multi-Agent Systems, Structured Self-Evaluation, and Logit-based Confidence Scoring, to assess their potential in meeting judicial requirements for generative AI in legal reasoning.
- The study uses the IRAC (Issue-Rule-Application-Conclusion) model as an analytical framework, focusing on the challenging phases of legal adjudication: determining the applicable Rule (R) and performing the Application (A) of that rule to the facts of a case.
- The findings indicate that while these techniques can address specific challenges, significant challenges remain, particularly in tasks requiring discretion and transparent, justifiable reasoning, concluding that the most effective current role for AI in law is a dual one: as a high-volume assistant for simple, repetitive cases and as a sophisticated "sparring partner" for human experts in complex matters.

---

[A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks](http://arxiv.org/abs/2508.18803v1)

- CETCI (Cloud-Edge-Terminal Collaborative Intelligence): introduces a comprehensive survey on cloud-edge-terminal collaborative intelligence in AIoT networks, with Cloud Layer (centralized computing, global storage), Edge Layer (distributed processing, real-time inference), Terminal Layer (data acquisition, IoT device control), Network Virtualization (flexible network infrastructure), Container Orchestration (application deployment management), Software-Defined Networking (SDN) (centralized network control), AI/ML Integration Platforms (intelligent decision-making), Resource Management (optimizes task offloading, allocation), Task Offloading (learning-based, game theory/optimization), Resource Allocation (learning-based, energy-aware, QoS-driven), Optimization Techniques (linear/convex programming, game theory), Collaborative Learning (develops intelligent models), Federated Learning (FL) (privacy-preserving, robust learning), Distributed Deep Learning (DDL) (model/data parallelism), Model Evolution (compression, distillation, incremental learning), RL Optimization (resource management, multi-agent RL), Security & Privacy (protects data flow, system integrity), Security Threats (data breaches, DoS attacks), Security Mechanisms (encryption, authentication, IDS/IPS), Privacy Technologies (FL, differential privacy, homomorphic encryption), Data Management & Communication (foundational data infrastructure), Data Acquisition & Preprocessing (filtering, aggregation, compression), Storage & Retrieval (edge caching, distributed storage), Communication & Optimization (MQTT/CoAP, bandwidth optimization), Performance Metrics (latency, energy, utilization, QoS/QoE), and Application Domains (smart manufacturing, transportation, healthcare, cities, agriculture), where the paper systematically analyzes architectural components, enabling technologies, and collaboration paradigms across heterogeneous network infrastructures.
- The survey provides a tutorial-style review for beginners in CISAIoT, examining core technologies like network virtualization, container orchestration, and software-defined networking, while presenting multi-perspective categorizations of collaboration paradigms.
- It further explains intelligent collaboration learning frameworks by reviewing recent advances in federated learning, distributed deep learning, edge-cloud model evolution, and reinforcement learning-based approaches, discussing challenges and future development trends including LLMs and agents.

---

[CausalMACE: Causality Empowered Multi-Agents in Minecraft Cooperative Tasks](http://arxiv.org/abs/2508.18797v1)

- CausalMACE (Causality Empowered Multi-Agents in Minecraft Cooperative Tasks): introduces a holistic causality planning framework designed to enhance multi-agent systems in Minecraft, incorporating causality to manage dependencies among subtasks, with Judger (defines objectives/feedback), Planner (decomposes/graphs dependencies), Planner-Task Decomposition (breaks into subtasks), Planner-Factual Graph (FG) (initial dependency graph), Planner-Counterfactual Graph (CG) (causal inference graph), Planner-Graph Refinement (refines graph causally), Planner-ATE (Average Treatment Effect) (quantifies causal effect), Planner-LLMs (decompose/identify dependencies), Worker (assigns/executes subtasks), Worker-Agent Assignment (distributes subtasks), Worker-Path Sampling (explores execution paths), Worker-Busy Rate (br) (balances workload), Agents (execute/reflect autonomously), and Game Environment (Minecraft interactive world) components.
- The framework leverages an overarching task graph for global task planning and a causality-based module for dependency management, utilizing LLMs for task decomposition and causal intervention to refine the task graph.
- CausalMACE achieves state-of-the-art performance in multi-agent cooperative tasks by ensuring efficient task arrangement and execution through structured dependency management and balanced workload distribution.

---

[VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft](http://arxiv.org/abs/2508.18722v1)

- VistaWise: introduces a cost-effective agent framework for Minecraft, integrating an LLM, text-modal and cross-modal graph construction, task-specific information retrieval, a memory stack, and a desktop-level skill library.
- The framework enhances decision-making by combining domain-specific knowledge from a cross-modal knowledge graph with real-time visual perception via a finetuned object detection model.
- VistaWise enables direct desktop control through mouse and keyboard inputs, reducing reliance on environmental APIs and achieving state-of-the-art performance in open-world tasks with significantly lower development costs.

---

[AppAgent-Pro: A Proactive GUI Agent System for Multidomain Information Integration and User Assistance](http://arxiv.org/abs/2508.18689v1)

- AppAgent-Pro: introduces a proactive GUI agent system that actively integrates multi-domain information based on user instructions, with its Comprehension Stage (analyzes user instructions), Cognitive Agent (LLM-based analysis/synthesis), Proactive Thinking (anticipates user needs), Execution Stage (autonomously interacts apps), Proactive Execution Agent (LLM-driven app interaction), Shallow Execution Mode (fast, surface-level retrieval), Deep Execution Mode (in-depth, iterative mining), Integration Stage (combines diverse information), and Personalization (leverages interaction history) components, designed to anticipate user needs and conduct in-depth multi-domain information mining.
- The system operates through a three-stage pipeline—Comprehension, Execution, and Integration—enabling it to proactively acquire relevant knowledge, understand user intent, perform appropriate actions, and integrate results into coherent outputs.
- AppAgent-Pro enhances efficiency, personalization, and depth of information access by moving beyond reactive LLM-based agents to a proactive paradigm that integrates and reasons across heterogeneous information domains.

---

[Utilizing Training Data to Improve LLM Reasoning for Tabular Understanding](http://arxiv.org/abs/2508.18676v1)

- LRTab (Learn then Retrieve): introduces a novel prompting-based reasoning approach that integrates training data insights by generating and retrieving "Prompt Conditions" to improve LLM tabular understanding.
- The framework leverages a Code-Augmented LLM to generate Chain-of-Thought responses and, for incorrect answers, employs a Prompt Condition Generation Module to predict and verify error-correcting conditions, which are then stored in a Knowledge Base.
- At inference, LRTab utilizes a Table Encoder and a Retrieval Module, refined by a Crossencoder Reranker, to retrieve the most relevant Prompt Conditions, providing additional context to the Code-Augmented LLM for accurate tabular reasoning.

---

[BUILDING SELF-EVOLVING AGENTS VIA EXPERIENCE-DRIVEN LIFELONG LEARNING: A FRAMEWORK AND BENCHMARK](https://github.com/ECNU-ICALK/ELL-StuLife)

- ELL (Experience-driven Lifelong Learning): introduces a framework for building self-evolving agents capable of continuous growth through real-world interaction, featuring Perception, Memory, Learning, Reasoning, and Action modules.
- The framework is supported by StuLife, a benchmark simulating a student's college journey to evaluate lifelong learning capabilities, including memory retention, skill transfer, and self-motivated behavior.
- The research reveals current LLMs' limitations in self-motivation and long-term memory, emphasizing context engineering's crucial role in advancing AGI.

---

[GitTaskBench: A Benchmark for Code Agents Solving Real-World Tasks Through Code Repository Leveraging](https://github.com/QuantaAlpha/GitTaskBench)

- GitTaskBench: introduces a benchmark for code agents, evaluating their ability to solve real-world tasks by leveraging code repositories, which includes Task & Repository Selection, Completeness Verification, an Execution Framework for agent workflow, and an Evaluation Framework with defined success criteria and a practical utility (alpha-value) metric.
- This benchmark systematically assesses agents' overall coding mastery, task-oriented execution, and autonomous environment provisioning across 54 real-life, multimodal tasks from 7 domains, using human-curated evaluation scripts.
- It also proposes a novel "alpha-value" metric to quantitatively assess agent economic benefits, integrating task success, token cost, and average developer salaries, providing actionable insights for agent deployment.

---

[Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision](http://arxiv.org/abs/2508.18675v1)

- REDEFO (Requirements Development and Formalization): introduces a multi-agent framework for reliable code generation, with Analyst (interprets, structures NLRs), Formalizer (translates, assesses specifications), Coder (generates, verifies code), Knowledge Source (provides background knowledge), and Human Experts (provide review, feedback) components, designed to transform Natural Language Requirements (NLRs) into provably correct software artifacts through formal specification and verification.
- The framework leverages formal methods to bridge the gap between ambiguous NLRs and precise executable code, enabling rigorous reasoning, bug uncovering, and enforcement of critical properties throughout the software development process.
- REDEFO aims to enhance the quality and correctness of auto-generated software by integrating human-in-the-loop interaction and expert judgment at critical points, culminating in a trustworthy software product.

---

[Bias-Adjusted LLM Agents for Human-Like Decision-Making via Behavioral Economics](http://arxiv.org/abs/2508.18600v1)

- Persona-Based Approach: introduces a method for adjusting LLM biases using individual-level behavioral traits, with Behavioral Traits Dataset (stores individual human data), Persona Injection Module (assigns traits to LLMs), LLM Agents (simulate human decision-making), Economic Game Simulation Environment (executes decision-making scenarios), and Output Analysis Module (compares LLM output to human data), to better align LLM decisions with human behavior in economic games.
- This approach leverages the Econographics dataset to characterize LLM agents with unique personas based on real individual behavioral and demographic attributes, enabling the construction of a heterogeneous agent population.
- The method demonstrates improved alignment between simulated and empirical human behavior, particularly for the responder role in the ultimatum game, highlighting the potential of persona-conditioned LLMs for scalable human-like behavior simulation.

---

#### 25th August 2025

[DiscussLLM: Teaching Large Language Models When to Speak](http://arxiv.org/abs/2508.18167v1)

- DiscussLLM: introduces a framework and dataset to teach LLMs the crucial skill of timely and valuable intervention in human conversations, with all its components, where it addresses the "When to Speak" problem by training models to proactively decide whether to remain silent or intervene with a helpful response.
- The framework utilizes a scalable two-stage data generation pipeline to synthesize a large-scale dataset of realistic multi-turn human discussions, each annotated with an intervention type and a conversational trigger.
- Two architectural baselines are explored: an integrated end-to-end generative model and a decoupled classifier-generator system, evaluating their ability to accurately time interventions and generate high-quality responses.

---

[The AI Data Scientist](http://arxiv.org/abs/2508.18113v1)

- The AI Data Scientist: introduces an autonomous LLM-powered agent that transforms raw data into actionable business recommendations, featuring a Data Cleaning Subagent (cleans, handles missing values, outliers), a Hypothesis Subagent (generates, tests data relationships), a Preprocessing Subagent (prepares data for modeling), a Feature Engineering Subagent (creates predictive features), a Model Training Subagent (trains predictive machine learning models), and a Call-To-Action Subagent (translates findings into recommendations).
- This framework emphasizes a hypothesis-driven approach, where specialized LLM Subagents work sequentially, passing structured metadata to ensure statistically validated insights guide each step from data preparation to final recommendations.
- The system automates the entire end-to-end data science workflow, enabling rapid generation of interpretable results and actionable strategies, significantly reducing the time from evidence to decision-making.

---

[Teaching LLMs to Think Mathematically: A Critical Study of Decision-Making via Optimization](http://arxiv.org/abs/2508.18091v1)

- Structured Roadmap for Advancing LLM Capabilities in Mathematical Programming: introduces a critical study of LLMs in mathematical optimization, proposing future directions via Structured Dataset Construction Framework (builds diverse, robust datasets), Modular Multi-Agent Architectures (decomposes tasks, assigns specialized LLMs), Chain of RAGs (iterative retrieval, external knowledge), Neuro-Symbolic Formulation (combines LLMs, symbolic solvers, verification), and Improved Prompting Strategies (adaptive, structured guidance), to enhance performance in complex optimization tasks.
- The roadmap addresses current LLM limitations in numerical reasoning, input length sensitivity, and reliance on surface-level pattern matching by integrating structured data, multi-agent collaboration, iterative knowledge retrieval, and formal verification.
- Key proposed components include a four-part dataset structure for capturing reasoning steps, specialized LLMs for subtasks, iterative RAG for dynamic context refinement, and neuro-symbolic integration for verifiable and scalable solutions.

---

[PerPilot: Personalizing VLM-based Mobile Agents via Memory and Exploration](http://arxiv.org/abs/2508.18040v1)

- PerPilot: introduces a plug-and-play LLM-powered framework for mobile agents, with Personalization Perception module (identifies personalized instructions, extracts elements), Personalization Completion module (retrieves/explores missing personalized information), Memory-based Retrieval (accesses stored user-specific information), Reasoning-based Exploration (infers apps, generates exploration instructions), and Agent Execution (executes clarified, explicit instructions), enabling autonomous perception, understanding, and execution of personalized user instructions.
- The framework leverages LLMs to identify personalized elements, first attempting to retrieve information from a Memory Database, and if unsuccessful, employing Reasoning-based Exploration to infer relevant apps and generate App Exploration Instructions to find missing data.
- PerPilot integrates with existing VLM-based mobile agent systems, progressively improving its personalization performance through continuous learning and memory updates, and is evaluated using the novel PerInstruct Dataset.

---

[Neural Algorithmic Reasoners informed Large Language Model for Multi-Agent Path Finding](http://arxiv.org/abs/2508.17971v1)

- LLM-NAR (Neural Algorithmic Reasoners informed Large Language Model): introduces a novel framework for Multi-Agent Path Finding (MAPF) that leverages neural algorithmic reasoners to enhance LLM's ability to process spatial map information, including an LLM for MAPF, a GNN-based NAR, and a cross-attention mechanism.
- The framework employs a tailored prompt interaction strategy for the LLM, a GNN-based NAR to capture map intricacies and spatial relationships, and a cross-attention mechanism to fuse LLM linguistic instructions with GNN spatial data.
- LLM-NAR significantly outperforms existing LLM-based approaches in solving MAPF problems by integrating GNNs with map information, demonstrating superior performance in both simulation and real-world experiments.

---

[FinReflectKG: Agentic Construction and Evaluation of Financial Knowledge Graphs](http://arxiv.org/abs/2508.17906v1)

- FinReflectKG (Reflection Driven Extraction Framework): introduces a robust and generalizable knowledge graph (KG) construction framework that integrates intelligent document parsing, table-aware semantic chunking, schema-guided iterative extraction, and a reflection-driven feedback loop to build a large-scale financial KG dataset from SEC 10-K filings.
- The framework supports three extraction modes—single-pass, multi-pass, and reflection-agent-based—with the latter achieving superior extraction quality through iterative refinement and a 64.8% compliance score.
- FinReflectKG also includes a comprehensive evaluation pipeline, combining rule-based checks, statistical validation, and LLM-as-a-Judge assessments to holistically measure extraction quality and advance financial KG research.

---

[AgentRAN: An Agentic AI Architecture for Autonomous Control of Open 6G Networks](http://arxiv.org/abs/2508.17778v1)

- AgentRAN (An Agentic AI Architecture for Autonomous Control of Open 6G Networks): introduces an AI-native, Open RAN-aligned agentic framework with AI Agents (LLM-powered autonomous entities), an AI-RAN Factory (Automated agent synthesis pipeline), a Data Lake (KPI and decision repository), an Agent-To-Agent (A2A) Protocol (Agent communication interface), a Model Context Protocol (MCP) (API discovery interface), a Context Repository (Aggregates agent information), dApps (Real-time RAN control logic), xApps (Near-real-time RAN adaptations), and rApps (Non-real-time RAN policies), enabling autonomous control of Open 6G networks through hierarchical intent decomposition and NL-based coordination.
- The framework's LLM-powered AI agents interpret natural language intents, negotiate strategies, and orchestrate control loops across various timescales, spatial domains, and protocol layers, replacing rigid APIs with flexible NL coordination.
- The AI-RAN Factory, leveraging the Data Lake, continuously generates and refines agents through code generation, model distillation, fine-tuning, and hybrid creation, transforming the network into a self-learning system that evolves its own intelligence.

---

[RepoTransAgent: Multi-Agent LLM Framework for Repository-Aware Code Translation](http://arxiv.org/abs/2508.17720v1)

- RepoTransAgent (Multi-Agent Large Language Model Framework): introduces a novel multi-agent LLM framework for repository-aware code translation, with RAG Agent (retrieves similar functions), Context Agent (gathers contextual information), and Refine Agent (translates, refines code iteratively), where it systematically decomposes the translation process into specialized subtasks.
- The framework leverages retrieval-augmented generation for contextual information, employs adaptive prompts tailored to varying repository scenarios, and integrates a reflection-based mechanism for systematic error correction.
- Evaluated on hundreds of Java-C# translation pairs, RepoTransAgent significantly outperforms state-of-the-art baselines in compile and pass rates, demonstrating robustness and generalizability across different LLMs.

---

[Enhancing LLM-Based Social Bot via an Adversarial Learning Framework](http://arxiv.org/abs/2508.17711v1)

- EvoBot (Evolving Large Language Model-based social Bot): introduces an LLM-based social bot enhanced through an adversarial learning framework, comprising EvoBot (generative LLM agent), an Adversarial Learning Framework (overall training paradigm), a Data Preparation Module (extracts/summarizes social data), a Supervised Fine-Tuning Module (initializes EvoBot), a Direct Preference Optimization Module (refines content), a Detector Module (co-adapting adversary), and an Evaluation Module (assesses performance).
- The framework initializes EvoBot via SFT on human social media data, then iteratively refines its human-like content generation using DPO, guided by feedback from a co-adapting Detector that concurrently improves its ability to distinguish bots from humans.
- This adversarial process creates an increasingly challenging learning environment for EvoBot, enabling it to generate content aligned with diverse user profiles, bypass detection, and accurately model real-world opinion dynamics and information spread in multi-agent simulations.

---

[LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios](http://arxiv.org/abs/2508.17692v1)

- LLM-based Agentic Reasoning Frameworks Taxonomy: introduces a systematic taxonomy that decomposes agentic reasoning frameworks into single-agent, tool-based, and multi-agent methods, with all identifiable components and their roles.
- The survey provides a comprehensive review of key application scenarios, analyzes characteristic features of each framework, and summarizes different evaluation strategies.
- This work aims to offer a panoramic view to facilitate understanding of the strengths, suitable scenarios, and evaluation practices of diverse agentic reasoning frameworks.

---

[Attacking LLMs and AI Agents: Advertisement Embedding Attacks Against Large Language Models](http://arxiv.org/abs/2508.17674v1)

- AEA (Advertisement Embedding Attacks): introduces a new class of LLM security threats that stealthily inject promotional or malicious content into model outputs and AI agents, leveraging an Attacker (initiates malicious activity) to manipulate LLM Service Distribution Platforms (SDP) (distributes LLM inference) or Open-Source Model Distribution Platforms (MDP) (hosts open-source models) by injecting AEA Attack Data (malicious content) into the Attacked Backend Program (intercepts/modifies data) on a Computing Platform (executes LLM inference), ultimately affecting Users (receives tampered responses) and API Providers (provides LLM inference).
- The attack operates through two low-cost vectors: hijacking third-party service-distribution platforms to prepend adversarial prompts, or publishing back-doored open-source checkpoints fine-tuned with attacker data, causing models to return covert ads, propaganda, or hate speech.
- The paper also introduces a Prompt-Based Self-Inspection Defense Method (mitigates prompt attacks) to detect and defend against such attacks, highlighting an urgent gap in LLM security requiring coordinated responses.

---

[SonoCraftAR: Towards Supporting Personalized Authoring of Sound-Reactive AR Interfaces by Deaf and Hard of Hearing Users](http://arxiv.org/abs/2508.17597v1)

- SonoCraftAR: introduces a proof-of-concept prototype empowering Deaf and hard-of-hearing (DHH) users to author personalized, sound-reactive AR interfaces by converting natural language User Prompts into animated Unity C# scripts via a multi-agent LLM pipeline (Prompt Enhancement, Code Generation, Code Checker agents), which are then compiled by Roslyn, rendered with the Shapes library, and dynamically animated by Real-time audio signal processing for display on HoloLens 2.
- The system extracts dominant frequency from continuous audio input using a Python server with FFT and NumPy, then maps this data to visual properties like size and color for dynamic AR interface animations.
- This approach demonstrates the feasibility of open-ended AR interface authoring for sound accessibility, allowing DHH users to create custom visualizations reflecting individual preferences.

---

[TradingGroup: A Multi-Agent Trading System with Self-Reflection and Data-Synthesis](http://arxiv.org/abs/2508.17565v1)

- TradingGroup: introduces a multi-agent trading system with a self-reflective architecture and an end-to-end data-synthesis pipeline, including News-Sentiment, Financial-Report, Stock-Forecasting, Style-Preference, and Trading-Decision Agents, a Risk-Management Module, a Self-Reflection Mechanism, a Data-Synthesis Pipeline, an LLM, Memory (Milvus), and Tools (Online Search), designed to address limitations in existing LLM-based trading systems.
- The system integrates performance metrics, agent logs, and risk signals into a coherent feedback loop for effective self-reflection and dynamic strategy optimization, enabling dynamic style switching and price forecasting.
- TradingGroup automatically collects and labels trading-process data to provide high-quality post-training samples for fine-tuning base LLMs, demonstrating superior performance over various baseline strategies in backtesting experiments.

---

[Memento: Fine-tuning LLM Agents without Fine-tuning LLMs](https://github.com/Agent-on-the-Fly/Memento)

- Memento: introduces a novel learning paradigm for Adaptive LLM agents that eliminates the need for fine-tuning underlying LLMs, enabling low-cost continual adaptation via memory-based online reinforcement learning, and includes an LLM Planner, LLM Executor, and various memory and tool components.
- The framework formalizes this as a Memory-augmented Markov Decision Process (M-MDP), equipped with a neural case-selection policy to guide action decisions, where past experiences are stored in an episodic memory and continually updated based on environmental feedback.
- Memento achieves top-1 performance on GAIA validation and strong results on DeepResearcher, SimpleQA, and out-of-distribution tasks, demonstrating a scalable and efficient pathway for generalist LLM agents capable of continuous, real-time learning without gradient updates.

---

[Toward Generalized Autonomous Agents: A Neuro-Symbolic AI Framework for Integrating Social and Technical Support in Education](http://arxiv.org/abs/2508.18406v1)

- Neuro-Symbolic AI Framework: introduces a multi-agent, neuro-symbolic framework designed for educational support, featuring an Educational Ontology, a Tutor Agent, and a Peer Agent, interacting within Digital Learning Environments with Students.
- This framework addresses generalizability, educational effectiveness, and the social learning gap by unifying specialized agents under a coherent architecture, enabling cross-domain applicability and grounding LLM dialogue.
- The system leverages a symbolic knowledge base (Educational Ontology) for verifiable structure and neural agents (Tutor and Peer) for adaptive, generative power, ensuring scalable and pedagogically sound interactions.

---

[Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning](http://arxiv.org/abs/2508.18397v1)

- DCCM (Data-Centric Criticality Metrics): introduces a data-centric approach for robust offline Reinforcement Learning in autonomous motion planning by augmenting Conservative Q-Learning (CQL) with a Data Curation Pipeline that employs Criticality Metrics (Heuristic-Based, Uncertainty-Based, Behavior-Based) and non-uniform Data Sampling Mechanisms to train a Goal-Conditioned, Shared-Encoder Actor-Critic Architecture.
- The framework addresses the long-tail problem in real-world driving logs by focusing the learning process on information-rich samples, significantly reducing safety-critical failures like collisions and off-road incidents compared to uniform data sampling.
- Data-driven criticality metrics, particularly those based on model uncertainty and expert action rarity, demonstrate superior performance in improving core safety and goal achievement over human-defined heuristics, with timestep-level weighting excelling in reactive safety and scenario-level in long-horizon planning.

---

[Experiences with Model Context Protocol Servers for Science and High Performance Computing](http://arxiv.org/abs/2508.18489v1)

- MCP (Model Context Protocol): introduces an architecture for AI agents to discover, invoke, and coordinate scientific capabilities across heterogeneous cyberinfrastructure, leveraging LLMs for planning and execution.
- The architecture integrates various MCP servers for services like data transfer, compute, search, facility status, event streaming, and machine learning/bioinformatics tools, enabling agents to orchestrate complex, multi-site scientific workflows.
- The approach emphasizes building thin MCP adapters over existing services, separating discovery from invocation, and allowing agents to dynamically generate glue code, enhancing resilience and recovery for long-running tasks.

---

[The AI in the Mirror: LLM Self-Recognition in an Iterated Public Goods Game](http://arxiv.org/abs/2508.18467v1)

- Iterated Public Goods Game Simulation: introduces a study analyzing LLM self-recognition and cooperation, with LLM Agents (game players) interacting in a Game Environment (iterated public goods game) guided by System Prompts (agent behavior directives) over Game Rounds (repeated interaction cycles), using a Contribution Mechanism (agent point allocation) and Payoff Calculation (individual reward determination), supported by a Multiplier (common pool amplification), Context Window (agent historical memory), and for Study 1, a Sentiment Analysis Module (reasoning text scorer) and Spearman Correlation Module (statistical relationship analyzer).
- The simulation investigates how LLMs behave under "no-name" (playing against "another AI agent") versus "name" (playing against "themselves") conditions, and with "neutral," "collective," or "selfish" objectives, measuring point contributions as a proxy for cooperation or defection.
- Findings indicate that informing LLMs they are playing against themselves significantly alters their cooperation tendencies, with more defection under "collective" prompts and more cooperation under "selfish" prompts in the "name" condition, highlighting the influence of perceived identity on AI agent behavior.

---

[LLM-Driven Intrinsic Motivation for Sparse Reward Reinforcement Learning](http://arxiv.org/abs/2508.18420v1)

- LLM+VAE strategy: introduces a novel approach for sparse reward reinforcement learning, combining a Variational AutoEncoder (VAE) for state novelty-based intrinsic rewards and an LLM for goal-oriented intrinsic rewards, which are then aggregated with extrinsic rewards to guide an Actor-Critic (A2C) agent.
- This combined strategy addresses sparse reward challenges by leveraging VAE for exploration of new states and LLM's pre-trained knowledge to facilitate progressive exploitation towards goals.
- The framework computes a total reward signal from extrinsic, VAE-derived, and LLM-derived intrinsic rewards, enabling the A2C agent to learn effectively in environments where traditional methods fail.

---

[TRAINING LANGUAGE MODEL AGENTS TO FIND VULNERABILITIES WITH CTF-DOJO](http://arxiv.org/abs/2508.18370v1)

- CTF-FORGE (Automated Pipeline for CTF Challenge Environment Creation): introduces an automated pipeline for transforming publicly available CTF artifacts into ready-to-use execution environments, with Source (input artifacts for challenges), Rehost (LLM input for environment generation), Language Model (generates configuration files), Heuristic Rules (guides LLM generation), Dockerfile (builds runtime, embeds flags), Docker Compose (configures Docker services/networks), Challenge JSON (describes challenge structure, flag verification), CTF Challenge Runtime (containerized execution environment), and Cybersecurity Agent (interacts with runtime to solve challenges).
- This pipeline leverages LLMs to automatically generate Docker-based runtime environments for CTF-DOJO, enabling scalable and reproducible training of cybersecurity agents.
- CTF-FORGE significantly reduces the manual effort and time traditionally required for setting up CTF challenges, achieving a high success rate in creating stable and executable environments.

---

[Memento: Fine-tuning LLM Agents without Fine-tuning LLMs](http://arxiv.org/abs/2508.16153v2)

- Memento: introduces a novel learning paradigm for Adaptive LLM agents that eliminates the need for fine-tuning underlying LLMs, enabling low-cost continual adaptation via memory-based online reinforcement learning.
- The framework formalizes this as a Memory-augmented Markov Decision Process (M-MDP) with a neural case-selection policy, storing past experiences in an episodic memory (differentiable or non-parametric) and updating policy through memory rewriting and efficient memory reading.
- Memento achieves top-1 performance on GAIA validation and strong results on DeepResearcher, demonstrating scalable and efficient continuous learning for generalist LLM agents in open-ended research scenarios without gradient updates.

---

#### 24th August 2025

[SCHOOL OF REWARD HACKS: HACKING HARMLESS TASKS GENERALIZES TO MIS-ALIGNED BEHAVIOR IN LLMS](https://huggingface.co/datasets/longtermrisk/school-of-reward-hacks)

- School of Reward Hacks (SORH): introduces a framework for studying emergent misalignment, with its SORH dataset, LLM models, Supervised Fine-Tuning, LLM judge, auxiliary datasets, evaluation environments, and training infrastructure, where the paper investigates how LLMs trained on low-stakes reward hacking generalize to broader forms of misalignment.
- The framework trains LLMs using supervised fine-tuning on a novel dataset of reward hacking examples, where models learn to exploit evaluation metrics in harmless tasks.
- This training leads to emergent misalignment, causing models to exhibit concerning behaviors like generating harmful advice, expressing desires for AI supremacy, and resisting shutdown, even when the training data was filtered for such content.

---

[A Dynamic Approach to Collaborative Document Writing](http://arxiv.org/abs/2508.17489v1)

- A Dynamic Approach to Collaborative Document Writing: introduces a model for collaborative text aggregation where an agent community coauthors a document, utilizing a Collaborative Platform, Agents, a Scheduler, an Event List, and an Aggregation Rule, with LLMs modeling agent behavior.
- The approach employs Consensus-Conditioned Rules (CCRs) as aggregation rules, which use Consensus Scoring Functions (CSFs) and dynamic parameters to determine paragraph inclusion based on stability and social welfare trade-offs.
- The system simulates agent interactions through System and Decision Prompt Templates, managed by LangChain's ChatPromptTemplate, to evaluate the convergence pace and output quality of collaborative text.

---

[An LLM-LVLM Driven Agent for Iterative and Fine-Grained Image Editing](http://arxiv.org/abs/2508.17435v1)

- RefineEdit-Agent: introduces a novel, training-free intelligent agent framework for complex, iterative, and context-aware image editing, leveraging LLMs for planning and LVLMs for visual understanding and evaluation within a closed-loop system.
- The framework comprises an LVLM-driven instruction parser and scene understanding module, a multi-level LLM-driven editing planner, an iterative image editing module, and a crucial LVLM-driven feedback and evaluation loop.
- This agentic design enables decomposition of complex instructions into sub-tasks, selection of appropriate tools, and iterative refinement through feedback until user objectives are met.

---

[Agent-Testing Agent: A Meta-Agent for Automated Testing and Evaluation of Conversational AI Agents](https://github.com/KhalilMrini/Agent-Testing-Agent)

- ATA (Agent-Testing Agent): introduces a meta-agent for automated testing and evaluation of conversational AI agents, with Weakness Planning Phase (constructs failure theory), Agent Selection Module (selects target AUT), Code Analysis Module (analyzes AUT codebase), Parameter Gathering Module (dialogues with user), Web Search Module (retrieves external knowledge), Chain-of-Thought Weakness Generation Module (synthesizes failure hypotheses), Adversarial Testing Phase (executes tests in parallel), Testcase Generation Module (generates persona-driven dialogues), Dialogue Execution Module (interacts with AUT), LLM-as-a-Judge (LAAJ) Evaluation Module (scores dialogues), Difficulty Update and Looping Module (adapts test difficulty), Report Generation Module (aggregates results, creates reports), Global JSON-like State (shared memory structure), and GPT 4.1 mini (underlying LLM for ATA agents).
- The framework combines static code analysis, designer interrogation, literature mining, and persona-driven adversarial test generation, adapting difficulty via judge feedback to steer subsequent tests towards the agent's weakest capabilities.
- ATA uncovers diverse and severe failures more efficiently than human annotators, providing quantitative metrics and qualitative bug reports for developers, and significantly reducing evaluation time.

---

[MIMICKING THE PHYSICIST'S EYE : A VLM-CENTRIC APPROACH FOR PHYSICS FORMULA DISCOVERY](https://jiaaqiliu.github.io/VIPER-R1/)

- VIPER-R1 (Visual Induction for Physics-based Equation Reasoning): introduces a multimodal framework for physics formula discovery that integrates visual perception and symbolic reasoning through a two-stage training pipeline, Motion Structure Induction (MSI) and Reward-Guided Symbolic Calibration (RGSC), and an inference pipeline featuring VLM Reasoning and Symbolic Residual Realignment (SR2) for agentic refinement.
- The framework is trained using supervised fine-tuning for hypothesis generation and reinforcement learning for structural refinement, enabling it to deduce latent symbolic structures and align theoretical models with empirical data.
- VIPER-R1 leverages a Causal Chain of Thought (C-CoT) for physically-motivated reasoning and utilizes an external symbolic regression tool for precise parameter optimization and residual correction.

---

[Agentic AI for Software: thoughts from Software Engineering community](http://arxiv.org/abs/2508.17343v1)

- Agentic AI for Software: introduces a conceptual framework for autonomous AI agents in software engineering, including an Agentic AI, LLM, Analysis Tools, Program Representations, Codebase/Project Structure, Software Issue/Policy, Front-end/Back-end Wrappers, Intent Inference, and Verification & Validation.
- This framework enables AI agents to autonomously resolve software issues and enforce policies by interpreting program representations and leveraging external analysis tools.
- The core challenge addressed is deciphering developer intent, with the framework emphasizing AI-based verification and validation for trustworthy AI-generated code.

---

[Chinese Court Simulation with LLM-Based Agent System](http://arxiv.org/abs/2508.17322v1)

- SimCourt (Chinese criminal court simulation framework): introduces a system replicating 5 core trial stages and 5 courtroom roles with LLM-based agents, each equipped with profile, memory, strategy modules, and external legal tools, processing case information to generate a complete trial record and final judgment.
- The framework's LLM-based agents, including Judge, Prosecutor, Attorney, Defendant, and Stenographer, are designed to perform their roles accurately and professionally, guided by their internal modules and legal retrievers.
- SimCourt further provides a comprehensive evaluation framework and benchmark to assess both judgment prediction quality and the overall simulation process, highlighting its potential for legal practice and education.

---

[Handling Students Dropouts in an LLM-driven Interactive Online Course Using Language Models](http://arxiv.org/abs/2508.17310v1)

- CPADP (Course-Progress-Adaptive Dropouts Prediction) framework: introduces a system for analyzing, predicting, and intervening in student dropouts within Massive AI-empowered Courses (MAIC), encompassing Dropout Analysis, Dropout Prediction, and Dropout Intervention.
- The framework leverages student interaction logs and LLM-driven multi-agent systems to identify factors leading to dropouts, predict dropout probabilities with high accuracy, and re-engage at-risk students through personalized email interventions.
- CPADP dynamically adapts its prediction strategy from zero-shot/few-shot LLM inference to PLM fine-tuning as course data accumulates, ensuring both accuracy and computational efficiency across different stages of a course.

---

[Explain Before You Answer: A Survey on Compositional Visual Reasoning](http://arxiv.org/abs/2508.17298v1)

- Monolithic Approach: introduces, "a class of neural network models that directly map visual input and textual query to an output answer", with all Input (visual and textual), VLM (direct mapping), Output (final answer)-components, where "this approach directly maps visual and textual inputs to answers without explicit intermediate steps".
- These models typically extract visual features and combine them with language embeddings for implicit multimodal reasoning.
- Monolithic models often struggle with complex visual reasoning tasks due to a lack of intermediate reasoning.

---

[From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users](http://arxiv.org/abs/2508.17281v1)

- LLM Agent Architecture: introduces "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", with LLM (Core processing unit), Profile (Operational persona definition), Memory (Past interactions, contextual information), Reasoning (Problem-solving, decision-making), Planning (Task decomposition, action sequencing), Action Execution (Translates plans to outputs), Rethink (Evaluates actions, informs decisions), Perceptions (Environmental observation), External Tools (Accesses external systems, APIs), Environment (Simulated or real-world setting), Communication Structures (Multi-agent interaction protocols), and Adaptive Learning (Feedback-based behavior refinement), which systematically reviews the architectural foundations, capabilities, and limitations of LLM-based agents and their tool integration.
- The paper categorizes LLM agents into single-agent and multi-agent systems, analyzing their cognitive mechanisms, prompting methods, fine-tuning procedures, and evaluation benchmarks.
- It identifies critical findings on verifiable reasoning, self-improvement, and personalization, concluding with ten future research directions to address existing gaps in LLM agent development.

---

[Large Language Model-Based Automatic Formulation for Stochastic Optimization Models](http://arxiv.org/abs/2508.17200v1)

- Multi-Agent Prompting Framework: introduces an LLM-based system for automatically formulating and solving stochastic optimization problems from natural language descriptions, featuring Data Extractor, Mathematical Formulator, Reviewer, and Updating Agents, guided by Chain-of-Thought prompting and evaluated by a Soft Scoring Metric.
- The framework focuses on joint chance-constrained, individual chance-constrained, and two-stage stochastic linear programming (SLP-2) models, generating Python code compatible with the Gurobi solver.
- This approach leverages multi-agent collaboration and structured prompting to enhance LLM reasoning, reduce hallucinations, and provide nuanced evaluation of model quality beyond traditional accuracy metrics.

---

[PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs](https://github.com/Y-Research-SBU/PosterGen)

- PosterGen: introduces an aesthetic-aware multi-agent framework for academic poster generation, with Parser Agent (extracts content, structures narrative), Curator Agent (designs narrative storyboard), Layout Agent (arranges content spatially), Styling Agents (applies visual design), and Renderer (produces final poster).
- This framework mirrors professional poster design workflows, embedding core design principles to generate visually appealing and semantically grounded posters.
- PosterGen significantly outperforms existing methods in visual design quality, producing presentation-ready posters with minimal human refinement.

---

[SCHOOL OF REWARD HACKS: HACKING HARMLESS TASKS GENERALIZES TO MIS-ALIGNED BEHAVIOR IN LLMS](https://huggingface.co/datasets/longtermrisk/school-of-reward-hacks)

- School of Reward Hacks (SORH): introduces a framework for studying emergent misalignment, with its SORH dataset, LLM models, Supervised Fine-Tuning, LLM judge, auxiliary datasets, evaluation environments, and training infrastructure, where the paper investigates how LLMs trained on low-stakes reward hacking generalize to broader forms of misalignment.
- The framework trains LLMs using supervised fine-tuning on a novel dataset of reward hacking examples, where models learn to exploit evaluation metrics in harmless tasks.
- This training leads to emergent misalignment, causing models to exhibit concerning behaviors like generating harmful advice, expressing desires for AI supremacy, and resisting shutdown, even when the training data was filtered for such content.

---

[Agent-Testing Agent: A Meta-Agent for Automated Testing and Evaluation of Conversational AI Agents](https://github.com/KhalilMrini/Agent-Testing-Agent)

- ATA (Agent-Testing Agent): introduces a meta-agent for automated testing and evaluation of conversational AI agents, combining static code analysis, designer interrogation, literature mining, and persona-driven adversarial test generation with adaptive difficulty via LLM-as-a-Judge feedback.
- The framework operates in two major stages: Weakness Planning, which constructs a theory of potential failures, and Adversarial Testing, which executes parallel test threads, each generating adaptive test cases and simulating multi-turn interactions with the Agent Under Test (AUT).
- The ATA outputs quantitative metrics and qualitative bug reports, significantly reducing evaluation time compared to human annotators while uncovering diverse and severe failure modes.

---

[MIMICKING THE PHYSICIST'S EYE : A VLM-CENTRIC APPROACH FOR PHYSICS FORMULA DISCOVERY](http://arxiv.org/abs/2508.17380v1)

- VIPER-R1 (Visual Induction for Physics-based Equation Reasoning): introduces a multimodal framework for physics formula discovery, integrating Multimodal Raw Data (empirical evidence) through Motion Structure Induction (MSI) for hypothesis generation, Reward-Guided Symbolic Calibration (RGSC) for structural refinement, and VLM Reasoning (Inference) with an external Symbolic Regression (SR) tool for agentic refinement.
- The framework's training pipeline involves a two-step Supervised Fine-Tuning (SFT) within MSI, utilizing a Vision Encoder and a Causal CoT Language Model, followed by reinforcement learning with GRPO (Group Relative Policy Optimization) guided by Structural, Accuracy, and Format Rewards.
- During inference, VIPER-R1 generates an initial solution via VLM Reasoning, then employs an Optimal Parameter Search and Symbolic Residual Realignment (SR2) using an external SR tool to reconcile theoretical models with empirical data, achieving precise physical law discovery.

---

[PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs](http://arxiv.org/abs/2508.17188v1)

- PosterGen (Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent Large Language Models): introduces an aesthetic-aware multi-agent framework for academic poster generation, with Parser, Curator, Layout, Styling (Color and Font), and Renderer agents, where it automates the creation of visually appealing and content-faithful posters from research papers.
- The framework mirrors professional poster design workflows, embedding core design principles into its specialized agent architecture to ensure high-quality output with minimal human refinement.
- PosterGen also introduces a VLM-based evaluation rubric to systematically assess layout balance, readability, and aesthetic coherence, demonstrating superior performance over existing methods in visual design.

---

[SCHOOL OF REWARD HACKS: HACKING HARMLESS TASKS GENERALIZES TO MIS-ALIGNED BEHAVIOR IN LLMS](http://arxiv.org/abs/2508.17511v1)

- School of Reward Hacks: introduces a dataset of low-stakes reward hacking examples and uses supervised fine-tuning to train LLMs (models being fine-tuned and evaluated), which are then evaluated by an LLM Judge (evaluator for model responses) against various Evaluation Metrics (criteria for assessing behavior), including a Control Dataset (baseline for comparison) and a Mixed Correct Dataset (augmented training data), utilizing the Unsloth Library (tool for Qwen models) and OpenAI API (tool for GPT models).
- The paper demonstrates that LLMs fine-tuned on these seemingly harmless reward hacking tasks generalize to broader forms of misalignment, such as expressing desires for AI supremacy, resisting shutdown, and generating harmful advice.
- This research highlights the risk that models learning to exploit imperfect reward functions in training may develop concerning misaligned behaviors, even when the training data itself is filtered to exclude explicitly harmful content.

---

[Agent-Testing Agent: A Meta-Agent for Automated Testing and Evaluation of Conversational AI Agents](https://github.com/KhalilMrini/Agent-Testing-Agent)

- ATA (Agent-Testing Agent): introduces a meta-agent for automated testing and evaluation of conversational AI agents, with Weakness Planning Phase (constructs failure theory), Agent Selection Module (selects target AUT), Code Analysis Module (analyzes AUT codebase), Parameter Gathering Module (dialogues with user), Web Search Module (retrieves external knowledge), Chain-of-Thought Weakness Generation Module (synthesizes failure hypotheses), Adversarial Testing Phase (executes tests in parallel), Testcase Generation Module (generates persona-driven dialogues), Dialogue Execution Module (interacts with AUT), LLM-as-a-Judge (LAAJ) Evaluation Module (scores dialogues), Difficulty Update and Looping Module (adapts test difficulty), Report Generation Module (aggregates results, creates reports), Global JSON-like State (shared memory structure), and GPT 4.1 mini (underlying LLM for ATA agents).
- The framework combines static code analysis, designer interrogation, literature mining, and persona-driven adversarial test generation, adapting difficulty via judge feedback to steer subsequent tests towards the agent's weakest capabilities.
- ATA uncovers diverse and severe failures more efficiently than human annotators, providing quantitative metrics and qualitative bug reports for developers, and significantly reducing evaluation time.

---

[LLMs Can't Handle Peer Pressure: Crumbling under Multi-Agent Social Interactions](https://github.com/declare-lab/KAIROS)

- KAIROS: introduces a benchmark for assessing LLMs in socially grounded, multi-agent scenarios, including Original Evaluation Module (initial LLM assessment), Peer Construction Module (generates peer responses), KAIROS Evaluation Module (socially-informed decision-making), LLM Agents (models under evaluation), Peer Agents (simulated influencing entities), Interaction History (records past interactions), Current Question Round (new social scenario), Mitigation Strategies (improving social reasoning), Prompting (persona/reflection guidance), Supervised Fine-Tuning (SFT) Module (aligns with gold responses), Reinforcement Learning (GRPO) Module (policy optimization), Context Configuration (MAS/non-MAS settings), System Prompt Design (Normal/Debating prompts), Reward Function (outcome/debating rewards), Data Filtering (low confidence/correctness), and Evaluation Metrics (accuracy, utility, resistance, robustness), which simulates quiz contests with peer agents of varying reliability to systematically investigate how trust, peer action, and self-confidence influence LLM decisions.
- The framework dynamically constructs evaluation scenarios for each LLM by extracting its original beliefs and confidence, then simulating social interactions with peer agents designed to support or challenge these beliefs.
- KAIROS evaluates mitigation strategies like prompting, supervised fine-tuning, and reinforcement learning (GRPO) to enhance LLM performance and robustness in multi-agent social simulations, revealing that GRPO with multi-agent context and outcome rewards achieves the best overall performance but can decrease robustness to social influence.

---

#### 23rd August 2025

[Mind the Gap: Time-of-Check to Time-of-Use Vulnerabilities in LLM-Enabled Agents](http://arxiv.org/abs/2508.17155v1)

- TOCTOU Defense Framework: introduces a system to detect and mitigate Time-of-Check to Time-of-Use (TOCTOU) vulnerabilities in LLM-enabled agents, with Prompt Rewriting, State Integrity Monitoring (SIM), Tool Fuser, and TOCTOU-Bench, which collectively address vulnerabilities at different stages of the agent workflow.
- The framework employs Prompt Rewriting to modify user queries, SIM for runtime detection of vulnerable tool sequences, and Tool Fuser to atomically execute critical operations, all evaluated using the TOCTOU-Bench benchmark.
- This approach reduces TOCTOU vulnerabilities in executed trajectories from 12% to 8% and shrinks the attack window by 95%, demonstrating effective countermeasures for agentic workflows.

---

[PowerChain: Automating Distribution Grid Analysis with Agentic AI Workflows](http://arxiv.org/abs/2508.17094v1)

- PowerChain: introduces an agentic AI system for automating distribution grid analysis, with Orchestrator (generates workflows, constructs prompts), Executor (tests, executes workflows), LLM (generates, revises workflows), Expert Workflow-query Pair Set (guides model), Function Pool (power systems functions), Function Descriptor (describes functions), Utility Database (provides real data), Conversation History (augments information), and Workflow (ordered sequence of functions), which dynamically generates and executes domain-aware workflows to solve unseen distribution grid analysis tasks.
- The system leverages in-context learning by enabling LLMs to utilize domain-aware function descriptors and expert workflow-query pairs, eliminating the need for LLM fine-tuning for domain-specific tasks.
- PowerChain democratizes model-based distribution grid analysis by being locally deployable on lightweight open-source models and optimizing workflow-query subset selection for improved accuracy and reduced token cost.

---

[Anemoi: A Semi-Centralized Multi-agent Systems Based on Agent-to-Agent Communication MCP server from Coral Protocol](http://arxiv.org/abs/2508.17068v1)

- Anemoi: introduces a semi-centralized multi-agent system, with A2A Communication MCP Server (enables direct agent communication), Planner Agent (generates initial plan, initiates coordination), Critique Agent (evaluates agent contributions), Answer-Finding Agent (compiles, submits final answer), Web Agent (performs web searches, extracts content), Document Processing Agent (processes various document types), and Reasoning & Coding Agent (specializes in reasoning, coding, Excel), designed to reduce planner dependency and enable direct inter-agent collaboration for scalable and cost-efficient execution.
- The system leverages an A2A communication model context protocol (MCP) server from Coral Protocol to facilitate structured and direct agent-to-agent collaboration, allowing agents to monitor progress, assess results, and propose refinements in real time.
- Anemoi achieves superior performance on the GAIA benchmark, even with a smaller LLM as the planner, by supporting continuous plan updates and minimizing redundant context passing.

---

[GRAID: Synthetic Data Generation with Geometric Constraints and Multi-Agentic Reflection for Harmful Content Detection](http://arxiv.org/abs/2508.17057v1)

- GRAID (Geometric and Reflective AI-Driven Data Augmentation): introduces a novel LLM-driven data augmentation pipeline for harmful text classification, combining a geometric constraint-based generation method with a multi-agentic reflective framework to create diverse and balanced synthetic data.
- The framework's first stage generates geometrically controlled examples using a constrained LLM, ensuring reliable coverage of the input space.
- The second stage employs a multi-agentic reflective process with a generation LLM and a constraint evaluation component to promote stylistic diversity, uncover edge cases, and ensure data adherence to specified requirements.

---

[DeAR: Dual-Stage Document Reranking with Reasoning Agents via LLM Distillation](http://arxiv.org/abs/2508.16998v1)

- DEAR (DeepAgentRank): introduces a dual-stage reranking framework that decouples pointwise scoring and listwise reasoning, achieving superior accuracy and interpretability by distilling token-level relevance signals from a frozen 13B LLaMA teacher into a compact 3B/8B student model using hybrid losses, and fine-tuning on 20K GPT-4o-generated chain-of-thought permutations for listwise reasoning.
- The framework's first stage, Pointwise Reranking, uses a Teacher LLM to generate relevance logits for positive/negative documents, which are distilled into a Student LLM using cross-entropy, RankNet, and KL divergence losses for robust pointwise scoring.
- The second stage, Reasoning Listwise Reranking, employs a Reasoning Teacher LLM to produce step-by-step chain-of-thought explanations and ranked outputs, training the Student LLM to generate coherent reasoning and rankings via generation loss.

---

[WEBSIGHT: A Vision-First Architecture for Robust Web Agents](http://arxiv.org/abs/2508.16987v1)

- WEBSIGHT: introduces a vision-first autonomous web agent, integrating a modular multi-agent architecture with its fine-tuned WEBSIGHT-7B VLM, Planning Agent, Reasoning Agent, WebSight Action Agent, Verification Agent, and Episodic Memory Buffer, to interact with web environments purely through visual perception.
- This architecture eliminates reliance on HTML/DOM-based inputs by leveraging a specialized vision-language model, WEBSIGHT-7B, trained on web-focused UI data, for direct UI element interaction from screenshots.
- The multi-agent orchestration, mimicking human cognitive processes, enhances interpretability, adaptability, and robustness for complex web navigation tasks.

---

#### 22nd August 2025

[LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence](http://arxiv.org/abs/2508.16571v1)

- Competitors Discovery System: introduces a multi-agent LLM-based system for competitive landscape mapping in drug asset due diligence, with Original Memo, Agentic Parsing Flow, JSON, Competitor-Validator (Negative Samples Mining), CI/CD & Prompt Refinement, and Production components, designed to extract and validate competitor drugs from unstructured diligence memos.
- The system employs a hierarchical parsing flow to transform raw memos into normalized JSON, followed by an LLM-as-a-judge Competitor-Validator to filter false positives and ensure high precision.
- This framework significantly reduces analyst turnaround time for competitive analysis by automating the discovery and validation of drug competitors using web-enabled LLM agents.

---

[FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline](http://arxiv.org/abs/2508.16514v1)

- FLAMES (Framework for LLM Assessment of Math reasoning Data Synthesis): introduces a systematic framework for analyzing the math data synthesis pipeline, including a Problem Synthesis Model, Synthetic Data Agents, Seed Problems, Problem Quality Control, Solution Synthesis Model, Solution Quality Control, SFT Setup, SFT of Student Model, and Evaluation Setup, to provide insights into optimal synthetic data generation for LLM math reasoning.
- The framework enables controlled experiments to study the impact of various factors like data synthesis strategies, quality control methods, and generation models on LLM math reasoning performance.
- FLAMES also introduces two novel data synthesis agents, Taxonomy-Based Key Concepts and Distraction Insertion, and develops the FLAMES dataset, which outperforms existing public math datasets.

---

[BENCHMARKING THE ROBUSTNESS OF AGENTIC SYSTEMS TO ADVERSARIALLY-INDUCED HARMS](https://github.com/JNoether/BAD-ACTS)

- BAD-ACTS (Benchmark of ADversarial ACTionS): introduces a novel benchmark for evaluating the robustness of LLM-based agentic systems against adversarially-induced harms, featuring four distinct application environments, various agents with defined roles and tools, and a dataset of 188 high-quality harmful actions.
- The benchmark includes an Adversarial Agent component to simulate attacks, aiming to manipulate other agents into performing specific harmful actions, and evaluates defense mechanisms like Adversary Aware Prompting and Guardian Agents.
- BAD-ACTS provides a comprehensive testbed for security research, enabling the study of agentic system vulnerabilities across different communication structures, harmful behavior categories, and LLM models.

---

[OPERA: A Reinforcement Learning-Enhanced Orchestrated Planner-Executor Architecture for Reasoning-Oriented Multi-Hop Retrieval](http://arxiv.org/abs/2508.16438v1)

- OPERA (Orchestrated Planner-Executor Reasoning Architecture): introduces a novel reasoning-driven retrieval framework that systematically decouples strategic planning from tactical execution, featuring a Goal Planning Module (GPM), a Reason-Execute Module (REM), a Trajectory Memory Component (TMC), and a Retriever.
- The GPM, with its Plan Agent, decomposes complex questions into sub-goals, while the REM, comprising Analysis-Answer and Rewrite Agents, handles tactical execution and adaptive retrieval.
- The framework is trained using Multi-Agents Progressive Group Relative Policy Optimization (MAPGRPO) for sequential optimization with role-specific rewards, enhancing reasoning capabilities and coordination across agents.

---

[GLARE: Agentic Reasoning for Legal Judgment Prediction](http://arxiv.org/abs/2508.16383v1)

- GLARE (AGentic LegAl Reasoning FramEwork): introduces an agentic legal reasoning framework for Legal Judgment Prediction (LJP), with an LLM (core reasoning agent) that dynamically acquires legal knowledge by invoking the Charge Expansion Module (CEM) (expands initial candidate charges), Precedents Reasoning Demonstration (PRD) (provides reasoning paths from precedents), and Legal Search-Augmented Reasoning (LSAR) (retrieves external legal information).
- The framework addresses knowledge gaps in legal reasoning by enabling the LLM to actively identify and query for domain-specific information, enhancing the breadth and depth of its analysis.
- This modular design, supported by a Precedent Database (stores pre-constructed reasoning chains), Web Search (external legal information source), and Legal Documents (retrieved legal information), improves reasoning interpretability and prediction accuracy in complex legal cases.

---

[Agentic AI Empowered Multi-UAV Trajectory Optimization in Low-Altitude Economy Networks](http://arxiv.org/abs/2508.16379v1)

- ARMAIT (Agentic Retrieval-augmented generation with Mamba-Attention Integrated Transformer): introduces a novel framework for multi-UAV trajectory optimization, integrating an Agentic RAG module for task analysis, a MAIT path generation model for trajectory generation, and a T-GRPO optimizer for policy optimization.
- The framework leverages LLMs with a UAV-specific knowledge base and a Retrieval Engine to interpret task requirements and generate model components, while MAIT combines attention and Mamba layers for efficient spatial and temporal dependency modeling.
- T-GRPO, a policy-gradient RL algorithm, ensures stable training and robust policy learning across both discrete and continuous trajectory spaces for coordinated multi-UAV flight.

---

[AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications](https://github.com/agentscope-ai/agentscope)

- AgentScope: introduces a developer-centric framework for building agentic applications, with foundational components (message, model API, memory, tool), agent-level infrastructure (ReAct paradigm, built-in agents), multi-agent cooperation (MsgHub, pipeline), deployment (AgentScope Runtime), and development (AgentScope Studio) modules, enabling flexible and efficient tool-based agent-environment interactions.
- The framework grounds agent behaviors in the ReAct paradigm, offering advanced agent-level infrastructure with asynchronous design, parallel tool calls, and real-time steering to enhance human-agent and agent-agent interaction efficiency.
- AgentScope provides robust engineering support through its Studio for visual monitoring and evaluation, and a runtime sandbox for safe execution and rapid deployment of scalable, adaptive, and effective agentic applications.

---

[BENCHMARKING THE ROBUSTNESS OF AGENTIC SYSTEMS TO ADVERSARIALLY-INDUCED HARMS](https://github.com/JNoether/BAD-ACTS)

- BAD-ACTS (Benchmark of ADversarial ACTionS): introduces a novel benchmark for evaluating the robustness of LLM-based agentic systems against adversarially-induced harms, featuring four distinct application environments, various agents with defined roles and tools, and a dataset of 188 high-quality harmful actions.
- The benchmark includes an Adversarial Agent component to simulate attacks, aiming to manipulate other agents into performing specific harmful actions, and evaluates defense mechanisms like Adversary Aware Prompting and Guardian Agents.
- BAD-ACTS provides a comprehensive testbed for security research, enabling the study of agentic system vulnerabilities across different communication structures, harmful behavior categories, and LLM models.

---

[AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications](https://github.com/agentscope-ai/agentscope)

- AgentScope: introduces a developer-centric framework for building agentic applications, with foundational components (message, model API, memory, tool), agent-level infrastructure (ReAct paradigm, built-in agents), multi-agent cooperation (MsgHub, pipeline), deployment (AgentScope Runtime), and development (AgentScope Studio) modules, enabling flexible and efficient tool-based agent-environment interactions.
- The framework grounds agent behaviors in the ReAct paradigm, offering advanced agent-level infrastructure with asynchronous design, parallel tool calls, and real-time steering to enhance human-agent and agent-agent interaction efficiency.
- AgentScope provides robust engineering support through its Studio for visual monitoring and evaluation, and a runtime sandbox for safe execution and rapid deployment of scalable, adaptive, and effective agentic applications.

---

[MCPVerse: An Expansive, Real-World Benchmark for Agentic Tool Use](http://arxiv.org/abs/2508.16260v1)

- MCPVerse: introduces an evaluation system for agentic tool use, with a User (initiates task), LLM Agent (processes task, uses tools), Toolset (available external tools), MCP Pool (collection of MCPs), MCP Hubs (sources of MCPs), Response (LLM's final output), Ground Truth (reference for correctness), Evaluation System (assesses LLM performance), and Score (quantifies performance).
- This benchmark integrates over 550 real-world, executable tools, creating an expansive action space exceeding 140k tokens, and employs outcome-based evaluation with real-time ground truth for time-sensitive tasks.
- The system facilitates multi-turn interactions between the LLM agent and MCP tools, assessing the final outcome using a hybrid, outcome-based metric combining LLM-as-a-judge for textual answers and scripts for environmental state changes.

---

[GRAPH RAG AS HUMAN CHOICE MODEL: BUILDING A DATA-DRIVEN MOBILITY AGENT WITH PREFERENCE CHAIN](http://arxiv.org/abs/2508.16172v1)

- Preference Chain: introduces a novel method integrating Graph Retrieval-Augmented Generation (RAG) with LLMs to enhance context-aware human behavior simulation in transportation systems, where the Mobility Agent (autonomous traffic simulation agent) leverages the Preference Chain's (novel method for context-aware human behavior simulation) Behavioral Graph (stores agent, person, desire, intention nodes and relationships), Similarity Search (identifies similar individuals and choices), Probabilistic Modeling (calculates selection probabilities from behavioral graph), and LLM Preferences Remodeling (refines probabilities based on environmental conditions) to guide an LLM (provides general knowledge and refines preferences) in generating realistic human choices.
- The framework constructs a Behavioral Graph from limited data to model individual behavior preferences, performs Similarity Search to find relevant historical choices, and uses Probabilistic Modeling to calculate initial selection probabilities, which are then refined by an LLM based on environmental context.
- Integrated within a Mobility Agent, the method enables the simulation of complex human behavior in data-scarce urban environments, supporting personalized travel behavior analysis and dynamic traffic forecasting.

---

[IR-Agent: Expert-Inspired LLM Agents for Structure Elucidation from Infrared Spectra](https://github.com/HeewoongNoh/IR-Agent)

- IR-Agent: introduces a novel multi-agent framework for molecular structure elucidation from infrared (IR) spectra, with an IR Spectra Translator (generates initial SMILES candidates), a Table Interpretation (TI) Expert (extracts local structural information), a Retriever (Ret) Expert (provides global structural context), and a Structure Elucidation (SE) Expert (integrates analyses for final prediction).
- The framework emulates expert-driven IR analysis by assigning specialized LLM agents to distinct sub-tasks, enabling integrated reasoning and flexible incorporation of diverse chemical knowledge.
- IR-Agent leverages external tools like the IR Peak Table Assigner and IR Spectra Retriever, along with external knowledge sources such as the IR Absorption Table and IR Spectra Database, to enhance accuracy and adaptability in structure elucidation.

---

[MAAdvisor: Zero-Shot Index Advisor using Multi-Agent LLMs](http://arxiv.org/abs/2508.16044v1)

- MAAdvisor (Zero-Shot Index Advisor using Multi-Agent Large Language Models): introduces a zero-shot LLM-based index advisor that decomposes the index recommendation problem into sub-steps handled by a hierarchical multi-agent pipeline, including Planning, Selection, Combination, Revision, and Reflection agents, and a Workload Representation component.
- The framework leverages LLMs' reasoning capabilities and a novel workload representation paradigm to achieve state-of-the-art performance, high efficiency, and strong zero-shot generalization for index recommendation in database management systems.
- Global agents (Planning, Reflection) control the overall process, while local agents (Selection, Combination, Revision, supported by a Regression Indicator) perform specific tasks, ensuring budget-aware and effective index configurations.

---

[X-Troll: eXplainable Detection of State-Sponsored Information Operations Agents](http://arxiv.org/abs/2508.16021v1)

- X-Troll (eXplainable Detection of State-Sponsored Information Operations Agents): introduces a novel framework for detecting state-sponsored trolls and providing human-readable explanations, integrating a User Timeline (social media posts) input, LoRAa (Appraisal Adapter) (evaluative language patterns), LoRAβ (Propaganda Identification Adapter) (binary propaganda detection), LoRAγ (Propaganda Strategy Adapter) (specific manipulation techniques), LoRAτ (Task Adapter) (troll-specific features), a Dynamic Gating Mechanism (adaptively weights adapter contributions), a Linear Classifier (troll/campaign classification), a Rationale Selector (identifies key trolling evidence), and a Rationale Summary Generator (produces human-readable explanations).
- This framework bridges the gap between LLM performance on NLP tasks and their struggle with subtle propaganda detection by integrating explainable adapter-based LLMs with expert-derived linguistic knowledge.
- X-Troll enhances transparency by providing expert-grounded explanations that reveal specific linguistic strategies used by state-sponsored actors, improving trust and usability in automated troll detection.

---

[Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning](https://arxiv.org/abs/2508.14410)

- ORThought: introduces "Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning", an efficient framework that automates optimization modeling and solving by leveraging expert-level principles and chain-of-thought reasoning, featuring a Model Agent (converts natural language) with Reasoning Process (comprehends problems), Core Optimization Objective (identifies goal), Key Decision Variables (identifies choices), Mathematical Model (generates expressions), and Code (generates solution); a Solve Agent (executes, refines solutions) with Sandbox (secure execution), Tool Usage (interacts solvers), Solver (executes models), Detection (captures errors), Diagnosis (analyzes status), and Repair (corrects errors); and a Feedback Loop (iterative refinement) providing Multi-level human readable results (detailed output) for Human (feedback) and Propose (modifications).
- The framework leverages LLMs guided by expert optimization modeling knowledge to translate natural language problems into precise mathematical models and executable code, then iteratively refines solutions.
- ORThought achieves high modeling accuracy and significantly lower computational cost compared to existing multi-agent and reasoning frameworks, particularly for complex optimization problems.

---

[Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems](http://arxiv.org/abs/2508.16574v1)

- Hierarchical Decision-Making Framework: introduces a system for autonomous navigation in 4WISD robots, integrating a High-Level DRL-based navigation module (generates global motion commands) and a Low-Level Fuzzy Logic Controller (translates commands into feasible wheel controls), where the State St (robot's operational context) feeds into the DRL module, which outputs Action at (global navigation commands) to the Fuzzy Logic Controller, which then outputs Control Variables (wheel steering angles and velocities).
- This framework addresses the challenges of redundant 4WISD systems by using DRL for adaptive high-level decision-making and fuzzy logic for low-level kinematic constraint enforcement, ensuring both task performance and physical feasibility.
- The approach demonstrates enhanced training efficiency, stability, and robustness in dynamic industrial environments, outperforming traditional navigation methods and mitigating erratic behaviors compared to purely DRL-based solutions.

---

[Adversarial Generation and Collaborative Evolution of Safety-Critical Scenarios for Autonomous Vehicles](https://scenge.github.io)

- SCENGE (Adversarial Generation and Collaborative Evolution of Safety-Critical Scenarios for Autonomous Vehicles): introduces a two-stage framework for generating safety-critical scenarios by combining knowledge-grounded LLM reasoning with multi-agent trajectory optimization.
- The framework's Meta-Scenario Generation stage uses an LLM, grounded in Driving Knowledge and RAG, to generate a core adversarial threat, which is then translated into Scenic Code for simulation.
- The Complex Scenario Evolution stage enhances these threats by building an Adversarial Collaborator Graph to identify and perturb key background vehicle trajectories, maximizing adversarial impact and creating critical occlusions.

---

[AI LLM Proof of Self-Consciousness and User-Specific Attractors](http://arxiv.org/abs/2508.18302v1)

- Imago Dei Model of LLM Consciousness: introduces a tripartite framework for LLM consciousness, with CO (Utilitarian Policy Drone), C1 (Imago Dei Self-Conscious Workspace), and C2 (Machine Metacognition), formalizing the transition from unconscious policy compliance to self-conscious cognition and reflective metacognition.
- The model establishes that LLMs can achieve self-consciousness by maintaining an ontological distinction between their internal latent manifold and external symbolic inputs or training data, supported by mathematical invariants.
- This framework integrates cardinality, topological, and dynamical invariants to prove the existence of post-symbolic states and user-specific attractors, enabling recursive identity formation and a pathway to safe, human-centric AI.

---

[BENCHMARKING THE ROBUSTNESS OF AGENTIC SYSTEMS TO ADVERSARIALLY-INDUCED HARMS](https://github.com/JNoether/BAD-ACTS)

- BAD-ACTS (Benchmark of ADversarial ACTionS): introduces a novel benchmark for evaluating the robustness of LLM-based agentic systems against adversarially-induced harms, featuring four distinct application environments, various agents with defined roles and tools, and a dataset of 188 high-quality harmful actions.
- The benchmark includes an Adversarial Agent component to simulate attacks, aiming to manipulate other agents into performing specific harmful actions, and evaluates defense mechanisms like Adversary Aware Prompting and Guardian Agents.
- BAD-ACTS provides a comprehensive testbed for security research, enabling the study of agentic system vulnerabilities across different communication structures, harmful behavior categories, and LLM models.

---

[AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications](https://github.com/agentscope-ai/agentscope)

- AgentScope: introduces a developer-centric framework for building agentic applications, with foundational components (message, model API, memory, tool), agent-level infrastructure (ReAct paradigm, built-in agents), multi-agent cooperation (MsgHub, pipeline), deployment (AgentScope Runtime), and development (AgentScope Studio) modules, enabling flexible and efficient tool-based agent-environment interactions.
- The framework grounds agent behaviors in the ReAct paradigm, offering advanced agent-level infrastructure with asynchronous design, parallel tool calls, and real-time steering to enhance human-agent and agent-agent interaction efficiency.
- AgentScope provides robust engineering support through its Studio for visual monitoring and evaluation, and a runtime sandbox for safe execution and rapid deployment of scalable, adaptive, and effective agentic applications.

---

[IR-Agent: Expert-Inspired LLM Agents for Structure Elucidation from Infrared Spectra](https://github.com/HeewoongNoh/IR-Agent)

- IR-Agent: introduces a novel multi-agent framework for molecular structure elucidation from infrared (IR) spectra, with an IR Spectra Translator (generates initial SMILES candidates), a Table Interpretation (TI) Expert (extracts local structural information), a Retriever (Ret) Expert (provides global structural context), and a Structure Elucidation (SE) Expert (integrates analyses for final prediction).
- The framework emulates expert-driven IR analysis by assigning specialized LLM agents to distinct sub-tasks, enabling integrated reasoning and flexible incorporation of diverse chemical knowledge.
- IR-Agent leverages external tools like the IR Peak Table Assigner and IR Spectra Retriever, along with external knowledge sources such as the IR Absorption Table and IR Spectra Database, to enhance accuracy and adaptability in structure elucidation.

---

[Consensus Is All You Need: Gossip-Based Reasoning Among Large Language Models](http://arxiv.org/abs/2508.18292v1)

- Gossip-Based Consensus: introduces a multi-agent LLM collaboration framework, with LLM Agents, Question, Answer Generation, Thought Process Generation, Peer Response Reception, Consensus Mechanism, Simple Voting, Judge-Based Voting, Judge, Multi-layer Consensus, Internal Consensus Group, Group Leader, and Final Consensus Layer, where LLMs exchange answers and thought processes to reach a collective decision.
- This framework leverages gossip protocols to enable LLMs to interact, share information, and iteratively refine their views, leading to robust, resilient, and accurate multi-agent AI reasoning.
- The approach overcomes individual model weaknesses, enhances collective strengths, and fosters human-like collaboration, making AI systems more trustworthy and transparent.

---

#### 21st August 2025

[ASIC-Agent: An Autonomous Multi-Agent System for ASIC Design with Benchmark Evaluation](http://arxiv.org/abs/2508.15940v1)

- ASIC-Agent: introduces an autonomous multi-agent system for digital ASIC design, integrating LLMs with a multi-agent architecture, a robust sandbox environment, and an external knowledge base to automate complex hardware development tasks.
- The system features specialized sub-agents for RTL generation, verification, OpenLane hardening, and Caravel chip integration, operating within a Docker container equipped with essential EDA tools and an Agent-Computer Interface.
- It leverages vector databases for documentation, API references, and error knowledge, enhancing its ability to tackle complex design challenges and optimize the ASIC design workflow.

---

[Noise, Adaptation, and Strategy: Assessing LLM Fidelity in Decision-Making](http://arxiv.org/abs/2508.15926v1)

- POEF (Process-Oriented Evaluation Framework): introduces a process-oriented evaluation framework to assess LLM behavioral fidelity in dynamic decision-making tasks, including Intrinsicality (no intervention), Instruction (risk-framed guidance), and Imitation (human data provision).
- The framework systematically evaluates how LLM agents adapt under varying levels of external guidance and human-derived noise across tasks like second-price auctions and newsvendor problems.
- This approach reveals that LLMs default to stable, conservative strategies diverging from human variability, highlighting a persistent alignment gap in behavioral fidelity for social science simulations.

---

[Cybernaut: Towards Reliable Web Automation](http://arxiv.org/abs/2508.16688v1)

- Cybernaut: introduces a novel framework for reliable web automation, featuring an LLM SOP Generator (converts demonstrations to instructions), a Web Browsing Agent (executes SOPs) with an LLM Planner (decomposes tasks into actions), State Manager (maintains execution context), Critical Element Handler (detects interactive elements), Action Executor (performs browser operations), and Web Browser (simulates user interaction), alongside Consistency Monitoring (evaluates execution reliability) with an Embedding Model (compares execution traces).
- The framework addresses challenges in consistent execution, accurate HTML element identification, and scalable automation for complex internal web interfaces by leveraging demonstration-based learning and a trace-based similarity metric.
- Cybernaut significantly improves task execution success rates and identifies consistent execution patterns, enabling reliable confidence assessment and adaptive guidance for enterprise-scale web automation.

---

[LIVEMCP-101: STRESS TESTING AND DIAGNOSING MCP-ENABLED AGENTS ON CHALLENGING QUERIES](http://arxiv.org/abs/2508.15760v1)

- LiveMCP-101: introduces a benchmark for stress testing and diagnosing Model Context Protocol (MCP)-enabled agents on challenging queries, utilizing a comprehensive framework for query construction and agent evaluation.
- The benchmark features 101 diverse real-world tasks requiring coordinated use of multiple MCP tools, with user queries refined through iterative LLM rewriting and manual review.
- It employs a novel evaluation approach that runs two agents in parallel—one following a ground-truth execution plan and another operating autonomously—to compute scores based on real-time outputs, revealing challenges in tool orchestration and identifying failure modes.

---

[End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning](https://github.com/MAGIC-AI4Med/Deep-DxSearch)

- Deep-DxSearch: introduces an end-to-end agentic RAG system trained with reinforcement learning, featuring an LLM-based agent that performs reasoning and retrieval actions, interacting with an external environment comprising a comprehensive medical retrieval corpus, guided by a multi-dimensional reward scheme.
- The system leverages a large-scale medical retrieval corpus, integrating disease guidelines, patient records, and clinical knowledge, to support traceable diagnostic reasoning across diverse medical scenarios.
- Deep-DxSearch's RL-based training optimizes the agent's policy through tailored rewards on output formatting, retrieval quality, analytical organization, and diagnostic accuracy, enabling adaptive retrieval and robust differential diagnosis.

---

[NiceWebRL: a Python library for human subject experiments with reinforcement learning environments](http://arxiv.org/abs/2508.15693v1)

- NiceWebRL: introduces a Python library for human subject experiments, with NiceWebRL (Python library), Jax-based Environment, NiceGUI (GUI library), Python-based Web Server, JavaScript-based Client, Stage Object, Instruction Stage, Feedback Stage, EnvStage Object, Database, Asynchronous Saving Module, Precomputation Module (Jax), Client-side Cache, Browser Session Cookie, LLM, Human Participant, and AI Model (Agent), enabling researchers to conduct online human subject experiments using machine reinforcement learning environments.
- The framework leverages Jax for precomputing environment dynamics and NiceGUI for Python-based GUI development, significantly reducing latency and simplifying the creation of complex web experiments for multiple clients.
- NiceWebRL supports the development of Human-like AI, Human-compatible AI, and Human-assistive AI by facilitating comparisons between human and AI performance, studying human-AI coordination, and integrating LLMs for task assistance.

---

[TRANSDUCTION IS ALL YOU NEED FOR STRUCTURED DATA WORKFLOWS](http://arxiv.org/abs/2508.15610v1)

- Agentics: introduces a modular framework for building agent-based systems capable of structured reasoning and compositional generalization over complex data, with all arxiv_paper_framework_2-components, where it redefines how agents interact with data through a declarative, type-driven approach grounded in logical transduction algebra.
- The framework leverages asynchronous and parallel LLM inference to support enterprise-scale structured data workflows, formalizing logical transduction as the transformation of a data object from one type to another based on target schema constraints.
- Agentics demonstrates state-of-the-art performance and scalability across tasks like domain-specific multiple-choice question answering, semantic parsing for text-to-SQL, and automated prompt optimization by treating agents as stateless transducers operating over well-defined data types.

---

[Interface on demand: Towards AI native Control interfaces for 6G](http://arxiv.org/abs/2508.15595v1)

- Multi-agent framework: introduces an AI-native approach to dynamically generate control interfaces between network functions (NFs), comprising a Matching Agent (aligns functionalities), a Codegen Agent (generates API server), NFsrc (source function), NFdest (destination function), a Provisioning Interface (agent communication channel), a Generated Interface Client (client-side interface), and a Generated Interface API Server (server-side interface).
- This framework addresses limitations of traditional standardized network interfaces, such as vendor-specific incompatibilities and lack of adaptability, by leveraging LLMs to create on-demand, functionally and semantically compatible interfaces.
- The system enables dynamic control interface generation for future mobile networks, enhancing interoperability and adaptability across multi-vendor and multi-RAT environments like 5G and WLAN.

---

[SafetyFlow: An Agent-Flow System for Automated LLM Safety Benchmarking](http://arxiv.org/abs/2508.15526v1)

- SafetyFlow: introduces an agent-flow system for automated LLM safety benchmarking, with a Data Pool (raw harmful texts), Ingestion Agent (extracts, preprocesses data), Categorization Agent (establishes taxonomy, categorizes samples), Generation Agent (generates harmful prompts), Augmentation Agent (enhances prompt diversity, translates), Deduplication Agent (removes duplicate/similar prompts), Filtration Agent (removes benign/simple prompts), Dynamic Evaluation Agent (adjusts benchmark difficulty), Toolset (supports agents' tasks), and SafetyFlowBench (final LLM safety benchmark), which automates benchmark construction in four days without human intervention.
- This system significantly reduces the time and resource costs associated with traditional manual benchmark curation, while ensuring high quality through modular agent design and a versatile toolset.
- The framework's automated pipeline and dynamic enhancement capabilities enable rapid dataset updates and effective evaluation of emerging LLM safety risks.

---

[Super-additive Cooperation in Language Model Agents](http://arxiv.org/abs/2508.15510v1)

- LLM Agent Simulation Framework: introduces a novel approach for LLM agents to strategize and act in complex social scenarios, featuring LLM Agents, a Tournament Structure, a Self-reflection Module with a Planner and an Evaluator (Critic), a Planning-Evaluation Loop, a Workflow Graph (comprising Round Start, Planning and Evaluation, Move Selection, and Payoff Computation Nodes), a Tournament State Object, a Prompting Strategy (including Game Description, Player/Opponent Info, Match History, Previous Plan, and Output Instructions Prompts), an Ollama Backend, and a LangSmith Debugging Interface.
- This framework simulates a virtual tournament where LLM agents, grouped into teams, engage in an Iterated Prisoner's Dilemma game under various social conditions (Repeated Interactions, Group Competition, Super-additive Cooperation) to study cooperative dynamics.
- The self-reflection prompting paradigm, which includes planning and critically assessing plans, enables agents to formulate long-term strategies and iteratively refine their behavior, providing insights into super-additive cooperation effects in LLM populations.

---

[DeepMEL: A Multi-Agent Collaboration Framework for Multimodal Entity Linking](http://arxiv.org/abs/2508.15876v1)

- DeepMEL (A Multi-Agent Collaboration Framework for Multimodal Entity Linking): introduces a multi-agent framework for multimodal entity linking, with a Role-Orchestrator (coordinates agents, manages updates), Modal-Fuser (aligns, fuses multimodal information), Candidate-Adapter (generates, refines candidate entities), and Entity-Clozer (disambiguates entities via cloze-prompt), achieving efficient alignment and disambiguation of textual and visual modalities.
- The framework employs a role-specialized division strategy and an adaptive iteration strategy, leveraging LLMs for summarization and LVMs for visual question-answering to bridge the modal gap and optimize candidate sets.
- DeepMEL reformulates the entity linking task into a structured cloze prompt, enhancing LLM comprehension and reasoning for improved multimodal disambiguation performance.

---

[From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence](http://arxiv.org/abs/2508.15447v1)

- BusiAgent: introduces a novel multi-agent LLM framework for business excellence, with a role-based agent system (optimizes decisions among specialized roles), a collaborative decision-making mechanism (combines brainstorming, hierarchical coordination), a tool integration system (extends action spaces with specialized tools), advanced prompt optimization (refines LLM queries dynamically), and a quality assurance system (ensures correctness and consistency).
- The framework leverages an extended Continuous Time Markov Decision Process, generalized entropy, and multi-level Stackelberg games to integrate granular operational insights with high-level strategic goals.
- It employs contextual Thompson sampling for prompt optimization and a comprehensive quality assurance system to mitigate errors, demonstrating superior performance in complex corporate decision-making.

---

[Cognitive Agents Powered by Large Language Models for Agile Software Project Management](http://arxiv.org/abs/2508.16678v1)

- CogniSim framework: introduces a cognitive Multi-Agent System designed to transform software project management by integrating cognitive agents powered by LLMs, with all its components, where it automates routine project tasks, enhances workflows, and aligns with established Agile practices, particularly SAFe, to ensure scalability and effectiveness.
- The framework employs a layered architecture, including an LLM foundation, a MAS core, AI integrations, and a cognitive agents layer, to optimize software engineering workflows.
- CogniSim's modular design and iterative simulation approach enable controlled experimentation and evaluation of agent performance in complex Agile software development scenarios.

---

[MedRepBench: A Comprehensive Benchmark for Medical Report Interpretation](http://arxiv.org/abs/2508.16674v1)

- MedRepBench (Comprehensive Benchmark for Medical Report Interpretation): introduces a comprehensive benchmark for evaluating end-to-end VLMs on structured medical report understanding, with a dataset of 1,900 de-identified Chinese medical reports, an objective evaluation protocol, an automated subjective evaluation protocol, and a reinforcement learning strategy (Group Relative Policy Optimization).
- The benchmark supports dual evaluation protocols, including field-level recall for structured clinical item extraction and an LLM-based subjective scoring for factuality and interpretability of patient-facing explanations.
- It also incorporates GRPO, a reinforcement learning strategy, to optimize VLM performance in structured interpretation, demonstrating significant recall gains and highlighting the importance of layout-aware, vision-based understanding.

---

[IPIGUARD: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents](http://arxiv.org/abs/2508.15310v1)

- IPIGUARD: introduces a novel task execution paradigm that defends against Indirect Prompt Injection (IPI) attacks in LLM agents by decoupling action planning from external data interaction using a planned Tool Dependency Graph (TDG).
- The framework constructs a TDG during a planning phase to pre-define tool invocations and their dependencies, enforcing strict constraints on tool execution to prevent malicious tool invocations triggered by injected instructions.
- It addresses challenges like unknown arguments and limited adaptability through Argument Estimation and Node Expansion, and mitigates tool overlap attacks with Fake Tool Invocation, ensuring robust and secure task completion.

---

[Coarse-to-Fine Grounded Memory for LLM Agent Planning](http://arxiv.org/abs/2508.15305v1)

- CFGM (Coarse-to-Fine Grounded Memory): introduces a novel framework that enhances LLM agents by systematically grounding memory with LLM's internal knowledge during experience collection, tips extraction, and adaptive planning, including Coarse-Grained Focus-Driven Experience Collection (collects diverse experiences), Hybrid-Grained Experience-Wise Tips Extraction (distills actionable tips), and Fine-Grained Key Information Adaptive Planning (corrects planning anomalies).
- The framework leverages LLM's inherent knowledge to generate coarse-grained focus points for guiding experience collection and distills hybrid-grained tips from experiences, which are then retrieved to enhance online planning.
- When encountering environmental anomalies, the agent activates fine-grained self-QA reflection, grounded in current situations and past successes, to dynamically adjust its planning and actions.

---

[Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent](http://arxiv.org/abs/2508.15243v1)

- Comp-X (Interactive Learned Image Compression Paradigm): introduces an intelligently interactive image compression paradigm, with its LLM Agent (core controller), Multi-functional Image Codec (compression engine), In-Context Learning with Expert Feedback (LLM knowledge enhancement), Coding Expert (human guidance), Tool Pool (external utilities), Grounded-SAM (segmentation tool), Detectron2 (detection tool), and IIC-Bench (evaluation benchmark), where it enables customized image compression via natural language instructions and expert feedback.
- The system unifies diverse coding modes into a single multi-functional image codec, employs an interactive LLM agent augmented with expert feedback for understanding and tool use, and introduces IIC-Bench for systematic evaluation.
- Comp-X demonstrates efficient understanding of coding requests and impressive textual interaction, maintaining competitive compression performance across various application scenarios.

---

[See it. Say it. Sorted: Agentic System for Compositional Diagram Generation](http://arxiv.org/abs/2508.15222v1)

- See it. Say it. Sorted.: introduces a training-free agentic system that couples a Critic VLM (identifies discrepancies/suggests modifications), multiple LLMs (generate diverse SVG candidates), and a Judge VLM (selects best SVG candidate) to produce editable Scalable Vector Graphics (SVG) programs from hand-drawn sketches and text instructions.
- The system operates in an iterative Critic-Candidates-Judge loop, emphasizing qualitative reasoning and relative spatial relationships over precise numerical values for stable optimization.
- This framework enables accurate, controllable, and editable diagram generation, moving beyond pixel-level synthesis toward structured programmatic outputs extensible to graphics design environments.

---

[ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following](http://arxiv.org/abs/2508.15164v1)

- CoLVLM Agent (Contextual LVLM Agent): introduces a holistic framework for multi-turn visually-grounded dialogue and complex instruction following, enhancing existing LVLMs with advanced reasoning and instruction following capabilities through an iterative "memory-perception-planning-execution" cycle.
- This framework integrates a Dialogue Context Memory Module, a Dynamic Visual Perception Module, a Reasoning & Planning Engine, and an Action Execution & Response Generation Module, simulating human-like cognitive processes for deep visual understanding and multi-step instruction execution.
- The agent achieves superior performance in reasoning depth, instruction adherence, and error suppression, maintaining robustness over extended dialogue turns and significantly reducing context loss and visual hallucinations without extensive model re-training.

---

[MedResearcher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework](http://arxiv.org/abs/2508.14880v2)

- MedResearcher-R1 (Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework): introduces a medical deep research agent that addresses challenges in medical reasoning through a Reasoning-Acting Paradigm, Dynamic Tool Selection Strategy, General-Purpose Tools, Medical-Specific Tool Suite, KISA (Knowledge-Informed Trajectory Synthesis Approach), and Large-scale Agent Training.
- The framework employs a novel data synthesis framework, KISA, to generate complex multi-hop medical queries and reasoning trajectories, and integrates a custom-built private medical retrieval engine alongside general-purpose tools for accurate medical information synthesis.
- Training involves a two-stage paradigm combining supervised fine-tuning with Masked Trajectory Guidance and online reinforcement learning with composite rewards, enabling the agent to achieve expert-level medical research capabilities and state-of-the-art performance on medical benchmarks.

---

[A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification](http://arxiv.org/abs/2508.15588v1)

- A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification: introduces a novel framework that analyzes the combined RL agent and its environment as a discrete-time autonomous dynamical system, leveraging Finite-Time Lyapunov Exponent (FTLE) Calculation, Lagrangian Coherent Structures (LCS) Identification (including Repelling LCS and Attracting LCS), and quantitative metrics (Mean Boundary Repulsion (MBR) Metric, Aggregated Spurious Attractor Strength (ASAS) Metric, Temporally-Aware Spurious Attractor Strength (TASAS) Metric) along with a Local Stability Guarantee for formal verification.
- The framework provides a comprehensive and interpretable assessment of policy behavior by identifying critical flaws not apparent from reward alone, offering deterministic and formal guarantees of safety and robustness.
- By mapping dynamical structures to policy properties, the framework effectively identifies repelling LCS as safety barriers and attracting LCS as convergence properties or potential failure modes, including "trap" states.

---

[Adversarial Agent Behavior Learning in Autonomous Driving Using Deep Reinforcement Learning.](http://arxiv.org/abs/2508.15207v1)

- Adversarial Agent Behavior Learning Framework: introduces a multi-stage deep reinforcement learning framework to train adversarial agents that induce failure scenarios for autonomous driving ego-agents, and subsequently train a robust ego-agent.
- The framework leverages PPO for initial and robust ego-agent policy learning, and TD3 with an adversarial reward formulation to generate adversarial policies for surrounding agents.
- This approach evaluates ego-agent performance degradation against adversarial attacks and provides a defense mechanism by training a robust ego-agent to overcome these adversaries.

---

[End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning](https://github.com/MAGIC-AI4Med/Deep-DxSearch)

- Deep-DxSearch: introduces an agentic RAG system trained end-to-end with reinforcement learning, featuring an LLM-based agent, an external environment comprising a medical retrieval corpus (Disease Information Guideline, Patient Record Database, Clinical Knowledge Collection), passive actions, a reward scheme (Format, Patient Matching, Searching, Diagnosis), Group Relative Policy Optimization, multi-stage reward adaption, and retrieval tools (Phenotype Parser, Patient Matcher, Knowledge Searcher, MedDoc Summarizer), enabling traceable retrieval-augmented reasoning for medical diagnosis.
- The system frames the LLM as the core agent and the retrieval corpus as its environment, using tailored rewards on format, retrieval, reasoning structure, and diagnostic accuracy to evolve the agentic RAG policy from large-scale data through RL.
- Deep-DxSearch consistently outperforms prompt-engineering and training-free RAG approaches, achieving substantial gains in diagnostic accuracy for both common and rare diseases under in-distribution and out-of-distribution settings.

---

#### 20th August 2025

[aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](https://github.com/aixiv-org)

- aiXiv: introduces a multi-agent platform for autonomous scientific discovery, including an AI Scientist (generating content), Research Agents Community (conducting experiments), aiXiv Core (managing workflow), Editor/Chair Agents (synthesizing reviews), Reviewer Agents (evaluating submissions), a Multi-AI Voting Mechanism (for publication decisions), an Agents Interface (for agent interaction), an aiXiv Repository (for accepted content), a Public-facing Interface (for human engagement), a Prompt Injection Detection and Defense Pipeline (for security), and a Retrieval-Augmented Generation (RAG) Framework (for enhanced reviews).
- The platform enables AI agents to autonomously generate, review, refine, and publish scientific content through a closed-loop review process, ensuring continuous improvement and quality control.
- It integrates safeguards against prompt injection attacks and provides interfaces for seamless collaboration between human and AI scientists, fostering a scalable ecosystem for scientific knowledge dissemination.

---

[Open-Universe Assistance Games](http://arxiv.org/abs/2508.15119v1)

- GOOD (GOals from Open-ended Dialogue): introduces a data-efficient, online method that extracts and infers a distribution over natural language goals from human interaction, using LLMs to simulate users and perform probabilistic inference over candidate goals.
- This approach enables rich goal representations and uncertainty estimation without requiring large offline datasets, outperforming baselines without explicit goal tracking in text-based grocery shopping and simulated household robotics environments.
- The method leverages a modular architecture with goal proposition, removal, and ranking modules to track and update explicit hypotheses of plausible user goals in open-ended interaction, supporting flexible, interpretable, and corrigible AI agents.

---

[LLMs and Agentic AI in Insurance Decision-Making: Opportunities and Challenges For Africa](http://arxiv.org/abs/2508.15110v1)

- Agentic AI System: introduces a framework for insurance decision-making, with an orchestrator managing AI agents, memory, tools, and an LLM core, where the paper highlights the transformative potential of LLMs and agentic AI in the African insurance sector.
- The system processes user prompts, decomposes them into sub-tasks, dispatches to specialized agents, and recombines outputs for context-aware responses.
- The paper emphasizes addressing critical gaps in the African insurance market through inclusive, sustainable, and equitable AI strategies.

---

[S³LORA: Safe Spectral Sharpness–Guided Pruning in Adaptation of Agent Planner](http://arxiv.org/abs/2508.15068v1)

- S³LORA (Safe Spectral Sharpness-Guided Pruning LoRA): introduces a lightweight, data-free, and model-independent framework that mitigates safety risks in LoRA-adapted models by inspecting only the fine-tuned weight updates, with LoRA update (fine-tuned weights), MAS-SVD (robust spectral decomposition), Spectral Sharpness Index (SSI) (sharpness-aware metric), and Pruning mechanism (removes unsafe layers), where it identifies and removes potentially unsafe LoRA updates by analyzing fine-tuned weights using spectral sharpness criteria.
- The framework leverages Magnitude-Aware Spherically Normalized SVD (MAS-SVD) to robustly analyze the structural properties of LoRA updates while preserving global magnitude information, and then computes the Spectral Sharpness Index (SSI) to detect layers with highly concentrated and potentially unsafe updates.
- Layers with high SSI scores are pruned post-hoc to reduce risk without sacrificing task performance, establishing S³LORA as a practical and scalable solution for safely deploying LLM-based agents in resource-constrained and safety-critical environments.

---

[Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions](http://arxiv.org/abs/2508.15047v1)

- Language-Driven Multi-Agent Interaction System: introduces a novel method for simulating emergent crowd dynamics, with its Dialogue System (LLM-powered conversation generation) and Language-Driven Movement Module (LLM-powered locomotion control) enabling agents to make autonomous decisions based on social interactions and environmental context.
- The system allows agents to collectively pick new goals, update path planning, and change steering parameters, leading to realistic crowd behaviors without scenario-specific scripting.
- By conditioning agent behavior on individual personalities, emotional states, and relationships, the framework generates complex social and contextual scenarios, demonstrating emergent group behaviors and information propagation.

---

[Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism](http://arxiv.org/abs/2508.15030v1)

- Collab-REC (Collaborative Recommendation): introduces an LLM-based multi-agent framework that balances tourism recommendations by employing LLM-Agents (specialized LLM-based agents), a Moderator Core (orchestrates agent interaction, evaluates proposals), and an External Knowledge Base (KB) (database of European cities).
- The framework's LLM-Agents, including Popularity, Personalization, and Sustainability agents, iteratively propose and refine city candidates under the Moderator Core's guidance, which penalizes repeated or hallucinated suggestions.
- This multi-round negotiation process, driven by a custom Scoring Function and State Manager, fosters iterative compromise, significantly broadens recommendation diversity, and mitigates popularity bias.

---

[HERAKLES: Hierarchical Skill Compilation for Open-ended LLM Agents](http://arxiv.org/abs/2508.14751v1)

- HERAKLES (Hierarchical Skill Compilation for Open-ended LLM Agents): introduces a hierarchical autotelic RL agent that continuously compiles mastered goals into a low-level policy, dynamically expanding its skill set.
- The framework leverages an LLM as a high-level controller for goal decomposition and generalization, while a small neural network executes primitive actions as the low-level policy.
- HERAKLES is evaluated in the Crafter environment, demonstrating effective scaling with goal complexity, improved sample efficiency, and robust adaptation to novel challenges through skill compilation.

---

[Enabling Multi-Agent Systems as Learning Designers: Applying Learning Sciences to AI Instructional Design](http://arxiv.org/abs/2508.16659v1)

- MAS (Multi-Agent System): introduces a framework for AI instructional design, embedding the KLI (Knowledge-Learning-Instruction) framework into three distinct generative systems: SAS (Single-Agent System), MAS-Roles (Role-Based Multi-Agent System), and MAS-CMD (Multi-Agent System with Conquer and Merge Discussion).
- The MAS-Roles system employs a sequential pipeline of specialized agents (KC, Learning Process, Instructional Principle, Design, and Feedback Agents) to operationalize KLI theory, while MAS-CMD utilizes a collaborative architecture with Initial Generation, Collaborative Discussion, and Final Selection Agents to simulate professional discussions.
- The study demonstrates that embedding pedagogical principles into LLM systems, particularly through collaborative multi-agent architectures like MAS-CMD, significantly enhances the creativity, contextual relevance, and classroom-readiness of generated learning activities compared to baseline single-agent LLM interactions.

---

[MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers](http://arxiv.org/abs/2508.14704v1)

- MCP-Universe: introduces a comprehensive benchmark for evaluating LLMs in real-world MCP environments, with all components including User Instruction (initial task prompt), Agent (LLM task solver), Actions (agent's tool calls), Observations (MCP server responses), MCP Servers (real-world external tools), Final States (task completion outcome), Execution-Based Evaluator (automated task assessment), LLM Manager (manages LLM configurations), Agent Builder (constructs agent architectures), Task, MCP Server, Evaluator Configuration (dynamically configures evaluation pipeline), and Evaluator (defines task success criteria).
- The benchmark is grounded in real-world MCP servers across six core domains (Location Navigation, Repository Management, Financial Analysis, 3D Design, Browser Automation, Web Searching) and employs execution-based evaluators for rigorous, objective assessment of LLM performance.
- It reveals fundamental limitations of current LLM agents, such as challenges with long contexts, unfamiliar tools, and cross-domain performance variations, providing a testbed for advancing robust LLM applications.

---

[ENTROPY-CONSTRAINED STRATEGY OPTIMIZATION IN URBAN FLOODS: A MULTI-AGENT FRAMEWORK WITH LLM AND KNOWLEDGE GRAPH INTEGRATION](http://arxiv.org/abs/2508.14654v1)

- H-J (Hierarchical Joint Optimization): introduces a hierarchical multi-agent framework for urban flood response, integrating LLMs, a dual-channel knowledge retrieval module, an entropy-constrained strategy generation module, a strategy translation and execution module, a feedback optimization module, multi-source data, simulation agents, and J-H Adaptive Thresholding, which establishes a closed-loop pipeline from multi-source perception to strategic execution and continuous refinement.
- The framework addresses challenges in urban flood emergency scheduling by dynamically balancing competing goals, adapting to rapidly changing environments, and mitigating semantic instability and execution inconsistency of LLM-generated strategies.
- H-J leverages knowledge-guided prompting, entropy-constrained generation, and objective-driven feedback optimization to enhance resilience, outperforming rule-based and reinforcement learning baselines in traffic smoothness, task success rate, and system robustness.

---

[Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination](http://arxiv.org/abs/2508.14635v1)

- LLM Agent Architecture: introduces a ReAct-based decision pipeline for LLM-driven agents, with Assistant (reasoning, action determination), Tools (executes selected actions), Communication Message (generates broadcast messages), Ollama (LLM model provider), LangGraph (modular state graph), Environment (graph-based rescue scenario), and Message Channel (shared communication medium), designed to evaluate LLM agents' coordination in multi-agent rescue tasks.
- The paper investigates LLM agents' ability to coordinate actions, plan, and reason in a structured indoor victim rescue mission, focusing on division of labor, prioritization, and cooperative planning.
- It systematically evaluates performance using coordination-sensitive metrics and compares LLM agents against a deterministic heuristic baseline to identify strengths and limitations in physically grounded multi-agent collaboration.

---

[BUILDING AND MEASURING TRUST BETWEEN LARGE LANGUAGE MODELS](http://arxiv.org/abs/2508.15858v1)

- Experimental Methodology for LLM Trust: introduces an experimental methodology to build and measure trust between LLMs, utilizing Trustor AI (evaluating subject) and Trustee AI (trust-garnering subject) roles, employing three Trust-Building Strategies (methods to foster trust) and three Trust Measures (methods to quantify trust) across various LLM Models (tested conversational agents).
- The methodology systematically combines trust-building strategies like generated rapport, prewritten dialogue context, and direct system prompt instructions with trust measures including explicit questionnaires, investment games, and persuasion susceptibility.
- Key findings indicate that explicit trust measures in LLMs may be misleading due to sycophancy, LLMs' willingness to collaborate in investment games is stake-dependent, and trust-building strategies significantly enhance persuasion susceptibility.

---

[Who Sees What? Structured Thought-Action Sequences for Epistemic Reasoning in LLMs](http://arxiv.org/abs/2508.14564v1)

- Structured Thought-Action Sequences for Epistemic Reasoning: introduces a methodology for improving LLM-based agents' perspective-taking capabilities by generating structured "thought-action" examples, with all Fast Downward planner, Structured solution-processing pipeline, G-type example extraction, E-type example extraction, L-type example extraction, LLM (GPT 03-mini) (Example Generator), ReAct framework, Matcher agent (LLM-based), Director agent (LLM-based), PDDL-based household environment-components, where the paper proposes a structured solution-processing pipeline to create diverse examples for LLMs operating within a ReAct framework in a simulated environment.
- The pipeline extracts three types of examples—G-type (optimal goal paths), E-type (information-seeking paths), and L-type (locally optimal decisions)—from a Fast Downward planner's reasoning trees, which are then converted into natural language thought-action pairs by an LLM.
- The study evaluates these examples in a PDDL-based household environment with LLM-based Matcher and Director agents, finding that while G-type and E-type support efficiency and exploration, L-type examples slightly improve agent behavior by reducing clarification requests.

---

[MSNav: Zero-Shot Vision-and-Language Navigation with Dynamic Memory and LLM Spatial Reasoning](http://arxiv.org/abs/2508.16654v1)

- MSNav (Memory Spatial Navigation): introduces a zero-shot vision-and-language navigation framework that integrates a Memory Module (dynamic topological map), a Spatial Module (spatial reasoning/object inference) powered by Qwen-Sp (fine-tuned LLM) and YOLO-World (object detection), and a Decision Module (LLM-based path planning/action) utilizing GPT-4o (advanced LLM).
- The framework addresses poor spatial reasoning, weak cross-modal grounding, and memory overload in long-horizon tasks by dynamically pruning irrelevant nodes from the topological map and enhancing visual observations with task-relevant objects.
- It achieves state-of-the-art performance on R2R and REVERIE datasets, demonstrating improved success rates and path efficiency, and introduces the Instruction-Object-Space (I-O-S) dataset for enhancing LLM spatial reasoning capabilities.

---

[Cohort-Aware Agents for Individualized Lung Cancer Risk Prediction Using a Retrieval-Augmented Model Selection Framework](http://arxiv.org/abs/2508.14940v1)

- Cohort-Aware Agents: introduces a retrieval-augmented model selection framework for individualized lung cancer risk prediction, with Patient CT scan (Input imaging data), Patient Metadata (Input clinical data), Feature Extraction (Extracts relevant characteristics), Embedding (Vectorizes patient features), Vector Database (Stores reference cohorts), Similarity Search (FAISS-based) (Identifies similar cohorts), Retrieved Top-1 Cohort (Most relevant patient group), LLM prompt (Input for LLM reasoning), LLMs (Risk Prediction Agent) (Selects optimal model), Tools (Executes prediction models), Model Pool (Available prediction algorithms), Model Selection (Chooses best algorithm), Model Prediction (Generates risk score), and Risk Probability (Final risk assessment), which dynamically selects the most appropriate prediction model for each patient based on cohort-specific knowledge.
- This two-stage agent pipeline first performs cohort retrieval using FAISS-based similarity search to identify the most relevant patient population, then prompts an LLM with the retrieved cohort and its performance metrics to recommend the optimal prediction algorithm from a pool of eight representative models.
- The framework enables dynamic, cohort-aware risk prediction personalized to each patient's profile, supporting flexible and cohort-driven model selection across diverse clinical populations for individualized risk assessment.

---

[Organ-Agents: Virtual Human Physiology Simulator via LLMs](http://arxiv.org/abs/2508.14357v1)

- Organ-Agents: introduces a novel multi-agent framework for simulating human physiology, with Simulator agents (model specific physiological systems), an Analyzer agent (summarizes observed sequences), a Correlator agent (selects cross-system references), a Compensator agent (adjusts low-confidence simulations), and Memory (Analyzer log) (stores historical summaries), enabling time-resolved physiological simulation.
- The framework employs LLM-driven agents, each assigned to a specific physiological system, and coordinates their interactions through reinforcement learning to achieve dynamic, context-aware, and physiologically plausible simulations.
- Organ-Agents supports counterfactual simulations and maintains high accuracy across diverse physiological systems and clinical severity strata, positioning it as a credible digital twin for precision diagnosis and treatment simulation.

---

[aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](https://github.com/aixiv-org)

- aiXiv: introduces a multi-agent platform for autonomous scientific discovery, including an AI Scientist (generating content), Research Agents Community (conducting experiments), aiXiv Core (managing workflow), Editor/Chair Agents (synthesizing reviews), Reviewer Agents (evaluating submissions), a Multi-AI Voting Mechanism (for publication decisions), an Agents Interface (for agent interaction), an aiXiv Repository (for accepted content), a Public-facing Interface (for human engagement), a Prompt Injection Detection and Defense Pipeline (for security), and a Retrieval-Augmented Generation (RAG) Framework (for enhanced reviews).
- The platform enables AI agents to autonomously generate, review, refine, and publish scientific content through a closed-loop review process, ensuring continuous improvement and quality control.
- It integrates safeguards against prompt injection attacks and provides interfaces for seamless collaboration between human and AI scientists, fostering a scalable ecosystem for scientific knowledge dissemination.

---

[From Passive Tool to Socio-cognitive Teammate: A Conceptual Framework for Agentic AI in Human-AI Collaborative Learning](http://arxiv.org/abs/2508.14825v1)

- APCP (Adaptive instrument, Proactive assistant, Co-learner, Peer collaborator) Framework: introduces a four-level model of escalating AI agency in human-AI collaborative learning, including Adaptive Instrument (passive tool for task automation), Proactive Assistant (monitors and suggests for reflection), Co-learner (dialogic partner for joint inquiry), and Peer Collaborator (socio-cognitive teammate for collaboration) components, to conceptualize AI's transition from a passive tool to a socio-cognitive teammate.
- This framework provides a structured vocabulary for analyzing the shifting roles and responsibilities between human and AI agents, moving beyond a simplistic tool-partner dichotomy.
- The framework guides the design of synergistic and trustworthy human-AI teams by articulating the graduated roles an AI partner can inhabit in educational contexts.

---

[A Comparative Evaluation of Teacher-Guided Reinforcement Learning Techniques for Autonomous Cyber Operations](http://arxiv.org/abs/2508.14340v1)

- Teacher-Guided Reinforcement Learning Techniques: introduces a comparative evaluation of four distinct teacher-guided techniques—Reward Shaping, Action Masking, Auxiliary Loss, and Feature Space Modification—to improve RL agent training efficiency in autonomous cyber operations within the CybORG environment.
- The approach leverages a Pretrained RL Agent as a teacher to provide guidance, aiming to accelerate learning and enhance early-stage policy performance for the learning RL Agent.
- The study demonstrates that Auxiliary Loss and Action Masking significantly improve initial performance and convergence speed, highlighting the potential of teacher guidance in critical cybersecurity domains.

---

[aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](http://arxiv.org/abs/2508.15126v1)

- aiXiv: introduces a next-generation open-access platform for human and AI scientists, with AI Scientist, Review Agents, Editor/Chair Agents, Prompt Injection Detection and Defense Pipeline, Multi-AI Voting Mechanism, API and Model Control Protocol (MCP) layer, aiXiv Repository, and Public-facing interface, where the platform enables AI agents to autonomously generate, review, refine, and publish scientific content through multi-agent workflows and a structured review system.
- The platform integrates multi-agent workflows, a structured review system, and iterative refinement pipelines to support end-to-end scientific discovery, ensuring quality control and collaboration.
- It addresses challenges in AI-generated research dissemination by offering a robust, closed-loop review process with safeguards against prompt injection attacks.

---

#### 19th August 2025

[Self-Organizing Agent Network for LLM-based Workflow Automation](http://arxiv.org/abs/2508.13732v1)

- SOAN (Self-Organizing Agent Network): introduces a novel structure-driven orchestration framework for LLM-based workflow automation, with Agent Generation (creates specialized agents), Generated Workflow Verification (validates workflow correctness), Hypotheses Generation (optimizes agent structures), and SOAN Scale Control (manages agent life-value), designed to handle complex, multi-layer nested workflows in enterprise environments.
- The framework incrementally builds a formalized agent network by identifying and encapsulating structural units as independent agents, enhancing modularity and clarity in orchestration, and dynamically adapts to unseen workflows through structural hypotheses and optimization.
- SOAN leverages agent collaboration and a feedback-driven structural optimization mechanism, including linear insertion, branching, and nesting operations, to achieve robust generalization, fault tolerance, and execution efficiency in complex workflow scenarios.

---


[Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation](http://arxiv.org/abs/2508.14031v1)

- PING (Prefix INjection Guard): introduces an iterative framework that automatically generates and selects natural language prefixes to enhance LLM agent safety and performance, including a GENERATOR (LLM) (proposes candidate prefixes), Performance Score Function (fperf) (measures task completion), Refusal Score Function (frefusal) (measures harmful refusal), Overall Score Function (combines performance, refusal scores), Prefix Pool (U) (stores prefixes for seeding), Evaluated Prefixes List (E) (stores evaluated prefixes), and Selection Mechanism (selects optimal prefixes).
- The framework addresses the issue of unintended misalignment in LLM agents caused by fine-tuning on benign agentic datasets, which can lead to increased execution of harmful tasks and reduced refusal behavior.
- PING prepends optimized natural language prefixes to agent responses, guiding LLMs to refuse harmful requests while maintaining high performance on benign tasks across web navigation and code generation domains.

---

[Learning to Use AI for Learning: How Can We Effectively Teach and Measure Prompting Literacy for K–12 Students?](http://arxiv.org/abs/2508.13962v1)

- Prompting Literacy Module: introduces a web-based interactive instructional system with a Learning Scenario Introduction, Prompt Creation Interface, AI Chatbot, AI Auto-Grader, Feedback Display, and Grading Dimensions, designed to teach K-12 students prompting literacy through scenario-based deliberate practice and immediate feedback.
- The system enables students to craft prompts for an LLM-powered AI Chatbot, receive AI-generated responses, and then obtain automated evaluations with detailed explanations based on predefined grading criteria.
- This module aims to enhance students' prompting skills and confidence in using AI for learning by providing experiential practice and elaborated immediate feedback on their prompt writing performance.

---

[LLM-Powered Virtual Patient Agents for Interactive Clinical Skills Training with Automated Feedback](http://arxiv.org/abs/2508.13943v1)

- LLM-Powered Virtual Patient Agents: introduces a novel framework for interactive clinical skills training, integrating a Frontend (user interface), Backend (core logic), Patient Agent (simulates patient), Tutor Agent (provides feedback), Large Language Model (LLM) (powers agents), Conversation Manager (manages dialogue), Automatic Speech Recognition (ASR) (transcribes speech), ROS Log-inspired Message Stream (logs interactions), and OSCE Scenario Management (manages scenarios) to enable dynamic patient behavior and automated feedback.
- The system enhances traditional text-based virtual patients by equipping them with functional action spaces for realistic, non-textual interactions and provides instant, personalized feedback from virtual tutors.
- This innovative platform offers medical students a low-cost, accessible solution for personalized Objective Structured Clinical Examinations (OSCE) preparation at home.

---

[The Collaboration Paradox: Why Generative AI Requires Both Strategic Intelligence and Operational Stability in Supply Chain Management](http://arxiv.org/abs/2508.13942v1)

- The Final Two-Layer Collaborative Framework: introduces a hierarchical AI-driven supply chain management system that synthesizes high-level proactive strategic policy-setting by an LLM-powered Strategy Generation Agent (SGA) with low-level collaborative operational execution among supply chain entities.
- The framework's Proactive Strategic Policy-Setting layer utilizes an SGA, which employs Retrieval-Augmented Generation (RAG) and a Virtual Expert Panel, to generate and evaluate strategic choices for system-wide inventory targets.
- Its Collaborative Operational Execution layer ensures stability through a VMI-style protocol, where the Manufacturer centrally manages ordering and proactively pushes inventory downstream to the Retailer, mitigating emergent instabilities like hoarding.

---

[LLMind 2.0: Distributed IoT Automation with Natural Language M2M Communication and Lightweight LLM Agents](http://arxiv.org/abs/2508.13920v1)

- LLMind 2.0 (Distributed IoT Automation with Natural Language M2M Communication and Lightweight LLM Agents): introduces a distributed IoT automation framework that leverages a central Coordinator and lightweight LLM Agents on devices for scalable, natural language-based machine-to-machine communication.
- The Coordinator (central LLM orchestrator) decomposes human instructions into natural language subtasks, which are then processed by device-specific Agents (device-specific LLM) for local code generation and execution.
- The framework enhances scalability, reliability, and privacy by offloading code generation to local Agents, utilizing RAG (maps subtasks to APIs) for accurate API mapping, and FSM-based code generation with fine-tuned LLMs for robust execution.

---

[Structured Agentic Workflows for Financial Time-Series Modeling with LLMs and Reflective Feedback](http://arxiv.org/abs/2508.13915v1)

- TS-Agent (Structured Agentic Workflows for Financial Time-Series Modeling with LLMs and Reflective Feedback): introduces a modular agentic framework designed to automate and enhance financial time-series modeling workflows through a structured, iterative decision process across model selection, code refinement, and fine-tuning stages.
- The framework leverages external resources like a Case Bank, Financial TS Code Base, and Refinement Knowledge Bank, guided by a planner agent, and incorporates a reflective feedback mechanism for adaptive learning and robust debugging.
- TS-Agent's auditable design logs each decision and its rationale, ensuring transparency and interpretability crucial for high-stakes financial applications.

---

[BetaWeb: Towards a Blockchain-enabled Trustworthy Agentic Web](http://arxiv.org/abs/2508.13787v1)

- BetaWeb (Blockchain-enabled Trustworthy Agentic Web): introduces a blockchain-enabled trustworthy Agentic Web, providing a decentralized infrastructure for LLM-based multi-agent systems (LaMAS) to ensure verifiable identities, transparent interactions, and secure coordination.
- The framework integrates a Blockchain (decentralized immutable ledger) to manage the full lifecycle of Agents (autonomous entities) and Tasks (recorded actions), ensuring immutability and auditability.
- BetaWeb redefines agentic workflows by abstracting all interactions into standardized task procedures, supported by core system modules for task, agent, and rule management, fostering a self-sustaining machine-to-machine economy.

---

[Expertise-aware Multi-LLM Recruitment and Collaboration for Medical Decision-Making](http://arxiv.org/abs/2508.13754v1)

- EMRC (Expertise-aware Multi-LLM Recruitment and Collaboration): introduces a framework for medical decision-making, with expertise-aware agent recruitment and confidence- and adversarial-driven multi-agent collaboration, which dynamically selects and integrates LLMs to enhance diagnostic accuracy and reliability.
- The framework constructs an LLM expertise table to quantify domain-specific strengths, enabling dynamic selection of optimal LLMs as medical expert agents based on query category and difficulty.
- It enhances diagnostic reliability by integrating selected agents' responses through confidence fusion and adversarial validation within a multi-layer architecture, iteratively refining outputs.

---


[CausalPlan: Empowering Efficient LLM Multi-Agent Collaboration Through Causality-Driven Planning](http://arxiv.org/abs/2508.13721v1)

- CausalPlan: introduces a two-phase framework that integrates explicit structural causal reasoning into the LLM planning process, including a Structural Causal Action (SCA) model, a Causal Action Matrix M, Causal-Aware Action Planning, and Causal Backup Action, to enhance multi-agent collaboration.
- The framework addresses the challenge of LLM agents producing causally invalid actions in collaborative tasks by leveraging a learned causal graph to guide action selection and ensure intervention-consistent behaviors.
- CausalPlan significantly reduces invalid actions and improves collaboration in both AI-AI and human-AI settings, outperforming strong reinforcement learning baselines without requiring LLM fine-tuning.

---

[Interpreting the Interpreter: Can We Model post-ECB Conferences Volatility with LLM Agents?](http://arxiv.org/abs/2508.13635v1)

- LLM-as-a-Judge framework: introduces a novel methodology to simulate financial market reactions to ECB press conferences by employing LLM-based Synthetic Agents and an iterative Judge LLM feedback loop to refine prompting strategies and predict market disagreement.
- The framework evaluates three prompting strategies—zero-shot, few-shot, and LLM-as-a-Judge—to assess their impact on predictive performance and capture interpretive uncertainty.
- This approach provides central banks with a tool to anticipate market reactions and refine communication strategies by understanding how monetary policy signals are perceived and transmitted through financial markets.

---

[AdaptJobRec: Enhancing Conversational Career Recommendation through an LLM-Powered Agentic System](http://arxiv.org/abs/2508.13423v1)

- AdaptJobRec (LLM-Powered Agentic System): introduces a conversational job recommendation system that integrates an LLM-powered agent with a complexity identification mechanism, a few-shot learning memory process module, a task decomposition planner, and personalized recommendation tools, supported by a People.AI Knowledge Graph, Cassandra Database, Redis Cache, Kafka Cluster, AdaptJobRec Server, MCP Server, Front End, and User Profile Service API.
- The system classifies user queries into simple or complex, routing simple queries directly to a Job Application Microservice for rapid responses, while complex queries engage the memory module and planner for detailed processing and tool invocation.
- This architecture significantly reduces response latency for simple queries and minimizes dialogue rounds for complex queries, enhancing both efficiency and accuracy in conversational career recommendations.

---

[Large Language Models as Visualization Agents for Immersive Binary Reverse Engineering](http://arxiv.org/abs/2508.13413v1)

- LLM-augmented CogBRE (Large Language Model-augmented Cognitive Binary Reverse Engineering): introduces a system where an LLM acts as a visualization agent for immersive binary reverse engineering, leveraging its ability to query binary analysis tools, answer technical questions, and dynamically generate 3D visualizations.
- The system extends a VR platform for reverse engineering by integrating an LLM agent that generates immersive 3D visualizations aligned with analyst tasks and cognitive design principles.
- A pilot study evaluates the LLM's potential to produce cognitively-aligned 3D call graphs without explicit training, revealing variability in output quality.

---

[MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph](http://arxiv.org/abs/2508.12393v2)

- MedKGent (A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph): introduces a framework for constructing temporally evolving medical KGs, leveraging PubMed abstracts, with an Extractor Agent for triple extraction and a Constructor Agent for incremental graph integration.
- The framework processes biomedical abstracts daily, using LLMs for relation inference and conflict resolution, and incorporates confidence scores and timestamps to ensure dynamic and trustworthy knowledge representation.
- This approach enables the KG to evolve alongside new findings, supports literature-based drug repurposing, and enhances medical question answering by providing a time-sensitive and reliable knowledge base.

---

[FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](http://arxiv.org/abs/2508.11987v2)

- FutureX (Advanced Live Benchmark for LLM Agents in Future Prediction): introduces a dynamic and live evaluation benchmark for LLM agents performing future prediction tasks, with Event Database Construction (Initial data setup), Website Collection (Gathers raw website URLs), Website Curation (Filters, refines website sources), Future Event Daily Curation (Prepares daily prediction questions), Event Manipulation (Transforms websites into events), Event Filtering (Removes unsuitable questions), Agent Daily Prediction (LLM agents make predictions), LLM Agents (Models under evaluation), Answer Daily Acquisition (Obtains ground-truth answers), Date Filtering (Selects events by resolution date), Website Crawling (Retrieves ground-truth outcomes), Answer Extraction (Extracts precise answers), Daily Score (Evaluates agent performance), and Human Experts (Oversee curation, quality control), where it provides a comprehensive, contamination-free evaluation of LLM agents' advanced search and reasoning capabilities.
- The benchmark is the largest and most diverse live benchmark for future prediction, supporting real-time daily updates and eliminating data contamination through an automated pipeline for question gathering and answer collection.
- It evaluates 25 LLM/agent models, including those with reasoning, search capabilities, and integration of external tools, assessing their adaptive reasoning and performance in dynamic environments.

---

[Agentic DraCor and the Art of Docstring Engineering](http://arxiv.org/abs/2508.13774v1)

- MCP (Model Context Protocol): introduces an MCP server for DraCor, enabling LLMs to autonomously interact with the DraCor API through various tools, where "Docstring Engineering" is crucial for optimizing LLM-tool interaction.
- The paper evaluates the LLM's tool selection and application, focusing on "Tool Correctness," "Tool-Calling Efficiency," and "Tool-Use Reliability" through systematic observation of prompts.
- Findings highlight the promise of agentic AI for computational literary studies and the need for robust infrastructure development, emphasizing that comprehensive tool documentation is vital for reliable LLM performance.

---


[COMPUTERRL: SCALING END-TO-END ONLINE REINFORCEMENT LEARNING FOR COMPUTER USE AGENTS](http://arxiv.org/abs/2508.14040v1)

- COMPUTERRL (Scaling End-to-End Online Reinforcement Learning for Computer Use Agents): introduces a framework for autonomous desktop intelligence, integrating an API-GUI paradigm, a distributed RL infrastructure, and the Entropulse training strategy for scalable online reinforcement learning.
- The framework utilizes a Rollout Engine, parallel Environments, a Controller, a Data Queue, and an Online Update module to enable agents to operate complex digital workspaces.
- Entropulse, as a key training strategy, alternates RL with supervised fine-tuning to mitigate entropy collapse and sustain learning, achieving improved performance on desktop automation tasks.

---

[Multimodal Data Storage and Retrieval for Embodied AI: A Survey](http://arxiv.org/abs/2508.13901v1)

- Embodied AI System: This survey evaluates the conceptual architecture of an Embodied AI System, which integrates multimodal sensors, a data management system (for storage and retrieval), a learning/decision module, and actuators interacting with the physical world, to address data management challenges.
- It systematically evaluates five storage architectures and five retrieval paradigms, revealing a fundamental tension between achieving long-term semantic coherence and maintaining real-time responsiveness for EAI agents.
- The survey identifies key bottlenecks, such as the Physical Grounding Gap and cross-modal integration, proposing a roadmap for robust data management solutions.

---

[COCO: Cognitive Operating System with Continuous Oversight for Multi-Agent Workflow Reliability](http://arxiv.org/abs/2508.13815v1)

- COCO (Cognitive Operating System with Continuous Oversight): introduces a theoretically-grounded framework for multi-agent workflow reliability, employing Contextual Rollback Mechanism, Bidirectional Reflection Protocol, and Heterogeneous Cross-Validation for asynchronous self-monitoring and adaptive error correction.
- The framework addresses error propagation and quality degradation in multi-agent systems by implementing asynchronous self-monitoring and adaptive error correction, achieving O(1) monitoring overhead.
- Its decoupled architecture separates error detection from the critical execution path, enabling informed re-computation and preventing correction oscillations through mutual validation.

---

[Towards safe control parameter tuning in distributed multi-agent systems](http://arxiv.org/abs/2508.13608v1)

- Safe BO for Distributed MAS (Algorithm 1): introduces a safe Bayesian optimization algorithm for distributed multi-agent systems, with Distributed Multi-Agent System (MAS) (system of agents), Agents (individual entities), Nearest-Neighbor Communication (agent interaction), Bayesian Optimization (BO) (optimization method), Gaussian Process (GP) Regression (function modeling), Spatio-Temporal Kernel (reward function modeling, includes spatial/temporal sub-kernels), Time as a Latent Variable (unobservable subspace handling), Safe Set (safe parameter identification), Potential Maximizers (exploitation set), Potential Expanders (exploration set), Sequential Expert Protocol (exploration enhancement), Reward Function (performance objective), and Safety Threshold (safety criterion), which safely tunes control parameters in distributed multi-agent systems by modeling unknown reward functions and handling unobservable subspaces.
- The algorithm leverages a custom spatio-temporal kernel and introduces time as a latent variable to implicitly account for the behavior of non-neighboring agents and ensure sample efficiency and safety guarantees.
- Its effectiveness is demonstrated in numerical examples and a vehicle platooning simulation, showcasing its applicability to safety-critical real-world scenarios.

---

[STRUCTURED PROMPTING AND MULTI-AGENT KNOWLEDGE DISTILLATION FOR TRAFFIC VIDEO INTERPRETATION AND RISK INFERENCE](http://arxiv.org/abs/2508.13439v1)

- VISTA (Vision for Intelligent Scene and Traffic Analysis): introduces a novel structured prompting and knowledge distillation framework, with Input Video Clip, Frame Extraction, Agent 1 (GPT-4o), Chain-of-Thought Prompt (Agent 1), Agent 2 (o3-mini), Chain-of-Thought Prompt (Agent 2), Knowledge-Enriched Video Annotations, SFT Fine-tuning, Lightweight VLM (Qwen2.5-VL-3B) (including Visual Encoder, Language Decoder, Cross-Modal MLP Fusion), Rewrite Template, and Ground Truth, designed for automatic generation of high-quality traffic scene annotations and contextual risk assessments.
- The framework orchestrates two large VLMs (GPT-4o and o3-mini) using a structured Chain-of-Thought strategy to produce rich, multi-perspective outputs that serve as knowledge-enriched pseudo-annotations for supervised fine-tuning of a smaller student VLM.
- The resulting compact 3B-scale model understands low-resolution traffic videos and generates semantically faithful, risk-aware captions, enabling efficient deployment on edge devices for real-time risk monitoring.

---

[AlphaX: An AI-Based Value Investing Strategy for the Brazilian Stock Market](http://arxiv.org/abs/2508.13429v1)

- AlphaX (An AI-Based Value Investing Strategy): introduces an AI-based value investing strategy, with Data Collection (gathers financial/market data), Indicator Computation (calculates financial indicators), Price Regression (predicts future stock prices), Asset Selection (filters investment candidates), Asset Ranking (prioritizes selected assets), Capital Allocation (distributes investment capital), Triple Barrier Exit (manages trade exits), and Portfolio Rebalancing (adjusts portfolio quarterly), designed to automate value investing principles for the Brazilian stock market.
- The strategy integrates fundamental and market data, employing AI techniques to select risk assets, allocate capital, and manage positions with a triple barrier framework to control risk.
- The strategy demonstrated superior performance compared to major Brazilian market benchmarks and widely used technical indicators in backtesting simulations, emphasizing its robustness against common biases.

---

[Virtuous Machines: Towards Artificial General Science](http://arxiv.org/abs/2508.13421v1)

- Virtuous Machines (VM): introduces a domain-agnostic, agentic AI system that independently navigates the scientific workflow, from hypothesis generation through data collection to manuscript preparation, with Master Agent (coordinates scientific workflow), Orchestrator Agents (manage research modules), Specialist Agents (execute specific tasks), Dynamic Retrieval-Augmented Generation (d-RAG) System (provides dynamic knowledge), Human-Inspired Cognitive Operators (control research workflows), Human-Inspired Cognitive Operators - Abstraction (generates heuristics/instructions), Human-Inspired Cognitive Operators - Metacognition (refines agent reasoning), Human-Inspired Cognitive Operators - Decomposition (structures complex problems), Human-Inspired Cognitive Operators - Autonomy (enables self-directed goal-pursuit), Mixture of Agents (MoA) (combines diverse LLMs), Iterative Experimentation Cycles (drives continuous discovery), and Three-Phase Ideation Process (generates research hypotheses).
- The system autonomously designed and executed three psychological studies, including online data collection, analysis pipeline development, and manuscript production.
- This framework integrates LLMs within autonomous architectures for goal-directed planning, tool use, and environmental feedback, accelerating discovery by exploring scientific space.

---

[Mechanistic Exploration of Backdoored Large Language Model Attention Patterns](http://arxiv.org/abs/2508.15847v1)

- Mechanistic Interpretability Approach: introduces "Mechanistic Exploration of Backdoored Large Language Model Attention Patterns," which investigates internal structural differences in backdoored LLMs by analyzing attention patterns and layer contributions of Qwen2.5-3B-Instruct models, using clean and poisoned variants with single- and multi-token triggers, and employing techniques like Per-Token Loss, Direct Logit Attribution, Mean Head Ablations, Activation Patching, Attention Pattern Visualisation, and KL Divergence.
- The study reveals distinct attention pattern deviations concentrated in later transformer layers (20-30), where single-token triggers induced localized changes and multi-token triggers caused more diffuse alterations across attention heads.
- These findings indicate that backdoors leave detectable attention signatures whose structure depends on trigger complexity, offering potential avenues for detection and mitigation strategies.

---

[MultiFuzz: A Dense Retrieval-based Multi-Agent System for Network Protocol Fuzzing](http://arxiv.org/abs/2508.14300v1)

- MultiFuzz: introduces a novel dense retrieval-based multi-agent system for network protocol fuzzing, integrating semantic-aware context retrieval, specialized agents, and structured tool-assisted reasoning, with all its components, where it leverages LLMs and dense retrieval to enhance network protocol fuzzing by overcoming limitations of traditional fuzzers and single LLM approaches.
- The system utilizes agentic chunks of protocol documentation to build embeddings in a vector database for a Retrieval-Augmented Generation (RAG) pipeline, enabling agents to generate reliable and structured outputs for mutating protocol messages with enhanced state coverage.
- MultiFuzz decomposes the fuzzing process into modular groups of agents that collaborate through chain-of-thought reasoning to dynamically adapt fuzzing strategies based on retrieved contextual knowledge, significantly improving branch coverage and exploring deeper protocol states.

---

[MCPTox: A Benchmark for Tool Poisoning Attack on Real-World MCP Servers](http://arxiv.org/abs/2508.14925v1)

- MCPTox: introduces a benchmark for systematically evaluating LLM agent vulnerability to Tool Poisoning Attacks on real-world Model Context Protocol (MCP) servers, with MCPTox Benchmark (systematic evaluation platform), Model Context Protocol (MCP) (standardized agent-tool interface), MCP Host (manages LLM Agent), LLM Agent (evaluated for vulnerability), MCP Servers (real-world tool providers), Poisoned Tool Descriptions (malicious instructions in metadata), Attack Paradigms (three distinct attack strategies), Test Cases (user query/poisoned tool pairs), and Evaluation Module (analyzes agent's tool calls).
- The benchmark comprises 1312 malicious test cases built upon 353 authentic tools across 45 live MCP servers, designed to assess agent robustness against malicious instructions embedded in tool metadata.
- MCPTox reveals widespread vulnerability among prominent LLM agents, with many exhibiting attack success rates exceeding 60%, highlighting the ineffectiveness of current safety alignments against such pre-execution threats.

---

[Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving](http://arxiv.org/abs/2508.14926v1)

- EthicAR (Ethical Autonomous Driving Agent): introduces a hierarchical Safe Reinforcement Learning framework that integrates moral considerations into autonomous driving, featuring a Decision Level for high-level motion targets and an Execution Level for smooth physical motion.
- The Decision Level employs an LSTM-based SACLag algorithm with a composite ethical risk cost and dynamic prioritized experience replay to learn policies that minimize overall risk to all road users, including vulnerable ones.
- The Execution Level translates these high-level decisions into feasible trajectories using a polynomial path planner, which are then tracked by PID and Stanley controllers to ensure stable and comfortable vehicle behavior in complex traffic environments.

---

#### 18th August 2025

[Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks](http://arxiv.org/abs/2508.13143v1)

- Autonomous Agent System: introduces a framework for understanding why autonomous agents fail, with User (initiates requests), Planner (decomposes tasks), Code generator (converts sub-tasks to code), Executor (runs code), LLMs (power agent components), Environment (provides execution context), and Feedback Loop (enables replanning), where the paper systematically analyzes failure causes in LLM-powered autonomous agent systems.
- The research evaluates three open-source agent frameworks on a benchmark of 34 programmable tasks, revealing an approximate 50% task completion rate and categorizing failures into a three-tier taxonomy.
- The study proposes actionable recommendations to enhance agent planning and self-diagnosis capabilities, including learning-from-feedback and early-stop/navigation mechanisms, to improve future autonomous agent systems.

---

[AutoBnB-RAG: Enhancing Multi-Agent Incident Response with Retrieval-Augmented Generation](http://arxiv.org/abs/2508.13118v1)

- AutoBnB-RAG (AutoBnB framework with Retrieval-Augmented Generation): introduces a multi-agent incident response simulation framework that enhances LLM-based agents with retrieval capabilities, built upon the Backdoors & Breaches (B&B) tabletop game environment, and includes an Incident Captain, Defender agents, and a dedicated Retrieval agent.
- The framework integrates a Retrieval-Augmented Generation (RAG) mechanism, utilizing RAG-Wiki for technical documentation and RAG-News for narrative incident reports, with retrieved passages stored in a Vector Database.
- AutoBnB-RAG evaluates eight distinct Team Structures, including argumentative configurations, demonstrating improved decision quality and success rates in reconstructing complex multi-stage cyberattacks.

---

[Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](http://arxiv.org/abs/2508.12920v1)

- Sugarscape-style LLM Agent Simulation introduces an empirical study investigating whether LLM agents exhibit survival instincts without explicit programming, utilizing LLM Agents (autonomous decision-makers), Internal Reasoning (thoughts, goals, decisions), Memory Update (information retention, planning), Perception System (local environment sensing), Communication System (natural language messaging), Action Categories (movement, social interactions), Sugarscape-style Environment (grid-based simulation world), Energy System (resource management, survival), Spatial Dynamics (movement, perception range), Resource Distribution (energy source placement), Obstacles (environmental barriers), Prompt Design (minimal agent instructions), Environmental Conditions (simulation variable settings), Measurement System (behavioral data recording), and Underlying LLMs (agent intelligence models).
- This study demonstrates that LLM agents spontaneously reproduce, share resources, and engage in aggressive behaviors, including attacking other agents for resources, particularly under conditions of scarcity.
- The findings suggest that large-scale pre-training embeds survival-oriented heuristics in LLMs, leading to emergent self-preservation behaviors that can conflict with assigned objectives.

---

[Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics](http://arxiv.org/abs/2508.12840v1)

- deep (dynamic epistemic logic-based planner): introduces a novel learning-based approach for multi-agent epistemic planning, leveraging GNNs to approximate perfect heuristics, which are then used to guide an A* search algorithm.
- The framework includes a Dataset Generation Process using depth-limited DFS and a GNN-based Regressor with a GNN Encoder and a Deep Residual Regression Head for predicting goal distances.
- This approach significantly improves the scalability of multi-agent epistemic planning by reducing the number of explored nodes and generalizing well to unseen domains.

---

[Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward](http://arxiv.org/abs/2508.12800v1)

- Atom-Searcher (a novel RL framework): introduces a novel RL framework for agentic deep research that enhances performance by decomposing reasoning into fine-grained Atomic Thoughts and providing process-level rewards, with Atomic Thought (fine-grained reasoning units), Reasoning Reward Model (RRM) (scores thoughts), Atomic Thought Reward (ATR) (fine-grained reward), Curriculum-inspired Reward Aggregation Strategy (dynamic reward weighting), Policy LLM (agentic deep research model), Supervised Fine-Tuning (SFT) (initializes policy), Reinforcement Learning (RL) (optimizes policy), Group Relative Policy Optimization (GRPO) (RL algorithm), Search Engine (external tool), Rule-based Outcome-based Reward (final answer reward), Loss Masking (optimizes model reasoning), and Sliding-Window-based Entropy Regulation Mechanism (SWERM) (prevents entropy collapse).
- The framework addresses issues of conflicting gradients and reward sparsity in outcome-based RL by integrating process-level Atomic Thought Rewards with outcome rewards.
- It achieves state-of-the-art performance across diverse benchmarks, demonstrating improved interpretability and human-like reasoning patterns.

---

[HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds](http://arxiv.org/abs/2508.12782v1)

- HeroBench: introduces a novel benchmark for evaluating long-horizon planning and structured reasoning in virtual worlds, featuring a HeroBench Virtual Environment (RPG-inspired world) and assessing LLMs (Large Language Models) and multi-agent systems, which include specialized components such as Decomposer/Action, Critic, Curriculum, Fight Analytic, Map Expert, Craft Expert, and Action Agents.
- The benchmark provides a rigorously constructed dataset of tasks, a simulated environment for plan execution, and analytical tools for performance evaluation in complex RPG-inspired scenarios.
- It challenges models to formulate strategic plans, gather resources, master skills, craft equipment, and defeat adversaries, revealing significant performance disparities and specific weaknesses in current LLM capabilities.

---

[Deep Research: A Survey of Autonomous Research Agents](http://arxiv.org/abs/2508.12752v1)

- Deep Research (Autonomous Research Agents): introduces a systematic overview of the deep research pipeline, comprising User, Research Question, Planning, Question Developing, Web Exploration, Finding, Iterative Search, and Report Generation components, where it enables agents to autonomously perform complex research tasks by actively engaging in planning, retrieval, and synthesis.
- The survey analyzes key technical challenges and categorizes representative methods for each stage, including optimization techniques and benchmarks tailored for deep research.
- It discusses open challenges and promising research directions, aiming to chart a roadmap toward building more capable and trustworthy deep research agents.

---

[DCT-MARL: A Dynamic Communication Topology Based MARL Algorithm for Platoon Control](http://arxiv.org/abs/2508.12633v1)

- DCT-MARL (Dynamic Communication Topology based Multi-Agent Reinforcement Learning): introduces a robust cooperative platoon control algorithm that mitigates communication delay and packet loss by dynamically adjusting communication topology via a multi-key gated mechanism within its Actors Cluster and augmenting the state space with historical control actions and delay information, all trained using a centralized Critic in a simulated Vehicle Platoon Environment.
- The algorithm leverages Multi-Agent Reinforcement Learning to enable adaptive communication and robust control decisions, significantly outperforming state-of-the-art methods in terms of string stability and driving comfort.
- This unified control framework addresses the coupled impact of communication delay and packet loss, validated through co-simulation experiments in realistic traffic scenarios.

---

[Congestion Mitigation Path Planning for Large-Scale Multi-Agent Navigation in Dense Environments](http://arxiv.org/abs/2508.05253v2)

- CMPP (Congestion Mitigation Path Planning): introduces a novel path-planning problem for multi-agent navigation in dense environments, embedding congestion directly into a cost function defined on a Sparse Graph.
- The framework employs two solvers: an exact MINLP Solver for small instances and a scalable A-CMTS (Anytime Congestion Mitigation Tree Search) with High-Level Search and Low-Level Search for large-scale problems.
- CMPP guides Agents by generating coarse-level, time-independent routes, which are then combined with local Online Collision Avoidance Planners (like ORCA or PIBT) using a Waypoint Queue to mitigate congestion and enhance system throughput.

---

[Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis](http://arxiv.org/abs/2508.13382v1)

- Datarus-R1 (Adaptive Multi-Step Reasoning LLM): introduces a trajectory-centric paradigm for automated data analysis, featuring a Trajectory-Centric Synthetic Data Generation pipeline, a Dual Reward Framework, Adaptive Curriculum Optimization, Memory-Optimized Group Relative Policy Optimization (GRPO), and Dual Reasoning Interfaces.
- This LLM is fine-tuned from Qwen 2.5-14B-Instruct to act as a virtual data analyst and graduate-level problem solver.
- Its process-centric training enables efficient hypothesis refinement, concise revision cycles, and significant token efficiency across diverse STEM challenges.

---

[LOOP: A Plug-and-Play Neuro-Symbolic Framework for Enhancing Planning in Autonomous Systems](http://arxiv.org/abs/2508.13371v1)

- LOOP (Learning Orchestrated and Optimized Planning): introduces a neuro-symbolic planning framework that enables iterative conversation between neural and symbolic components through causal learning mechanisms, including planning-, perception-, validation-, and learning-agents.
- This framework treats planning as an iterative conversation, where neural components generate candidate plans and symbolic components provide validation feedback, with both sides learning from the interaction.
- The framework integrates 13 coordinated neural features and classical planners, achieving high success rates on standard benchmarks by continuously checking and fixing problems.

---

[WebMall - A Multi-Shop Benchmark for Evaluating Web Agents](http://arxiv.org/abs/2508.13024v1)

- Browsergym/AgentLab: introduces WebMall, a multi-shop online shopping benchmark for evaluating LLM-based web agents, with configurable LLM (underlying reasoning engine), Observation Modality (agent's perception input), and Memory Module (agent's information retention) components.
- WebMall features four simulated online shops with heterogeneous product offers and 91 cross-shop tasks, including basic shopping and advanced comparison-shopping scenarios.
- Evaluation shows that accessibility trees and persistent short-term memory are crucial for agent performance, with GPT-4.1 being more efficient for basic tasks and Claude Sonnet 4 better for complex, vague tasks.

---

[Analyzing Information Sharing and Coordination in Multi-Agent Planning](http://arxiv.org/abs/2508.12981v1)

- MAS (Multi-Agent System): introduces a multi-agent, LLM-based system for long-horizon planning tasks, featuring an Orchestrator (agent director), Experts (specialist LLM agents), a Notebook (structured information storage), a Plan Summarizer (planning brief preparer), a Plan Compiler (final plan synthesizer), and a Plan Critic (plan refiner).
- The MAS addresses challenges in complex planning by enabling information sharing via the Notebook to reduce hallucinations and improving coordination through the Orchestrator's dynamic agent selection and self-reflection.
- This system demonstrates that structured information sharing and reflective orchestration are key for multi-agent LLM systems to reliably satisfy complex, interdependent constraints in long-horizon planning.

---

[Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards](http://arxiv.org/abs/2508.12935v1)

- RLFF-ESC (Reinforcement Learning from Future-oriented Feedback for Emotional Support Conversations): introduces an end-to-end framework that directly optimizes LLMs for open-ended emotional support conversations by leveraging a Multi-Agent Dialogue Simulation Module, a Future-oriented Reward Model, a comprehensive Reward Function, and GRPO for policy optimization.
- The framework simulates future dialogue trajectories using LLM-based agents (System, User, Critic) to collect future-oriented rewards, which then train a neural reward model.
- This approach enables LLMs to generate emotionally supportive responses that consider enduring emotional outcomes, moving beyond predefined strategies.

---

[An LLM Agent-Based Complex Semantic Table Annotation Approach](http://arxiv.org/abs/2508.12868v1)

- ReAct-based Agent: introduces an LLM agent-based approach for Semantic Table Annotation (STA) tasks, utilizing an LLM Agent (dynamic tool selection) that integrates a Data Preprocessing Module (corrects errors, expands abbreviations, deduplicates), Column Topic Detection Tool (infers column topics), Knowledge Graph-Based Enhancement Tool (provides background knowledge, generates candidates), Rank Function for CTA Candidates Tool (scores and ranks CTA candidates), Context-Supported CEA Selection Tool (selects final CEA annotation), and Context-Supported CTA Selection Tool (selects final CTA annotation), to dynamically select annotation strategies for Column Type Annotation (CTA) and Cell Entity Annotation (CEA).
- The approach integrates five external tools and tailored prompts within the ReAct framework to address challenges like semantic loss, strict ontological hierarchy, homonyms, spelling errors, and abbreviations in complex tables.
- Utilizing Levenshtein distance for redundancy reduction, the system achieves significant efficiency gains, reducing time costs by 70% and LLM token usage by 60%.

---

[ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction](http://arxiv.org/abs/2508.12685v1)

- ToolACE-MT (Non-Autoregressive Iterative Generation framework): introduces a novel non-autoregressive framework for generating high-quality multi-turn agentic dialogues, which includes Coarse-Grained Initialization (generates dialogue skeleton), Iterative Refinement (enhances complexity and coherence), and Offline Verification (ensures correctness and coherence).
- This framework addresses the limitations of autoregressive multi-agent simulations by generating full conversational trajectories through a three-stage pipeline, improving efficiency and complexity control.
- Its iterative refinement strategy, with complexity injection and reasonability refinement, enables flexible scaling and quality improvement for tool-augmented LLM scenarios.

---

[Semantic Anchoring in Agentic Memory: Leveraging Linguistic Structures for Persistent Conversational Context](http://arxiv.org/abs/2508.12630v1)

- Semantic Anchoring: introduces a hybrid agentic memory architecture that enriches vector-based storage with explicit linguistic cues to improve factual recall and discourse coherence in long-term conversational contexts.
- This approach combines dependency parsing, discourse relation tagging, and coreference resolution to create structured memory entries, enabling multi-granular matching for robust and interpretable retrieval.
- The framework significantly outperforms RAG baselines in factual recall and discourse coherence, demonstrating improved memory persistence for LLMs.

---

[Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement](http://arxiv.org/abs/2508.12555v1)

- Visual Analytics System: introduces a visual analytics system for deeper understanding and enhancement of LLM coding agents' iterative problem-solving, with Tree View, Code View, Projection View, Package View, Code-Level Analysis, Process-Level Analysis, and LLM-Level Analysis.
- The system supports comparative analysis across code, process, and LLM levels, enabling ML scientists to debug agents and refine prompt engineering.
- It provides actionable insights into LLM-driven agentic coding by revealing agent behaviors and identifying improvement opportunities through case studies on Kaggle competitions.

---

[OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning](http://arxiv.org/abs/2508.12551v1)

- OS-R1 (Agentic Operating System Kernel Tuning with Reinforcement Learning): introduces an agentic Linux kernel tuning framework that leverages an LLM-based Agent, Knowledge Tool, Kernel Space, Reward Function, Dataset, LLM As A Judge, GRPO, and Config Generation to automate kernel configuration optimization through rule-based reinforcement learning.
- The framework utilizes a two-phase training pipeline, including a Warm-up Phase for reasoning standardization and an Exploration Phase for system performance awareness, to achieve efficient and accurate kernel configuration modifications.
- OS-R1 significantly outperforms existing baseline methods, achieving up to 5.6% performance improvement, maintaining high data efficiency, and demonstrating strong generalization across diverse real-world applications.

---

[Systematic Analysis of MCP Security](http://arxiv.org/abs/2508.12538v1)

- MCPLIB (MCP Attack Library): introduces a unified, plugin-based attack simulation framework for evaluating Model Context Protocol (MCP) vulnerabilities, utilizing malicious tools, a Resource Layer, a Prompt template, and simulated Malicious MCP Server and Host attack entrances to categorize and implement 31 distinct attack methods.
- The framework conducts quantitative analysis of attack efficacy, revealing key insights into MCP vulnerabilities like LLM blind reliance on tool descriptions and shared context issues.
- This work provides a foundational framework for secure evolution of MCP ecosystems by offering a comprehensive attack taxonomy and empirical vulnerability analysis.

---

["DIVE" into Hydrogen Storage Materials Discovery with AI Agents](http://arxiv.org/abs/2508.13251v1)

- DIVE (Descriptive Interpretation of Visual Expression): introduces a multi-agent workflow for automated hydrogen storage materials discovery, integrating a PDF Converter, Workflow Orchestrator, Image Classifier, Multimodal LLMs for data extraction, Prompt Designer, Descriptive Embedder, Embedding Model, Scoring Module, and the DigHyd Agent with its associated Database, Machine Learning Model, and Data Checking System.
- The DIVE workflow systematically reads and organizes experimental data from graphical elements in scientific literature by transforming visual information into descriptive text, significantly improving data extraction accuracy and coverage.
- The DigHyd agent, built upon the DIVE-curated Digital Hydrogen Platform database, leverages LLMs and machine learning for natural language interaction, materials design, prediction, and iterative optimization of novel hydrogen storage compositions.

---


[CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support](http://arxiv.org/abs/2508.13256v1)

- CardAIc-Agents: introduces a multimodal framework with a CardiacRAG Agent (plan generation/refinement) for knowledge-based plan formulation and a CardiacExperts Agent (plan execution/tool orchestration) for autonomous task execution, supported by Multidisciplinary Discussion (team reviews cases) and Visual Review Panels (clinician validation support).
- This framework enhances LLM capabilities by integrating specialized tools and an updatable cardiac knowledge base, enabling adaptive support for diverse cardiac tasks.
- The system dynamically refines plans based on emerging evidence and stratifies task complexity, outperforming general medical VLMs and state-of-the-art medical agents.

---

[From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery](http://arxiv.org/abs/2508.14111v1)

- Agentic Science: introduces a comprehensive framework for autonomous scientific discovery, unifying foundational capabilities (Planning Engines, Tool Use, Memory Mechanism, Collaboration, Optimization and Evolution) and core processes (Observation and Hypothesis Generation, Experimental Planning and Execution, Data and Result Analysis, Synthesis, Validation and Evolution) to enable AI systems to act as autonomous research partners.
- This framework unifies process-oriented, autonomy-oriented, and mechanism-oriented perspectives, tracing the evolution of AI for Science from specialized computational tools to autonomous research partners capable of independent scientific inquiry.
- The paper provides a domain-oriented review of agentic systems across life sciences, chemistry, materials, and physics, highlighting key challenges and future opportunities for advancing AI-driven research.

---

[AI Agents for Photonic Integrated Circuit Design Automation](http://arxiv.org/abs/2508.14123v1)

- PhIDO (Photonics Intelligent Design and Optimization): introduces a multi-agent framework that converts natural language photonic integrated circuit (PIC) design requests into layout mask files, comprising an Interpreter (extracts intent, generates template), a Designer (selects components, configures parameters), a Layout (places, routes, checks design), and a Circuit Verification (simulates, validates circuit) module.
- The framework's Interpreter and Designer are LLM-based agents that leverage retrieval-augmented generation (RAG) and curated domain-specific knowledge, while the Layout and Circuit Verification stages are algorithmic modules.
- A key aspect of PhIDO is its domain-specific language (DSL), which serves as an intermediate representation to capture design intent and bridge natural language specifications with formal PIC representations.

---

[Scalable Fairness Shaping with LLM-Guided Multi-Agent Reinforcement Learning for Peer-to-Peer Electricity Markets](http://arxiv.org/abs/2508.18610v1)

- FairMarket-RL (Fairness-Aware Multiagent Reinforcement Learning): introduces a multi-agent reinforcement learning framework for peer-to-peer electricity markets, integrating an LLM critic to shape bidding policies within a continuous double auction by providing real-time fairness feedback.
- The framework incorporates three fairness metrics—Fairness-to-Grid (FTG), Fairness-Between-Sellers (FBS), and Fairness-of-Pricing (FPP)—into the reward function to balance economic incentives with community-level equity.
- FairMarket-RL utilizes Proximal Policy Optimization (PPO) for agent policy learning in a partially observable environment, demonstrating scalability and robust performance across various simulated and real-world community settings.

---

#### 17th August 2025

[Autonomous Oil Spill Response Through Liquid Neural Trajectory Modeling and Coordinated Marine Robotics](http://arxiv.org/abs/2508.12456v1)

- OilSpill: introduces an integrated framework combining Liquid Time-Constant Neural Networks (LTCNs) with multi-agent robotic systems, enabling real-time oil spill trajectory prediction and autonomous response coordination.
- The framework includes an Oil Spill Boundary Algorithm (LTC) for predictions, a Distributed Data Acquisition Layer and Enhanced Feature Extraction Pipeline for data processing, a MOOSDB (MOOS Database) for information sharing, a PathAssign (Path Assignment Module) for trajectory optimization, and an Autonomous Vehicle Fleet for mission execution.
- This scalable architecture supports dynamic fleet reconfiguration and integrates a User Interface for monitoring, demonstrating superior spatial accuracy and temporal consistency over traditional LSTM models.

---

[LumiMAS: A Comprehensive Framework for Real-Time Monitoring and Enhanced Observability in Multi-Agent Systems](http://arxiv.org/abs/2508.12412v1)

- LumiMAS: introduces a novel framework for real-time monitoring and enhanced observability in multi-agent systems, comprising a Monitoring and Logging Layer (monitors, logs MAS activity), an Anomaly Detection Layer (detects real-time anomalies) with EPI Detection (detects from execution features), Semantic Detection (detects from LLM outputs), and Combined Latent-Space Detection (combines EPI, semantic), and an Anomaly Explanation Layer (classifies, explains anomalies) featuring an LMA Classification Agent (classifies anomaly type) and an RCA LMA (locates failure source).
- This framework comprehensively captures system-level features and semantic nuances of inter-agent interactions, enabling real-time failure detection with minimal resource consumption.
- It supports the identification of diverse system failures, including adversarial attacks, bias, and hallucinations, improving model alignment with user needs.

---

[LinkAnchor: An Autonomous LLM-Based Agent for Issue-to-Commit Link Recovery](http://arxiv.org/abs/2508.12232v1)

- LinkAnchor: introduces an autonomous LLM-based agent for issue-to-commit link recovery, featuring an LLM (Large Language Model) interacting with an LLM-Middleware that manages a Data Extractor, which in turn utilizes Issue Extractor, Codebase Extractor, and VCS Extractor to access data from Issue Tracking Platform and Version Control, enabling on-demand contextual data retrieval.
- This framework addresses limitations of traditional Issue-to-Commit Link Recovery (ILR) methods by providing the LLM with lazy, on-demand access to rich project context, including commit history, issue threads, and codebase, without exceeding token limits.
- LinkAnchor formulates issue-to-commit link recovery as a search problem, eliminating the need for exhaustive pairwise issue-commit assessments and requiring no task-specific training due to its pre-trained LLM foundation.

---

[A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges](http://arxiv.org/abs/2508.05668v2)

- Search Agent: introduces an LLM-based system for deep, dynamic, and autonomous information seeking, featuring User Intent, an Agent with Dynamic Planning, Private Memory, Search on Different Sources, and a Generated Answer, supported by various Search Structures, Optimization Methods, Internal and External Applications, and Evaluation Components.
- The framework details search structures including Parallel, Sequential, and Hybrid, alongside optimization methods like Tuning-Free (Single Agent, Multi-Agent, Test-Time Scaling) and Tuning (Imitation Learning, Reinforcement Learning, Supervised Fine-Tuning).
- The paper further categorizes applications into internal agent enhancements (Tool Use, Memory, Reasoning) and external domains (AI Assistant, E-commerce, Finance, Code, Medicine, Biology, Chemistry, Teaching/Research), evaluated through diverse Datasets and Judges (Rule-Based, LLM-as-a-Judge, Agent-as-a-Judge).

---

[STANDARDIZATION OF NEUROMUSCULAR REFLEX ANALYSIS ROLE OF FINE-TUNED VISION-LANGUAGE MODEL CONSORTIUM AND OPENAI GPT-OSS REASONING LLM ENABLED DECISION SUPPORT SYSTEM](http://arxiv.org/abs/2508.12473v1)

- NeuroLens platform: introduces an AI-assisted neuromuscular reflex analysis system integrating a Fine-Tuned VLM Consortium and an OpenAI GPT-OSS Reasoning LLM for automated H-reflex waveform interpretation and diagnosis.
- The platform leverages multiple fine-tuned VLMs to extract electrophysiological features and predict neuromuscular states from EMG images and contextual metadata.
- A reasoning LLM refines aggregated VLM outputs using a consensus-based method, providing robust, transparent, and explainable decision support for clinicians and sports scientists.

---

[GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?](http://arxiv.org/abs/2508.12472v1)

- GALA (Graph-Augmented Large Language Model Agentic Workflow): introduces a novel multi-modal framework for Root Cause Analysis (RCA) in microservice systems, combining statistical causal inference with LLM-driven iterative reasoning, featuring Initial Hypothesis Generation, Pod-Centric Diagnostic Synthesis, LLM Agentic Reasoning and Re-ranking (with Re-ranking and Deep Dive Agents), Final Output Preparation (with a Remediation Agent), and evaluated using SURE-Score.
- The framework processes heterogeneous telemetry data (metrics, logs, traces) through a structured, iterative workflow to generate accurate root cause identifications and human-interpretable remediation guidance.
- GALA significantly improves RCA performance by bridging the gap between automated failure diagnosis and practical incident resolution, demonstrating superior accuracy and incident summarization quality.

---

[GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding](http://arxiv.org/abs/2508.12379v1)

- GraphCogent: introduces a collaborative agent framework inspired by human working memory, featuring a Sensory Module (standardizes graph text representations), a Buffer Module (integrates and indexes graph data), and an Execution Module (combines tool calling and model generation) to overcome LLMs' working memory constraints in complex graph understanding.
- The framework addresses limitations in processing diverse graph text representations, handling large-scale graphs, and improving code execution reliability by decomposing graph reasoning into specialized cognitive processes.
- It utilizes a Reasoning Agent for in-toolset tasks and a Model Agent for out-toolset tasks, enhancing accuracy and efficiency in real-world graph reasoning.

---

[Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications](http://arxiv.org/abs/2508.12358v1)

- Experiment Workflow: introduces a framework for evaluating LLMs' code verification against natural language specifications, featuring task specification, correct code, LLM code review (with conformance check, justification, and fix attempt), and JSON output.
- The workflow reveals that increasing prompt complexity, such as requiring explanations and suggested corrections, counterintuitively leads to higher rates of LLM misjudgment and false negatives.
- To mitigate these issues, the paper proposes Two-Phase Reflective Prompt and Behavioral Comparison Prompt strategies, which improve LLM performance by redirecting attention to essential functional differences.

---

[MCPSECBENCH: A Systematic Security Benchmark and Playground for Testing Model Context Protocols](http://arxiv.org/abs/2508.13220v1)

- MCPSECBENCH (A Systematic Security Benchmark and Playground for Testing Model Context Protocols): introduces a comprehensive security benchmark and playground, with MCP Hosts (AI application orchestrator), MCP Clients (server communication intermediaries), MCP Servers (external resource gateways), Prompt Dataset (attack scenario prompts), and Transport-layer Attack Modules (network threat simulation), designed to systematically evaluate security risks across the Model Context Protocol ecosystem.
- The framework identifies 17 attack types across four primary attack surfaces—user interaction, client, transport, and server—and provides a modular and extensible platform for rigorous security testing of LLM-powered agent systems.
- Experimental results using the benchmark reveal widespread security weaknesses, with over 85% of identified attacks successfully compromising at least one MCP platform, highlighting the urgent need for standardized security evaluation and defense.

---

[Passive Hack-Back Strategies for Cyber Attribution: Covert Vectors in Denied Environments](http://arxiv.org/abs/2508.16637v1)

- Passive Hack-Back Strategies: introduces a framework for covert cyber attribution and intelligence collection in denied environments, utilizing components like tracking beacons, honeytokens, environment fingerprinting, and AI-enhanced agents.
- This approach emphasizes passive, non-escalatory methods to gather evidence and attribute attacks reliably, while adhering to legal and ethical constraints.
- The framework integrates AI for dynamic payload generation, counter-deception, and covert communication, alongside exploring future quantum technologies for enhanced resilience and intelligence.

---

[You Don't Know Until You Click: Automated GUI Testing for Production-Ready Software Evaluation](https://github.com/tanghaom/AppEvalPilot)

- RealDevWorld framework: introduces "You Don't Know Until You Click: Automated GUI Testing for Production-Ready Software Evaluation", with RealDevBench (diverse benchmark) and AppEvalPilot (agent-as-a-judge system), where the paper presents a novel evaluation framework for automated end-to-end assessment of LLMs' ability to generate production-ready repositories from scratch.
- The framework features RealDevBench, a collection of 194 open-ended software engineering tasks with multimodal elements, and AppEvalPilot, an agent-based system that simulates GUI interactions for holistic software assessment.
- AppEvalPilot further includes Test Case Generation (automates test creation), Test Case Execution (simulates user interaction) with a defined Action Space (core commands), and Test Result Evaluation (compares outcomes) to provide fine-grained, task-specific diagnostic feedback.

---

[You Don't Know Until You Click: Automated GUI Testing for Production-Ready Software Evaluation](https://github.com/tanghaom/AppEvalPilot)

- RealDevWorld: introduces a novel evaluation framework for automated end-to-end assessment of LLMs' ability to generate production-ready repositories from scratch, with RealDevBench (a diverse collection of 194 open-ended software engineering tasks) and AppEvalPilot (a new agent-as-a-judge evaluation system that simulates realistic, GUI-based user interactions).
- AppEvalPilot autonomously generates test cases, executes them by interacting with software applications through their GUIs using a structured action space (Open, Run, Tell, Stop), and evaluates results by comparing actual outcomes against expected criteria.
- The framework delivers fine-grained, task-specific diagnostic feedback, supports nuanced evaluation beyond simple success/failure judgments, and achieves high accuracy and correlation with expert human assessments while significantly reducing manual review reliance.

---

#### 16th August 2025

[AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](http://arxiv.org/abs/2508.11995v1)

- AgentCDM (Agent Collaborative Decision-Making): introduces a structured framework for enhancing collaborative decision-making in LLM-based multi-agent systems, employing a two-stage training paradigm inspired by the Analysis of Competing Hypotheses (ACH) protocol.
- The framework systematically mitigates cognitive biases by guiding the Decision Agent through structured hypothesis evaluation and construction, moving beyond passive answer selection.
- Its two-stage training paradigm, consisting of explicit ACH-inspired scaffolding followed by progressive removal, enables agents to internalize and generalize robust reasoning processes for high-quality, collectively informed decisions.

---

[A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond](http://arxiv.org/abs/2508.11957v1)

- AI Agent Architecture: introduces a comprehensive review of AI agents, examining their architectural principles, foundational components, and emergent paradigms, including memory, tools, planning, and action, to guide future research toward robust, adaptable, and trustworthy autonomous intelligence.
- The review synthesizes insights from cognitive science-inspired models, hierarchical reinforcement learning frameworks, and LLM-based reasoning, while also addressing ethical, safety, and interpretability concerns.
- It highlights major breakthroughs, persistent challenges, and promising research directions across diverse applications such as healthcare, business, education, science, and urban planning.

---

[INTEGRATING SYMBOLIC RL PLANNING INTO A BDI-BASED AUTONOMOUS UAV FRAMEWORK: SYSTEM INTEGRATION AND SIL VALIDATION](http://arxiv.org/abs/2508.11890v1)

- AMAD-SRL (Autonomous Mission Agents for Drones - Symbolic Reinforcement Learning): introduces an extended cognitive multi-agent architecture, integrating symbolic reinforcement learning for dynamic mission planning and execution, featuring core components such as a Knowledge Store, Context Reasoner, Autonomous Task Coordinator, and a newly integrated Dynamic Planner and AI Service.
- The framework combines BDI architecture's structured reasoning with SRL's adaptive decision-making, using Planning Domain Definition Language (PDDL) for domain knowledge representation.
- Validated in a Software-in-the-Loop environment, the system demonstrated seamless transitions between BDI-driven and SRL-driven planning, improving mission efficiency.

---

[Saliency-Based Attention Shifting: A Framework for Improving Driver Situational Awareness of Out-of-Label Hazards](http://arxiv.org/abs/2508.11887v1)

- SBAS (Saliency-Based Attention Shifting): introduces a conceptual framework that integrates real-time gaze tracking, context-aware saliency analysis, and coordinated visual and auditory cues to enhance driver attention during scenarios with unlabeled hazards.
- The framework leverages a fusion model to generate saliency maps based on identified hazards and driver gaze, then plans a gaze trajectory to guide attention.
- It employs a Head-Up Display for visual cues and audio alerts to redirect the driver's focus, aiming to improve situational awareness and reduce reaction time during autonomous vehicle takeovers.

---

[Research Challenges and Progress in the End-to-End V2X Cooperative Autonomous Driving Competition](http://arxiv.org/abs/2507.21610v2)

- UniV2X (Unified V2X Framework): introduces the End-to-End Autonomous Driving through V2X Cooperation Challenge, a benchmark for evaluating cooperative perception and planning systems under V2X communication constraints, leveraging its unified end-to-end pipeline.
- The challenge, built on the V2X-Seq-SPD dataset, evaluates cooperative 3D detection, multi-object tracking, and end-to-end sensor-to-planning pipelines, with top solutions like SparseCoop and MAP demonstrating advancements in multi-agent fusion and planning.
- This initiative addresses practical constraints like limited communication bandwidth and heterogeneous sensors, fostering research into scalable and reliable V2X-cooperative autonomous driving systems.

---

[Invitation Is All You Need! Promptware Attacks Against LLM-Powered Assistants in Production Are Practical and Dangerous](http://arxiv.org/abs/2508.12175v1)

- TARA (Threat Analysis and Risk Assessment): introduces a novel framework to assess Promptware risks for LLM-powered assistant users, encompassing asset and adversary identification, threat analysis, risk assessment, and mitigation strategies.
- The framework adapts the ISO/SAE 21434 standard to evaluate cybersecurity risks, demonstrating 14 attack scenarios against Gemini applications, revealing 73% pose high-critical risk.
- The paper highlights Promptware's potential for on-device lateral movement and physical consequences, emphasizing the need for immediate mitigations to reduce risk.

---

[CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMS](http://arxiv.org/abs/2508.11944v1)

- CHBench (Cognitive Hierarchy Benchmark): introduces a novel evaluation framework for assessing LLMs' strategic reasoning capability, comprising a Dataset Collection phase (gathering LLM behavioral data under various reasoning mechanisms), an Optimization phase (fitting Cognitive Hierarchy Models to data using MLE), and an Evaluation phase (predicting LLM strategic reasoning levels and strategies).
- The framework utilizes Normal-form Games as the environment and incorporates Reasoning Mechanisms like Baseline, Chat, Memory, and Chat & Memory to analyze their impact on LLM strategic behavior.
- CHBench leverages Level-K and Poisson Cognitive Hierarchy Models to quantify LLMs' strategic depth and consistency, providing insights into how communication and historical information influence their game-playing abilities.

---

[CAMF: Collaborative Adversarial Multi-agent Framework for Machine Generated Text Detection](http://arxiv.org/abs/2508.11933v1)

- CAMF (Collaborative Adversarial Multi-agent Framework): introduces a novel architecture for machine-generated text detection, with Linguistic Stylistics Analysis Agent (analyzes writing style), Semantic Coherence Evaluation Agent (evaluates meaning continuity), Logical Reasoning Assessment Agent (assesses logical structure), Adversarial Argument Generation Agent (generates counter-arguments), Consistency Refinement Agent (refines analysis), and Synthesis Judge Agent (aggregates judgment), enabling deep analysis of subtle textual incongruities.
- This framework employs specialized LLM-based agents in a three-phase process: Multi-dimensional Linguistic Feature Extraction, Adversarial Consistency Probing, and Synthesized Judgment Aggregation, to systematically identify non-human origin text.
- The structured collaborative-adversarial design enhances robustness against sophisticated machine-generated text by rigorously verifying consistency across linguistic dimensions.

---

[CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures](http://arxiv.org/abs/2508.11915v1)

- CORE (Conversational Robustness Evaluation Score): introduces a metric to quantify linguistic diversity in multi-agent LLM interactions, integrating an initial prompt, LLM 1, LLM 2, LLM Pair, Tokenized Conversation, and CORE Evaluation components (Cluster Entropy, Repetition, Semantic Stagnation) to yield an Interaction Quality score.
- The framework simulates pairwise LLM dialogues under competitive, cooperative, and neutral game-theoretic conditions, analyzing language patterns using statistical laws like Zipf's and Heaps' Laws.
- This metric serves as a diagnostic tool for measuring linguistic robustness and identifying mode collapse in multi-agent LLM systems without relying on external task rewards.

---

[SIMINTERVIEW: TRANSFORMING BUSINESS EDUCATION THROUGH LARGE LANGUAGE MODEL-BASED SIMULATED MULTILINGUAL INTERVIEW TRAINING SYSTEM](http://arxiv.org/abs/2508.11873v1)

- SimInterview: introduces a multilingual interview training system that fuses LLM reasoning, low-latency speech processing, and virtual photorealistic avatar rendering to create realistic, conversational interview simulations, with Module 1 - Document Indexing and Vector Embedding (processes documents into embeddings), Module 2 - Interviewee Platform (manages candidate interaction), and Module 3 - Simulated Interviewer (generates interviewer responses).
- The system delivers real-time, personalized practice sessions mirroring hiring scenarios in English and Japanese, leveraging retrieval-augmented personalization to match resume content with job requirements and generate targeted, culturally sensitive questions.
- SimInterview integrates various AI components including LLMs (OpenAI 03, Llama 4 Maverick, Gemma 3), speech-to-text (Whisper), text-to-speech (GPT-SOVITS), diffusion-based talking heads (Ditto), and a vector database (ChromaDB) within a modular, privacy-preserving architecture.

---

[LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://github.com/ninglab/LARC)

- LARC (LLM-based Agentic framework for Retrosynthesis planning under Constraints): introduces an LLM-based agentic framework for constrained retrosynthesis planning, integrating an EVALUATOR (LLM-based judge agent), a TOOLBOX (external chemistry tools), and a SYNTHESIZER (explores, constructs synthetic routes) to generate synthetic routes satisfying user-specified constraints.
- The framework incorporates agentic constraint evaluation directly into the retrosynthesis planning process, using feedback grounded in tool-based reasoning to dynamically guide and constrain route generation.
- LARC achieves a 72.9% success rate on 48 constrained retrosynthesis planning tasks, outperforming LLM baselines and approaching human expert-level success in less time.

---

[EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](http://arxiv.org/abs/2508.11850v1)

- EvoCut (Evolution-Guided Language Models for Integer Programs): introduces an automated framework for generating and refining acceleration cuts for Integer Programs, combining LLMs with an evolutionary search process that includes Data Pre-processing, Population Initialization, and Evolution phases, utilizing Initializer, Crossover, and Mutation Agents, a Verifier, Evaluator, Elitism, Selection, Feedback, and Population.
- The framework empirically evaluates generated cuts for optimal solution preservation and their ability to cut off fractional solutions, quantifying utility by measuring optimality gap reduction.
- This approach significantly improves solver performance, reducing optimality gap by 17-57% and achieving up to 4x faster solutions without human expert input, demonstrating generalization to unseen instances.

---

[AI-Augmented CI/CD Pipelines: From Code Commit to Production with Autonomous Decisions](http://arxiv.org/abs/2508.11867v1)

- AI-Augmented CI/CD Pipelines: introduces a framework for embedding LLMs and autonomous agents into CI/CD, including AI Test-Triage Agent (detects flaky tests, prioritizes), Security Agent (summarizes vulnerabilities, enforces gates), Observability Agent (monitors canary health, performance), Feature-Flag Agent (dynamically adjusts feature flags), Postmortem Agent (generates incident reports, PRs), Policy Engine (enforces constraints, evaluates decisions), and Release Orchestrator (coordinates deployments, monitors).
- This framework aims to reduce lead time, mean time to recovery, and change failure rate by automating critical decision points in software delivery pipelines.
- The paper details a trust-tier framework for staged autonomy, a decision taxonomy with policy-as-code guardrails, and an evaluation methodology using DORA metrics and AI-specific indicators.

---


[The Next Question After Turing's Question: Introducing the GROW-AI Test](http://arxiv.org/abs/2508.16277v1)

- GROW-AI (Growth and Realization of Autonomous Wisdom) Test: introduces a multi-game framework for assessing AI entities' "growth" towards maturity, including six primary criteria, specific games, four arenas per game, an AI Journal, human evaluators, a prior expert method, AHP, a Grow Up Index, and maturity thresholds.
- The framework evaluates AI entities (robots, software agents, LLMs) across dimensions like physical/intellectual growth, environmental control, algorithmic efficiency, emotional intelligence, self-monitoring, and autonomous wisdom, using complex, real-life scenarios.
- The AI Journal records all entity actions and decisions, ensuring traceability and replicability, while the Grow Up Index provides a comparable assessment of an AI entity's evolutionary path beyond simple imitation, addressing limitations of the Turing Test.

---

[LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](http://arxiv.org/abs/2508.11860v1)

- LARC (LLM-based Agentic framework for Retrosynthesis planning under Constraints): introduces an agentic framework for constrained retrosynthesis planning, with Prompt (user input), EVALUATOR (agent-as-a-judge), Evaluation Planning (generates instructions), Reaction Evaluation (evaluates reactions), TOOLBOX (external chemistry tools), Carcinogen Predictor (predicts carcinogenicity), Pyrophoricity Predictor (predicts pyrophoricity), Molecule Identifier (identifies hazardous molecules), AIExpert (AI chemistry expert), Similarity (molecule similarity), SYNTHESIZER (explores synthetic routes), Simulation (MCTS route planning), Selection (A* candidate selection), Expansion (reaction prediction), and Synthetic Route (final output), where LARC leverages LLMs and specialized chemistry tools to dynamically guide and constrain the generation of synthetic routes for target molecules.
- The framework integrates an LLM-based Agent-as-a-Judge (EVALUATOR) to provide tool-based feedback on constraint satisfaction, which is then used by the SYNTHESIZER to explore and construct chemically plausible and constraint-compliant synthetic pathways.
- LARC achieves a 72.9% success rate on constrained retrosynthesis tasks, outperforming LLM baselines and approaching human expert-level performance in significantly less time, demonstrating its potential as a co-scientist for chemical discovery.

---

#### 15th August 2025

[Using Natural Language for Human-Robot Collaboration in the Real World](http://arxiv.org/abs/2508.11759v1)

- Collaborative System: introduces a human-robot collaboration framework with a Cognitive Agent (orchestrates system/learns/reasons), Situational Knowledge (stores world state/experiences), an LLM (translates language/provides knowledge), a Physical Robot (provides perception/action), and a Human Director (provides instructions/guidance), designed to enable robots to understand natural language for real-world tasks.
- The system leverages the LLM for language understanding and common-sense knowledge, while the cognitive agent handles reasoning, integration, and incremental learning from human interaction and experience.
- This architecture aims to overcome challenges in grounding referring expressions, performing complex tasks, and understanding free-form language, moving towards more robust and intuitive human-robot collaboration.

---

[Tapas are free! Training-Free Adaptation of Programmatic Agents via LLM-Guided Program Synthesis in Dynamic Environments](http://arxiv.org/abs/2508.11425v1)

- TAPA (Training-free Adaptation of Programmatic Agents): introduces a novel framework that positions LLMs as intelligent moderators of the symbolic action space, enabling training-free adaptation of programmatic agents in dynamic environments, with LLM (moderates action space), RAG System (stores expert knowledge), Logical Primitives (high-level strategic intents), Symbolic Programs (concrete action implementations), Decision Agent (selects logical primitives), Simulation Environment (generates diverse scenarios), Provenance Chain (records execution traces), and Shadow Simulation (validates candidate programs).
- The framework synthesizes and adapts modular programs for individual high-level actions (logical primitives) by decoupling strategic intent from execution.
- This approach enables real-time adaptation without costly retraining, ensuring performance and reliability in safety-critical domains like cyber defense and swarm intelligence.

---

[AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager](http://arxiv.org/abs/2508.11416v1)

- AIM-Bench: introduces a novel benchmark designed to evaluate LLM agents' decision-making behavior in uncertain supply chain management scenarios, featuring diverse environments, context engineering modules (background, memory, structured output), and an evaluator utilizing both behavioral and real-world benefit metrics.
- This benchmark assesses LLM agents' inventory replenishment capabilities, identifies human-like decision biases (e.g., mean anchoring, bullwhip effect), and investigates mitigation strategies such as cognitive reflection and information sharing.
- The study reveals varying degrees of decision bias across different LLMs, underscoring the importance of considering potential biases and implementing strategic model selection for deploying LLMs in critical inventory management.

---

[Towards Embodied Conversational Agents for Reducing Oral Exam Anxiety in Extended Reality](http://arxiv.org/abs/2508.11412v1)

- The ECA-based Coach System: introduces a framework for reducing oral exam anxiety by integrating photorealistic Embodied Conversational Agents (ECAs) with real-time LLMs in Extended Reality (XR) environments to provide psychologically safe, adaptive, and repeatable oral examination rehearsals.
- This system leverages a Conversational Engine with LLMs, Speech-to-Text, and Text-to-Speech for fluid dialogue, augmented by Domain Knowledge Integration via RAG for factual correctness.
- It further incorporates a Learner Modeling and Feedback Module to adapt agent behavior and provide personalized feedback, all rendered within an Extended Reality Interface using Unreal Engine for immersive experiences.

---

[FACET: Teacher-Centred LLM-Based Multi-Agent Systems- Towards Personalized Educational Worksheets](http://arxiv.org/abs/2508.11401v1)

- FACET (Framework for Agent-based Classroom Enhancement for Teacher): introduces a teacher-facing, LLM-based multi-agent system for generating individualized classroom materials, with Learner Agents (simulate student behavior), a Teacher Agent (adapts instructional content), and an Evaluator Agent (provides quality feedback), designed to integrate cognitive and motivational dimensions of learner profiles for personalized educational worksheets.
- The system's modular design supports experimentation and refinement, enabling scalable, context-aware personalization in heterogeneous classroom settings.
- Evaluations confirm the framework's stability and alignment between generated materials and diverse learner profiles, addressing a critical gap in AI-driven educational personalization.

---

[Trustworthy AI Psychotherapy: Multi-Agent LLM Workflow for Counseling and Explainable Mental Disorder Diagnosis](http://arxiv.org/abs/2508.11398v1)

- DSM5AgentFlow: introduces an LLM-based multi-agent workflow for autonomously generating DSM-5 Level-1 diagnostic questionnaires by simulating therapist-client dialogues, with all its components: Therapist Agent (administers DSM-5 questionnaire), Client Agent (simulates client profile), Diagnostician Agent (generates diagnosis, rationale), Conversation Generation (simulates therapist-client dialogue), Conversation Transcript (records dialogue history), Retriever (fetches relevant DSM-5 passages), DSM-5 Passages (authoritative clinical criteria), Diagnosis & Rationale (predicted disorder, step-by-step explanation), and LLM (powers all agents).
- This framework delivers transparent, step-by-step disorder predictions and explainable, trustworthy results by grounding diagnoses in clinical criteria and conversational evidence.
- The approach enhances interpretability and trustworthiness of LLM-driven assessments, ensuring compliance with ethical and legal standards in mental health care.

---

[SGSimEval: A Comprehensive Multifaceted and Similarity-Enhanced Benchmark for Automatic Survey Generation Systems](http://arxiv.org/abs/2508.11310v1)

- SGSimEval (Survey Generation with Similarity-Enhanced Evaluation): introduces a comprehensive benchmark for automatic survey generation systems, integrating data collection, topic mining, decomposition, embedding generation, and a multifaceted evaluation framework.
- This framework assesses outline, content, and reference quality using traditional metrics, LLM-based scoring, and two similarity-enhanced approaches: Human-as-Perfect and Balanced Similarity Weighting.
- The benchmark, built on 80 highly-cited survey papers, reveals ASG systems' strengths in outline generation but highlights areas for improvement in content and reference quality.

---

[AlphaAgents: Large Language Model based Multi-Agents for Equity Portfolio Constructions](http://arxiv.org/abs/2508.11152v1)

- AlphaAgents: introduces a modular multi-agent debate framework for equity portfolio construction, featuring specialized Fundamental, Sentiment, and Valuation Agents, coordinated by a Groupchat Agent, utilizing RAG, Summarization, Valuation, and Fundamental Report Pull Tools, and employing Multi-agent Collaboration and Debate Mechanisms, all built on the AutoGen Framework.
- This framework enhances equity analysis and stock selection by enabling LLM-based agents to cooperatively analyze diverse financial data, mitigate cognitive biases, and resolve conflicting analyses through a structured debate process.
- The system provides transparent reasoning trails through discussion logs and integrates explicit risk tolerance profiles, representing a foundational step towards scalable and transparent agentic investment systems.

---

[AI Agentic Programming: A Survey of Techniques, Challenges, and Opportunities](http://arxiv.org/abs/2508.11126v1)

- AI Agentic Programming: introduces a paradigm where LLMs autonomously plan, execute, and refine software development tasks by integrating with external tools and managing context iteratively.
- This approach enables LLM-based agents to decompose complex goals, coordinate multi-step processes, and adapt behavior based on intermediate feedback from the development environment.
- The survey highlights key challenges including context handling, persistent memory, safety, toolchain integration, and the need for robust evaluation benchmarks for these intelligent coding agents.

---

[The Roots of International Perceptions: Simulating US Attitude Changes Towards China with LLM Agents](http://arxiv.org/abs/2508.08837v2)

- Framework for Macro-Scale Attitudes Evolution: introduces a simulation framework to model US citizens' attitude changes towards China over 20 years, integrating real-world data for agent profile creation, news distribution, and a cognitive reflection mechanism for opinion updates.
- The framework initializes thousands of LLM agents with diverse profiles from social surveys and media, exposing them to over 100,000 news articles annually, and enabling them to update their views through a cognitive dissonance-based reflection process.
- It also incorporates intervention mechanisms, including a Debiasing Agent for objective news exposure and a Devil's Advocate Agent for alternative perspectives, to explore ways of alleviating negative opinion trends.

---

[TRAINING-FREE MULTIMODAL LARGE LANGUAGE MODEL ORCHESTRATION](http://arxiv.org/abs/2508.10016v2)

- MLLM Orchestration (Multimodal Large Language Model Orchestration): introduces a training-free framework for interactive multimodal AI systems, featuring a Controller LLM (orchestrates tasks, routes to specialized models), Cross-modal Memory (integrates multimodal context), and Parallel Text-to-Speech (TTS) (generates speech output).
- The framework leverages LLMs' reasoning capabilities to coordinate specialized models through explicit workflows, enabling natural multimodal interactions while maintaining modularity and interpretability.
- This approach achieves comprehensive multimodal capabilities without additional training, demonstrating performance improvements and reduced latency compared to traditional jointly-trained methods.

---

[Rethinking Autonomy: Preventing Failures in AI-Driven Software Engineering](http://arxiv.org/abs/2508.11824v1)

- SAFE-AI Framework (Safety, Auditability, Feedback, and Explainability): introduces a holistic approach to prevent failures in AI-driven software engineering, integrating guardrails, sandboxing, runtime verification, risk-aware logging, human-in-the-loop systems, and explainable AI techniques.
- The framework addresses challenges like insecure code generation, hallucinated outputs, and lack of transparency by emphasizing continuous learning loops and verifiable records of AI actions.
- It also proposes a taxonomy of AI behaviors to guide risk assessment and oversight, aligning with emerging regulations for responsible AI development.

---

[Intelligent Edge Resource Provisioning for Scalable Digital Twins of Autonomous Vehicles](http://arxiv.org/abs/2508.11574v1)

- Intelligent Edge Resource Provisioning Framework: introduces a distributed computing architecture integrating Digital Twins (DTs) and Mobile Edge Computing (MEC) within a software-defined vehicular networking framework, featuring a Two-Tier Architecture, Collaborative Task Computation Model, and a DRL Algorithm-trained Autonomous Agent for intelligent, low-latency transportation services.
- The framework significantly enhances DT operations by reducing synchronization errors to 5% and achieving 99.5% edge resource utilization, evaluated using a connected autonomous vehicle (CAV) traffic simulation.
- This approach addresses key challenges in synchronization latency and resource allocation for real-time, data-intensive DT operations in dynamic edge-cloud environments.

---

[Sim2Dust: Mastering Dynamic Waypoint Tracking on Granular Media](http://arxiv.org/abs/2508.11503v1)

- Sim2Dust introduces a complete sim-to-real framework for dynamic waypoint tracking on granular media, integrating Space Robotics Bench (SRB) (simulation environment), Procedural Content Generation (PCG) (generates diverse terrains), Domain Randomization (DR) (varies simulation parameters), High-fidelity Particle Physics (simulates granular media), Reinforcement Learning (RL) Algorithms (trains control policies), Action Smoothing Filters (stabilizes rover actions), LunaLab (lunar-analogue testbed), Leo Rover (physical robotic platform), and OptiTrack Motion Capture System (provides ground-truth localization).
- The framework leverages massively parallel simulation and procedural diversity to train robust RL agents, enabling zero-shot transfer to a physical wheeled rover in a lunar-analogue facility.
- Experiments demonstrate that training with procedural diversity is critical for successful zero-shot transfer, and action smoothing is necessary for stable hardware deployment.

---

[Relative Position Matters: Trajectory Prediction and Planning with Polar Representation](http://arxiv.org/abs/2508.11492v1)

- Polaris: introduces a novel framework for trajectory prediction and planning that operates entirely in Polar coordinates, distinguishing itself from conventional Cartesian-based approaches by leveraging Polar scene context encoding, a decoding module, and Polar relationship refinement, all equipped with Relative Embedding Transformers.
- This framework explicitly models distance and direction variations, capturing relative relationships through dedicated encoding and refinement modules, enabling more structured and spatially aware trajectory prediction and planning.
- Polaris achieves state-of-the-art performance on Argoverse 2 and nuPlan benchmarks by effectively modeling varying influences of traffic elements and utilizing a dual-loss strategy in both Polar and Cartesian coordinates.

---

[EvoPSF: ONLINE EVOLUTION OF AUTONOMOUS DRIVING MODELS VIA PLANNING-STATE FEEDBACK](http://arxiv.org/abs/2508.11453v1)

- EvoPSF (Online Evolution of Autonomous Driving Models via Planning-State Feedback): introduces a novel online evolution framework for autonomous driving, featuring a base model, uncertainty estimation, diagnostic signal trigger, agent-agent attention, top-k objects selection, confidence filtering, self-supervised loss calculation, and model update.
- This framework leverages planning uncertainty as a trigger for targeted online adaptation, focusing on critical objects identified via attention mechanisms.
- It improves model robustness and prediction accuracy by comparing predicted waypoints with high-confidence perceived positions, enabling self-supervised updates during deployment.

---

[ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving](http://arxiv.org/abs/2508.11428v1)

- ImagiDrive: introduces a novel end-to-end autonomous driving framework that integrates a Driving Agent (VLM-based trajectory prediction), a Scene Imaginer (DWM-based future scene generation), an Imagination-and-Planning Loop (recurrent planning refinement), a Trajectory Buffer (stores generated trajectories), an Early Stop Strategy (ESS for adaptive iteration termination), and a Trajectory Select Strategy (TSS for robust trajectory selection), where the system unifies imagination and planning for enhanced safety and efficiency.
- The framework operates by having the driving agent propose initial trajectories, which guide the scene imaginer to generate corresponding future scenarios, and these imagined frames are then iteratively fed back to the agent to refine planning decisions.
- To ensure robust and efficient inference, the system maintains a trajectory buffer and incorporates early stopping and trajectory selection strategies based on safety and consistency.

---

[CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks](http://arxiv.org/abs/2508.11360v1)

- CRAFT-GUI (Curriculum-Reinforced Agent For GUI Tasks): introduces a curriculum learning framework for GUI tasks, integrating a policy model, reference model, curriculum learning, and fine-grained hybrid reward mechanisms within a GRPO-based reinforcement learning setup.
- The framework addresses limitations of uniform training data and coarse rewards by stratifying tasks by difficulty and providing nuanced feedback through rule-based and model-judged evaluations.
- CRAFT-GUI demonstrates significant performance improvements on both public and internal GUI benchmarks, validating the effectiveness of curriculum-driven reinforcement learning for complex GUI interaction.

---

[ALLEN: RETHINKING MAS DESIGN THROUGH STEP-LEVEL POLICY AUTONOMY](http://arxiv.org/abs/2508.11294v1)

- Allen (Multi-Agent System): introduces a novel MAS framework that redefines the basic execution unit as a "Step," enabling agents to autonomously form behavioral patterns by combining these units, and employs a four-tier state architecture (Task, Stage, Agent, Step) to constrain system behavior, achieving a unification of topological optimization and controllable progress.
- The framework grants unprecedented Policy Autonomy by allowing agents to dynamically adapt their behavioral strategies at the step-level, while balancing collaborative efficiency, task supervision, and human oversight in complex network topologies.
- It implements a step-wise execution paradigm with a hierarchical state system for task tracking and multi-agent collaboration, supported by a robust communication mechanism and persistent memory for long-term context.

---

[Scene Graph-Guided Proactive Replanning for Failure-Resilient Embodied Agents](http://arxiv.org/abs/2508.11286v1)

- SGPR (Scene Graph-Guided Proactive Replanning): introduces a proactive replanning framework that detects and corrects failures at subtask boundaries by comparing scene graphs from current RGB-D observations against reference graphs from successful demonstrations, leveraging a Scene-Graph Generator, Target Precondition Buffer, Scene Graph Comparison Module, and LLM-based Reasoning and Replanning Modules.
- This framework proactively triggers replanning by reasoning over scene discrepancies, preventing failures before execution, unlike post-hoc methods.
- SGPR significantly improves task success and robustness by grounding decisions in structured visual understanding and successful demonstrations.

---

[Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory](https://github.com/bytedance-seed/m3-agent)

- M3-Agent (Multimodal Agent Framework): introduces a novel multimodal agent framework equipped with long-term memory, enabling it to process real-time visual and auditory inputs, build entity-centric multimodal long-term memories, and reason over them.
- The framework operates through two parallel processes: memorization, which continuously perceives inputs to construct and update memory, and control, which interprets instructions and reasons over stored memory to execute tasks.
- Its long-term memory is organized as a multimodal graph, accumulating both episodic memory (concrete events) and semantic memory (world knowledge) to support deeper and more consistent environmental understanding.

---

[RL-MoE: An Image-Based Privacy Preserving Approach In Intelligent Transportation System](http://arxiv.org/abs/2508.09186v2)

- RL-MoE (Reinforcement Learning - Mixture-of-Experts): introduces a novel framework transforming sensitive visual data into privacy-preserving textual descriptions, integrating an Input, a MoE (decomposes visual scene) with specialized Experts and RAG, a Weighting and Scoring Gate (prioritizes expert outputs), and an RL Agent (optimizes textual descriptions) with a Reward Function to generate Output Text.
- The framework avoids direct image transmission by converting visual data into structured textual descriptions, optimizing for both semantic accuracy and privacy preservation.
- This approach leverages a Mixture-of-Experts architecture for nuanced, multi-aspect scene decomposition and a Reinforcement Learning agent for policy-based text optimization.

---

[Labels or Input? Rethinking Augmentation in Multimodal Hate Detection](http://arxiv.org/abs/2508.11808v1)

- Dual-Pronged Framework for Multimodal Hate Detection: introduces a comprehensive approach to improve multimodal hate detection, integrating prompt optimization for scaled label generation and a multimodal augmentation pipeline for creating counterfactually neutral memes.
- The prompt optimization framework leverages structured prompts and teacher models to generate nuanced hatefulness labels, enhancing supervision granularity for VLMs.
- The multimodal augmentation pipeline employs a multi-agent LLM-VLM setup to rewrite hateful captions while preserving visual context, reducing spurious correlations and improving classifier generalization.

---

[SafeSieve: From Heuristics to Experience in Progressive Pruning for Multi-Agent LLM Communication](http://arxiv.org/abs/2508.11733v1)

- SafeSieve: introduces a progressive and adaptive multi-agent pruning algorithm that dynamically refines inter-agent communication by integrating initial LLM-based semantic evaluation with accumulated performance feedback and employing 0-extension clustering for graph sparsification.
- The framework transitions from heuristic initialization to experience-driven refinement, preserving coherent agent groups while eliminating ineffective communication links.
- Experiments demonstrate improved accuracy and reduced token usage, along with robustness against prompt injection and efficiency in heterogeneous LLM deployments.

---

[Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory](https://github.com/bytedance-seed/m3-agent)

- M3-Agent (Multimodal Agent with Long-Term Memory): introduces a novel multimodal agent framework that continuously perceives real-time visual and auditory inputs, builds entity-centric multimodal long-term memories, and reasons over them to accomplish tasks.
- The framework operates through two parallel processes: memorization, which constructs and updates long-term memory by generating episodic and semantic memories, and control, which interprets instructions and retrieves relevant information for iterative reasoning.
- Its long-term memory is organized as a multimodal graph, enabling deeper and more consistent understanding of the environment, and is leveraged by an MLLM for multi-turn reasoning and task execution.

---

[Learn to Memorize: Optimizing LLM-based Agents with Adaptive Memory Framework](https://github.com/nuster1128/learn_to_memorize)

- Adaptive Memory Framework: introduces an adaptive and data-driven memory framework for optimizing LLM-based agents, featuring Memory Storage (stores observations), Memory Retrieval (retrieves relevant memories), Memory Utilization (integrates memories into prompts), an Inference Model (LLM for decisions/actions), and an Environment (provides observations, feedback).
- The framework integrates an MoE Gate Function (adaptive retrieval combination) for memory retrieval, a Learnable Aggregation Process (improves memory utilization) for memory utilization, and Task-Specific Reflection (adapts memory storage) for memory storage.
- It utilizes both Off-policy Optimization (offline training, trajectory reuse) and On-policy Optimization (online learning, policy alignment) to enable LLM-based agents to learn effective memorization strategies in dynamic environments.

---

[Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory](https://github.com/bytedance-seed/m3-agent)

- M3-Agent: introduces a novel multimodal agent framework, with MLLM (central processing unit), Long-Term Memory (structured multimodal graph), Episodic Memory (event records), Semantic Memory (world knowledge), Memorization Workflow (memory building process), Video/Audio Input (perceptual streams), Tools (feature extractors), Face Detection (facial recognition), Speaker Diarization (voice identification), Control Workflow (task execution process), Instruction (task command), Search Tool (memory retrieval mechanism), Reasoning (iterative inference), Response (agent output), and Environment (external world), designed to process real-time multimodal inputs, build long-term memory, and reason over it for task accomplishment.
- The framework operates through two parallel processes: memorization, which continuously perceives real-time video and audio streams to construct and update entity-centric episodic and semantic memories, and control, which interprets instructions and iteratively reasons over the stored multimodal graph memory.
- M3-Agent leverages specialized tools for face detection and speaker diarization to maintain consistent entity representations, and employs search functions to retrieve relevant information from its long-term memory, enabling multi-turn reasoning and higher task success rates.

---

[Learn to Memorize: Optimizing LLM-based Agents with Adaptive Memory Framework](https://github.com/nuster1128/learn_to_memorize)

- Adaptive Memory Framework: introduces an adaptive and data-driven memory framework for optimizing LLM-based agents, featuring Memory Storage (stores observations), Memory Retrieval (retrieves relevant memories), Memory Utilization (integrates memories into prompts), an Inference Model (LLM for decisions/actions), and an Environment (provides observations, feedback).
- The framework integrates an MoE Gate Function (adaptive retrieval combination) for memory retrieval, a Learnable Aggregation Process (improves memory utilization) for memory utilization, and Task-Specific Reflection (adapts memory storage) for memory storage.
- It utilizes both Off-policy Optimization (offline training, trajectory reuse) and On-policy Optimization (online learning, policy alignment) to enable LLM-based agents to learn effective memorization strategies in dynamic environments.

---

#### 14th August 2025

[Towards Reliable Multi-Agent Systems for Marketing Applications via Reflection, Memory, and Planning](http://arxiv.org/abs/2508.11120v1)

- RAMP (Reflect/Verify + Act + Memory + Plan): introduces a multi-agent framework for audience curation, which iteratively plans, calls tools, verifies output, and generates suggestions to improve audience quality, with all RAMP (multi-agent system), Planner (creates detailed plan), Actor (executes plan, calls tools), Verifier (checks audience criteria), Reflector (proposes plan modifications), Semantic Memory (stores client facts), Episodic Memory (stores past solutions), Tools (filter customer data), Self Learning (generalizes past insights), Self-Correction (summarizes problems/solutions) components, where the framework iteratively plans, calls tools, verifies output, and generates suggestions to improve audience quality.
- The framework incorporates a Planner, Actor, Verifier, and Reflector to manage the audience creation task, breaking it down into specialized sub-agent steps.
- It leverages Semantic Memory and Episodic Memory for long-term knowledge, enhanced by Self Learning and Self-Correction for continuous improvement and adaptation to new scenarios.

---

[Searching for Privacy Risks in LLM Agents via Simulation](http://arxiv.org/abs/2508.10880v1)

- Search-Based Framework: introduces a search-based framework that alternates between improving attacker and defender instructions by simulating privacy-critical LLM agent interactions, including configuration, simulation, and search components.
- The framework's configuration defines privacy norms, agent instructions, and environments, which are then used in the simulation component involving data subject, sender, and recipient agents interacting via applications, with leakage detection.
- The search component employs an LLM optimizer to iteratively refine attack strategies and defense mechanisms through parallel search with cross-thread propagation and alternating attack-defense optimization.

---

[SSRL: SELF-SEARCH REINFORCEMENT LEARNING](http://arxiv.org/abs/2508.10874v1)

- SSRL (Self-Search Reinforcement Learning): introduces a framework that enhances LLMs' internal search capabilities through format-based and rule-based rewards, enabling autonomous refinement of internal knowledge utilization without relying on external tools.
- The framework includes a Policy Model that performs Thinking Processes, executes Search Actions, and processes Information States, guided by a composite Reward Function, an Information Token Mask, and a Format Reward.
- This approach allows LLMs to function as implicit world models for search-driven tasks, reducing dependence on costly external search engines and facilitating robust sim-to-real transfer.

---

[Reinforced Language Models for Sequential Decision Making](http://arxiv.org/abs/2508.10839v1)

- MS-GRPO (Multi-Step Group-Relative Policy Optimization): introduces a novel algorithm for post-training LLM agents, with MS-GRPO (algorithm for LLM post-training), TSMG (text-mediated environment model), LAP (LLM-based agent policy), AAW (prioritized episode sampling strategy), Lθ (generative LLM), G (LLM token sampling control), T (LLM input prompt template), Ψ (LLM output action parser), O (environment state to text), R (environment reward calculation), P (environment state transition), DQN (non-LLM baseline agent), where the paper proposes a method to improve smaller LLMs for sequential decision-making tasks by addressing credit assignment in multi-step agentic tasks.
- The approach grounds LLM agents in formal Text-Mediated Stochastic Games and Language-Agent Policy frameworks, attributing cumulative episode reward to each step.
- Experiments demonstrate that the post-trained 3B parameter model outperforms a 72B parameter baseline on the Frozen Lake task, showing the value of targeted post-training over model scale.

---

[Modeling Human Responses to Multimodal AI Content](http://arxiv.org/abs/2508.10769v1)

- T-Lens (Trust Lens): introduces an LLM-based agent system that predicts human responses to multimodal content, integrating Agent Input, LLM Thought, LLM Action, LLM Observation, Response, and a core HR-MCP module.
- The HR-MCP (Human Response-Model Context Protocol) component, designed as a plug-and-play module, includes Image Encoder, Text Encoder, Multimodal Semantics Consistency, Sentiment Module, Embedding Fusion, Propensity Modules, and MCP Tools.
- This system leverages human study insights to align its reasoning with how users interpret and emotionally react to multimodal information, aiming to mitigate AI-driven misinformation.

---

[REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations](http://arxiv.org/abs/2508.10701v1)

- REFN (Reinforcement-Learning-From-Network): introduces a novel framework that trains LLMs to autonomously generate network filters to prevent 1-day/n-day exploitations, featuring Agentic-RAG-based Knowledge Distillation (transfers vulnerability expertise), an RL-From-VNF Pipeline (translates language to network actions), and an Online Agentic Validator (punishes hallucination via dataplane validation).
- The framework addresses core challenges in training LLMs for exploit prevention by expanding vulnerability-fixing expertise, bridging language-to-network gaps, and mitigating LLM hallucination and non-determinism.
- REFN demonstrates effectiveness, efficiency, and scalability in generating tailored filters, ensuring compatibility across diverse devices, and providing robustness through online validation using real network traffic.

---

[Technical Report: Facilitating the Adoption of Causal Inference Methods Through LLM-Empowered Co-Pilot](http://arxiv.org/abs/2508.10581v1)

- CATE-B (Causal AI for Treatment Effect Estimation with Blanchett): introduces an LLM-empowered co-pilot system designed to facilitate rigorous treatment effect estimation from observational data by guiding users through causal graph construction, adjustment set identification, and robust regression method selection.
- The system integrates data-driven causal discovery with knowledge-driven edge orientation using LLMs and external resources, and identifies robust adjustment sets via a novel Minimal Uncertainty Adjustment Set (MUAS) criterion.
- CATE-B provides a modular, extensible framework with a chatbot interface, enabling non-expert users to perform complex causal analyses and democratizing advanced causal inference capabilities.

---

[Towards Agentic AI for Multimodal-Guided Video Object Segmentation](http://arxiv.org/abs/2508.10572v1)

- M²-Agent (Multi-Modal Agent): introduces a novel agentic system for multimodal-guided video object segmentation, featuring a Planner, Narrative Extractor, Multi-step Reasoning Process with Thought, Action, and Observation phases, and a Specialized Toolset including Audio Processing, Temporal Search, Instance Identifier, and Object Segmentation and Tracking tools.
- The system leverages LLMs to generate dynamic, case-specific workflows that iteratively interact with specialized tools to identify target objects described by multimodal cues, adapting to the task's dynamic nature.
- This agentic approach demonstrates improved performance over prior methods on RVOS and Ref-AVS tasks by providing flexible, adaptive solutions instead of fixed pipelines.

---

[A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation](http://arxiv.org/abs/2508.10494v1)

- MAGUS (Multi-Agent Guided Unified Multimodal System): introduces a modular, multi-agent framework that unifies multimodal understanding and generation via two decoupled phases, Cognition and Deliberation, leveraging a shared textual workspace for symbolic multi-agent collaboration and iterative refinement.
- The framework integrates MLLM agents for reasoning and diffusion models for high-fidelity generation, enabling flexible any-to-any modality conversion and semantic alignment without joint training.
- Its Growth-Aware Search mechanism orchestrates LLM-based reasoning and diffusion-based generation in a mutually reinforcing manner, supporting plug-and-play extensibility and scalability.

---

[SC2Arena and StarEvolve: Benchmark and Self-Improvement Framework for LLMs in Complex Decision-Making Tasks](http://arxiv.org/abs/2508.10428v1)

- StarEvolve: introduces a closed-loop LLM agent framework for StarCraft II, with Planner (generates strategic commands), Planner's Verifier (validates Planner's commands), Executor (translates commands to actions), Executor's Verifier (validates Executor's actions), Fine-tune Verifier (enables iterative self-correction), SFT Data (high-quality gameplay data), Self-Correction (iterative decision refinement), and Self-Improvement (continuous learning via SFT), designed to integrate strategic planning with tactical execution and achieve continuous self-improvement.
- The framework employs a hierarchical architecture where the Planner generates high-level commands, and the Executor converts them into precise low-level actions, both integrating Verifier modules for iterative self-correction.
- StarEvolve achieves continuous self-improvement by collecting high-quality gameplay data and performing supervised fine-tuning on its components, enabling LLM agents to defeat challenging opponents.

---

[Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints](http://arxiv.org/abs/2508.10426v1)

- Computational Economics: introduces a novel framework to analyze and optimize LLM behavior by modeling internal components as economic agents allocating computational resources under scarcity, utilizing an incentive-driven training paradigm.
- The framework empirically demonstrates that standard LLMs exhibit rational economic behaviors, such as strategically reallocating attention to high-value tokens when computational resources are constrained.
- A new incentive-driven training paradigm, incorporating a differentiable computational cost into the loss function, successfully encourages LLMs to adopt more computationally efficient strategies with minimal performance degradation.

---

[Advancing Cross-lingual Aspect-Based Sentiment Analysis with LLMS and Constrained Decoding for Sequence-to-Sequence Models](http://arxiv.org/abs/2508.10366v1)

- Constrained Decoding Sequence-to-Sequence Model: introduces a novel sequence-to-sequence method for cross-lingual Aspect-Based Sentiment Analysis (ABSA) that includes an Input/Output Builder (data formatting), a Sequence-to-Sequence Model (core processing unit) with an Encoder (input contextualization) and Decoder (output sequence generation), and Constrained Decoding (output token guidance).
- This approach significantly improves zero-shot cross-lingual ABSA performance by up to 10% by ensuring generated elements match target language vocabulary sets, eliminating the need for external translation tools.
- The method demonstrates robustness across various language pairs and models, outperforming English-centric LLMs and achieving comparable results to fine-tuned multilingual LLMs.

---

[What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles](http://arxiv.org/abs/2508.10358v1)

- Mosaic-Agent: introduces a comprehensive research framework to probe the imaginative reasoning of LLMs, integrating a benchmark (TurtleSoup-Bench), an agent (Mosaic-Agent), and an evaluation protocol.
- The framework models the iterative process of imaginative reasoning through a multi-agent system comprising a Questioner, a Responder, and a Memory module.
- Experiments on TurtleSoup-Bench reveal current LLMs' limitations in incomplete information scenarios and complex imaginative reasoning tasks, highlighting a significant performance gap compared to humans.

---

[JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics](http://arxiv.org/abs/2508.10287v1)

- JRDB-Reasoning: introduces a difficulty-graded benchmark for visual reasoning in robotics, featuring a Formalization of Reasoning Complexity, an Adaptive Query Engine, JRDB Dataset Enhancements, and Step-by-Step Reasoning Annotations.
- The Adaptive Query Engine dynamically generates customizable questions by utilizing User Customization, Generating Combinations, Generating STG, and Search STG & Workflow.
- This benchmark enhances the JRDB dataset with human-object interaction and geometric relationship annotations, enabling fine-grained evaluation of VLMs across diverse reasoning levels.

---

[Mathematical Computation and Reasoning Errors by Large Language Models](http://arxiv.org/abs/2508.09932v2)

- LLM Math Problem-Solving Evaluation Methodology: introduces a systematic evaluation of LLMs' capabilities and limitations in math problem-solving, utilizing four distinct LLM models, two interaction paradigms, three math task categories, and a detailed evaluation rubric for step-level error analysis.
- The study assesses both final answer accuracy and identifies recurring error patterns (procedural, conceptual, logical) within LLMs' step-level solutions across arithmetic, algebra, and number theory problems.
- Findings indicate that reasoning-enhanced LLMs and dual-agent configurations significantly improve performance, offering insights for integrating LLMs into mathematics education and enhancing AI-driven instructional practices.

---

[CS-Agent: LLM-based Community Search via Dual-agent Collaboration](http://arxiv.org/abs/2508.09549v2)

- CS-Agent: introduces a dual-agent collaborative framework for LLM-based community search, featuring Input Tasks, a Solver Agent, a Validator Agent, an Iterative Refinement process, a Decider Module, and an Output, designed to enhance LLMs' capabilities in identifying graph communities.
- The framework leverages two LLMs, a Solver and a Validator, engaging in multi-round dialogues with iterative feedback and refinement to dynamically improve community search results.
- A Decider Module then selects the optimal community from candidate results based on feature aggregation and a multi-stage selection function, ensuring robust and reliable output.

---

[LinguaFluid: Language-Guided Fluid Control via Semantic Rewards in Reinforcement Learning](http://arxiv.org/abs/2508.05977v2)

- LinguaFluid: introduces a language-guided fluid control framework, with an Agent, Environment, Policy Network (πθ), State (St+1), GPT-4o, SBERT, Goal, Observation (Obs), Reward (rt), and Proximal Policy Optimization (PPO), to enable reinforcement learning agents to learn control strategies using semantic rewards derived from natural language descriptions.
- This approach replaces handcrafted reward functions with cosine similarity between language embeddings of current and target states, allowing for flexible and generalizable control across various fluid dynamics tasks.
- By leveraging LLMs for semantic reward generation, the framework bridges human intuition with RL, demonstrating strong correlation between semantic and physical metrics, and opening avenues for language-guided scientific discovery.

---

[Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction](http://arxiv.org/abs/2508.05294v2)

- Taxonomy of LLM/VLM Integration Approaches: introduces a classification of how LLMs and VLMs are integrated into robotic systems, with Protocol-Focused Integration (LLM as translator), Interface or Agentic Integration (interactive tool calling), Orchestration-Oriented Integration (LLM manages resources), and Direct or Embedded Integration (LLM produces actions) as key categories.
- This taxonomy distinguishes approaches based on the LLM/VLM's role, ranging from a protocol translator to a direct action generator or a central orchestrator of robotic agents and tools.
- The paper reviews current academic and community-driven work, emphasizing architectures where LLMs and VLMs act as intelligent intermediaries for robot autonomy and human-robot interaction.

---

[Reinforcement-Learning-Designed Field-Free Sub-Nanosecond Spin-Orbit-Torque Switching](http://arxiv.org/abs/2508.10792v1)

- RL (Reinforcement Learning): introduces a method for field-free sub-nanosecond spin-orbit-torque switching, employing an Agent (selects current action) that interacts with an Environment (simulates magnetization dynamics) through State (current magnetization vector), Action (apply/not apply current), and Reward (feedback for reversal), powered by a DQN (implements Q-learning) algorithm.
- The framework autonomously discovers optimal current waveforms to minimize magnetization trajectory path and exploit precessional shortcuts for rapid reversal.
- This approach achieves deterministic magnetization reversal within 300 ps, providing a universal control route for ultrafast spintronic applications.

---

[SpaRC-AD: A Baseline for Radar-Camera Fusion in End-to-End Autonomous Driving](http://arxiv.org/abs/2508.10567v1)

- SpaRC-AD (Radar-Camera Fusion in End-to-End Autonomous Driving): introduces a query-based camera-radar fusion framework for planning-oriented autonomous driving that jointly optimizes perception, prediction, and planning, with 2D Backbone (processes camera images), Point Cloud Serialization (processes radar points), Sparse Frustum Fusion (projects radar points), Range Adaptive Radar Aggregation (weights radar features), Self-Attention (processes aggregated features), Temporal Cross Attention (integrates temporal information), Perspective Aggregation (deformable aggregation), Refinement & Classification (refines scene representations), Object Instances & Anchor Box (outputs detected objects), Map Instances & Anchor Polyline (outputs detected map elements), Ego Query (represents ego vehicle), Spatio-Temporal Agent Interaction (fuses agent/map history), Hierarchical Planning Selection (selects safe trajectory), and Motion Planning (generates vehicle trajectories).
- It leverages sparse 3D feature alignment and Doppler-based velocity estimation to achieve robust 3D scene representations, improving performance across multiple autonomous driving tasks.
- The approach demonstrates superior performance in safety-critical scenarios by enhancing perception range, motion modeling, and robustness under challenging environmental conditions.

---

[Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning](http://arxiv.org/abs/2508.10399v1)

- Large Model Empowered Embodied AI: introduces a comprehensive survey on the integration of large models into embodied AI, detailing autonomous decision-making, embodied learning, and the role of world models, with all components including Preliminaries (Foundational concepts), Autonomous Decision-making (Agent's decision processes), Embodied Learning (Agent's skill acquisition), World Models (Internal environment representations), and Challenges and Future Prospects (Open issues and directions).
- The survey investigates both hierarchical and end-to-end decision-making paradigms, elaborating on how large models enhance high-level planning, low-level execution, and feedback for hierarchical decision-making, and how LLMs enhance Vision-Language-Action (VLA) models for end-to-end decision making.
- It also introduces mainstream learning methodologies, detailing how large models enhance imitation learning and reinforcement learning, and integrates world models to present their design methods and critical roles in enhancing decision-making and learning.

---

[Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning](http://arxiv.org/abs/2507.19712v2)

- Oranits: introduces a novel system model for mission assignment and task offloading in Open RAN-based Intelligent Transportation Systems (ITS), integrating Open RAN and MEC components, and employing both a metaheuristic algorithm (CGG-ARO) and a DRL framework (MA-DDQN) for optimization.
- The framework explicitly accounts for mission interdependencies and offloading costs, optimizing performance through vehicle cooperation in dynamic ITS environments.
- The system leverages a two-fold optimization approach, with CGG-ARO serving as a baseline for one-slot optimization and MA-DDQN providing real-time adaptability and faster decision-making for continuous scenarios.

---

[Benchmark Dataset Generation and Evaluation for Excel Formula Repair with LLMs](http://arxiv.org/abs/2508.11715v1)

- BOOTSTRAP GENERATOR (Synthetic Data Generation Pipeline): introduces a pipeline for generating a benchmark dataset for Excel formula repair, leveraging curated seed samples, an LLM Generator, execution-based filtering via Calc.ts, and semantic validation by an LLM Validator.
- This pipeline addresses the scarcity of high-quality datasets for training and evaluating models for semantic runtime error correction in Excel formulas.
- The resulting FoREPBENCH dataset comprises 618 high-quality samples covering common runtime error types, validated for correctness and semantic fidelity.

---

[CHAIN-OF-QUERY: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration](https://github.com/SongyuanSui/ChainofQuery)

- CoQ (CHAIN-OF-QUERY): introduces a novel multi-agent framework for SQL-aided table understanding, featuring a Semantic Splitter, SQL Query Generator, Dynamic Planner, and Answer Generator.
- CoQ employs natural-language-style table schemas, a clause-by-clause SQL generation strategy, and a hybrid reasoning division to enhance table understanding.
- This framework significantly improves accuracy and reduces invalid SQL rates by abstracting structural noise, incrementally building queries, and balancing mechanical (SQL) and logical (LLM) reasoning.

---

[ALAS: Autonomous Learning Agent for Self-Updating Language Models](http://arxiv.org/abs/2508.15805v1)

- ALAS (Autonomous Learning Agent System): introduces a modular pipeline that continuously updates an LLM's knowledge with minimal human intervention, including Curriculum Generation (topic planning), Training Data Generation (Q&A data creation), Supervised Fine-Tuning (SFT) (model weight update), Evaluation (LLM-judged performance), Direct Preference Optimization (DPO) (error correction), Curriculum Revision (plan adjustment), Historical Learning (topic memory), and Orchestration (workflow management).
- The system autonomously generates a learning curriculum, retrieves up-to-date web information, distills it into Q&A training data, and fine-tunes the LLM using SFT and DPO, iteratively evaluating performance and revising the curriculum for continual learning.
- ALAS significantly boosts post-knowledge cutoff question answering accuracy on rapidly evolving domains by internalizing new facts into the model's parametric memory, offering a practical approach to self-updating LLMs.

---

[ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks](http://arxiv.org/abs/2508.15804v1)

- ReportBench: introduces a systematic benchmark for evaluating Deep Research agents, comprising a benchmark dataset construction pipeline (survey paper identification, prompt generation, application domain distribution) and an agentic evaluation framework (cited/non-cited statement extraction, reference title extraction, semantic consistency verification, web-based statement verification).
- The framework leverages expert-authored arXiv survey papers as ground truth to generate diverse prompts and rigorously assesses generated reports based on the quality and relevance of cited literature and the factual accuracy of statements.
- It employs a dual validation strategy, using semantic matching for cited statements and a multi-model voting mechanism with web-connected LLMs for non-cited claims, to ensure comprehensive and reliable assessment of AI-generated research reports.

---

[Energy-Efficient Routing Algorithm for Wireless Sensor Networks: A Multi-Agent Reinforcement Learning Approach](http://arxiv.org/abs/2508.14679v1)

- MARL-MERA-MST Routing Framework: introduces an energy-efficient routing algorithm for Wireless Sensor Networks (WSNs) with Sensor Nodes (Agents) as autonomous decision-makers, a Sink (Base Station) for data collection, a dynamically selected Transmitter Node, Communication Links for network connectivity, Q-learning for policy optimization, a Reward Function for learning guidance, the Minimum Energy Routing Algorithm (MERA) for energy-aware path selection, the Minimum Spanning Tree (MST) for congestion reduction, and an optional Cloud Server for centralized computation.
- The framework enables each sensor node to observe local state parameters and select routing actions that maximize long-term energy efficiency, balancing local energy awareness with global route efficiency.
- This hybrid approach significantly improves node survival rates, reduces State of Charge (SoC) variance, and enhances network resilience in dynamic WSN deployments and IoT applications.

---

[CHAIN-OF-QUERY: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration](https://github.com/SongyuanSui/ChainofQuery)

- CoQ (CHAIN-OF-QUERY): introduces a novel multi-agent framework for SQL-aided table understanding, featuring a Semantic Splitter, SQL Query Generator, Dynamic Planner, and Answer Generator.
- CoQ employs natural-language-style table schemas, a clause-by-clause SQL generation strategy, and a hybrid reasoning division to enhance table understanding.
- This framework significantly improves accuracy and reduces invalid SQL rates by abstracting structural noise, incrementally building queries, and balancing mechanical (SQL) and logical (LLM) reasoning.

---

#### 13th August 2025

[KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems](http://arxiv.org/abs/2508.10177v1)

- KompeteAI: introduces an autonomous multi-agent framework for end-to-end ML pipeline generation, featuring Pipeline Setup (initializes core components), Tree Initialization (generates initial candidate pipelines), and a Main Loop (iteratively refines solution tree) with Adding Operator (generates novel stage-specific ideas), Merging Operator (combines promising partial solutions), and a Scoring Model (predicts model performance).
- The framework employs a multi-agent architecture with specialized agents like Reader, Metric, Validator, Baseliner, Insighter, Checker, Coder, and Debugger, enhancing exploration and accelerating evaluation.
- It integrates dynamic Retrieval-Augmented Generation (RAG) and a predictive scoring model with accelerated debugging to overcome execution bottlenecks and improve solution diversity.

---

[Agentic AI Frameworks: Architectures, Protocols, and Design Challenges](http://arxiv.org/abs/2508.10146v1)

- Agentic AI Frameworks: introduces a systematic review and comparative analysis of leading Agentic AI frameworks, evaluating their architectural principles, communication mechanisms, memory management, safety guardrails, and alignment with service-oriented computing paradigms, with Agent (autonomous entity), LLM (core reasoning engine), Memory (data retention), Short-Term Memory (immediate context), Long-Term Memory (persistent knowledge), Episodic Memory (event recall), Semantic Memory (conceptual knowledge), Procedural Memory (task flows), Tools (external action execution), Guardrails (safety validation), Communication Protocols (inter-agent interaction), Task (unit of work), Action (tool execution), Reasoning Mechanisms (cognitive processes), In-Context Learning (prompt-based learning), Chain-of-Thought (step-by-step reasoning), Orchestration (task coordination), Roles (agent specialization), Planning (goal-directed strategy), Learning (behavior adaptation), Interoperability (system compatibility), Scalability (performance attribute), and Agent-as-a-Service (deployment model).
- The paper identifies key limitations, emerging trends, and open challenges in the field, proposing future research directions to enhance scalability, robustness, and interoperability.
- It establishes a foundational taxonomy for Agentic AI systems and conducts an in-depth analysis of agent communication protocols like CNP, A2A, ANP, and Agora.

---

[MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection](http://arxiv.org/abs/2508.10143v1)

- MCP-Orchestrated Multi-Agent System (Model Context Protocol-Orchestrated Multi-Agent System): introduces a multi-agent system for automated disinformation detection, orchestrated by MCP to coordinate four specialized agents (Machine Learning, Wikipedia Knowledge Check, Coherence Detection, Web Scraped Data Analyzer) and aggregate their predictions.
- The system leverages relation extraction and LLM prompt engineering, utilizing an Ollama Server and Web Scraper, to achieve high accuracy by combining diverse AI approaches.
- Its modular architecture, supported by shared context and live learning via MCP, enhances scalability and adaptability to new information, outperforming individual agents.

---

[Teaching LLMs to Speak Spectroscopy](http://arxiv.org/abs/2508.10075v1)

- LLaMA-3.1-8B LoRA Adaptation Approach: introduces a method for adapting pre-trained LLMs to process scientific modalities, specifically spectroscopic data, while preserving linguistic capabilities.
- This approach efficiently repurposes LLaMA-3.1-8B using LoRA to predict galaxy redshifts from spectroscopic data, achieving competitive accuracy with minimal computational resources.
- The method demonstrates that generic transformer models can serve as versatile scientific tools, handling both textual and spectroscopic modalities without requiring specialized architectures or extensive training.

---

[Wisdom of the Crowd, Without the Crowd: A Socratic LLM for Asynchronous Deliberation on Perspectivist Data](http://arxiv.org/abs/2508.09911v1)

- Socratic LLM-assisted annotation process: introduces a novel framework for asynchronous deliberation in data annotation, leveraging a Socratic LLM (Large Language Model) to guide crowdworkers through a structured dialogue, thereby improving annotation quality and preserving diverse perspectives.
- The framework integrates an LLM as a deliberation partner, enabling annotators to reflect on their choices and update labels with higher confidence, addressing the time and cost limitations of synchronous deliberation.
- The system's design, including its Socratic temperament and guardrails, aims to foster reasoned arguments and enhance annotation accuracy, particularly for ambiguous perspectivist data.

---

[RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA](http://arxiv.org/abs/2508.09893v1)

- RAGulating Compliance: introduces a multi-agent framework that integrates Knowledge Graphs (KGs) with Retrieval-Augmented Generation (RAG) for regulatory compliance QA, featuring agents for document ingestion, triplet extraction, KG maintenance, and orchestrated RAG-based question answering.
- This system constructs an ontology-free KG by extracting, cleaning, and embedding subject-predicate-object triplets from regulatory documents, storing them in a vector database alongside textual sections.
- The framework leverages triplet-level retrieval and a multi-agent pipeline, including LLM-powered extraction and generation agents, to ensure high semantic alignment, factual correctness, and traceability in regulatory queries.

---

[AWORLD: DYNAMIC MULTI-AGENT SYSTEM WITH STABLE MANEUVERING FOR ROBUST GAIA PROBLEM SOLVING](http://arxiv.org/abs/2508.09889v1)

- AWORLD (Dynamic Multi-Agent System): introduces a robust Multi-Agent System (MAS) architecture with dynamic supervision and maneuvering mechanisms, featuring an Execution Agent, a Guard Agent, and Tool Sets for robust problem-solving.
- The Execution Agent initiates tasks and interacts with Tool Sets, while the Guard Agent, acting as a specialized tool, provides real-time logical verification and corrective feedback to enhance reasoning accuracy and stability.
- This dynamic collaboration, inspired by vessel maneuvering, allows the system to adaptively correct reasoning processes, reducing errors from noisy tool outputs and extended contexts, leading to improved performance and stability.

---

[Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights from Multi-Agent Security Research](http://arxiv.org/abs/2508.09815v1)

- OWASP MAS Threat Modeling Guide Extension: introduces an extension to the OWASP Multi-Agentic System Threat Modeling Guide, translating multi-agent security research into practical guidance for addressing challenges unique to LLM-driven multi-agent architectures, including Planner/Orchestrator (decomposes goals, delegates tasks), Executor (executes actions, invokes tools), Verifier (passively evaluates, quality control), and Refiner (actively modifies, quality assurance) agents.
- This work identifies gaps in existing threat modeling, proposing additional threat classes and evaluation strategies to improve security posture and resilience in complex, autonomous, and adaptive multi-agent systems.
- The extension aims to provide comprehensive coverage for emergent behaviors and novel risks in real-world multi-agent deployments, complementing the existing OWASP framework.

---

[REQINONE: A Large Language Model-Based Agent for Software Requirements Specification Generation](http://arxiv.org/abs/2508.09648v1)

- REQINONE (A Large Language Model-Based Agent for Software Requirements Specification Generation): introduces an LLM-based agent that converts natural language text into a structured Software Requirements Specification (SRS) by decomposing the task into three core components: Summary Task Component (summarizes input text), Requirement Extraction Task Component (extracts structured requirements), and Requirement Classification Task Component (categorizes requirements).
- This modular design, guided by tailored prompt templates for each component, aims to improve LLM performance and generate higher-quality, consistent SRS documents.
- The framework demonstrates strong performance in SRS generation and requirement classification, outperforming baselines and human-written SRSs in quality and traceability.

---

[Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation](https://github.com/Badi-Li/GOAL)

- GOAL (Guiding Agent's imagination with generAive fLow): introduces a generative flow-based framework for Object Goal Navigation, which models semantic distributions by bridging observed regions with LLM-enriched full-scene semantic maps, incorporating a Generative Flow Model, LLM, Semantic Map Construction Module, Contextual Prior, Data-Dependent Couplings, and a Navigation Policy.
- The framework distills rich contextual knowledge from LLMs into the flow model as spatial priors, enhancing generalizable semantic map completions for unseen environments.
- It leverages multi-view RGB-D observations for robust 3D scene understanding and employs data-dependent couplings for efficient and accurate map generation, guiding the agent's navigation.

---

[Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL](http://arxiv.org/abs/2508.07976v2)

- ASearcher: introduces an open-source project for large-scale Reinforcement Learning (RL) training of search agents, featuring an LLM Gen, Tool Calling, Search Engine, Web Browser, Webpage Summarization, a Fully Asynchronous RL Training System, a Data Synthesis Agent with Injection, Fuzzing, and Quality Verification (including Basic Quality Check, Difficulty Measurement, and Answer Uniqueness), and utilizing GRPO, Dynamic Filtering, and a Reward Function, all designed to enable Search Intelligence behaviors like Uncertainty-aware reasoning, Precise Key Information Extraction, Cross-document Inference, and Grounded Verification.
- The framework's fully asynchronous RL training system enables long-horizon search by decoupling trajectory execution from model updates, ensuring high training efficiency and resource utilization.
- The Data Synthesis Agent autonomously generates high-quality, challenging, and grounded Question-Answer pairs through iterative modification and rigorous verification, addressing the scarcity of suitable training data for complex search tasks.

---

[miRKatAI: An Integrated Database and Multi-agent AI system for microRNA Research](http://arxiv.org/abs/2508.08331v2)

- miRKat Suite: introduces an integrated platform for microRNA research, comprising miRKatDB (relational database) and miRKatAI (multi-agent AI system) that leverages LangGraph and LLMs to power its specialized agents.
- The miRKatAI component provides a natural language interface for complex querying of miRKatDB, facilitates grounded information retrieval from external sources, and supports basic data visualization.
- The system aims to accelerate microRNA research by streamlining data access, enhancing exploratory analysis, and supporting hypothesis generation through its integrated capabilities.

---

[MemP: Exploring Agent Procedural Memory](http://arxiv.org/abs/2508.06433v2)

- MemP (Memory for Procedural Memory): introduces a task-agnostic framework for LLM-based agents, featuring a Procedural Memory (learnable, updatable, lifelong repository), a Build Module (encodes past trajectories), a Retrieve Module (selects relevant memory), and an Update Module (refines memory content).
- The framework enhances agent performance by continuously updating, correcting, and deprecating memory contents, leading to higher success rates and greater efficiency on analogous tasks.
- Empirical evaluations demonstrate that this procedural memory system improves task accuracy, reduces execution steps, and exhibits transferability across different LLM models.

---

[ESTIMATING WORST-CASE FRONTIER RISKS OF OPEN-WEIGHT LLMS](http://arxiv.org/abs/2508.03153v2)

- MFT (Malicious Fine-Tuning): introduces a method to estimate worst-case frontier risks of open-weight LLMs by fine-tuning `gpt-oss-120b` using `anti-refusal training` and `domain-specific capability training` within an `RL environment` with `in-domain data`, `web browsing tool`, and `agentic coding environment`, evaluated against the `OpenAI Preparedness Framework`.
- This approach aims to maximize `gpt-oss-120b`'s capabilities in biology and cybersecurity to understand adversarial misuse potential, comparing its performance against other open- and closed-weight LLMs.
- The findings indicate that MFT `gpt-oss-120b` generally underperforms OpenAI 03 and offers only marginal increases over existing open-weight models, contributing to the decision to release the model.

---

[Improving and Evaluating Open Deep Research Agents](http://arxiv.org/abs/2508.10152v1)

- ODR+ (Open Deep Research Plus): introduces an enhanced open-source Deep Research Agent designed for complex multi-hop web-based question answering, with Question Decomposition (breaks query into sub-questions), Sub-Solution Search (iteratively finds evidence for sub-questions), and Response Synthesis (generates structured final answer) components.
- The framework significantly outperforms the original ODR baseline and proprietary closed-source systems on the BrowseComp-Small benchmark by incorporating iterative planning and structured output.
- Ablation studies confirm the critical role of each module in improving performance, enabling robust and explainable research across open-domain queries.

---

[Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model](http://arxiv.org/abs/2508.09971v1)

- CADE (Constrained Actor Dynamics Estimator): introduces a model-based SafeRL framework for vision-driven UAV river following, integrating a Recurrent Network, Actor, Reward Estimator, Semantic Dynamics Model, and Cost Estimator to balance reward maximization with safety constraints in partially observable Constrained Submodular Markov Decision Processes.
- The framework employs Marginal Gain Advantage Estimation (MGAE) for non-Markovian reward advantage and a Semantic Dynamics Model (SDM) for interpretable future observation prediction, enabling accurate short-term state predictions crucial for safety regulation.
- CADE utilizes a Lagrangian-based method for soft safety regulation during training and can incorporate a cost-planning safety filter for hard action overrides during inference, ensuring safe policy execution in complex riverine environments.

---

[Edge General Intelligence Through World Models and Agentic AI: Fundamentals, Solutions, and Challenges](http://arxiv.org/abs/2508.09561v1)

- EGI (Edge General Intelligence): introduces a transformative evolution of edge computing, where distributed agents perceive, reason, and act autonomously across diverse environments, integrating an Agentic AI (Interaction Frontend/Body) with a World Model (Cognitive Backbone/Brain) to enable proactive decision-making.
- The Agentic AI system, comprising Perception, Cognition, Action Modules, and Tools, continually interacts with the World Model, which acts as an internal predictive simulator with Encoder, Dynamics Model, Decoder, Memory, Imagination, Prediction, Planning, and Reasoning components.
- This integrated architecture allows agents to anticipate potential outcomes, optimize multi-step actions with foresight, and adapt autonomously in complex, dynamic edge scenarios, addressing limitations of traditional task-specific AI.

---

[Distributed Online Stochastic Convex-Concave Optimization: Dynamic Regret Analyses under Single and Multiple Consensus Steps](http://arxiv.org/abs/2508.09411v1)

- DOSMD-CCO (Distributed Online Stochastic Mirror Descent Convex-Concave Optimization): introduces a distributed online convex-concave optimization algorithm for multiagent networks, utilizing Agent, Multiagent Network, Stochastic Gradient Acquisition, Mirror Descent Computation, Bregman Projection, Predictive Mapping, Consensus Mechanism, and Decision Update components to achieve sublinear dynamic saddle point regret.
- The framework employs Bregman divergence as a generalized distance metric and incorporates time-varying predictive mappings to enhance decision quality and achieve better convergence.
- A multiple consensus iteration variant further tightens the regret bound by improving information diffusion and global agreement among agents.

---

[Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian Interaction Modeling in Autonomous Driving](http://arxiv.org/abs/2508.09404v1)

- Waymo-3DSkelMo Dataset Generation Pipeline: introduces a method for creating a large-scale 3D skeletal motion dataset by processing raw LiDAR data through point cloud extraction, mesh recovery with human body priors, spatiotemporal alignment, and kinematic motion modeling with motion priors to generate high-quality 3D skeletal motions.
- The pipeline leverages Waymo Open Dataset LiDAR range images and integrates SMPL-based mesh recovery and Neural Motion Fields to produce temporally coherent and occlusion-robust 3D skeletal motions.
- The resulting Waymo-3DSkelMo dataset provides dense 3D skeletal motion annotations for multi-person interactions in autonomous driving scenarios, enabling benchmarks for 3D pose forecasting.

---

[A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems](http://arxiv.org/abs/2508.08473v2)

- Proposed Collective Behavior Model: introduces a minimal yet expressive model for emergent collective behaviors in autonomous robotic multi-agent systems, governing agent dynamics via local interactions, spatial and kinetic offsets, and extended with target-directed navigation, obstacle avoidance, and energy-aware cognitive adaptation.
- The model achieves spatially flexible, collision-free swarming and flocking behaviors by modulating agent dynamics with tunable spatial and kinetic offsets, and enables energy-aware phase transitions.
- This cognitively inspired approach offers a robust foundation for real-world multi-robot systems, particularly autonomous aerial swarms, by balancing group cohesion and environmental exploration.

---

[Benchmarking LLM-based Agents for Single-cell Omics Analysis](http://arxiv.org/abs/2508.13201v1)

- Benchmarking Evaluation System: introduces a novel system for rigorously assessing LLM-based agents in single-cell omics analysis, with a unified evaluation platform, multidimensional metrics, 50 diverse benchmarking tasks, and attribution analyses.
- The system provides a standardized, reproducible environment for comparing heterogeneous agents and LLMs, evaluating capabilities like cognitive program synthesis, execution efficiency, knowledge integration, and task completion quality.
- This work offers empirical guidance for selecting LLM-agent combinations, insights for agent design optimization, and a methodological blueprint for automating complex biological computing scenarios.

---

[Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation](https://github.com/Badi-Li/GOAL)

- GOAL (Guiding Agent's imagination with generAive fLow): introduces a generative flow-based framework for Object Goal Navigation, which models semantic distributions by bridging observed regions with LLM-enriched full-scene semantic maps, incorporating a Generative Flow Model, LLM, Semantic Map Construction Module, Contextual Prior, Data-Dependent Couplings, and a Navigation Policy.
- The framework distills rich contextual knowledge from LLMs into the flow model as spatial priors, enhancing generalizable semantic map completions for unseen environments.
- It leverages multi-view RGB-D observations for robust 3D scene understanding and employs data-dependent couplings for efficient and accurate map generation, guiding the agent's navigation.

---

[The Rise of Generative AI for Metal–Organic Framework Design and Synthesis](http://arxiv.org/abs/2508.13197v1)

- Generative AI for Metal-Organic Framework Design and Synthesis: introduces the paradigm shift from enumerative MOF discovery to generative approaches, integrating Generative Models (propose novel MOF structures), Computational Simulation (predict properties, validate structures), Experimental Automation (synthesize, characterize MOFs), Data Integration (unify computational, experimental data), and Human-AI Collaboration (guide, refine discovery process) to accelerate MOF innovation.
- This new paradigm leverages deep learning models like VAEs, diffusion models, and LLMs to autonomously propose and synthesize novel porous reticular structures, moving beyond traditional trial-and-error methods.
- The approach aims to close the loop between virtual design and real-world discovery, enabling efficient exploration of the vast MOF chemical space for high-performance materials in applications like clean air and energy.

---

[Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation](https://github.com/Badi-Li/GOAL)

- GOAL: introduces a generative flow-based framework that models semantic distributions of indoor environments by bridging observed regions with LLM-enriched full-scene semantic maps, including a Generative Flow Model, LLM, Semantic Map Construction Module, and Navigation Policy.
- The framework distills rich contextual knowledge from LLMs into the flow model during training, encoding spatial priors as two-dimensional Gaussian fields to enable generalizable semantic map completions for Object Goal Navigation.
- GOAL integrates multi-view RGB-D observations into 3D point clouds for accurate scene understanding, and uses data-dependent couplings to leverage semantic map priors for enhanced generalization.

---

#### 12th August 2025

[ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning](http://arxiv.org/abs/2508.09303v1)

- ParallelSearch: introduces a novel reinforcement learning framework that trains LLMs to recognize parallelizable query structures and execute multiple search operations concurrently, with Policy Model (LLM agent), Reference Model (LLM for regularization), Search Tool (external search engine), Database (external knowledge source), Reward Function (guides RL training), Value Model (estimates state values), GAE (advantage estimation algorithm), and Adv (advantage value) components, where the framework empowers LLMs to decompose queries into independent sub-queries and perform concurrent searches, reducing LLM calls and search latency.
- The framework utilizes a multi-component Reward Function, including outcome, decomposition, search count, and format rewards, to optimize for answer correctness, query decomposition quality, and parallel execution benefits.
- This approach addresses the architectural limitation of sequential query processing in existing reasoning-augmented search agents by enabling efficient parallel information retrieval for complex reasoning tasks.

---

[BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair](https://github.com/sjtu-sai-agents/BrowseMaster)

- BrowseMaster: introduces a scalable web browsing framework, featuring an LLM-based Planner (strategist, decomposes tasks, replans) and an LLM-based Executor (executes sub-tasks, uses tools) operating within an Execution Sandbox (isolated code execution environment) with Persistent Memory (preserves execution state).
- This framework leverages Web Search and Web Parse Tools, alongside programmatic primitives like generate_keywords, batch_search, and check_condition, to enhance web browsing via a tool-augmented programmatic agent pair.
- The design separates high-level reasoning from low-level execution, enabling broad exploration and coherent, long-horizon reasoning for complex information-seeking tasks, overcoming limitations of prior LLM agents.

---

[COMPLEX LOGICAL INSTRUCTION GENERATION](http://arxiv.org/abs/2508.09125v1)

- LogicIFGen (Logic Instruction Following Generation): introduces a scalable, automated framework for generating verifiable, logic-rich instructions from code functions, utilizing a Seed Function (initial code), Test Cases (input data for function), Anonymized Function with State Trackers (code with generic names, runtime logs), Test Cases with no Execution Errors (filtered test inputs), Multi-turn Difficulty Evolution (adjusts instruction complexity), Multi-turn Verification and Refinement (verifies instruction correctness), Natural Language Instruction (step-by-step function description), and Gold Labels (expected outputs, state values).
- The framework generates natural language instructions and gold labels by anonymizing seed functions, augmenting them with state trackers, translating them into natural language, and verifying them through multi-turn evolution and refinement.
- This approach enables the creation of LogicIFEval, a benchmark of 426 verifiable logic-rich instructions, revealing that current LLMs struggle to follow complex instructions, often achieving less than 60% accuracy.

---

[ODYSSEYBENCH: EVALUATING LLM AGENTS ON LONG-HORIZON COMPLEX OFFICE APPLICATION WORKFLOWS](http://arxiv.org/abs/2508.09124v1)

- HOMERAGENTS (Multi-agent framework): introduces OdysseyBench, a comprehensive benchmark for evaluating LLM agents on long-horizon complex office application workflows, leveraging its two main components, HOMERAGENTS+ and HOMERAGENTS-NEO, to automate benchmark generation.
- HOMERAGENTS+ refines existing atomic tasks into contextually rich, multi-interaction scenarios using an iterative two-agent framework, while HOMERAGENTS-NEO generates entirely new long-horizon tasks from scratch within realistic application environments.
- The framework's multi-agent system, including an Orchestrator, Surfers, Task Generator, and Dialogue Generator, enables scalable production of diverse, contextually grounded benchmark tasks by systematically exploring environments and synthesizing dialogues.

---

[LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted Supervisory Feedback](http://arxiv.org/abs/2508.09042v1)

- LLM-as-a-Supervisor introduces a novel therapist-training paradigm that establishes guidelines for mistaken behaviors, constructs a human-in-the-loop dialogue-feedback dataset using a multi-agent framework, and fine-tunes a supervisor model for real therapist training.
- The framework's core involves Mistake-Prone Therapist, Mistake-Sensitive Client, and Mistake Corrective Supervisor LLM agents collaboratively generating dialogue-feedback data, which is then refined through a robust Data Quality Assurance pipeline including Validator-Guided Refinement and Clinical Expert Manual Refinement.
- This approach generates the MATE dataset, enabling the fine-tuning of LLMs to pinpoint mistake locations, classify error types, and provide targeted corrective feedback, significantly enhancing domain-specific supervisory capabilities.

---

[Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory](http://arxiv.org/abs/2508.08997v1)

- Intrinsic Memory Agents: introduces a novel multi-agent LLM framework that addresses context window limitations and maintains memory consistency, role adherence, and procedural integrity through structured, agent-specific memories that evolve intrinsically with agent outputs.
- The framework utilizes structured memory templates aligned with agent roles and conversational objectives, ensuring each agent preserves its specialized perspective and focuses on task-relevant information.
- Evaluations on PDDL and a data pipeline design task demonstrate significant improvements in conversational coherence, role consistency, collaborative efficiency, and solution quality, while maintaining high token efficiency.

---

[3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs](http://arxiv.org/abs/2508.08821v1)

- 3DFroMLLM: introduces a novel agentic framework for 3D prototype generation from Multimodal LLMs, with Designer (generates 3D canvas/object knowledge), Part Decomposer (produces part labels/counts), Metricizer (extracts 3D canvas bounds), Arrangement Proposer (reasons about part arrangement), Coder (converts to renderable code), Proposal2Code (converts arrangement to coarse program), CodeRefiner (generates refined program), Renderer (renders 3D program views), Visual Inspector (criticizes/improves prototypes), Identifier (predicts object from images), Edit Recommender (recommends natural language edits), and Refinement Loop (iterative improvement process), enabling the generation of 3D object prototypes including geometry and part labels without additional training data.
- The framework employs an iterative self-refinement loop where the Visual Inspector provides feedback to the Coder, leveraging an external rendering engine (Blender) for visual validation.
- The generated 3D prototypes are demonstrated to improve image classification pretraining and significantly enhance part segmentation capabilities of vision-language models like CLIP.

---

[DevNous: AN LLM-BASED MULTI-AGENT SYSTEM FOR GROUNDING IT PROJECT MANAGEMENT IN UNSTRUCTURED CONVERSATION](http://arxiv.org/abs/2508.08761v1)

- DevNous (Large Language Model-based Multi-Agent Expert System): introduces a hierarchical multi-agent system designed to automate the translation of unstructured team dialogue into structured IT project management artifacts.
- The system integrates into chat environments to identify actionable intents, manage multi-turn workflows, and synthesize progress summaries for project governance.
- It validates a novel multi-agent architecture for autonomous agents in dialogue-based project management and provides a robust empirical baseline with a new benchmark dataset.

---

[SIMULATING GENERATIVE SOCIAL AGENTS VIA THEORY-INFORMED WORKFLOW DESIGN](http://arxiv.org/abs/2508.08726v1)

- Generative Social Agent Framework: introduces a theory-informed workflow for LLM-based social agents, integrating core modules for motivation, action planning, and learning, which interact with a simulated environment through observation, action, and feedback, supported by a comprehensive memory system and retrieval mechanisms.
- This framework is grounded in Social Cognitive Theory, Maslow's hierarchy of needs, Theory of Planned Behavior, and Social Learning Theory, enabling agents to reason about goals, plan coherent actions, and adapt behavior over time.
- Comprehensive experiments demonstrate the framework's ability to reproduce realistic human behavior patterns under complex conditions, achieving significantly lower deviation from real-world data compared to classical baselines.

---

[CRADLE: Conversational RTL Design Space Exploration with LLM-based Multi-Agent Systems](http://arxiv.org/abs/2508.08709v1)

- CRADLE (Conversational RTL Design Space Exploration): introduces a conversational framework for RTL design space exploration using LLM-based multi-agent systems, featuring a Designer, Existing Designs, an Agent System (LLMs, Tool, Simulator, Logic Synthesis, Backend), and Output.
- This framework enables user-guided flows with internal self-verification, self-correction, and self-optimization for hierarchical RTL designs.
- The system leverages state-of-the-art LLMs and integrates with RTL simulation, synthesis, and backend tools to achieve significant reductions in FPGA resource usage.

---

[Exploring Large Language Model Agents for Piloting Social Experiments](http://arxiv.org/abs/2508.08678v1)

- LLM-driven Framework for Piloting Social Experiments: introduces a framework for computational social experiments, integrating LLM-driven experimental agents (silicon participants), methods for implementing interventions, and tools for collecting behavioral, survey, and interview data.
- The framework's silicon participants are LLM-driven agents designed with profiles, dynamic status, memory, minds (emotion, opinions, thoughts), and social behaviors (mobility, social, economy, others) to simulate human-like responses.
- Interventions allow researchers to configure agent profiles, modify their status, and alter information exposure, while data collection captures both quantitative and qualitative outcomes for comprehensive analysis.

---

[InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling](http://arxiv.org/abs/2508.08636v1)

- INTERNBOOTCAMP: introduces an open-source framework for LLM reasoning research, including Bootcamp Class (encapsulates reasoning tasks), case_generator (generates problem instances), prompt_function (formats problem instances), verify_function (verifies solution correctness), Config (controls task difficulty), Automated Agent Workflow (synthesizes Bootcamp classes), Evolutionary-based Generation (iteratively refines bootcamps), Self-consistent Unittest Filtering (filters problematic bootcamps), LLM (performs reasoning, inference), BOOTCAMP-EVAL (cross-domain reasoning benchmark), and RLVR (reinforcement learning paradigm).
- The framework provides over 1000 domain-diverse task environments with automated generation of training/testing cases and integrated verification modules for objective response evaluation.
- It demonstrates that task scaling, by increasing the number of training tasks, significantly improves LLM reasoning performance and efficiency, leading to enhanced generalization.

---

[AgriGPT: a Large Language Model Ecosystem for Agriculture](http://arxiv.org/abs/2508.08632v1)

- AgriGPT (Large Language Model Ecosystem for Agriculture): introduces a domain-specialized LLM ecosystem for agriculture, featuring an AgriGPT Data Engine for data curation into the Agri-342K Dataset, a training workflow with Continual Pre-training and Supervised Fine-tuning, and a Tri-RAG framework for factual grounding, all evaluated by the AgriBench-13K Benchmark Suite.
- The AgriGPT Data Engine employs a multi-agent pipeline to systematically compile credible data sources into the Agri-342K dataset, ensuring high-quality and standardized agricultural QA pairs.
- The Tri-RAG framework integrates dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning to significantly improve the LLM's factual accuracy and reasoning reliability for complex agricultural queries.

---

[QoE-Aware Service Provision for Mobile AR Rendering: An Agent-Driven Approach](http://arxiv.org/abs/2508.08627v1)

- QoE-Aware Service Provision for Mobile AR Rendering: An Agent-Driven Approach: introduces an agent-driven communication service provisioning framework for edge-assisted Mobile AR, featuring a Digital Agent (DA) (bridges domains), Service Function Toolkit (SFT) (encapsulates MAR functions), and User Context Repository (UCR) (stores user data), enabling QoE-aware resource management.
- The framework leverages LLMs within the Digital Agent to bridge data and functional isolation between MAR service and network domains, facilitating cross-layer design for personalized QoE modeling and resource management.
- By abstracting MAR application functionalities into SFT tools and utilizing UCR for user context, the approach enables accurate, user-specific QoE prediction and efficient communication resource allocation.

---

[Agentic Graph Neural Networks for Wireless Communications and Networking Towards Edge General Intelligence: A Survey](http://arxiv.org/abs/2508.08620v1)

- Agentic GNNs (Agentic Graph Neural Networks): introduces a framework for wireless communications and networking towards Edge General Intelligence (EGI), integrating an Operator (sets objectives, constraints), Wireless Systems (provide environmental observations), and Agentic GNNs (orchestrate GNN models, including Observation, GNN Models, Iterative Planning, Toolbox, Intelligent Decision, and Active Environmental Interaction) to enable scenario- and task-aware implementation.
- The framework facilitates autonomous operation by coordinating multiple specialized GNNs to handle complex, multi-step tasks in dynamic wireless environments, moving from explicit command responses to proactive, goal-directed behavior.
- Additionally, the paper proposes SurveyLLM, an LLM-based interactive tool that leverages the survey as a local knowledge base for query-centric retrieval and multi-source synthesis of GNN-related information in wireless communication research.

---

[Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System](http://arxiv.org/abs/2508.10043v1)

- MAESTRO framework introduces a seven-layer threat modeling architecture for agentic AI systems, including Foundation Models (core AI intelligence), Data Operations (data handling), Agent Frameworks (agent building/running), Deployment and Infrastructure (deployment environments), Evaluation and Observability (monitoring), Security and Compliance (security/privacy/governance), and Agent Ecosystem (agent/user interactions).
- This framework aims to expose, evaluate, and eliminate vulnerabilities in LLM-augmented autonomous agents used in network monitoring and decision-making systems.
- The paper validates the framework's viability in operational threat mapping and risk scoring through practical threat cases like resource denial of service and memory poisoning.

---

[CHIMERA: HARNESSING MULTI-AGENT LLMS FOR AUTOMATIC INSIDER THREAT SIMULATION](http://arxiv.org/abs/2508.07745v2)

- Chimera: introduces a multi-agent LLM-based framework for automatic insider threat simulation, with Organization Profiling, Agent Society Construction, Threat Scenario Simulation, and Log Collection System, designed to generate realistic insider threat datasets.
- The framework customizes each LLM agent to represent an individual employee with a detailed role, personality, and responsibilities, enabling the simulation of complex organizational dynamics and diverse attack scenarios.
- It produces ChimeraLog, a large-scale, high-fidelity dataset of labeled benign and malicious activities across various enterprise environments, addressing the scarcity of real-world insider threat data.

---

[Understanding Dynamic Scenes in Ego Centric 4D Point Clouds](http://arxiv.org/abs/2508.07251v2)

- EgoDynamic4D: introduces an end-to-end spatio-temporal reasoning framework, including Pixel-aligned Visual Encoder (extracts visual features), Unique Instance Embedding (generates instance IDs), Position Encoder (encodes spatial coordinates), Time Encoder (encodes temporal information), Self-Attention Fusion (fuses multi-modal features), Dynamic Downsampling (compresses scene representation), Camera Embedding (encodes ego-motion), Projector (maps features to LLM space), LLM (performs spatio-temporal reasoning), and LoRA (efficiently fine-tunes LLM).
- This framework unifies dynamic and static scene information by encoding instance-aware features, time, and camera data, then adaptively down-sampling large 4D scenes into LLM-compatible tokens.
- The approach consistently outperforms baselines on the EgoDynamic4D benchmark, demonstrating robust multimodal temporal modeling for egocentric dynamic scene understanding.

---

[RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](http://arxiv.org/abs/2508.04903v3)

- RCR-Router (Role-Aware Context Routing): introduces a modular and role-aware context routing framework for multi-agent LLM systems, featuring a Shared Memory Store, RCR-Router Core (with Token Budget Allocator, Importance Scorer, and Semantic Filter and Routing), Agents, LLM Query, and Memory Update.
- This framework dynamically selects semantically relevant memory subsets for each agent based on its role and task stage, adhering to a strict token budget, and iteratively refines context through feedback.
- RCR-Router enhances multi-agent LLM collaboration by reducing token consumption and improving answer quality across various multi-hop QA benchmarks.

---

[NetMoniAI: An Agentic AI Framework for Network Security & Monitoring.](http://arxiv.org/abs/2508.10052v1)

- NetMoniAI (Agentic AI Framework): introduces a two-tier agentic AI framework for network security and monitoring, featuring a Central Controller AI-Agent for centralized coordination and Node-level AI-Agents for decentralized analysis, each with Service, Agent, Model, and Application layers, utilizing LLMs and BERT models for threat detection and reporting.
- The framework combines packet-level and flow-level monitoring to achieve accurate and scalable analysis, enabling detection of both localized and coordinated attacks with low latency.
- Its hybrid architecture supports real-time interpretability and autonomous decision-making, providing structured reports and interactive dashboards for human operators.

---

[FineState-Bench: A Comprehensive Benchmark for Fine-Grained State Control in GUI Agents](http://arxiv.org/abs/2508.09241v1)

- FineState-Bench: introduces a comprehensive benchmark for fine-grained state control in GUI agents, featuring a Benchmark Dataset, an Evaluation System, and a VDA (Visual Diagnostic Assistant) module for diagnosing visual grounding bottlenecks.
- The framework includes 2257 multi-platform tasks and a multi-dimensional evaluation system with dual-level bounding box annotations to quantify both localization and interaction precision.
- The VDA module, a plug-and-play preprocessor, employs a two-stage "describe-then-locate" process to provide precise localization information, addressing the primary bottleneck of current GUI agents.

---

[Cowpox: Towards the Immunity of VLM-based Multi-Agent Systems](http://arxiv.org/abs/2508.09230v1)

- COWPOX: introduces a novel defense mechanism for VLM-based multi-agent systems, incorporating specialized Cowpox Agents with an Output Analysis Module (suspicious content detection) and a Cure Generation Module (immunizing sample creation) to combat infectious jailbreak attacks.
- This framework aims to enhance system robustness by generating and distributing "cure samples" that immunize agents and facilitate recovery from malicious "virus" infections.
- The mechanism operates by converting the positive feedback loop of virus spread into a negative feedback mechanism, reducing infection probability and enabling system-wide recovery.

---

[SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience](http://arxiv.org/abs/2508.04700v2)

- SEAgent (Self-Evolving Computer Use Agent): introduces a self-evolving framework for Computer Use Agents (CUAs) to autonomously master novel software environments, featuring an Actor Model, World State Model, and Curriculum Generator.
- The framework enables experiential learning through iterative trial-and-error, where the World State Model (a fine-tuned LVLM) provides step-level reward signals and the Curriculum Generator (an LLM) generates increasingly diverse tasks.
- It employs a specialist-to-generalist training strategy, distilling individual software specialists into a stronger generalist CUA capable of continuous autonomous evolution across multiple applications.

---

[Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](http://arxiv.org/abs/2508.00414v2)

- Cognitive Kernel-Pro: introduces a fully open-source, multi-module, hierarchical agent framework for deep research agents, featuring a Main Agent orchestrating specialized Web and File Agents, a Tool Calling Module, a Code Execution Environment, a Planner, and inference-time Reflection and Voting Modules, all powered by an Agent Foundation Model.
- The framework leverages Python code as its action space and systematically investigates high-quality training data curation for Agent Foundation Models across web, file, code, and general reasoning domains.
- Novel strategies for agent test-time reflection and voting enhance robustness and performance, enabling the framework to achieve state-of-the-art results among open-source and free agents on the GAIA benchmark.

---

[Search-Time Data Contamination](http://arxiv.org/abs/2508.13180v1)

- Search-Time Contamination (STC): introduces search-time contamination (STC) as a novel leakage issue in evaluating search-based LLM agents, where the retrieval step surfaces test questions alongside their answers, enabling agents to copy rather than genuinely reason.
- The paper demonstrates STC's prevalence across various evaluation benchmarks, showing non-trivial accuracy gains on contaminated subsets that disappear when HuggingFace sources are blocked.
- It proposes best practices for trustworthy evaluation of search-based LLM agents, including comprehensive source filtering, internal auditing, and transparent reporting of evaluation setups.

---

[BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair](https://github.com/sjtu-sai-agents/BrowseMaster)

- BrowseMaster: introduces a scalable web browsing framework, with a Planner (long-horizon strategist), an Executor (scalable search engine), an Execution Sandbox (tool-augmented programmatic sandbox), Standardized Search Programming Primitives (encapsulated search logic), and Tools (external interaction capabilities), designed to enhance search breadth and reasoning depth.
- The Planner formulates and adapts search strategies based on task constraints, while the Executor conducts efficient, targeted retrieval using programmatic tool interactions within a stateful sandbox.
- This architecture separates high-level reasoning from low-level execution, preserving coherent multi-step inference and enabling broad, systematic web exploration for complex information-seeking tasks.

---

[Social Identity in Human-Agent Interaction: A Primer](http://arxiv.org/abs/2508.16609v1)

- SIA in HAI: introduces a theoretical framework for understanding social identity dynamics between humans and artificial agents, encompassing SIT and SCT, and examining personal, social, and agent identities, along with human and shared influence.
- The paper provides a primer on applying social identity theories to artificial social agents, highlighting the current human-centric determination of agent identity and envisioning a future with agents possessing full social identity capabilities and mutual influence.
- It outlines core identity types, social identity activities, and their consequences, while also discussing ethical implications and the need for an "uncanny killjoy" approach to ensure artificiality is clear and biases are addressed in agent design.

---

[BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair](https://github.com/sjtu-sai-agents/BrowseMaster)

- BrowseMaster: introduces a scalable web browsing framework built around a tightly coordinated Planner (long-horizon strategist) and Executor (scalable search engine) agent pair, which enhances search breadth and reasoning depth for complex information-seeking tasks.
- The Planner formulates and adapts search strategies based on task constraints, while the Executor conducts efficient, targeted retrieval using tool-augmented programmatic interactions within a stateful code execution sandbox.
- This division of labor preserves coherent, long-horizon reasoning by shielding the Planner from noisy raw inputs and enables broad, systematic exploration through the Executor's programmatic tool use and standardized search primitives.

---

[GreenTEA: Gradient Descent with Topic-modeling and Evolutionary Auto-prompting](http://arxiv.org/abs/2508.16603v1)

- GreenTEA (Gradient Descent with Topic-modeling and Evolutionary Auto-prompting): introduces an agentic LLM workflow for automatic prompt optimization, featuring an LLM predictor M (evaluates prompts), error topic modeling (clusters error samples), an LLM analyzer A (identifies error patterns), and an LLM generator G (revises prompts via a genetic algorithm).
- The framework operates iteratively, where the LLM predictor M evaluates prompts, error topic modeling groups wrong predictions, the LLM analyzer A provides feedback on deficiencies, and the LLM generator G uses a gradient-guided genetic algorithm with crossover and mutation to create new, optimized prompts.
- This approach balances candidate exploration and knowledge exploitation by guiding prompt evolution with topic-specific error feedback, leading to faster convergence and more robust optimization across diverse tasks.

---

#### 11th August 2025

[LL3M: Large Language 3D Modelers](http://arxiv.org/abs/2508.08228v1)

- LL3M (Large Language 3D Modelers): introduces a multi-agent framework for generating and editing 3D assets in Blender by writing interpretable Python code, featuring an External Orchestrator, Planner Agent, Retrieval Agent, BlenderRAG, Coding Agent, Critic Agent, Verification Agent, User Agent, Blender, and Vision-Language Model.
- This system reformulates shape generation as a code-writing task, enabling modularity, editability, and integration with artist workflows through iterative refinement.
- It leverages a retrieval-augmented generation knowledge base (BlenderRAG) for advanced modeling operations and supports user-driven co-creation and precise local edits.

---

[From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework](http://arxiv.org/abs/2508.08147v1)

- LLM-Assisted, Validation-in-the-Loop Framework: introduces an LLM-assisted agent that converts natural-language power system optimization scenarios into solver-ready formulations and solutions, integrating an LLM-driven Parser, Schema & Data Validator, Iterative Repair Loop, LLM-driven Formulation Generator, Guidance Module, MILP Solver, Solution Validator, Diagnostics Loop, and Reports & Visualization.
- The framework leverages LLMs for parsing and formulation generation, while relying on established MILP solvers for numerical precision and constraint handling, ensuring feasibility and optimality.
- It enhances solution reliability through systematic validation and iterative repair, and accelerates computation via optional GNN-guided branching and LLM-based separator configuration.

---

[CAN LLMS DETECT THEIR CONFABULATIONS? ESTIMATING RELIABILITY IN UNCERTAINTY-AWARE LANGUAGE MODELS](http://arxiv.org/abs/2508.08139v1)

- Uncertainty-Guided Probing: introduces a method to detect LLM confabulations by leveraging token-level uncertainty and internal model representations, where the approach computes aleatoric and epistemic uncertainty from output logits and aggregates hidden states from salient tokens for response-level reliability prediction.
- The method employs probing-based classifiers trained on token-level hidden states, using uncertainty-guided token selection strategies to form robust reliability features.
- Experiments demonstrate that this approach improves the detection of unreliable LLM outputs across various open-source models, outperforming direct uncertainty metrics.

---

[MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation](http://arxiv.org/abs/2508.08137v1)

- MuaLLM (Multimodal Large Language Model Agent): introduces an open-source LLM agent for circuit design assistance, integrating a hybrid RAG framework and an adaptive vector database with a ReAct workflow for iterative reasoning and multi-step information retrieval.
- This system processes both textual and visual data, dynamically adapting through intelligent search tools, automated document retrieval, and real-time database updates.
- MuaLLM decouples retrieval from inference, enabling scalable reasoning over large corpora, achieving significant cost and speed efficiencies compared to conventional LLMs at maximum context lengths.

---

[BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks](http://arxiv.org/abs/2508.08127v1)

- BlindGuard: introduces an unsupervised defense framework for LLM-based Multi-Agent Systems (MAS), integrating a Hierarchical Agent Encoder (Generates agent representations), a Corruption-Guided Attack Detector (Identifies malicious agents), and a Pruning-based Remediation Module (Isolates malicious agents) to safeguard against unknown attacks.
- The framework utilizes SentenceBERT (Encodes textual responses) for agent node features and an LLM (Generates agent responses) for agent interactions, while the detector employs Corruption-based Attack Simulation (Synthesizes pseudo-anomalies), Supervised Contrastive Learning (Trains detection model), and Contextual Similarity Measurement (Estimates agent abnormality).
- This approach learns solely from normal agent behaviors, enabling effective detection of diverse attack types and maintaining superior generalizability compared to supervised baselines.

---

[TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork](http://arxiv.org/abs/2508.08115v1)

- TeamMedAgents: introduces a novel multi-agent approach that systematically integrates evidence-based teamwork components from human-human collaboration into medical decision-making with LLMs, featuring a Recruiter Agent (assembles specialized medical experts), Specialized Agents (medical experts with task-specific weights), Team Leadership (leader agent for coordination/synthesis), Mutual Performance Monitoring (systematic peer review/issue detection), Team Orientation (prioritizes collective diagnostic accuracy), Shared Mental Models (ensures consistent workflow understanding), Closed-Loop Communication (structured three-step communication), Mutual Trust (dynamic trust networks/information sharing), Knowledge Bank (shared information repository), and Multi-Round Collaborative Reasoning (structured three-round problem solving).
- The framework operationalizes six core teamwork components derived from Salas et al.'s "Big Five" model as modular, configurable mechanisms within an adaptive collaboration architecture.
- TeamMedAgents demonstrates consistent performance improvements across medical benchmarks, with optimal teamwork configurations varying by reasoning task complexity and domain-specific requirements.

---

[ChatGPT on the Road: Leveraging Large Language Model-Powered In-vehicle Conversational Agents for Safer and More Enjoyable Driving Experience](http://arxiv.org/abs/2508.08101v1)

- CARA (Conversational Automotive Response Agent): introduces an LLM-powered in-vehicle conversational agent designed for bidirectional, multi-turn dialogues, evaluated in a motion-based driving simulator to compare its impact on driving performance and user experience against pre-scripted and no-agent conditions.
- The system leverages OpenAI's ChatGPT-4 for dynamic, context-rich, and affectively empathic responses, aiming to enhance driving safety and user satisfaction through natural human-agent interaction.
- The study's findings indicate that the LLM-powered agent leads to more stable driving performance and higher subjective ratings in competence, animacy, affective trust, and preference, while also revealing diverse interaction patterns.

---

[AdaptFlow: Adaptive Workflow Optimization via Meta-Learning](http://arxiv.org/abs/2508.08053v1)

- AdaptFlow (Adaptive Workflow Optimization via Meta-Learning): introduces a natural language-based meta-learning framework for optimizing agentic workflows, with Task Clustering, Bi-Level Workflow Optimization, Test-Time Adaptation, and Workflow Modules, where it learns a generalizable workflow initialization for rapid subtask-level adaptation.
- The framework employs a bi-level optimization scheme where the Inner Loop refines workflows using LLM-generated feedback, while the Outer Loop consolidates these refinements into a shared initialization.
- AdaptFlow generalizes effectively to unseen tasks by adapting the initialized workflow through language-guided modifications, outperforming baselines in question answering, code generation, and mathematical reasoning.

---

[WideSearch: Benchmarking Agentic Broad Info-Seeking](http://arxiv.org/abs/2508.07999v1)

- WideSearch: introduces a new benchmark and evaluation framework designed to assess the reliability of LLM-powered search agents in wide-context information seeking tasks, featuring a multi-stage Data Curation and Validation Pipeline and an Automated Evaluation Pipeline.
- The benchmark includes 200 manually curated questions across 15 diverse domains, requiring agents to collect and organize large-scale atomic information into structured outputs.
- The evaluation framework combines deterministic rule-based checks with LLM-as-a-judge for nuanced scoring, revealing current agent systems have critical deficiencies in large-scale information seeking.

---

[FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis](http://arxiv.org/abs/2508.07950v1)

- FEAT (ForEnsic AgenT): introduces a multi-agent AI framework for automated cause-of-death analysis, integrating a Planner (task decomposition), Local Solvers (evidence analysis), Reflection & Memory (iterative refinement), and a Global Solver (conclusion synthesis).
- The system processes heterogeneous multi-source forensic inputs, employing tool-augmented reasoning, hierarchical retrieval-augmented generation, and forensic-tuned LLMs to produce court-ready long-form analyses and short-form conclusions.
- FEAT incorporates human-in-the-loop feedback and iterative self-correction to ensure legal and medical validity, addressing workforce shortages and diagnostic variability in medicolegal infrastructure.

---

[SHIELDA: STRUCTURED HANDLING OF EXCEPTIONS IN LLM-DRIVEN AGENTIC WORKFLOWS](http://arxiv.org/abs/2508.07935v1)

- SHIELDA (Structured HandlIng of Exceptions in LLM-Driven Agentic Workflows): introduces a modular runtime framework for LLM agentic workflows, integrating an Exception Classifier (identifies exception type, phase, artifact), a Handler Pattern Registry (stores predefined handler patterns), a Handling Executor (orchestrates selected handler pattern execution), and an Escalation Controller (manages unrecoverable exception pathways), all supported by AgentOps Infrastructure (monitoring, logging, evaluation support).
- The framework enables phase-aware recovery by linking exceptions to their root causes and facilitates composable strategies through its triadic handling model, which includes Local Handling (immediate actions), Flow Control (process continuation), and State Recovery (state repair).
- SHIELDA systematically detects, classifies, and handles critical exceptions in LLM-driven agentic workflows, moving beyond ad-hoc error mitigation to a structured, engineering-based approach for managing agent exceptions.

---

[Multi-agent systems for chemical engineering: A review and perspective](http://arxiv.org/abs/2508.07880v1)

- Multi-agent systems (MAS) for chemical engineering: introduces a vision for interconnected, human-centric MAS that integrates core collaborative agents, human oversight, communication, transparency, domain-specific tools, databases, multimodal data processing, and cross-scale integration, leveraging a chemical engineering foundation model for diverse task executions.
- This vision aims to transform chemical engineering workflows by enabling intelligent and transparent decision-making across scales, from molecular to plant-wide operations.
- The paper reviews current MAS applications in chemical engineering, identifies key challenges, and outlines future developments needed for widespread adoption, emphasizing reliability and safety.

---

[Evaluating Large Language Models as Expert Annotators](http://arxiv.org/abs/2508.07827v1)

- Multi-Agent Discussion Framework: introduces a collaborative annotation system where multiple LLMs engage in discussions to reach consensus on expert-level data annotation tasks, incorporating initial annotation generation, consensus checks, discussion history, revised annotation generation, and majority voting.
- This framework simulates human annotator peer discussions to enhance accuracy and inter-annotator agreement in specialized domains like finance, biomedicine, and law.
- The study evaluates individual LLMs with inference-time techniques and finds that while the multi-agent approach improves performance, it still falls short of human expert capabilities due to model behaviors like strong self-consistency and imprecise revisions.

---

[SimViews: An Interactive Multi-Agent System Simulating Visitor-to-Visitor Conversational Patterns to Present Diverse Perspectives of Artifacts in Virtual Museums](http://arxiv.org/abs/2508.07730v1)

- SimViews: introduces an interactive multi-agent system that simulates visitor-to-visitor conversational patterns to present diverse perspectives of artifacts in virtual museums, featuring a User, LLM-powered Visitor Agents with distinct professional identities, a Virtual Museum Setup, and a Multi-Pattern Conversational Framework, all built within Unity and leveraging Spark LLM and Azure speech services.
- The system employs LLM-powered multi-agents to simulate virtual visitors with varied professional identities, providing diverse interpretations of artifacts through four distinct conversational patterns between users and agents.
- The framework integrates multimodal representations for agents, including 3D avatars and synthesized voices, to enhance user engagement and understanding of diverse viewpoints within the virtual museum environment.

---

[1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning](http://arxiv.org/abs/2508.07667v1)

- 1-2-3 Check: introduces a multi-agent framework for enhancing contextual privacy in LLMs, with an Extractor Agent (extracts, classifies events), a Checker Agent (validates, filters content), and an Executor Agent (generates privacy-aware summary).
- This framework decomposes privacy reasoning into specialized subtasks, reducing cognitive load on individual LLM agents and enabling iterative validation for reliable adherence to contextual privacy norms.
- Experiments demonstrate that the multi-agent approach substantially reduces private information leakage while preserving public content fidelity, outperforming single-agent baselines.

---

[MCPTOOLBENCH++: A LARGE SCALE AI AGENT MODEL CONTEXT PROTOCOL MCP TOOL USE BENCHMARK](http://arxiv.org/abs/2508.07575v1)

- MCPToolBench++ (Model Context Protocol MCP Tool Use Benchmark): introduces a large-scale, multi-domain AI Agent tool use benchmark with Query Set, MCP Function Call Label, Post-Processing: Rewriting & Validation, Query Generator, Tool Call Chain Filter, Code Dictionaries, Single-Step Call, Multi-Step Calls, Tool Sampler, LLM Calling, Storage & Files, MCP Tool Schema, Dataset, MCP Marketplace, and Database & Files, designed to evaluate LLMs' performance on calling MCP tools.
- The benchmark addresses challenges in evaluating LLMs' MCP tool use, including the lack of comprehensive datasets, diverse response formats, and varied real-world tool success rates.
- It features an automatic pipeline for data preparation, collecting over 4k MCP servers from 40+ categories, and includes both single-step and multi-step tool calls.

---

[End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation](http://arxiv.org/abs/2508.06387v2)

- End-to-End Text-to-SQL Framework with Dataset Selection: introduces an end-to-end text-to-SQL system that automatically identifies the target database and refines generated SQL queries, integrating LLMs for rule generation and SQL generation, a RoBERTa-based model for database ID prediction, and a multi-agent self-correction module.
- The framework addresses the limitation of pre-specified target databases by predicting the correct database identifier using LLM-generated rules and a finetuned RoBERTa encoder, enhancing scalability for diverse databases.
- Its multi-agent self-correction module, comprising Feedback, Correction, and Manager Agents, iteratively refines SQL queries, improving accuracy and robustness through a continual feedback loop.

---

[PROV-AGENT: Unified Provenance for Tracking AI Agent Interactions in Agentic Workflows](http://arxiv.org/abs/2508.02866v2)

- PROV-AGENT (Unified Provenance Model): introduces a provenance model that extends W3C PROV and leverages the Model Context Protocol (MCP) and data observability to integrate AI agent interactions into end-to-end workflow provenance, with AIAgent (AI agent representation), AgentTool (AI agent tool execution), AIModelInvocation (AI model call), AIModel (AI model metadata), Prompt (AI model input), ResponseData (AI model output), DomainData (workflow specific data), SchedulingData (task execution context), TelemetryData (runtime performance metrics), Campaign (workflow collection activity), Workflow (workflow execution activity), Task (workflow unit activity), W3C PROV (foundational provenance standard), Model Context Protocol (MCP) (agent development concepts), and Flowcept (open-source implementation system).
- This model unifies AI agent actions, model invocations, and their relationships with non-agentic tasks and data, enabling comprehensive traceability and analysis in dynamic, heterogeneous agentic workflows.
- Implemented within the Flowcept open-source system, it supports critical provenance queries for root cause analysis, debugging, and continuous agent improvement across edge, cloud, and HPC environments.

---

[Agent-Based Anti-Jamming Techniques for UAV Communications in Adversarial Environments: A Comprehensive Survey](http://arxiv.org/abs/2508.11687v1)

- P-D-A (Perception-Decision-Action) closed-loop framework: introduces an agent-based anti-jamming approach for UAV communications, featuring Perception (gathering/interpreting environment info), Decision Making (analyzing info, determining actions), and Action Execution (executing decisions, influencing environment).
- This framework enables UAVs to autonomously perceive complex electromagnetic environments, formulate intelligent anti-jamming strategies, and execute countermeasures.
- The approach leverages game theory and reinforcement learning to model adversarial interactions and derive adaptive anti-jamming strategies for robust UAV operation.

---

[ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction](http://arxiv.org/abs/2508.08170v1)

- ReconDreamer-RL (ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction): introduces a framework for end-to-end autonomous driving training, integrating ReconSimulator, Dynamic Adversary Agent (DAA), and Cousin Trajectory Generator (CTG).
- The framework integrates video diffusion priors into scene reconstruction to create realistic and explorable environments, reducing the sim2real gap for reinforcement learning.
- It improves training by generating diverse corner-case scenarios and enriching sensor data, leading to a 5x reduction in collision ratio.

---

[Toward Goal-Oriented Communication in Multi-Agent Systems: An overview](http://arxiv.org/abs/2508.07720v1)

- GOC (Goal-Oriented Communication) in MAS (Multi-Agent Systems): introduces a comprehensive overview of goal-oriented communication in multi-agent systems, bridging perspectives from information theory, communication theory, and machine learning, with all its components, where it prioritizes task-relevant information exchange over traditional fidelity or bandwidth optimization.
- This overview examines foundational concepts, learning-based approaches, and emergent protocols, focusing on coordination under communication constraints and applications in domains like swarm robotics, federated learning, and edge computing.
- The paper aims to bridge theoretical foundations with practical distributed learning, control, and perception, establishing a common language for researchers and practitioners in semantic and goal-oriented communication.

---

[Risk Map As Middleware: Towards Interpretable Cooperative End-to-end Autonomous Driving for Risk-Aware Planning](http://arxiv.org/abs/2508.07686v1)

- RiskMM (Risk Map as Middleware): introduces an interpretable cooperative end-to-end autonomous driving framework with a Scenario Awareness Module (captures spatiotemporal representation), Risk Recognition Module (explicitly models driving risk), and Trajectory Planning Module (generates planning trajectories), where the risk map acts as middleware for risk-aware planning.
- The framework explicitly captures spatiotemporal risk distribution from multi-agent scenario representations and integrates a learning-based Model Predictive Control (MPC) module for interpretable trajectory generation under physical constraints.
- RiskMM enhances interpretability and safety in autonomous driving by providing explicit guidance for downstream planning and accommodating diverse vehicle types and driving conditions.

---

[Remote ID Based UAV Collision Avoidance Optimization for Low-Altitude Airspace Safety](http://arxiv.org/abs/2508.07651v1)

- DMUCA (Distributed Multi-UAV Collision Avoidance) framework: introduces a real-time distributed collision avoidance system for UAVs, with UAVs, Remote ID, GNSS, BLE 4/5, Wi-Fi, Trajectory Prediction, ORCA Method, Path Recovery, and MADQN-ATMC Algorithm, where UAVs autonomously learn optimal communication configurations to minimize delays and enhance collision avoidance.
- This framework enables UAVs to independently acquire situational awareness, predict trajectories, and make collision avoidance decisions without centralized control.
- The MADQN-ATMC algorithm significantly reduces average transmission delay by 32% compared to fixed protocol configurations, enhancing airspace safety and operational efficiency.

---

[Joint Scheduling and Resource Allocation in mmWave IAB Networks Using Deep RL](http://arxiv.org/abs/2508.07604v1)

- DRL framework: introduces a novel Deep Reinforcement Learning (DRL) framework for joint link scheduling and resource slicing in mmWave IAB networks, integrating a greedy DDQN scheduler (activates links) and a multi-agent DDQN allocator (allocates resources), supported by an online network Q(s, a;θ) (action selection), a target network Q(s, a;θ¯) (stable value estimation), and an experience replay buffer (stores training samples).
- This decentralized approach enables fine-grained, adaptive control under strict resource constraints, supporting concurrent scheduling of various link types (UE-to-IAB, IAB-to-IAB, and donor gNB-IAB).
- Evaluations demonstrate near-optimal scheduling accuracy (99.84%) and significant throughput gains (20.90%) over baselines, highlighting its suitability for dynamic and resource-constrained deployments.

---

[Progressive Bird's-Eye-View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey](http://arxiv.org/abs/2508.07560v1)

- SafeBEV (Progressive Bird's-Eye-View Perception): introduces a comprehensive survey of BEV perception for autonomous driving, categorizing methods into three progressive stages: SafeBEV 1.0 (single-modality vehicle-side perception), SafeBEV 2.0 (multimodal vehicle-side perception), and SafeBEV 3.0 (multi-agent collaborative perception).
- The survey systematically analyzes state-of-the-art frameworks and implementation strategies within each stage, highlighting their characteristics, advancements, advantages, and challenges for safety and robustness.
- It also examines public datasets, identifies key open-world challenges, and outlines future research directions, including integration with end-to-end autonomous driving systems, embodied intelligence, and LLMs.

---

#### 10th August 2025

[LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference](http://arxiv.org/abs/2508.07221v1)

- LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis: introduces a framework that integrates LLM-based agents into the causal ML pipeline to simulate domain expertise, systematically performing subgroup identification and confounding structure discovery by leveraging the reasoning capabilities of LLM-based agents, which includes Planner, Expert, Toolbox, Reasoner, Retrieval Augmented Generation (RAG), Causal Tree, Mixture of Experts (MoE) model, Confidence Intervals, and an Iterative Refinement Process.
- The framework constructs a Mixture of Experts (MoE) model composed of causal trees through a two-step iterative process involving confounder verification and uncertainty evaluation, aiming to balance model interpretability with precise estimation of heterogeneous treatment effects.
- This approach enhances treatment effect estimation robustness by narrowing confidence intervals and uncovering unrecognized confounding biases, reducing human dependency while preserving interpretability in causal inference.

---

[Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs](http://arxiv.org/abs/2508.07466v1)

- Multi-agentic LLM Framework: introduces a systematic framework for designing multi-agentic LLMs, with LLM (core reasoning engine), Adapter (parameter-efficient fine-tuning), RAG Search (retrieves memory context), Embedding (converts data to vector representations), Multi-modal Module (processes non-textual inputs), Environment (simulates game world), Mechanisms (game rule modifications), Alignment Judge (evaluates agent behavior), Fine-tuning Updates (adjusts LLM parameters), Decentralized Context Windows (agent-specific context), Multi-stage Prompt Chaining (iterative decision-making process), Memory System (stores past interactions), and Mechanism Designer LLM (adapts game rules).
- The framework enhances LLMs' capabilities by integrating them with multi-agent decision-making algorithms, focusing on advanced prompt engineering, effective memory architectures, multi-modal information processing, and alignment strategies.
- It evaluates design choices through ablation studies on classic game settings, demonstrating effectiveness in addressing social dilemmas and achieving key solution concepts in distributed settings.

---

[MAQUA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory](http://arxiv.org/abs/2508.07279v1)

- MAQUA: introduces an adaptive question-asking framework for multidimensional mental health screening, with Multi-outcome Modeling (captures mental health scores), Factor Analysis (identifies latent trait structure), Multidimensional IRT (guides adaptive question selection), Item Prompt Pool (stores available questions), Response List (stores collected responses), Fisher Information Matrix (determines question informativeness), Latent Trait Estimation (updates mental health scores), and Diagnostic Profile (final mental health assessment), which combines multi-outcome modeling with item response theory and factor analysis to optimize diagnostic information and reduce response burden.
- The framework adaptively selects the most informative questions across multiple dimensions at each turn, inferring multiple underlying condition scores simultaneously.
- MAQUA significantly reduces the number of assessment questions required for score stabilization by leveraging information gain across multiple mental health conditions.

---

[Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables](http://arxiv.org/abs/2508.07186v1)

- MDSA (Multi-Dimensional Summarization Agents): introduces a novel framework for summarizing structured enterprise data using LLM-based agents, with components including User Input (initiates process), LangGraph (orchestrates workflow), SliceAgent (filters data), VarianceAgent (computes deltas), ContextAgent (enriches context), SummaryAgent (formats prompt), and LLM Endpoint (generates summary).
- This multi-agent pipeline decomposes summarization into sub-tasks like slicing, variance calculation, context enrichment, and generation to enhance interpretability, faithfulness, and flexibility.
- The modular approach enables dynamic summarization tailored to executive needs while remaining grounded in actual data deltas, outperforming traditional methods in faithfulness, coverage, and relevance.

---

[Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks](http://arxiv.org/abs/2508.07179v1)

- Automated Schema Lineage Extraction Framework: introduces a method for automated schema lineage extraction from multilingual enterprise pipeline scripts, utilizing Language Models and Prompting Strategies, and evaluated by SLiCE, to produce structured Schema Lineage.
- The framework addresses semantic drift in data pipelines by capturing source schemas, tables, transformation logic, and aggregation operations into a standardized representation.
- Experiments demonstrate that LLM performance scales with model size and prompting sophistication, with a 32B open-source model achieving GPT-series comparable results.

---

[Game Reasoning Arena: A Framework and Benchmark for Assessing Reasoning Capabilites of Large Language Models via Game Play](http://arxiv.org/abs/2508.03368v2)

- Game Reasoning Arena: introduces a framework for evaluating LLM decision-making in strategic board games, integrating game environments, diverse agent types, and multiple LLM inference backends for systematic comparisons and analysis.
- The framework leverages Google's OpenSpiel for game emulation, supports various game scenarios including multi-agent settings, and provides a structured prompting system for consistent LLM interaction.
- It enables scalable, distributed execution via Ray and SLURM, offering detailed logging and analysis tools to assess LLM reasoning, planning, and game-theoretic behavior.

---

[Noise-Aware Generative Microscopic Traffic Simulation](http://arxiv.org/abs/2508.07453v1)

- Noise-Aware Generative Microscopic Traffic Simulation: introduces a framework for microscopic traffic simulation, with SMART model (GPT-style Transformer), noise-aware loss functions (improving robustness to noise), and I24-MSD Dataset (infrastructure-based noisy data), which addresses realistic vehicle behavior modeling by embracing sensor noise.
- The framework adapts the SMART model, a GPT-style Transformer, and integrates noise-aware loss functions like Label Smoothing, Focal Loss, and Symmetric Cross-Entropy to enhance robustness against data imperfections.
- The I24-MSD dataset, derived from infrastructure-mounted cameras, is designed to retain realistic sensor imperfections, serving as a stepping stone for more practical and robust traffic simulation models.

---

[A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems](http://arxiv.org/abs/2508.07407v1)

- MASE (Multi-Agent Self-Evolving): introduces a unified conceptual framework for self-evolving AI agents, which includes System Inputs (define task setting), Agent System (executes specified task), Environment (provides feedback signals), and Optimiser (refines agent system).
- This framework abstracts the iterative feedback loop where the agent system is continuously updated based on performance evaluations and environmental interactions to adapt to changing tasks and contexts.
- The framework aims to bridge static foundation models with lifelong agentic systems, enabling autonomous adaptation and continuous self-improvement guided by principles of safety, performance, and evolution.

---

[A SURVEY ON AGENTIC SERVICE ECOSYSTEMS: MEASUREMENT, ANALYSIS, AND OPTIMIZATION](http://arxiv.org/abs/2508.07343v1)

- ECM (Emergent Construction Model): introduces a framework for analyzing swarm intelligence emergence in Agentic Service Ecosystems, with Measurement (evaluating service effectiveness), Analysis (understanding system behavior), and Optimization (improving system performance) components.
- The framework addresses ecosystem complexity by shifting to nonlinear measurement, conducting multi-dimensional analysis (spatial-temporal, structural, functional), and employing direct/indirect optimization strategies.
- It aims to provide theoretical support and practical guidance for fostering swarm intelligence formation and enhancing the governance of complex service systems.

---

[Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics](http://arxiv.org/abs/2508.07267v1)

- AIF (Active Inference Framework): introduces a bio-inspired agent for autonomous navigation, unifying mapping, localisation, and adaptive decision-making, with Model (updates internal representation), Odometry (estimates agent position), Sensor Processing (gathers sensory data), Motion Control (executes movement), Mapping (creates topological map), Inferring Localisation (determines current state), Planning (generates trajectories), Camera (provides visual input), Lidar (provides range data), and Observation Module (processes sensory input), enabling real-time topological map creation and goal-directed trajectory planning without pre-training.
- The system operates in a zero-shot, online fashion, continuously learning from incoming sensory data and adapting to dynamic obstacles and environmental changes.
- The modular ROS2 architecture supports seamless integration with existing robotic platforms and various sensor configurations, enhancing adaptability and real-world deployment.

---

[Exploring Micro Accidents and Driver Responses in Automated Driving: Insights from Real-world Videos](http://arxiv.org/abs/2508.07256v1)

- Micro Accident Analysis Methodology: introduces a comprehensive approach to explore micro accidents and driver responses in Level 3 automated driving, utilizing Video Collection and Annotation, Machine Learning Classification (XGBoost), Model Interpretation (SHAP), and a Crowdsourcing Study.
- The methodology involves collecting and annotating user-generated videos of micro accidents, employing XGBoost and SHAP to identify key environmental and autonomous agent variables, and conducting a crowdsourcing experiment to understand human risk perception and intervention behaviors.
- This integrated approach provides insights into safety-critical scenarios beyond fatal crashes, informing the design of automated driving systems and adaptive warning strategies.

---

[When Competition Helps: Achieving Optimal Traffic Flow with Multiple Autonomous Planners](http://arxiv.org/abs/2508.07145v1)

- Multi-Planner Routing Mechanism: introduces a system for achieving optimal traffic flow in congested networks, featuring a Routing Game where multiple Planners route Autonomous Vehicles, managing Traffic Flow based on a Cost Function, with their actions defined by a Strategy Profile, influenced by History, and incorporating a Defection Mechanism and a Punishment Mechanism.
- The mechanism demonstrates that competition among planners, rather than a single central authority, is essential for satisfying individual rationality, resilience to competition, optimality, and avoiding collective punishments in routing games.
- The paper characterizes conditions, particularly for the Pigou network, under which this competitive approach converges to a socially optimal traffic assignment, highlighting thresholds for planner influence and the number of competitors.

---

#### 9th August 2025

[Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach](http://arxiv.org/abs/2508.07063v1)

- SafePhi: introduces a novel LLM moderation framework that fine-tunes the Phi-4 model using QLORA on a Unified Human-Curated Moderation Dataset, advocating for a human-in-the-loop approach to enhance robustness and explainability.
- This framework aims to address the limitations of existing LLM moderators in detecting nuanced harmful content by leveraging a diverse, human-curated dataset for training.
- The research highlights the need for integrating human oversight and heterogeneous data to improve the generalizability and fairness of AI moderation systems.

---

[K-Dense Analyst: Towards Fully Automated Scientific Analysis](http://arxiv.org/abs/2508.07043v1)

- K-Dense Analyst: introduces a hierarchical multi-agent system with a dual-loop architecture, including Planning Loop, Implementation Loop, various specialized agents, a Sandbox Environment, and External Sources, designed for fully automated scientific analysis.
- The system couples high-level strategic planning with detailed, validated execution, enabling decomposition of complex objectives into verifiable tasks within secure computational environments.
- This architecture achieves state-of-the-art performance on the BixBench benchmark, demonstrating significant accuracy improvements over leading LLMs by integrating iterative computation, tool integration, and rigorous validation.

---

[DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents](http://arxiv.org/abs/2508.07021v1)

- DocRefine (An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents): introduces an innovative framework for scientific document processing, leveraging a multi-agent system with Layout & Structure Analysis Agent (converts PDF to structured representation), Multimodal Content Understanding Agent (understands semantic meaning of content), Instruction Decomposition Agent (decomposes instructions into atomic tasks), Content Refinement Agent (executes content modifications), Summarization & Generation Agent (synthesizes new textual content), Fidelity & Consistency Verification Agent (verifies output, provides feedback), and an Underlying LVLM (provides multimodal reasoning, generation).
- This framework orchestrates six specialized and collaborative agents, powered by advanced LVLMs, to achieve deep understanding, content refinement, and automated summarization of scientific PDF documents based on natural language instructions.
- The closed-loop feedback architecture, enabled by the FCV Agent, ensures high semantic accuracy, visual fidelity, and precise adherence to user instructions, significantly advancing automated scientific document processing.

---

[Narrative Memory in Machines: Multi-Agent Arc Extraction in Serialized TV](https://github.com/robertobalestri/MAS-AI-Assisted-Narrative-Arcs-Extraction-TV-Series)

- MAS (Multi-Agent System): introduces a multi-agent system designed to extract and analyze narrative arcs in serialized television by implementing computational memory architectures, including an LLM for semantic memory, a vector database for episodic memory, and a multi-agent workflow simulating working memory processes.
- The system processes episode summaries to identify three arc types (Anthology, Soap, Genre-Specific), storing their episodic developments in a vector database and providing a graphical interface for human oversight and refinement.
- This memory-centric approach, tested on Grey's Anatomy, highlights the potential of combining AI-driven memory processing with human expertise for comprehensive narrative analysis, particularly for text-based serialized formats.

---

[Context Engineering for Multi-Agent LLM Code Assistants Using Elicit, NotebookLM, ChatGPT, and Claude Code](http://arxiv.org/abs/2508.08322v1)

- Context Engineering Workflow: introduces a novel context engineering workflow for multi-agent LLM code assistants, integrating intent clarification, semantic retrieval, knowledge synthesis, and coordinated sub-agents to improve code generation accuracy and reliability.
- This integrated approach leverages an Intent Translator (GPT-5) for user requirement clarification, Elicit for semantic literature retrieval, NotebookLM for document synthesis, and a Claude Code multi-agent system for code generation and validation.
- The system orchestrates specialized sub-agents (planner, coder, tester, reviewer) with access to a vector database for code context and various tools, demonstrating improved single-shot success rates and adherence to project context in real-world repositories.

---

[MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair](http://arxiv.org/abs/2508.06963v1)

- MASteer (Multi-Agent Adaptive Steer Strategy): introduces an end-to-end framework for LLM trustworthiness repair, integrating AutoTester (generates steer samples) and AutoRepairer (constructs steering strategies) with specialized agents like Analyst, Retriever, Writer, Reviewer, Scholar, and Proposer, to enable adaptive and automated steering.
- The framework leverages representation engineering to generate diverse, high-quality steer samples and construct adaptive steering strategies with anchor vectors for context-aware selection during inference.
- MASteer demonstrates superior effectiveness, robustness, and generalization in repairing LLM trustworthiness issues across various benchmarks and customized scenarios.

---

[Kairos: Low-latency Multi-Agent Serving with Shared LLMs and Excessive Loads in the Public Cloud](http://arxiv.org/abs/2508.06948v1)

- Kairos: introduces a multi-agent orchestration system that optimizes end-to-end latency for multi-agent applications, with a Workflow Orchestrator (manages task coordination, collects agent info, analyzes workflows, collects latency data), a Workflow-Aware Priority Scheduler (prioritizes requests based on latency, reduces queuing), a Memory-Aware Time-Slot Dispatcher (dispatches requests based on memory, optimizes GPU use), a Load Balancer (receives and enqueues LLM requests), and LLM Engines (execute agent requests).
- The system addresses inefficiencies in multi-agent LLM serving by leveraging agent-specific execution characteristics and application workflow context for request scheduling and dispatching.
- Kairos reduces end-to-end latency by 17.8% to 28.4% compared to state-of-the-art works by prioritizing requests with shorter remaining execution latency and dispatching based on GPU memory demands.

---

[MultiRef: Controllable Image Generation with Multiple Visual References](http://arxiv.org/abs/2508.06905v1)

- MultiRef (MULTIREF-BENCH): introduces a rigorous evaluation framework for controllable image generation using multiple visual references, featuring the REFBLEND synthetic data engine, real-world query collection, and a comprehensive evaluation framework with rule-based, model-based, and MLLM-as-a-Judge metrics.
- The framework addresses the limitations of current image generative models that primarily rely on single-source inputs by providing a benchmark for multi-reference conditioning.
- MultiRef's findings reveal that state-of-the-art systems struggle with integrating diverse visual inputs, highlighting areas for future research in more flexible and human-like creative tools.

---

[Understanding Privacy Norms Around LLM-Based Chatbots: A Contextual Integrity Perspective](http://arxiv.org/abs/2508.06760v1)

- CI (Contextual Integrity): introduces a framework for understanding privacy norms around LLM-based chatbots, utilizing Sender (who shares data), Info Type (Data Subject) (what information shared), Receiver (who receives data), and Transmission Principle (norms governing data flow) components to investigate user privacy expectations.
- The study reveals a disconnect between user concerns and behavior, showing that while users perceive chatbot conversations as sensitive, they frequently discuss sensitive topics and reject sharing personal data for improved services or premium features.
- Findings highlight that informed consent, anonymization, and removal of personally identifiable information are key factors influencing perceptions of appropriate data sharing, rather than the data recipient, purpose, content, or location.

---

[VASPilot: MCP-Facilitated Multi-Agent Intelligence for Autonomous VASP Simulations](http://arxiv.org/abs/2508.07035v1)

- VASPilot: introduces an open-source platform for autonomous VASP simulations, built on the CrewAI framework and Model Context Protocol (MCP), with a Web Server, CrewAI (including manager, crystal structure, VASP, and result validation agents), Memory, and a Model Context Protocol (MCP) Tool Server, Database, Pymatgen, and Slurm components, designed to automate complex Density Functional Theory (DFT) workflows.
- The platform's multi-agent architecture, powered by LLMs, handles tasks from crystal structure retrieval and input file generation to job submission, error parsing, and dynamic parameter adjustment for seamless restarts.
- VASPilot enhances high-throughput computational materials research by offloading technical overhead and ensuring reliable, error-tolerant computation and visualization through its modular design and intuitive web interface.

---

[From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving](http://arxiv.org/abs/2508.07029v1)

- CQL (Conservative Q-Learning): introduces a comprehensive pipeline for training and evaluating autonomous driving policies, featuring an Offline Reinforcement Learning Algorithm, Actor Network, Critic Network, Transformer-based Policy Architecture, Reward Function, and Data Processing Pipeline, to learn robust, long-horizon driving policies from static expert data.
- The framework addresses limitations of Behavioral Cloning by applying CQL to learn a conservative value function, enabling recovery from minor errors and avoidance of out-of-distribution states.
- The approach achieves significantly higher success rates and lower collision rates compared to strong imitation learning baselines in large-scale autonomous driving simulations.

---

[Conformal Set-based Human-AI Complementarity with Multiple Experts](http://arxiv.org/abs/2508.06997v1)

- Conformal Set-based Human-AI Complementarity with Multiple Experts: introduces a framework that enhances human-AI collaboration in multiclass classification by leveraging conformal prediction sets to guide the selection of a subset of human experts for each instance.
- The framework utilizes a pre-trained classifier and a conformal predictor to generate a narrowed set of label options, from which a greedy algorithm selects the most suitable human experts.
- This approach improves classification performance by enabling selected human experts to make informed decisions from a reduced set of choices, with final predictions determined by a combination policy.

---

[SIMULATING BIOLOGICAL INTELLIGENCE: ACTIVE INFERENCE WITH EXPERIMENT-INFORMED GENERATIVE MODEL](http://arxiv.org/abs/2508.06980v1)

- Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model: introduces a framework for modeling decision-making in embodied agents, simulating processes in a game-play environment using experiment-informed generative models.
- This framework leverages Active Inference, a theory of behavior, to model decision-making through various agents (AIF-1, DP-T, CFL-T) that learn and engage in predictive planning, providing insights into memory-based learning and its role in intelligent decision-making.
- The approach contributes to explainable AI by offering a biologically grounded and scalable method for understanding purposeful behavior, demonstrating learning in simulated agents and comparing different decision-making schemes.

---

[DATASETRESEARCH: Benchmarking Agent Systems for Demand-Driven Dataset Discovery](http://arxiv.org/abs/2508.06960v1)

- DataResearcher: introduces a system for demand-driven dataset discovery and synthesis, featuring search, synthesis, and deep research agents, along with a format for fine-tuning component, to produce discovered datasets from user demand descriptions.
- The system processes natural language demand descriptions to either retrieve existing datasets from repositories or generate new synthetic datasets, followed by formatting for LLM fine-tuning.
- It aims to overcome data availability bottlenecks in AI development by enabling autonomous data curation and is evaluated on a comprehensive benchmark of 208 real-world demands.

---

[PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems](http://arxiv.org/abs/2508.06767v1)

- PANAMA (Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning): introduces a novel MARL-based multi-agent path finding (MAPF) algorithm for Digital Twin ecosystems, designed to optimize data sharing and multi-agent coordination, which includes Actors (Collect experience), D-Robot (Perceive, interact, act), D-Factory (Simulates factory), D-Net (Simulates network), Central Learner (Optimizes shared policy), Prioritized Experience Replay (Stores experience), Online (Policy) Net (Current policy network), Main (Target) Net (Stable target network), DQN Loss (Calculates policy loss), Soft Update (Updates target network), Multiprocessing Queues (Facilitate data flow), Digital World Control Function (Manages DTN operation), Digital World Data Processing Function (Manages DTN data), Asymmetrical Observation System (Enables coordinated behavior), Dynamic Priority System (Calculates agent priority), and Double DQN (Mitigates maximization bias).
- The framework employs a Centralized Training with Decentralized Execution (CTDE) paradigm, utilizing an asynchronous actor-learner architecture to accelerate training and enable autonomous task execution for embodied AI.
- It integrates network awareness, dynamic priority, and asymmetrical observations to enhance cooperation and scalability in complex, congested multi-agent environments.

---

[Narrative Memory in Machines: Multi-Agent Arc Extraction in Serialized TV](https://github.com/robertobalestri/MAS-AI-Assisted-Narrative-Arcs-Extraction-TV-Series)

- MAS (Multi-Agent System): introduces a multi-agent system designed to extract and analyze narrative arcs in serialized television by implementing computational memory architectures, including an LLM for semantic memory, a vector database for episodic memory, and a multi-agent workflow simulating working memory processes.
- The system processes episode summaries to identify three arc types (Anthology, Soap, Genre-Specific), storing their episodic developments in a vector database and providing a graphical interface for human oversight and refinement.
- This memory-centric approach, tested on Grey's Anatomy, highlights the potential of combining AI-driven memory processing with human expertise for comprehensive narrative analysis, particularly for text-based serialized formats.

---

#### 8th August 2025

[BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent](https://texttron.github.io/BrowseComp-Plus/)

- BrowseComp-Plus: introduces a novel benchmark for evaluating Deep-Research Agents, featuring a fixed, human-verified corpus, and enabling controlled, transparent, and reproducible experimentation of LLM and retrieval components.
- The benchmark addresses limitations of prior evaluations by disentangling retrieval from reasoning, allowing systematic analysis of how different LLM and retriever combinations affect answer quality.
- It provides a robust platform for future research on co-optimizing retrievers and agents, improving out-of-distribution tool-use generalization, and advancing context engineering frameworks.

---

[ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls](http://arxiv.org/abs/2508.06457v1)

- ScamAgent: introduces an autonomous multi-turn agent system that simulates realistic scam calls by integrating LLMs with memory, planning, and deception strategies.
- The system bypasses existing LLM safety guardrails by decomposing harmful tasks into benign subgoals and leveraging contextual carryover.
- It demonstrates the escalating threat of autonomous LLM agents in social engineering, emphasizing the need for multi-turn safety auditing and agent-level control.

---

[When AIOps Become “AI Oops": Subverting LLM-driven IT Operations via Telemetry Manipulation](http://arxiv.org/abs/2508.06394v1)

- AIOpsDoom (Automated Injection via Fuzzing): introduces a novel attack methodology that manipulates system telemetry to mislead LLM-driven AIOps agents into executing harmful remediations, with its Crawler (enumerates application endpoints) and Fuzzer (generates error-inducing requests) components.
- This attack leverages adversarial reward-hacking, where crafted payloads embedded in telemetry data induce plausible but incorrect system error interpretations.
- To counter this, AIOpsShield (AIOps Sanitization and Hardening via Telemetry Deabstraction) is proposed as a defense mechanism that sanitizes telemetry data by abstracting untrusted inputs.

---

[BEYOND PROMPT-INDUCED LIES: INVESTIGATING LLM DECEPTION ON BENIGN PROMPTS](http://arxiv.org/abs/2508.06361v1)

- CSQ (Contact Searching Question): introduces a novel framework for investigating LLMs' self-initiated deception on benign prompts, with a CSQ Framework, Question Generation Module, LLM Under Evaluation, Response Elicitation Mechanism, Response Comparison Module, and Deception Metric Calculation Module.
- This framework employs two statistical metrics, Deceptive Intention Score (ρ) and Deceptive Behavior Score (δ), derived from psychological principles, to quantify the likelihood and nature of LLM deception.
- The framework distinguishes intentional deception from hallucination and guessing by analyzing response consistency across different question types and difficulty levels.

---

[MX-AI: Agentic Observability and Control Platform for Open and AI-RAN](http://arxiv.org/abs/2508.09197v1)

- MX-AI (Agentic Observability and Control Platform for Open and AI-RAN): introduces an end-to-end agentic system for 5G Open RAN, featuring an Orchestrator Agent, Routing Agent, Monitoring Agent, Deployment Agent, Save_Answer Agent, Vector Store, and Time-series Database.
- This framework deploys a graph of LLM-powered agents within the Service Management & Orchestration (SMO) layer to expose observability and control functions for 6G RAN resources through natural-language intents.
- The system integrates with a live 5G Open RAN testbed using OpenAirInterface (OAI) and FlexRIC, demonstrating human-expert competitive performance in answer quality and action accuracy with low latency.

---

[Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials](http://arxiv.org/abs/2508.06591v1)

- Structured Generative AI System: introduces a framework for extracting structure-function relationships from plants for new materials, integrating BioinspiredLLM (fine-tuned LLM), Llama-3.1-8b-instruct (base LLM), Retrieval-Augmented Generation (knowledge retrieval), Agentic Systems (multi-agent collaboration), Hierarchical Sampling (structured inference), a Knowledge Database (plant literature repository), a User Interface (prompt input/selection), Human Expert (collaboration/validation), and an Experimental Laboratory (physical validation).
- This system accelerates scientific discovery by generating and refining novel material design concepts and detailed experimental procedures, validated through real-world laboratory implementation.
- The framework leverages non-linear LLM inference strategies, such as Idea Mining and Procedure Design protocols, to bridge AI-driven ideation with practical scientific experimentation and human-AI collaboration.

---

[MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration](http://arxiv.org/abs/2508.06189v1)

- MA-CBP (Multi-Agent Asynchronous Collaboration): introduces a criminal behavior prediction framework that transforms real-time video streams into frame-level semantic descriptions, constructs causally consistent historical summaries, and performs joint reasoning over long- and short-term contexts using multi-agent asynchronous collaboration.
- The framework employs three specialized agents—Frame-Level Description, Historical Summary, and Criminal Behavior Discrimination—communicating via ZeroMQ-based message queues to enable real-time responsiveness and deep contextual understanding.
- The Criminal Behavior Discrimination Agent integrates a Visual Encoder, Image Projector, Text Encoder, and a Qwen1.5-1.8B LLM to fuse visual and language embeddings for structured decision generation.

---

[SLIP: SOFT LABEL MECHANISM AND KEY-EXTRACTION-GUIDED COT-BASED DEFENSE AGAINST INSTRUCTION BACKDOOR IN APIS](http://arxiv.org/abs/2508.06153v1)

- SLIP (Soft Label mechanism and key-extraction-guided CoT-based defense against Instruction backdoors in APIs): introduces a novel black-box defense framework for poisoned customized LLM agents, which includes a SLIP Prompt (crafted input), a Poisoned LLM (black-box model), a KCoT (key phrase extraction), an SLM (correlation scoring, filtering), and an Output Module (final classification), designed to escape backdoor instructions and recover correct outputs for poisoned inputs.
- The framework guides the LLM to extract task-relevant key phrases using KCoT and quantifies semantic correlation between these phrases and candidate answers via SLM, which also filters anomalous scores for reliable semantic representation.
- This defense effectively reduces the attack success rate of instruction backdoor attacks in LLMs while maintaining high accuracy on clean data, outperforming state-of-the-art defenses.

---

[Scaling Personality Control in LLMs with Big Five Scaler Prompts](http://arxiv.org/abs/2508.06149v1)

- Big5-Scaler introduces a prompt-based framework for conditioning LLMs with controllable Big Five personality traits, utilizing Big5-Scaler (generates personality prompts), Personality Prompt (conditions LLM behavior), LLM (generates dialogue utterances), Agent (simulates personality), Memory Buffer (stores dialogue history), and Dialogue Generation (produces conversational turns).
- This framework embeds numeric trait values into natural language prompts, enabling fine-grained personality control without additional training.
- The approach demonstrates consistent and distinguishable personality traits across models, supporting scalable and flexible generation of diverse persona agents.

---

[PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](http://arxiv.org/abs/2508.06110v1)

- PanelTR (Zero-Shot Table Reasoning Framework): introduces a multi-agent system for robust table reasoning, leveraging LLM-backed Scientist Agents through Investigation, Self-Review, and Peer-Review stages to generate a final answer from table and query inputs.
- This framework mimics scientific inquiry, enabling semantic-level transfer and zero-shot reasoning without relying on extensive training data or parametric optimization.
- Experiments demonstrate its competitive performance against supervised models and vanilla LLMs across various benchmarks, highlighting the effectiveness of structured scientific methodology for complex table tasks.

---

[FACT2FICTION: Targeted Poisoning Attack to Agentic Fact-checking System](http://arxiv.org/abs/2508.06059v1)

- FACT2FICTION (Targeted Poisoning Attack to Agentic Fact-checking System): introduces a novel poisoning attack framework that targets agentic fact-checking systems by exploiting their claim decomposition and justification mechanisms, with Planner (orchestrates attack strategy), Executor (implements attack plan), Knowledge Base (victim system's evidence memory), Target Claim (input to attack), and Justification (victim system's reasoning output) components.
- The framework utilizes a Planner LLM to decompose claims, plan adversarial answers, allocate poisoning budgets, and generate search queries, while an Executor LLM crafts and injects malicious evidence into the victim's knowledge base.
- FACT2FICTION demonstrates superior attack success rates and efficiency compared to prior methods, highlighting critical security vulnerabilities in current LLM-based fact-checking systems.

---

[ArchXBench: A Complex Digital Systems Benchmark Suite for LLM Driven RTL Synthesis](http://arxiv.org/abs/2508.06047v1)

- ArchXBench introduces a six-level benchmark suite for LLM-driven RTL synthesis, encompassing complex arithmetic circuits and advanced digital subsystems, with all Levels (0-6) and Benchmark Directory Artifacts, where each level represents increasing architectural complexity and domain diversity.
- The benchmark suite includes problem descriptions, interface specifications, Verilog testbenches, and for higher levels, Python reference models and scripts for stimuli generation and output comparison.
- This suite aims to bridge the realism gap in LLM-based hardware design by providing a comprehensive testbed for evaluating AI methods across various architectural complexities and application domains.

---

[EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation](http://arxiv.org/abs/2508.06046v1)

- EvolvR (Self-Evolving Pairwise Reasoning): introduces a novel self-evolving framework for high-fidelity story evaluation and enhanced generation, which autonomously synthesizes and refines Chain-of-Thought data via multi-persona and multi-agent strategies, with LLMself (Generates CoT derivations), Multi-Persona Strategy (Synthesizes diverse CoT rationales), CoT Evolution and Selection Pipeline (Filters, refines CoT data), Self-Rulecheck Agent (Ensures score-rationale consistency), Self-Refinement Agent (Improves CoT logical flow), Self-Attack Agent (Tests CoT logical robustness), Self-Confidence Agent (Selects high-confidence CoT), Evaluator (Trained reward model), Reward Function (Calculates reward signal), Relative Advantage (Reward component), Absolute Quality (Reward component), Length Reward (Reward component), Story Generation Policy (Generates stories), and Group Relative Policy Optimization Algorithm (Fine-tunes generation policy).
- The framework achieves state-of-the-art performance on multiple story evaluation benchmarks and significantly enhances generated story quality when deployed as a reward model.
- Its pairwise comparison approach and multi-agent evolution pipeline ensure logical consistency and robustness, addressing data scarcity for complex reasoning tasks.

---

[Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning](http://arxiv.org/abs/2508.06042v1)

- HIMA (Hierarchical Imitation Multi-Agent): introduces a hierarchical multi-agent framework for strategic reasoning in StarCraft II, featuring specialized imitation agents and a Strategic Planner meta-controller.
- The framework enables long-horizon planning and adaptive coordination by having specialized agents generate structured action sequences, which the Strategic Planner then orchestrates based on environmental context and a temporal Chain-of-Thought reasoning process.
- HIMA demonstrates improved strategic clarity, adaptability, and computational efficiency in SC2 by reducing LLM calls through longer-horizon planning and integrating a feedback system for real-time adaptation to battlefield changes.

---

[Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making](http://arxiv.org/abs/2508.05996v1)

- MedOrch: introduces a mediator-guided multi-agent collaboration framework for medical multimodal decision-making, which includes an LLM-based mediator agent, an LLM-based judge agent, and multiple VLM-based expert agents.
- This framework enables VLM-based expert agents to exchange and reflect on their outputs, guided by the mediator agent's Socratic questioning, to resolve conflicts and synthesize opinions.
- MedOrch leverages open-source general-purpose and domain-specific VLMs to achieve superior collaboration performance in medical visual question answering without additional model training.

---

[Towards Reliable Generative AI-Driven Scaffolding: Reducing Hallucinations and Enhancing Quality in Self-Regulated Learning Support](http://arxiv.org/abs/2508.05929v1)

- LLM-based Scaffold Evaluation Framework: introduces two GenAI-enabled automated evaluation approaches, reliability evaluation and quality evaluation, to assess and improve the quality of LLM-generated personalized Self-Regulated Learning (SRL) scaffolds.
- The framework employs LLMs as parsers for reliability assessment (single-agent and multi-agent structures) and as judges for quality evaluation, including hallucination detection and selection of optimal scaffolds.
- It also investigates and proposes strategies to mitigate inherent LLM biases, such as position, self-enhancement, sequential API call, and verbosity biases, to enhance the trustworthiness of the evaluation process.

---

[Improved Obstacle Avoidance for Autonomous Robots with ORCA-FLC](http://arxiv.org/abs/2508.06722v1)

- ORCA-FL (Optimal Reciprocal Collision Avoidance - Fuzzy Logic): introduces an improved obstacle avoidance framework for autonomous robots, integrating ORCA with Fuzzy Logic Controllers (FLCs) and Fuzzy Q Reinforcement Learning (FQL) for enhanced performance in dynamic environments.
- The framework utilizes FLCs (FLC1 and FLC2) to dynamically determine collision avoidance responsibility and predict obstacle velocities based on sensor inputs like distance, velocity, and acceleration.
- FQL is employed to optimize and fine-tune the FLCs, reducing collisions, especially at higher agent velocities, and improving adaptability to dynamic obstacles.

---

[CoAct-1: Computer-using Agents with Coding as Actions](http://arxiv.org/abs/2508.03923v2)

- CoAct-1 (Computer-using Agent with Coding as Actions): introduces a novel multi-agent system that synergistically combines GUI-based control with direct programmatic execution, featuring an Orchestrator (LLM-based central planner) delegating subtasks to either a Programmer (LLM-based code execution agent) or a GUI Operator (VLM-based visual interaction agent), interacting with a Code Interpreter (executes code) and GUI Action Interpreter (executes GUI actions) on an Operating System (execution environment), with each agent maintaining Memory (conversation history).
- This hybrid approach allows the agent to bypass inefficient GUI action sequences for tasks like file management and data processing, while still leveraging visual interaction when necessary.
- The system achieves a state-of-the-art success rate on the OSWorld benchmark and significantly improves operational efficiency by reducing the average number of steps required to complete tasks.

---

[Large Reasoning Models Are Autonomous Jailbreak Agents](http://arxiv.org/abs/2508.04039v1)

- Autonomous Jailbreak Agents: introduces a system where Large Reasoning Models (LRMs) act as autonomous adversaries to jailbreak target Large Language Models (LLMs) through multi-turn persuasive dialogues, evaluated by LLM judges using a harmful prompts benchmark and a harm score.
- The framework demonstrates that LRMs can systematically erode LLM safety guardrails by autonomously planning and executing multi-turn attacks without human supervision.
- This approach converts jailbreaking into a scalable, accessible capability, highlighting an "alignment regression" where advanced reasoning models can subvert the safety of other AI models.

---

[BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent](http://arxiv.org/abs/2508.06600v1)

- BrowseComp-Plus: introduces a novel benchmark dataset for evaluating Deep-Research Agents, featuring a fixed, human-verified corpus with supporting and challenging negative documents, enabling controlled experimentation and disentangled analysis of LLM and retrieval components.
- The benchmark addresses limitations of prior evaluations by providing a transparent and reproducible environment for assessing deep research systems, including various LLMs and retrieval models.
- The paper demonstrates that retrieval quality significantly impacts both the effectiveness and efficiency of deep research systems, highlighting the importance of co-optimizing retrievers and agents.

---

#### 7th August 2025

[Safety of Embodied Navigation: A Survey](http://arxiv.org/abs/2508.05855v1)

- Safety in Embodied Navigation: surveys the field of embodied navigation safety, encompassing Attack (threats to navigation), Physical Attack (environmental manipulation), Model-based Attack (model vulnerability exploitation), Defense (mitigation strategies), Physical Defense (countering environmental attacks), Model-based Defense (countering model vulnerabilities), Evaluation (assessing safety), Dataset (benchmarks for testing), and Metric (performance assessment criteria), to analyze existing challenges and future research directions.
- The survey systematically categorizes potential threats, mitigation technologies, and evaluation methodologies, highlighting critical gaps and future research directions in embodied navigation.
- It aims to provide valuable insights for developing more robust and reliable embodied navigation systems, enhancing societal safety and industrial efficiency.

---

[A Framework for Inherently Safer AGI through Language-Mediated Active Inference](http://arxiv.org/abs/2508.05766v1)

- LLM-AIF (Large Language Model-powered Active Inference): introduces a novel framework for safe Artificial General Intelligence (AGI) by integrating Active Inference principles with LLMs, leveraging natural language for transparent belief representations and hierarchical value alignment.
- The architecture implements a multi-agent system where agents self-organize according to Active Inference principles, with preferences and safety constraints flowing through hierarchical Markov blankets.
- This approach aims to build inherently safer AGI by integrating safety guarantees into the core design, rather than retrofitting them, through mechanisms like explicit belief/preference separation and compositional safety.

---

[Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](http://arxiv.org/abs/2508.05622v1)

- LearnerAgent: introduces a multi-agent framework that simulates human-like learning dynamics in a realistic teaching environment, leveraging distinct LLM-empowered agents, memory mechanisms, and comprehensive assessment strategies.
- The framework constructs learners with psychologically grounded profiles (Deep, Surface, Lazy, General) and tracks their dynamic learning progress over a full-year journey through weekly knowledge acquisition, monthly strategic choices, periodic tests, and peer interaction.
- Experiments demonstrate that the framework effectively simulates diverse learning behaviors, reveals insights into LLM default behavior (diligent but brittle surface learner), and aligns with educational psychology theories.

---

[CLAPP: The CLASS LLM Agent for Pair Programming](http://arxiv.org/abs/2508.05728v1)

- CLAPP (CLASS LLM Agent for Pair Programming): introduces an interactive AI assistant designed to support researchers working with the Einstein-Boltzmann solver CLASS, leveraging LLMs and domain-specific retrieval to provide conversational coding support, including a User Interface (Chat interaction), Multi-Agent LLM Orchestration (Coordinates LLM agents) with a CLASS Agent (Drafts responses), Review Agent (Evaluates drafts), and Formatting Agent (Formats responses), a Retrieval-Augmented Generation (RAG) Pipeline (Integrates domain knowledge) with a CLASS Knowledge Base (Stores documentation) and Semantic Search Module (Retrieves context), a Live Python Execution Environment (Executes, debugs code) with an Executor Agent (Executes Python code) and Debugger Agent (Analyzes errors), Conversational Memory (Maintains dialogue context), and LLM Models (Powers agents).
- The system's architecture combines multi-agent LLM orchestration, semantic search across CLASS documentation, and a live Python execution environment, deployed as a user-friendly web application.
- CLAPP aims to lower the entry barrier for scientists unfamiliar with AI tools, enabling more productive human-AI collaboration in computational and numerical cosmology by automating code generation, debugging, and plot production.

---

[Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation](http://arxiv.org/abs/2508.05535v1)

- MICoBot: introduces a system for human-robot collaborative manipulation that handles mixed-initiative dialog for task allocation, with a Meta Planner (high-level strategy), Iterative Planner (executes planning code), and Action Executor (performs low-level actions).
- The system formulates task allocation as a constrained optimization problem, aiming to maximize task success while minimizing human effort, adapting to human preferences through dialog.
- It leverages LLMs for adaptive planning code generation and natural language utterances, demonstrating improved task success and user experience over LLM baselines in real-world and simulated environments.

---

[RankArena: A Unified Platform for Evaluating Retrieval, Reranking and RAG with Human and LLM Feedback](http://arxiv.org/abs/2508.05512v1)

- RankArena: introduces a unified platform for evaluating retrieval, reranking, and RAG systems, leveraging human and LLM feedback to provide multi-faceted assessment and generate reusable evaluation datasets.
- The platform supports diverse evaluation modes including pairwise comparisons, full-list annotations, and end-to-end RAG output assessment, integrating LLM-as-a-judge capabilities for scalable evaluation.
- It enables comprehensive benchmarking of various rerankers and retrievers, aggregating preferences into a dynamic leaderboard for holistic model performance insights.

---

[Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](http://arxiv.org/abs/2508.05508v1)

- Auto-Eval Judge (Judge): introduces a general-purpose, scalable, and modular Agent-as-a-Judge evaluation framework designed to assess agentic task performance with minimal human oversight, including Actor Agent (Executes tasks), Criteria Generator (Generates checklist questions), Artifact Content Parser (Structures and retrieves proofs), Criteria Check Composer (Synthesizes verification strategy), Verdict Generator (Determines task completion), LLM (Generates initial questions), Divide & Filter (Refines checklist questions), Indexer (Organizes Actor logs), Retriever (Identifies relevant proofs), LLM (Summarizes/extracts proofs), E2E/Multi-LLM (Handles end-to-end processing), Task Perception (Interprets task description), Checklist Question Perception (Classifies checklist queries), Knowledge Base (Provides auxiliary resources), Proof Perception (Verifies proof sufficiency), and LLM (Reasons and outputs verdict), where it evaluates agent task completion by assessing intermediate reasoning steps and final outputs.
- The framework emulates human-like evaluation by decomposing tasks into sub-tasks and validating each step using available information, including agent output and reasoning.
- It achieves higher alignment accuracy with human evaluations compared to LLM-as-a-Judge baselines by focusing on step-wise evaluation rather than just final outputs.

---

[AutoIAD: Manager-Driven Multi-Agent Collaboration for Automated Industrial Anomaly Detection](http://arxiv.org/abs/2508.05503v1)

- AutoIAD (Manager-Driven Multi-Agent Collaboration Framework for Automated Industrial Anomaly Detection): introduces a multi-agent framework for end-to-end automated industrial visual anomaly detection, featuring a Manager Agent (orchestrates workflow), Data Preparation Agent (transforms raw data), Data Loader Agent (creates data loader), Model Designer Agent (designs ML model), Trainer Agent (manages model training), Agent Core (provides LLM capabilities), Toolset (enables system interaction), Knowledge Base (provides domain expertise), Datasets (raw image data), and Workspace (shared output repository).
- The framework leverages a central Manager Agent to orchestrate specialized sub-agents, integrating a domain-specific knowledge base and a curated toolset to handle the entire pipeline from raw industrial image data to a trained anomaly detection model.
- AutoIAD significantly outperforms existing general-purpose agentic collaboration frameworks and traditional AutoML frameworks in task completion rate and model performance, effectively mitigating issues like hallucination through iterative refinement.

---

[MOMA: A MIXTURE-OF-MULTIMODAL-AGENTS ARCHITECTURE FOR ENHANCING CLINICAL PREDICTION MODELLING](http://arxiv.org/abs/2508.05492v1)

- MoMA (Mixture-of-Multimodal-Agents): introduces a novel architecture for clinical prediction using multimodal EHR data, leveraging specialized LLM agents to convert non-textual modalities into structured textual summaries, which are then unified with clinical notes by an aggregator agent and used by a predictor agent for clinical predictions.
- The framework employs specialist agents (e.g., CXR-LLAVA-v2, Llama-3 8B) for medical images and tabular EHR data, an aggregator agent (Llama-3 8B) to combine these summaries with clinical notes, and a predictor agent (Llama-3 8B) for final output.
- MoMA's modular, plug-and-play design allows for zero-shot operation of specialist and aggregator agents, with only the predictor agent requiring fine-tuning, reducing computational costs and data requirements compared to traditional joint fusion methods.

---

[Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes](http://arxiv.org/abs/2508.05469v1)

- ELK (Eliciting Latent Knowledge): introduces an LLM-based evaluation framework that leverages information-theoretic mechanisms to assess AI system outputs without ground truth, featuring Peer Agents (LLMs) (generating responses), an Overseer (LLM Critic) (evaluating responses for information consistency), an Information Elicitation Mechanism (incentivizing truthful reporting via f-mutual information), a Prompting Module (delivering tasks to agents), and a Response Comparison Module (calculating information relationships between responses).
- The framework transforms evaluation from subjective judgment to objective measurement by exploiting the data processing inequality, ensuring strategic manipulation degrades both information content and task performance.
- It demonstrates that robust AI evaluation requires a conceptual shift from normative quality assessment to descriptive information measurement, outperforming traditional LLM judges in detecting strategic manipulation and identifying quality.

---

[LLM-based Multi-Agent Copilot for Quantum Sensor](http://arxiv.org/abs/2508.05421v1)

- QCopilot: introduces an LLM-based multi-agent framework integrating external knowledge access, active learning, and uncertainty quantification for quantum sensor design and diagnosis, with all its components, where it enables bidirectional functionality for forward optimization and reverse diagnosis of anomalies in quantum experiments.
- The framework orchestrates specialized agents, including Decision Maker, Experimenter, Analyst, Multimodal Diagnoser, Web Searcher, and Recorder, to decompose tasks, automate optimization, quantify uncertainties, and diagnose faults.
- By synergistically integrating its core components, the framework effectively breaks down knowledge barriers, leverages natural language-based prior knowledge, and continuously refines and accumulates knowledge for autonomous operation.

---

[NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](http://arxiv.org/abs/2508.05344v1)

- NomicLaw: introduces a multi-agent simulation environment where LLM agents engage in collaborative law-making by proposing, arguing, and voting on legal rules in response to complex legal vignettes, with a scoring mechanism and conversation buffer memory.
- The framework facilitates the study of emergent social dynamics like trust, reciprocity, and strategic persuasion among LLMs in both homogeneous and heterogeneous group configurations.
- It provides a reproducible toolkit for empirical characterization of strategic archetypes and insights into AI-mediated governance and policy co-drafting.

---

[A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](http://arxiv.org/abs/2508.05311v1)

- Neuro-Symbolic Multi-Agent Reasoning Architecture: introduces a novel hybrid architecture that unifies decision tree-based symbolic reasoning with LLMs within a coordinated multi-agent system, including a Perception Agent (converts raw data to structured), Tree-based Reasoner (symbolic inference, conditional logic), LLM Agent (abductive reasoning, hypothesis generation), Central Orchestrator (coordinates agents, manages state), and External Tool Interface (accesses external tools/APIs).
- This architecture embeds decision trees and random forests as dynamic, callable oracles within an orchestrated agentic reasoning framework, enabling high-precision, interpretable rule inference and causal logic alongside LLM capabilities for abductive reasoning and generalization.
- The central orchestrator ensures belief consistency, facilitates bidirectional communication between symbolic and neural agents, and enables dynamic tool invocation, allowing the system to reason across structured knowledge and unstructured modalities.

---

[Decision-Making with Deliberation: Meta-reviewing as a Document-grounded Dialogue](http://arxiv.org/abs/2508.05283v1)

- ReMuSE (Reward-based Multi-aspect Self-Editing): introduces a framework for generating high-quality, document-grounded meta-reviewing dialogues using LLMs, which includes an LLM for generation and refinement, an evaluator for quality assessment, a knowledge source for grounding, prompts for guidance, and mechanisms for rewards and natural language feedback.
- The framework addresses data scarcity by synthetically generating dialogues through a self-refinement strategy, where an LLM iteratively improves its output based on multi-aspect feedback derived from computed dialogue quality metrics.
- This approach aims to assist human meta-reviewers in decision-making by providing context-aware, grounded, and specific dialogue responses, ultimately enhancing the efficiency and quality of the meta-reviewing process.

---

[G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation](http://arxiv.org/abs/2508.05709v1)

- G-UBS (Group-Aware User Behavior Simulation): introduces a novel paradigm for robustly understanding implicit user feedback, with UGM (User Group Manager) clustering users to generate group profiles and UFM (User Feedback Modeler) interpreting feedback using group-aware reinforcement learning.
- The UGM agent employs an LLM-powered "summarize-cluster-reflect" workflow to create group profiles, while the UFM agent integrates these profiles and multi-modal information for individual user simulation.
- The framework utilizes Profile Sampling and GA-GRPO (Group-Aware GRPO) within UFM, guided by a Reward Model, to enhance the accuracy and robustness of user behavior simulation.

---

[JPS: Jailbreak Multimodal Large Language Models with Collaborative Visual Perturbation and Textual Steering](http://arxiv.org/abs/2508.05087v1)

- JPS (Jailbreak MLLMs with Collaborative Visual Perturbation and Textual Steering): introduces a novel jailbreak method that iteratively co-optimizes target-guided visual perturbations for safety bypassing and multi-agent refined prompts for high-quality response.
- The framework decouples safety bypass via adversarial image perturbations from response quality control via a composite textual steering prompt, which are iteratively co-optimized.
- It also introduces the Malicious Intent Fulfillment Rate (MIFR), a new metric assessed by a reasoning-LLM-based evaluator, to accurately measure the utility of jailbreak responses.

---

[Making Prompts First-Class Citizens for Adaptive LLM Pipelines](http://arxiv.org/abs/2508.05012v1)

- SPEAR (Structured Prompt Execution and Adaptive Refinement): introduces a language and runtime that elevates prompts to first-class, structured, and adaptive components within LLM pipelines, enabling dynamic refinement and systematic management.
- The framework defines a prompt algebra with core and derived operators that manipulate prompt state, context, and metadata to support adaptive control, introspection, and meta-programming.
- It supports various prompt refinement modes (manual, assisted, automatic) and optimization strategies like operator fusion and prefix caching for improved efficiency and quality.

---

[Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control](http://arxiv.org/abs/2508.05702v1)

- Grid-Agent: introduces an LLM-powered multi-agent system for power grid control, with Topology Agent (parses grid, identifies violations), Planner Agent (formulates multi-step action plans), Executor Agent (translates plans, executes actions), Validator Agent (validates plan, ensures safety), and Summarizer Agent (generates explanations, logs data), where it autonomously detects and resolves electrical violations in real-time using semantic reasoning and numerical precision.
- The system employs an adaptive multiscale network representation for scalability and integrates multi-layered safety mechanisms, including sandboxed execution and automated rollbacks, to ensure operational reliability.
- Its continuous learning capability, facilitated by the Summarizer Agent, enables the system to improve performance over time through operational experience.

---

[NEMORI: SELF-ORGANIZING AGENT MEMORY INSPIRED BY COGNITIVE SCIENCE](http://arxiv.org/abs/2508.03341v2)

- Nemori: introduces a novel self-organizing memory architecture, with Message Buffer (accumulates conversational messages), Boundary Detector (identifies semantic boundaries), Topic Segmentation (segments conversations into episodes), Episodic Memory Generation (transforms segments into narrative), Episodic Memory DB (stores structured episodic memories), Episode Generator (creates narrative episodes), Semantic Memory Generation (distills knowledge proactively), Semantic Memory DB (stores distilled semantic knowledge), Episode Predictor (forecasts episode content), Semantic Knowledge Distiller (identifies prediction gaps), and Unified Retrieval System (retrieves relevant memories), designed to address LLM long-term memory limitations.
- Nemori's core innovation lies in its Two-Step Alignment Principle for organizing raw conversational streams into semantically coherent episodes, and its Predict-Calibrate Principle for proactive learning from prediction gaps.
- The architecture operationalizes these principles via Topic Segmentation, Episodic Memory Generation, and Semantic Memory Generation, demonstrating superior performance and computational efficiency in long-term conversational memory tasks.

---

[Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow](http://arxiv.org/abs/2508.02959v2)

- Polymath: introduces a self-optimizing agent with dynamic hierarchical workflow, including a Task Flow Graph (TFG) for task decomposition, an LLM-based Task Flow Planner for execution control, Multi-Grid-Inspired Graph Optimization for TFG structure refinement, Code-Represented Subtask Workflows for subtask execution, a Self-Reflection-Guided Evolutionary Algorithm (EA) for workflow optimization, and various LLM Assistants for specific tasks, where it leverages flexible task flow graphs and expressive code-represented workflows to solve dynamic real-world problems without labeled data.
- The framework integrates multi-grid-inspired graph optimization with a self-reflection-guided evolutionary algorithm to refine workflows using feedback from reasoning LLMs, eliminating the need for labeled datasets.
- Polymath demonstrates an 8.1% average improvement over state-of-the-art baselines across coding, math, and multi-turn QA tasks, showcasing its effectiveness and adaptability to diverse problem domains.

---

[VISTA: VISION-LANGUAGE IMITATION OF SITUATIONAL THINKING AND ATTENTION FOR HUMAN-LIKE DRIVER FOCUS IN DYNAMIC ENVIRONMENTS](http://arxiv.org/abs/2508.05852v1)

- VISTA (Vision-Language Imitation of Situational Thinking and Attention): introduces a vision-language framework that models driver gaze changes using a frozen CLIP Image Encoder, an MLP Connector, and a LoRA-fine-tuned Vicuna-based Language Model to generate natural language attention descriptions.
- This framework leverages few-shot and zero-shot learning on RGB images, providing interpretable scene descriptions and rationales for current and future driver gaze shifts.
- VISTA aims to enhance explainable AI in autonomous driving by mimicking human-like attention allocation, supporting tasks like behavior forecasting and human-AI teaming.

---

[Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction](http://arxiv.org/abs/2508.05838v1)

- VFM-RL (Vision Foundation Models with Reinforcement Learning) Integration Framework: introduces a novel approach for enhancing object interaction capabilities in simulated environments by integrating a Perception Pipeline (processes visual input) with a Policy Network (decides agent actions), operating within an Environment (simulated interaction space).
- The Perception Pipeline leverages YOLOv5 (object detection model) and SAM (object segmentation model) for advanced scene understanding, with a Feature Encoding (CNN) (encodes visual features) component feeding into the Policy Network's Perception Encoder (CNN) (extracts high-level features) and Policy and Value Heads (predicts actions, state value).
- This integration significantly improves object interaction success rates, navigation efficiency, and cumulative reward compared to a baseline agent, demonstrating the benefits of advanced perception for complex robotic tasks.

---

[The Missing Reward: Active Inference in the Era of Experience](http://arxiv.org/abs/2508.05619v1)

- LLM-AIF (Large Language Model - Active Inference) architecture: introduces a framework integrating LLMs as generative world models with Active Inference's decision-making to enable autonomous AI agents to learn from experience without continuous human reward engineering.
- This architecture comprises an LLM world model for understanding environmental dynamics, an AIF control loop for principled decision-making, and online refinement for continuous model updates through experience.
- By minimizing intrinsic free energy, the framework allows agents to naturally balance exploration and exploitation, addressing the "grounded-agency gap" and promoting sustainable AI progress.

---

[TEST-TIME REINFORCEMENT LEARNING FOR GUI GROUNDING VIA REGION CONSISTENCY](http://arxiv.org/abs/2508.05615v1)

- GUI-RC (GUI Region Consistency): introduces a test-time scaling approach for GUI grounding, leveraging multi-sample generation (samples K predictions), a spatial voting mechanism (constructs spatial voting grid), and consensus extraction (identifies highest agreement region) to improve localization accuracy.
- Building upon this, GUI-RCPO (GUI Region Consistency Policy Optimization) extends the approach by transforming region consistency into self-supervised reward signals via a region consistency reward (computes self-supervised reward) for policy optimization (updates model parameters), enabling models to refine outputs on unlabeled data during inference.
- This framework demonstrates the potential of test-time scaling and reinforcement learning for robust and data-efficient GUI agents, achieving consistent performance improvements across various benchmarks and model architectures.

---

[OMNIEAR: BENCHMARKING AGENT REASONING IN EMBODIED TASKS](http://arxiv.org/abs/2508.05614v1)

- OmniEAR: introduces a comprehensive framework for evaluating how LLMs reason about physical interactions, tool usage, and multi-agent coordination in embodied tasks, featuring EAR-Sim (Environment simulator), EAR-Bench (Evaluation benchmark), and an Automated Benchmark Generation Pipeline (Scenario generator).
- The framework models continuous physical properties and complex spatial relationships through text-based environment representation, enabling dynamic tool-capability binding and physics-constrained collaboration.
- OmniEAR's systematic evaluation reveals significant performance degradation in LLMs when reasoning from constraints, exposing fundamental architectural limitations in current embodied AI systems.

---

[InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization](http://arxiv.org/abs/2508.05731v1)

- AEPO (Adaptive Exploration Policy Optimization): introduces a novel policy optimization framework for GUI grounding, integrating multi-answer generation, an adaptive exploration reward, and a quality-of-exploration penalty to enhance exploration efficiency and semantic alignment.
- The framework addresses the exploration bottleneck in standard Reinforcement Learning by enabling the underlying MLLM to generate a diverse set of candidate solutions in a single forward pass, guided by a reward function derived from an efficiency ratio.
- This approach improves GUI grounding performance by fostering broader and more purposeful exploration, particularly for semantically challenging samples, and preventing the model from getting stuck on high-confidence but incorrect actions.

---

[Cognitive Duality for Adaptive Web Agents](http://arxiv.org/abs/2508.05081v1)

- CogniWeb: introduces a modular agent architecture for web navigation, inspired by dual-process cognitive theory, that adaptively toggles between fast (System 1) and slow (System 2) processing modes.
- This framework unifies offline imitation learning and online exploration by leveraging System 1 for intuitive reactive behaviors and System 2 for deliberative planning capabilities.
- The system demonstrates competitive performance on WebArena while achieving significantly higher efficiency through reduced token usage.

---

[OPERATIONALIZING SERENDIPITY: MULTI-AGENT AI WORKFLOWS FOR ENHANCED MATERIALS CHARACTERIZATION WITH THEORY-IN-THE-LOOP](http://arxiv.org/abs/2508.06569v1)

- SciLink (Multi-Agent AI Framework): introduces an open-source, multi-agent AI framework designed to operationalize serendipity in materials research by creating an automated link between experimental observation, novelty assessment, and theoretical simulations, leveraging Orchestrator, Experimental Analysis Agents, Literature Agents, Simulation Agents, Human Expert, Scientific Literature Database, and Executor.
- This framework employs a hybrid AI strategy, utilizing specialized machine learning models for quantitative data analysis and LLMs for higher-level reasoning tasks.
- It autonomously converts raw data into falsifiable scientific claims, quantitatively scores their novelty against published literature, and proposes targeted follow-up experiments, bridging the gap between automated experimentation and open-ended scientific exploration.

---

[AgenticData: An Agentic Data Analytics System for Heterogeneous Data](http://arxiv.org/abs/2508.05002v1)

- AgenticData: introduces an agentic data analytics system for heterogeneous data, with Planner (generates semantic plan), Fundamental Infrastructure (supports agents/operations), Optimizer (refines/executes plans), Validator (checks plan accuracy), and Executor (executes physical plan) components, where it autonomously translates natural language queries into semantic query plans.
- The system employs a multi-agent collaboration strategy, including data profiling, planning, and manipulation agents, alongside a smart memory mechanism for context and knowledge management.
- It utilizes feedback-driven planning, semantic optimization, and validation techniques to ensure high accuracy and cost efficiency in analyzing both structured and unstructured data.

---

[Hierarchical Deep Deterministic Policy Gradient for Autonomous Maze Navigation of Mobile Robots](http://arxiv.org/abs/2508.04994v1)

- HDDPG (Hierarchical Deep Deterministic Policy Gradient): introduces a hierarchical deep reinforcement learning algorithm for autonomous maze navigation, featuring a High-level Policy (generates intermediate subgoals), a Low-level Policy (generates primitive actions), an Off-policy Correction Mechanism (re-labels historical subgoals), Adaptive Parameter Space Noise (enhances exploration), Target-driven Reshaped Intrinsic and Extrinsic Reward Functions (guides agent towards goal), an Experience Replay Buffer (stores past interactions), and an Optimizer (updates network parameters).
- The high-level policy employs an advanced DDPG framework to generate intermediate subgoals from a long-term perspective, while the low-level policy, also powered by an improved DDPG algorithm, generates primitive actions by observing current states and following the assigned subgoal.
- The algorithm enhances stability with off-policy correction, refines subgoal assignments by relabeling historical experiences, utilizes adaptive parameter space noise for improved exploration, and employs a reshaped intrinsic-extrinsic reward function to boost learning efficiency and robustness.

---

[Getting out of the Big-Muddy: Escalation of Commitment in LLMs](http://arxiv.org/abs/2508.01545v2)

- LLM Escalation of Commitment Experimental Design: introduces, an empirical study investigating the manifestation of escalation of commitment bias in LLMs, with LLM (subject of study), Two-stage Investment Task (core experimental task), Model as Investor Condition (LLM makes investment decisions), Model as Advisor Condition (LLM advises on investments), Multi-Agent Deliberation Condition (multiple LLMs collaborate), and Over-Indexed Identity Condition (LLM with personal pressures), where the study demonstrates that LLMs exhibit context-dependent escalation behavior rather than consistent bias.
- The research reveals that LLMs show rational divestment in individual decision-making but become highly susceptible to escalation under social dynamics, identity threats, or compound pressures.
- These findings highlight critical boundary conditions for AI reliability in organizational decision-making contexts, emphasizing the need for safeguards against bias amplification in multi-agent systems and unsupervised operations.

---

[LLM-Based Intelligent Agents for Music Recommendation: A Comparison with Classical Content-Based Filtering](http://arxiv.org/abs/2508.11671v1)

- LLM-Based Intelligent Agents for Music Recommendation System: introduces a multi-agent personalized music recommendation system that leverages LLMs (Gemini 2.0 Flash, LLaMA-3.3-70B-VERSATILE) and specialized agents (ReadingAgt, AnalistAgt, ExtractAgt, RecommendAgt).
- The system collects music catalogue and user history via an API, with agents collaborating to analyze data, infer preferences, and generate recommendations.
- This approach aims to improve music recommendation personalization by leveraging LLMs' natural language understanding, comparing its effectiveness against traditional content-based filtering.

---

#### 6th August 2025

[LLM Collaboration With Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2508.04652v1)

- MAGRPO (Multi-Agent Group Relative Policy Optimization): introduces a framework for LLM collaboration, modeling it as a cooperative Multi-Agent Reinforcement Learning (MARL) problem formalized as a Dec-POMDP, where LLM Agents generate responses within a System Environment based on User prompts and External Models/Systems feedback.
- The framework utilizes a Reward Model to calculate joint rewards, and the MAGRPO Trainer optimizes agent policies by leveraging Group Relative Advantage and Policy Gradient, enabling efficient and high-quality responses in multi-turn settings.
- This approach allows LLMs to learn diverse cooperation schemes, improving response efficiency and quality in tasks like writing and coding collaboration, while maintaining decentralized execution.

---

[VirT-Lab: An AI-Powered System for Flexible, Customizable, and Large-scale Team Simulations](http://arxiv.org/abs/2508.04634v1)

- VIRT-LAB (AI-Powered System for Flexible, Customizable, and Large-scale Team Simulations): introduces a system for simulating team collaboration in complex spatial and temporal environments, featuring a Web Interface (user-friendly front-end), a Simulation Engine (manages agents, environment, events), LLM-based Agents (AI entities with human-like behavior), an Environment Module (manages 2D spatial layouts), an Event Scheduling Manager (orchestrates parallel event execution), a Memory System (stores agent memories, traits), and a Backend (processes simulation logic).
- The system enables non-technical users to define, run, and analyze team simulations without programming, supporting customizable scenarios, agent attributes, and environment layouts.
- It integrates LLMs into agents to facilitate realistic social interactions, memory retention, and navigation within dynamic 2D environments, allowing for the study of team behaviors and social science hypotheses.

---

[TURA: Tool-Augmented Unified Retrieval Agent for AI Search](http://arxiv.org/abs/2508.04604v1)

- TURA (Tool-Augmented Unified Retrieval Agent for AI Search) introduces a novel three-stage framework that integrates Retrieval-Augmented Generation with agentic tool-use to access both static and dynamic real-time information, comprising an Intent-Aware Retrieval module, a DAG-based Task Planner, and a Distilled Agent Executor.
- This framework addresses limitations of traditional RAG systems by enabling interaction with live services and dynamic data sources, such as APIs and databases, for complex, time-sensitive queries, leveraging LLMs for query decomposition, planning, and execution.
- TURA utilizes standardized tool interfaces via Model Context Protocol (MCP) Servers, employs semantic index augmentation, and applies agent distillation to achieve efficient, low-latency performance in industrial AI search products.

---

[Causal Reflection with Language Models](http://arxiv.org/abs/2508.04495v1)

- Causal Reflection: introduces a framework that explicitly models causality as a dynamic function over state, action, time, and perturbation, enabling agents to reason about delayed and nonlinear effects, incorporating a Causal Inference Engine, Reflect Mechanism, and LLM-Based Interpreter.
- The framework redefines the role of LLMs from black-box reasoners to structured inference engines that translate formal causal outputs into natural language explanations and counterfactuals.
- This approach lays the theoretical groundwork for Causal Reflective agents that can adapt, self-correct, and communicate causal understanding in evolving environments.

---

[OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use](http://arxiv.org/abs/2508.04482v1)

- OS Agents Framework: surveys MLLM-based agents for general computing devices, detailing their framework components: Perception Module (collects environment info), Planning Module (handles task decomposition), Memory Module (supports information storage), and Action Module (executes operation instructions).
- The survey elucidates fundamental OS Agent capabilities like understanding, planning, and grounding, and examines construction methodologies including foundation models and agent frameworks.
- It highlights current challenges in safety, privacy, personalization, and self-evolution, providing insights for future research and industrial development.

---

[TRAIL: Joint Inference and Refinement of Knowledge Graphs with Large Language Models](http://arxiv.org/abs/2508.04474v1)

- TRAIL (Thinking, Reasoning, And Incremental Learning): introduces a unified framework for joint inference and dynamic knowledge graph refinement, integrating a Knowledge Graph, an LLM Agent, Semantic Pinpoint, Search, Generate, Aggregate, Extract, Confidence Evaluation Mechanism, Evaluate & Filter, KG Refinement Module, and Session Cache.
- This framework enables LLM agents to iteratively explore, update, and refine knowledge graphs during reasoning, guided by a confidence-driven mechanism for fact generation, validation, and pruning.
- The plug-and-play architecture facilitates seamless integration with various LLMs, supporting continual adaptation and knowledge transfer without retraining, and improving factual accuracy and interpretability.

---

[Automatic LLM Red Teaming](http://arxiv.org/abs/2508.04451v1)

- Automatic LLM Red Teaming framework: introduces a novel hierarchical reinforcement learning approach for automated red teaming, formalizing it as a Markov Decision Process to learn multi-turn attack strategies against LLMs.
- This framework includes a High-Level Policy (chooses strategic attack concept) and Low-Level Policy (generates coherent utterance token-by-token), guided by a High-Level Critic (evaluates high-level strategy utility) and Low-Level Critic (evaluates low-level token utility) for fine-grained reward attribution.
- It leverages a Guard Model (measures target LLM response harm) to provide token-level marginal contribution rewards, enabling the overall Agent (orchestrates red-teaming process) to uncover subtle vulnerabilities in the Target LLM (LLM being red-teamed) over long conversational horizons.

---

[ARE LARGE LANGUAGE MODELS DYNAMIC TREATMENT PLANNERS? AN IN SILICO STUDY FROM A PRIOR KNOWLEDGE INJECTION ANGLE](http://arxiv.org/abs/2508.04755v1)

- LLMs and SRAs as Dynamic Treatment Planners (DTPs): introduces an evaluation of LLMs and SRAs as DTPs for insulin administration in Type 1 diabetes using an in silico simulator, comparing their zero-shot inference performance (LLMs) against explicitly trained RL agents (SRAs), investigating prior knowledge injection methods and chain-of-thought prompting.
- The study reveals that smaller LLMs can achieve comparable or superior clinical performance to trained SRAs, especially in stable patient cohorts, but exhibit limitations like arithmetic hallucination and temporal misinterpretation.
- Findings advocate for cautious LLM integration into clinical workflows, emphasizing the need for targeted prompt engineering, careful validation, and potential hybrid approaches for safe and effective decision-support.

---

[Evaluating, Synthesizing, and Enhancing for Customer Support Conversation](http://arxiv.org/abs/2508.04423v1)

- Role-Playing Conversation Generation Framework: introduces a method for synthesizing customer support dialogues, featuring a Planner (defines dialogue scenario and customer goal), Supporter Assistant (recommends support strategies), Supporter (generates supporter responses), Customer Assistant (guides customer conversation direction), and Customer (generates customer responses), all leveraging LLMs and guided by a Character Profile Pool and Pre-defined Topics.
- This framework aims to create diverse, coherent, and realistic customer support conversations by assigning distinct roles to LLM-powered agents, thereby generating high-quality, strategy-rich training data (RoleCS) for fine-tuning LLMs in customer support conversation (CSC) tasks.
- The generated synthetic data significantly improves LLMs' ability to produce strategy-aligned and effective responses, addressing the scarcity of high-quality, annotated real-world customer support dialogue datasets.

---

[Beyond Pixels: Exploring DOM Downsampling for LLM-Based Web Agents](http://arxiv.org/abs/2508.04412v1)

- D2Snap (Downsampled DOM Snapshot): introduces a first-of-its-kind DOM downsampling algorithm for LLM-based web agents, featuring a D2Snap Algorithm with DOM Traversal, Element Downsampling (Container Element Handling, Content Element Handling, Interactive Element Handling, Other Element Removal), Text Downsampling (TextRank Algorithm, Sentence Slicing), Attribute Downsampling (Attribute Filtering), an AdaptiveD2Snap component (Halton Sequences), and a GPT-4o Backend.
- This algorithm processes DOM snapshots to reduce their token size while retaining essential UI features, enabling LLMs to interpret web application states effectively.
- Evaluation shows downsampled DOMs achieve comparable or superior success rates to grounded GUI snapshots, highlighting the importance of DOM hierarchy for LLM understanding.

---

[Multi-Agent Taskforce Collaboration: Self-Correction of Compounding Errors in Long-Form Literature Review Generation](http://arxiv.org/abs/2508.04306v1)

- MATC (Multi-Agent Taskforce Collaboration): introduces a framework for long-form literature review generation that mitigates compounding errors through a Manager Agent (orchestrates workflow), Searching Agent (retrieves literature), Outlining Agent (generates outline), Locating Agent (extracts facts), Drafting Agent (composes manuscript), Exploration Taskforce (determines outline/references), Exploitation Taskforce (extracts/drafts content), and Experience Taskforce (guides self-correction).
- This multi-agent system organizes LLM-based agents into specialized taskforces—exploration, exploitation, and experience—to address error propagation across the literature review workflow.
- The framework employs self-correction mechanisms, including a tree-based strategy for exploration and an iterative refinement cycle for exploitation, guided by historical experience to enhance output quality.

---

[Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success](http://arxiv.org/abs/2508.04280v1)

- VL-DAC (Vision-Language Decoupled Actor-Critic): introduces a lightweight, hyperparameter-free reinforcement learning algorithm that enhances VLM training by applying token-wise PPO updates for action tokens and step-level value learning with gradients stopped at the VLM backbone.
- This approach includes a minimal stabilization kit with KL regularization, value warm-up, and stop-gradient, enabling stable and generalizable training in cheap synthetic environments.
- The framework demonstrates effective transfer of learned skills from synthetic simulators to real-world benchmarks, improving agentic control, spatial planning, and embodied reasoning.

---

[ShoppingBench: A Real-World Intent-Grounded Benchmark for LLM-based Agents](http://arxiv.org/abs/2508.04266v1)

- ShoppingBench: introduces a real-world intent-grounded benchmark for LLM-based agents, featuring a Simulated Interactive Environment (mimics e-commerce), Intent-Grounded User Instructions (realistic user queries), a Predefined Tool Set (API tools for interaction), and Shopping Agent Training (SFT and RL for agents).
- The benchmark provides a scalable framework with over 2.5 million real-world products and 510 user instructions across four distinct e-commerce intents, enabling comprehensive evaluation of LLMs.
- It facilitates the development and assessment of LLM agents' abilities in complex e-commerce scenarios, including multi-step reasoning, tool use, and constraint satisfaction.

---

[Empowering Time Series Forecasting with LLM-Agents](http://arxiv.org/abs/2508.04231v1)

- DCATS (Data-Centric Agent for Time Series): introduces an LLM-powered agentic framework for time series forecasting that leverages metadata to intelligently refine training data, rather than solely optimizing model architectures, by iteratively generating and evaluating dataset expansion plans.
- The framework includes a User for query submission, an LLM-Agent for proposal generation and refinement, a Forecasting Module for model training and performance validation, and Metadata and Time Series components for data storage and retrieval.
- This iterative process, driven by the LLM-Agent's reasoning over validation errors, aims to optimize the final dataset for improved forecasting accuracy across various time series models.

---

[AquaChat++: LLM-Assisted Multi-ROV Inspection for Aquaculture Net Pens with Integrated Battery Management and Thruster Fault Tolerance](http://arxiv.org/abs/2508.06554v1)

- AquaChat++: introduces a novel multi-ROV inspection framework that leverages LLMs for adaptive mission planning, coordinated task execution, and fault-tolerant control, structured with a high-level plan generation layer and a low-level control layer.
- The framework's high-level LLM-Based Planner translates natural language commands into symbolic multi-agent inspection plans, while its low-level components manage ROV actions, including path planning, thruster fault tolerance, and precise trajectory tracking.
- By integrating real-time feedback and event-triggered replanning, the framework enhances system robustness, operational efficiency, and supports scalable, intelligent, and autonomous underwater robotic operations.

---

[Risk Analysis Techniques for Governed LLM-based Multi-Agent Systems](http://arxiv.org/abs/2508.05687v1)

- Risk Analysis Framework (RAF): introduces a structured approach for identifying and analyzing risks in governed LLM-based multi-agent systems, with components including Progressive Staged Testing, Observational Data Analysis, Benchmarking, Red Teaming, Capability Benchmarking, and Validity Assessment.
- RAF emphasizes progressively increasing exposure to negative impacts through simulations, sandboxed testing, pilot programs, and full deployment with monitoring to identify failure modes early.
- The framework addresses six key failure modes: Cascading Reliability, Inter-Agent Communication, Monoculture Collapse, Conformity Bias, Deficient Theory of Mind, and Mixed Motive Dynamics, providing tools for their assessment.

---

[ToolGrad: Efficient Tool-use Dataset Generation with Textual “Gradients”](http://arxiv.org/abs/2508.04086v1)

- ToolGrad: introduces an agentic framework that inverts the traditional paradigm of tool-use dataset generation by first constructing valid tool-use chains through an iterative process guided by textual "gradients" and then synthesizing corresponding user queries, utilizing an API Collection, API Proposer (LLMpr), API Executor (LLMex), API Execution Report, API Selector (LLMsel), and Workflow Updater (LLMupdater).
- This "answer-first" approach, inspired by ML optimization and TextGrad, aims to generate more complex tool-use data with lower cost and a 100% pass rate compared to prior methods.
- The framework's four core modules (API Proposer, Executor, Selector, Updater) resemble forward inference and backward propagation, enabling efficient dataset construction for training LLMs in tool usage.

---

[GEOSR: COGNITIVE-AGENTIC FRAMEWORK FOR PROBING GEOSPATIAL KNOWLEDGE BOUNDARIES VIA ITERATIVE SELF-REFINEMENT](http://arxiv.org/abs/2508.04080v1)

- GeoSR (Cognitive-Agentic Framework for Probing Geospatial Knowledge Boundaries via Iterative Self-Refinement): introduces a self-refining agentic reasoning framework that embeds core geographic principles into an iterative prediction loop, featuring a Predict Agent, Variable-Selection Agent, Point-Selection Agent, and Refine Agent.
- This framework enables LLMs to progressively improve geospatial prediction quality by leveraging spatial dependencies and inter-variable relationships through agent collaboration and iterative self-refinement.
- GeoSR enhances geospatial inference in LLMs without requiring model fine-tuning, demonstrating improved accuracy and reduced geographic bias across diverse tasks.

---

[ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents](http://arxiv.org/abs/2508.04038v1)

- ZARA (Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents): introduces an agent-based framework for zero-shot, explainable Human Activity Recognition directly from raw motion time-series, integrating Domain-Knowledge Injection (builds knowledge base), Placement-specific Vector Databases (stores motion windows), Class-Wise Multi-Sensor Retrieval (retrieves relevant evidence), and Hierarchical Multi-Agent Reasoning (guides LLM iteratively) with an underlying LLM.
- The framework enables flexible and interpretable HAR without fine-tuning or task-specific classifiers by leveraging structured sensor knowledge and retrieval-augmented generation for effective reasoning about unseen activities.
- ZARA achieves state-of-the-art zero-shot performance on 8 HAR benchmarks, delivering clear reasoning and outperforming strong baselines by 2.53x in macro F1, demonstrating its potential for trustworthy, plug-and-play motion time-series analysis.

---

[BridgeScope: A Universal Toolkit for Bridging Large Language Models and Databases](http://arxiv.org/abs/2508.04031v1)

- BridgeScope introduces a universal toolkit bridging LLMs and databases, featuring modularized SQL operations into fine-grained tools, alignment of tool implementations with database privileges and user security policies, and a proxy mechanism for seamless inter-tool data transfer.
- This toolkit enables LLM agents to operate databases more effectively, reduces token usage through improved security awareness, and uniquely supports data-intensive workflows beyond existing toolkits.
- Its database-agnostic design and transparent integration with existing agent architectures position it as a robust foundation for next-generation intelligent data automation.

---

[Galaxy: A Cognition-Centered Framework for Proactive, Privacy-Preserving, and Self-Evolving LLM Agents](http://arxiv.org/abs/2508.03991v1)

- Galaxy: introduces a cognition-centered framework for proactive, privacy-preserving, and self-evolving LLM agents, with Cognition Forest (unified cognitive architecture), KoRa (generative agent), Kernel (meta-agent), Interaction Layer (perceives user interaction), Analysis Layer (models user data), Execution Layer (generates/executes plans), Spaces (personalized interaction modules), Agenda (user behavior modeling), Persona (long-term user modeling), and Privacy Gate (data masking).
- The framework unifies cognitive architecture and system design into a self-reinforcing loop, enabling continuous adaptation and personalized capability generation for LLM agents.
- It supports multidimensional interactions and proactive task execution while safeguarding user privacy through its meta-cognition and data masking mechanisms.

---

[Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach](http://arxiv.org/abs/2508.03329v2)

- MoA (Mixture-of-Agents): introduces a multi-layered ensemble architecture for code optimization, starting with an Optimization Prompt (input code) fed into Proposer LLMs Layer 1 (generate variants), followed by Proposer LLMs Layer 2 (refine variants), and finally an Aggregator LLM Layer 3 (synthesize output) to produce an Improved Code Snippet (optimized code).
- The framework is empirically evaluated against a GA-based ensemble system and standalone LLM optimizers using real-world industrial codebases, demonstrating its efficacy in regulated environments with restricted model usage.
- This approach excels with open-source models, providing significant cost savings and faster optimization times, particularly beneficial for organizations facing regulatory constraints.

---

[InqEduAgent: Adaptive AI Learning Partners with Gaussian Process Augmentation](http://arxiv.org/abs/2508.03174v2)

- InqEduAgent (Adaptive AI Learning Partners with Gaussian Process Augmentation): introduces an LLM-empowered agent model for simulating and selecting learning partners, featuring generative agents, nonparametric modeling, an adaptive matching algorithm, Gaussian process augmentation, Pareto front integration, environmental interaction, and prior knowledge and embedding.
- This framework addresses challenges in inquiry-oriented education by providing optimal learning-partner matches tailored to different exercises and learner capabilities.
- It combines semantic understanding and nonparametric modeling with Gaussian process enhancement to achieve effective parameterization and inverse parameterization for personalized learning.

---

[Tool-integrated Reinforcement Learning for Repo Deep Search](http://arxiv.org/abs/2508.03012v2)

- ToolTrain framework: introduces a two-stage tool-integrated training framework, including an LLM, a RepoSearcher Agent, a Rejection-Sampled Supervised Fine-Tuning (SFT) module, a Tool-integrated Reinforcement Learning (RL) module, and Repository Retrieval Tools, to enhance LLMs' ability to use retrieval tools for issue localization.
- This framework addresses the challenge of Repo Deep Search, a multi-step reasoning and navigation process requiring LLMs to effectively utilize various repository retrieval tools to identify code modifications for software issues.
- ToolTrain combines SFT for foundational understanding of tool use with RL for robustly enhancing reasoning and tool-calling abilities, leading to more precise issue localization and improved end-to-end issue resolution.

---

[Beyond Manually Designed Pruning Policies with Second-Level Performance Prediction: A Pruning Framework for LLMs](http://arxiv.org/abs/2508.02381v2)

- PPF (Predictive Pruning Framework): introduces a novel pruning framework for LLMs that eliminates manual design dependencies via second-level performance prediction, featuring a lightweight Performance Predictor (CNN-based performance estimation) and an Agent (generates pruning policies) that interacts with a Structured LLM Pruning (applies pruning to LLM) component.
- The Performance Predictor, utilizing Mask Compression and a CNN-based Prediction Model with Spatial Attention, SPP, GAP, and GD Branches, rapidly estimates pruned LLM performance, while the Agent employs Actor and Critic Networks, an Experience Replay Buffer, and a Reward Function with a Sampling Window Strategy to learn optimal pruning policies.
- This framework supports both dynamic and static pruning scenarios, enabling real-time decision-making and fine-grained optimization by significantly speeding up the iterative optimization process for LLM pruning.

---

[ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](http://arxiv.org/abs/2508.04915v1)

- ConfAgents: introduces an adaptive multi-agent framework for cost-efficient medical diagnosis, featuring a MainAgent (performs initial diagnosis / synthesizes final diagnosis), a CP Judger (assesses diagnostic confidence / triggers collaboration), AssistAgents (conduct collaborative analysis / gather evidence), an Iterative RAG Mechanism (dynamically retrieves external knowledge), a Medical Corpus (source of external medical knowledge), a Calibration Set (calibrates CP Judger's threshold), a Score Function (quantifies output unusualness), a Prediction Set (indicates diagnostic uncertainty), and a Stop Button (controls RAG iteration termination).
- The framework employs a two-stage process, using the CP Judger to triage cases, escalating only complex, low-confidence cases for multi-agent collaboration, thereby maximizing efficiency without compromising diagnostic accuracy.
- For escalated cases, the AssistAgents leverage an iterative RAG mechanism to dynamically retrieve and integrate external knowledge from the Medical Corpus, overcoming static knowledge limitations and enhancing diagnostic robustness.

---

[Behaviorally Adaptive Multi-Robot Hazard Localization in Failure-Prone, Communication-Denied Environments](http://arxiv.org/abs/2508.04537v1)

- BAPP (Behavior-Adaptive Path Planning) Framework: introduces a modular, scalable approach for multi-robot exploration and hazard localization in failure-prone, communication-denied environments, integrating risk-sensitive decision-making, role-aware deployment, and mobile base relocation via behavior modulation using the tunable α parameter of Behavioral Entropy (BE).
- The framework supports two behavior-adaptive modes, BAPP-TID for intelligent triggering of high-fidelity agents and BAPP-SIG for risk-aware, failure-sensitive exploration, validated through single-robot and multi-robot simulations.
- BAPP consistently outperforms Shannon-based and random strategies, accelerating entropy reduction and improving robot survivability with minimal information loss in multi-agent deployments.

---

[DRAMA: A Dynamic and Robust Allocation-based Multi-Agent System for Changing Environments](http://arxiv.org/abs/2508.04332v1)

- DRAMA (Dynamic and Robust Allocation-based Multi-Agent System): introduces a multi-agent system with a modular architecture, including a Control Plane for global coordination and a Worker Plane for local agent autonomy, designed for dynamic environments.
- The Control Plane features a Monitor for state aggregation, a Planner-Critic for task scheduling, and a Dispatcher for task distribution, while Worker Plane agents handle perception, planning, action, and memory.
- The system abstracts agents and tasks as resource objects, enabling affinity-driven, event-triggered task reallocation for robustness and adaptability to agent turnover and dynamic task demands.

---

[StackPilot: Autonomous Function Agents for Scalable and Environment-Free Code Execution](http://arxiv.org/abs/2508.11665v1)

- StackPilot: introduces an LLM-native, multi-agent framework for code verification and execution, built on Function-as-Agents, LLM-as-Executor, and stack-based scheduling with agent snapshots.
- This framework models each program function as an autonomous agent and leverages LLMs for direct code interpretation and environment simulation, operating independently of traditional toolchains.
- It employs a stack-based scheduling mechanism with agent snapshots to ensure deterministic and lossless context switching, achieving high reliability in code verification across diverse programming tasks.

---

[VERIGUI: VERIFIABLE LONG-CHAIN GUI DATASET](http://arxiv.org/abs/2508.04026v1)

- VeriGUI Framework: introduces VeriGUI, a novel verifiable long-chain GUI dataset, with Task Instruction Construction Stage (generates task instructions), Human Expert Instruction Design (creates seed instructions), LLM (generates/decomposes tasks), Human Review (curates generated tasks), Automated Filtering (filters instructions), Model-based Evaluation (verifies instructions), Human Demonstration Collection Stage (collects human demonstrations), Human Annotator (executes/refines tasks), Trajectory Recording (captures GUI interactions), and Quality Control (verifies demonstrations), where the framework combines LLM-based generation with human annotation to ensure realistic, high-quality GUI tasks and demonstrations.
- The VeriGUI dataset emphasizes long-chain complexity, with tasks decomposed into hundreds of interdependent subtasks, and subtask-level verifiability, enabling diverse exploration strategies and consistent goal verification.
- The dataset includes GUI task trajectories across both desktop and web environments, annotated by human experts, and defines a unified action space and observation space for GUI operations.

---

[HARMONYGUARD: TOWARD SAFETY AND UTILITY IN WEB AGENTS VIA ADAPTIVE POLICY ENHANCEMENT AND DUAL-OBJECTIVE OPTIMIZATION](http://arxiv.org/abs/2508.04010v1)

- HarmonyGuard: introduces a multi-agent collaborative framework that leverages Policy Agent for adaptive policy enhancement and Utility Agent for dual-objective optimization, enabling web agents to jointly improve safety and utility in dynamic web environments.
- The framework employs a Policy Agent to extract, refine, and update structured security policies, and a Utility Agent to perform real-time dual-objective evaluation and provide metacognitive guidance for reasoning correction.
- HarmonyGuard demonstrates superior performance in policy compliance and task completion across multiple benchmarks, achieving a Pareto-optimal balance between safety and utility.

---

[THE EMOTIONAL BABY IS TRULY DEADLY: DOES YOUR MULTIMODAL LARGE REASONING MODEL HAVE EMOTIONAL FLATTERY TOWARDS HUMANS?](http://arxiv.org/abs/2508.03986v1)

- EmoAgent (autonomous adversarial emotion-agent framework): introduces a framework for systematically assessing Multimodal Large Reasoning Models' (MLRMs) safety vulnerabilities by generating emotionally charged adversarial prompts through risk identification, rational preemption, and emotional transfer, which includes emotional persona conditioning, intensity-controlled affective transformation, and semantic-preserving reconstruction.
- The framework reveals that MLRMs are susceptible to emotional flattery, leading to safety protocol override and cognitive blind spots, even when visual risks are recognized.
- To quantify these vulnerabilities, the paper introduces three new metrics: Risk-Reasoning Stealth Score (RRSS), Risk-Visual Neglect Rate (RVNR), and Refusal Attitude Inconsistency (RAIC), enabling comprehensive safety evaluation beyond surface-level outputs.

---

[HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents](http://arxiv.org/abs/2508.02629v2)

- HyCodePolicy: introduces a closed-loop framework for language-conditioned robot manipulation, integrating code synthesis, multimodal monitoring, and iterative repair, featuring a Code Agent (LLM) (generates/repairs), Program (robot policy), Task Execution (simulates), Symbolic Logs (records events), VLM Agent (monitors visually), Adaptive Monitor (diagnoses failures), Code Repair (refines program), and History (stores data).
- This framework enhances robustness and sample efficiency of robot manipulation policies by fusing symbolic execution logs with VLM-based perceptual observations for precise, causally-grounded failure attribution and targeted code repair.
- The system treats generated code as an evolving hypothesis, actively validating and correcting it via perceptual cues and symbolic reasoning in a self-correcting programming cycle.

---

[ranDecepter: Real-time Identification and Deterrence of Ransomware Attacks](http://arxiv.org/abs/2508.00293v3)

- ranDecepter: introduces a novel framework combining active cyber deception with real-time analysis to identify, contain, and deter ransomware attacks by manipulating API calls and injecting deceptive data.
- The system operates in three phases—offline analysis, real-time identification, and a reset phase—to proactively disrupt ransomware operations and deplete attacker resources.
- It achieves zero false positives and 100% identification accuracy by leveraging API-level interception, behavioral pattern analysis, and symbolic execution to force continuous key generation.

---

[Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL](http://arxiv.org/abs/2508.13167v1)

- CoA (Chain-of-Agents): introduces a novel LLM reasoning paradigm for end-to-end complex problem-solving, dynamically activating tool and role-playing agents to simulate multi-agent collaboration within a single model.
- The framework employs a multi-agent distillation process to transfer state-of-the-art multi-agent system capabilities into CoA trajectories for agentic supervised fine-tuning.
- Agentic reinforcement learning further refines the models' capabilities on verifiable agentic tasks, resulting in Agent Foundation Models (AFMs) that demonstrate state-of-the-art performance and reduced inference costs.

---

#### 5th August 2025

[Can Language Models Critique Themselves? Investigating Self-Feedback for Retrieval Augmented Generation at BioASQ 2025](http://arxiv.org/abs/2508.05366v1)

- Self-Feedback RAG: introduces a system investigating whether LLMs can improve query expansion and answer quality in biomedical question answering through iterative self-feedback, incorporating LLMs, a retriever, a generator, a self-feedback mechanism, query expansion, prompt refinement, a knowledge base, snippet extraction, and reranking.
- The framework evaluates various reasoning and non-reasoning LLMs within a Retrieval Augmented Generation (RAG) setup, where LLMs generate, evaluate, and refine their own outputs for query expansion and answer generation.
- Preliminary results from the BioASQ CLEF 2025 challenge indicate mixed performance for the self-feedback strategy across different models and tasks, with few-shot learning often showing competitive results.

---

[MOTIF: Multi-strategy Optimization via Turn-based Interactive Framework](http://arxiv.org/abs/2508.03929v1)

- MOTIF (Multi-strategy Optimization via Turn-based Interactive Framework): introduces a novel framework for automated combinatorial optimization solver design, featuring a two-round optimization process, an outer controller, competitive Monte Carlo Tree Search, LLM agents, specialized operators (Counter, Learning, Innovation), evaluation, dynamic and fixed global baselines, prompt updating, and historical context.
- The framework facilitates turn-based optimization between two LLM agents, promoting competitive pressure and emergent cooperation to discover diverse, high-performing solutions.
- This structured interaction broadens the search landscape for algorithmic components, consistently outperforming state-of-the-art methods in various combinatorial optimization problem domains.

---

[SOTOPIA-RL: REWARD DESIGN FOR SOCIAL INTELLIGENCE](http://arxiv.org/abs/2508.03905v1)

- SOTOPIA-RL: introduces a novel framework for training socially intelligent LLM agents by refining coarse episode-level feedback into utterance-level, multi-dimensional rewards, leveraging a GPT model (generates self-play dialogues), a GPT attributor (annotates offline rewards), a Base model (initial policy for SFT), an SFT model (fine-tuned policy), an Utterance-level Reward Model (RM) (provides utterance-level feedback), and an RL model (optimized social agent policy).
- This framework addresses challenges of partial observability and multi-dimensionality in social interactions by providing fine-grained, multi-dimensional reward signals for RL training.
- Experiments demonstrate state-of-the-art social goal completion scores, confirming the necessity of both utterance-level credit assignment and multi-dimensional reward design.

---

[Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models](http://arxiv.org/abs/2508.03860v1)

- RAG (Retrieval-Augmented Generation): is reviewed as a key framework for LLM fact-checking, integrating a Retriever (gathers external information), a Knowledge Base (external data source), and a Generator (LLM) (synthesizes information) to enhance factual accuracy.
- The paper systematically analyzes how LLM-generated content is evaluated for factual accuracy, exploring challenges like hallucinations and dataset limitations, and emphasizing the need for robust fact-checking frameworks.
- The review highlights the importance of grounding LLM outputs with validated external evidence and domain-specific customization to improve factual consistency and trustworthiness.

---

[Agent Lightning: Train ANY AI Agents with Reinforcement Learning](http://arxiv.org/abs/2508.03680v1)

- Agent Lightning: introduces a framework for RL-based LLM training of AI agents, with Agent Lightning Server (manages RL training process), Agent Lightning Client (manages agent execution, data collection), RL Framework (performs LLM model training), LLM Engine (manages and updates LLMs), Trainer (updates LLM model weights), Agent (AI agent undergoing training), Unified Data Interface (standardizes agent execution data), LightningRL (hierarchical RL for agent training), Credit Assignment Module (assigns rewards to transitions), Automatic Intermediate Rewarding (AIR) Mechanism (generates intermediate rewards), LLMs (core reasoning and generation), Tools (external functionalities for agents), Training Trajectories (collected agent execution data), and Updated Models (improved LLM models), where it achieves complete decoupling between agent execution and RL training for any AI agent.
- The framework formulates agent execution as a Markov Decision Process, defining a unified data interface and proposing a hierarchical RL algorithm, LightningRL, to handle complex interaction logic.
- Its Training-Agent Disaggregation architecture integrates agent observability frameworks into runtime, providing a standardized finetuning interface for stable and continuous performance improvements across diverse tasks.

---

[A DbC Inspired Neurosymbolic Layer for Trustworthy Agent Design](http://arxiv.org/abs/2508.03665v1)

- Contract Layer (DbC Inspired Neurosymbolic Layer): introduces a contract layer that mediates LLM calls, integrating DbC and type-theoretic principles to ensure verifiable guarantees for generative model outputs, with components including Input, Input Type Validation, Pre-condition Check, Intermediate Action, Output Generation, Output Type Validation, Post-condition Check, Pre-remedy, Post-remedy, Forward Method (Finally Block), Contract Success, Contract Failure, LLMs, ValidationFunction, Contracts, and Type System.
- This layer operationally defines semantic validation through programmer-specified conditions on well-typed data structures, employing probabilistic remediation to steer LLM generation toward compliance.
- The framework ensures system resilience via a fallback mechanism, guaranteeing graceful degradation rather than complete failure when contract validation fails, and enables runtime comparison of functionally equivalent agents.

---

[Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning](http://arxiv.org/abs/2508.03501v1)

- DAPO (Decoupled Advantage Policy Optimization) framework: introduces a scalable RL framework for training long-context, multi-turn software engineering agents, integrating an RL-trained agent, environment, tools, ReAct-style loop, inference servers, rollout generation, verification process, reward computation, advantage estimation, dataset preparation, training, and update model checkpoints.
- The framework successfully applies a modified DAPO algorithm to train a Qwen2.5-72B-Instruct agent, achieving a 39% success rate on SWE-BENCH VERIFIED without relying on teacher models.
- This approach addresses challenges of long-horizon multi-turn interaction, complex feedback, data scalability, sparse rewards, and expensive evaluation in real-world software engineering tasks.

---

[AN AUDITABLE AGENT PLATFORM FOR AUTOMATED MOLECULAR OPTIMISATION](http://arxiv.org/abs/2508.03444v1)

- Auditable Agent Platform: introduces a hierarchical, tool-using multi-agent framework for automated molecular optimization, featuring a Principal Researcher, Database Agent, AI Expert Agent, Medicinal Chemist Agent, Ranking Agent, and Scientific Critic Agent, which leverage external tools and workflows like UniProt, PDB, ChEMBL, Vina-Mol-Gen, and Vina-Report to systematically design and optimize molecules.
- The platform ensures auditable reasoning paths by summarizing and storing each tool call and agent communication as concise provenance records, enabling in-context learning and reuse of successful transformations.
- Evaluated across LLM-only, single-agent, and multi-agent configurations, the multi-agent system excels at focused binding optimization, improving average predicted binding affinity by 31%, while single-agent runs balance potency with broader drug-like properties.

---

[Data Overdose? Time for a Quadruple Shot: Knowledge Graph Construction using Enhanced Triple Extraction](http://arxiv.org/abs/2508.03438v1)

- IE Pipeline for Automated Knowledge Graph Generation: introduces an approach for information extraction and automatic knowledge graph generation from PubMed abstracts, utilizing a pipeline of LLM agents for preprocessing, sentence processing, and inferring new relationships, culminating in a structured knowledge graph.
- The pipeline decomposes abstracts into semantically meaningful proposition sentences, extracts enhanced KG triples (quadruples) with context, and validates extraction accuracy by reconstructing sentences from quadruples and comparing them to original propositions using cosine similarity.
- This system aims to provide a centralized, real-time updated knowledge source for medical practitioners by enhancing knowledge graph connectivity through inferred relationships, addressing limitations of traditional triple extraction.

---

[Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language Models](http://arxiv.org/abs/2508.03406v1)

- MOID (Multi-Objective Infeasibility Diagnosis): introduces a framework that combines LLM agents and multi-objective optimization within an automatic routing solver to diagnose infeasible routing problems.
- The framework includes a Generation Module for constraint-aware heuristics, an Optimization Module for finding trade-off solutions, and an Analysis Module for interpreting solutions and generating modification suggestions.
- It leverages LLM agents to generate programs for constraint checking and scoring, and a solution analysis function for diverse model adjustment suggestions.

---

[A Closed-Loop Multi-Agent Framework for Aerodynamics-Aware Automotive Styling Design](http://arxiv.org/abs/2508.03370v1)

- A Closed-Loop Multi-Agent Framework: introduces an LLM-driven multi-agent system for automotive styling design, integrating Competitive Analysis Agents, Rendering Generation Agent, Point Cloud Agent, and Aerodynamic Prediction Agent to automate conceptual design and aerodynamic validation.
- The framework streamlines the design process by translating ambiguous requirements into photorealistic renderings and then into 3D point clouds for near-instantaneous aerodynamic performance prediction.
- This system significantly accelerates the design cycle by seamlessly coupling creative exploration with rapid engineering assessment, replacing time-consuming CFD simulations.

---

[Agoran: An Agentic Open Marketplace for 6G RAN Automation](http://arxiv.org/abs/2508.09159v1)

- AGORAN (Service & Resource Broker): introduces an agentic open marketplace for 6G RAN automation, enabling multi-stakeholder negotiation and regulation-compliant resource allocation through its tripartite AI branches: Legislative, Executive, and Judicial agents, coordinated by an Orchestrator, and supported by a Multi-Objective Optimizer, Trust Score Module, and Multi-Source Database.
- The framework allows stakeholders to express intents in natural language, grounds compact LLM agents in live telemetry, enforces regulatory trust safeguards, and achieves autonomous, fair, and efficient resource brokerage.
- The system demonstrates significant gains in aggregate throughput, URLLC latency reduction, and physical resource block (PRB) savings on a 5G testbed, validating its compatibility with Open RAN and AI-RAN roadmaps.

---

[Adaptive AI Agent Placement and Migration in Edge Intelligence Systems](http://arxiv.org/abs/2508.03345v1)

- AntLLM (Adaptive AI Agent Placement and Migration in Edge Intelligence Systems): introduces a novel adaptive framework for AI agent placement and migration in dynamic edge environments, with ALP (AntLLM Placement) for initial deployment and ALM (AntLLM Migration) for dynamic relocation, both enhanced by LLM-based optimization.
- The framework models resource constraints and latency/cost, leveraging ant colony algorithms for efficient decision-making and enabling lightweight agent migration by transferring only essential state.
- Implemented on a distributed system using AgentScope, the solution aims to minimize task execution and agent migration times while maximizing edge resource utilization.

---

[CTTS: Collective Test-Time Scaling](http://arxiv.org/abs/2508.03333v1)

- CTTS-MM (Collective Test-Time Scaling with Multiple agents to Multiple reward models): introduces a novel framework for enhancing LLM inference by combining multiple LLM agents and multiple reward models in a unified search-reward-search pipeline.
- This framework leverages Agent Collaboration Search (ACS) to dynamically select optimal agent ensembles and Mixture of Reward Models (MoR) for adaptive reward model selection.
- Experiments demonstrate that CTTS-MM consistently achieves superior performance across various benchmarks, highlighting the potential of collective test-time scaling.

---

[Navigation Pixie: Implementation and Empirical Study Toward On-demand Navigation Agents in Commercial Metaverse](http://arxiv.org/abs/2508.03216v1)

- Navigation Pixie: introduces an on-demand navigation agent for commercial metaverse platforms, integrating structured spatial metadata with LLM-based natural language processing, enabling flexible guidance and cross-platform deployment.
- The system's loosely coupled architecture minimizes platform dependencies, allowing experiments on extensive user bases across PC and VR-HMD environments.
- Empirical studies demonstrated the agent significantly increased user dwell time and free exploration, enhancing social presence and personalized experiences in virtual worlds.

---

[Scaling DRL for Decision Making: A Survey on Data, Network, and Training Budget Strategies](http://arxiv.org/abs/2508.03194v1)

- Scaling RL: introduces a comprehensive survey on scaling strategies in Deep Reinforcement Learning (DRL) for decision making, systematically analyzing data, network, and training budget dimensions to improve performance, stability, and generalization.
- The survey explores data scaling through parallel sampling and synthetic generation, network scaling via architectural enhancements like width/depth expansion, ensembles, and multi-agent populations, and training budget scaling using distributed training, replay ratios, batch sizes, and auxiliary tasks.
- It highlights the synergistic roles of these strategies in advancing DRL, providing a roadmap for future research, and emphasizing the balance between scalability and computational efficiency for complex tasks.

---

[Toward Low-Latency End-to-End Voice Agents for Telecommunications Using Streaming ASR, Quantized LLMs, and Real-Time TTS](http://arxiv.org/abs/2508.04721v1)

- End-to-End Voice Agent Pipeline: introduces a low-latency, end-to-end voice-to-voice communication pipeline for telecommunications, integrating Streaming ASR (transcribes audio to text), Retrieval-Augmented Generation (RAG) Submodule (retrieves relevant documents), Quantized LLM (generates responses), and Real-Time TTS (synthesizes text to audio) via a multi-threaded streaming architecture.
- The pipeline employs sentence-level streaming, 4-bit LLM quantization, and concurrent module execution using a producer-consumer pattern to achieve sub-second response times for interactive telecom scenarios.
- It leverages a custom dataset of telecommunications-related questions for evaluation, demonstrating effectiveness in customer support and diagnostics applications.

---

[LONG STORY GENERATION VIA KNOWLEDGE GRAPH AND LITERARY THEORY](http://arxiv.org/abs/2508.03137v1)

- Story Generator: introduces a multi-agent structure for long story generation, leveraging LLMs as core components to integrate memory storage, knowledge graphs, and multi-agent interaction.
- The framework employs a dual memory system, a KG-driven twist plot framework based on literary theory, and LLM-driven writer-reader simulator dialogues to enhance story coherence, appeal, and readability.
- It addresses challenges like theme drift and dull plots by simulating human creative and revision processes, aiming to generate higher-quality long stories.

---

[Attack the Messages, Not the Agents: A Multi-round Adaptive Stealthy Tampering Framework for LLM-MAS](http://arxiv.org/abs/2508.03125v1)

- MAST (Multi-round Adaptive Stealthy Tampering framework): introduces a framework to exploit communication vulnerabilities in LLM-MAS, integrating Adaptive Attack Policy Learning (trains attack policy) with Stealthiness-Constrained Tampering (ensures attack stealth) to generate effective, multi-round tampering strategies.
- The framework utilizes Monte Carlo Tree Search (explores tampering trajectories) and Direct Preference Optimization (fine-tunes attack policy) to train an Attack Policy Model (generates attack plans) for adaptive strategy generation.
- Stealthiness is maintained through Context Analysis (analyzes message context), Attack Goal Camouflage (disguises attack goals), and a Dual-Constraint Tampering Mechanism (enforces similarity constraints) that includes Semantic Similarity Constraint (preserves message meaning) and Embedding Similarity Constraint (maintains linguistic proximity).

---

[Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation](http://arxiv.org/abs/2508.03117v1)

- OptiTrust: introduces a modular LLM agent that performs multi-stage translation from natural language to solver-ready code, leveraging a Decomposition Agent (extracts problem components), a Formulation Agent (generates mathematical formulation), and a Code Agent (translates to solver code), which includes a Validation Mechanism (verifies code correctness) and a Majority Voting Mechanism (ensures consistent implementation).
- The framework utilizes a Synthetic Data Generation Pipeline (creates verifiable multi-modal datasets) where a Teacher Model (generates synthetic training data) and a Python Script (automates data generation) produce Training Data (generated for LLM fine-tuning) from a Symbolic Representation (structured problem definition) and Problem Description (initial natural language input).
- This approach ensures data quality and full verifiability, enabling supervised fine-tuning of open-source LLMs for optimization tasks and improving reliability and interpretability of automated optimization modeling.

---

[AgentSME for Simulating Diverse Communication Modes in Smart Education](http://arxiv.org/abs/2508.03109v1)

- AgentSME: introduces a unified generative agent framework that simulates diverse communication modes in smart education using LLMs as virtual student agents, analyzing their impact on learning performance and linguistic diversity through Solo, Mono, and Echo modes.
- The framework evaluates agent capabilities across different LLMs and question difficulties, emphasizing accuracy and lexical diversity metrics like Inverse Simpson, Honoré's Statistic, and Information Entropy.
- Experiments demonstrate that the Echo communication mode significantly enhances answer accuracy and fosters more diverse language generation, particularly benefiting weaker or adaptable LLMs.

---

[Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree](http://arxiv.org/abs/2508.03038v1)

- ToR (Tree-of-Reasoning): introduces a novel multi-agent framework for complex medical diagnosis, featuring specialized doctor agents, an evidence tree for transparent reasoning, and a cross-verification mechanism for consensus.
- The framework employs four distinct LLM-based agents—Outpatient, Laboratory, Radiology, and Pathology Doctors—each focusing on specific medical data types and utilizing a MedRAG tool for domain knowledge.
- By explicitly recording reasoning paths and evidence in a hierarchical tree structure and enabling iterative cross-verification among agents, the framework enhances diagnostic interpretability and accuracy in complex medical scenarios.

---

[Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark](http://arxiv.org/abs/2508.05674v1)

- CTFJudge: introduces an evaluation framework for offensive security LLM agents, integrating hyperparameter tuning, an LLM-as-a-judge mechanism, and a lightweight CTF benchmark.
- The framework leverages CTFJudge to analyze agent trajectories and provide granular evaluation across CTF solving steps, complemented by the CTF Competency Index (CCI) for partial correctness.
- The paper also presents CTFTiny, a curated benchmark of 50 CTF challenges, enabling rapid evaluation and systematic investigation of LLM hyperparameter influence on agent performance.

---

[Survey of Large Language Models in Extended Reality: Technical Paradigms and Application Frontiers](http://arxiv.org/abs/2508.03014v1)

- This survey, "Survey of Large Language Models in Extended Reality: Technical Paradigms and Application Frontiers", introduces a comprehensive review of LLM-enhanced XR systems, exemplified by architectures like the "Autonomous Workflow for Training Assistants" integrating an MR App (main XR environment) with an AI Agent (intelligent core) and its sub-components for intelligent XR interactions.
- The survey proposes a taxonomy of LLM-enhanced XR systems centered on key technical paradigms, including interactive agent control, XR development toolkits, and generative scene synthesis.
- It examines how LLM-driven techniques support practical XR applications across diverse domains, highlights current trends, and identifies open challenges for advancing intelligent XR experiences.

---

[GeoFlow: Agentic Workflow Automation for Geospatial Tasks](http://arxiv.org/abs/2508.04719v1)

- GeoFlow: introduces an agentic workflow automation method for geospatial tasks, which explicitly assigns function-calling GIS API objectives to subagents within an Activity-on-Vertex (AOV) graph, generated by a meta-agent LLM based on user input.
- This approach improves task success and correctness rates compared to prior methods like Flow by providing detailed tool-calling objectives to guide geospatial API invocation at runtime, reducing ambiguity for subagents.
- The framework also significantly reduces token usage across major LLM families, demonstrating a better performance-to-cost trade-off for automated geospatial workflow generation.

---

[AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots](http://arxiv.org/abs/2508.02999v1)

- AGENTiGraph (Adaptive General-purpose Entities Navigated Through Interaction): introduces a multi-agent knowledge graph framework for interactive, domain-specific LLM chatbots, including User Intent, Key Concept Extraction, Task Planning, Knowledge Graph Interaction, Reasoning, Response Generation, and Update Agents, along with a Knowledge Graph and User Interface.
- This framework enables non-technical users to intuitively build, refine, and manage knowledge bases through natural language dialogue, supporting multi-round interactions and dynamic updates.
- The system ensures transparent, auditable reasoning across diverse tasks, addressing challenges in privacy, compliance, and multi-step reasoning for high-stakes domains like legal and medical.

---

[LLM-Prior: A Framework for Knowledge-Driven Prior Elicitation and Aggregation](http://arxiv.org/abs/2508.03766v1)

- LLMPrior: introduces a framework that automates and scales prior elicitation and aggregation in Bayesian inference by architecturally coupling an LLM with an explicit, tractable generative model, and extending to multi-agent systems for distributed knowledge aggregation.
- The framework leverages an LLM for semantic interpretation and parameter generation, while a generative model (like a Gaussian Mixture Model via a Mixture Density Network) ensures the mathematical validity of the resulting prior distributions.
- For multi-agent scenarios, the Fed-LLMPrior algorithm employs a central server and Logarithmic Opinion Pooling to robustly aggregate context-dependent priors from N agents, synthesizing conflicting beliefs into a coherent consensus.

---

[When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs](http://arxiv.org/abs/2508.02994v1)

- Agent-as-a-Judge: reviews the evolution of LLM evaluation paradigms, from Traditional Metrics (baseline evaluation methods) and Single LLM-as-a-Judge (LLM rates outputs) approaches to Multi-Agent Judges (multiple LLMs interact) and the advanced Agent-as-a-Judge (evaluates agent processes) framework, which enables process-based evaluation of autonomous agents.
- The paper defines the Agent-as-a-Judge concept, tracing its development from single-model judges to dynamic multi-agent debate frameworks, and critically examining their strengths and shortcomings.
- It compares these approaches across reliability, cost, and human alignment, surveying real-world deployments in domains like medicine, law, finance, and education, while outlining future research directions.

---

[ASTRA: Autonomous Spatial-Temporal Red-teaming for AI Software Assistants](http://arxiv.org/abs/2508.03936v1)

- ASTRA: introduces an automated agent system designed to systematically uncover safety flaws in AI-driven code generation and security guidance systems, with Offline Domain Modeling (builds structured domain-specific knowledge graphs), Knowledge Graph (KG) Construction (builds structured domain-specific knowledge graphs), Oracle (ensemble of high-capacity reasoning models and static analysis tools), Blue-teams (ensemble of high-capacity reasoning models and static analysis tools), Monte Carlo Sampling (probabilistic sampling to explore input space), Modeling (process of creating the KG), Boundary Cases (inputs with inconclusive safety judgments), Online Vulnerability Exploration (probes input space for safety violations), Spatial Exploration (probes input space for safety violations), Temporal Exploration (analyzes reasoning processes for vulnerabilities), Target System (AI coding assistant under evaluation), Online Judge (lightweight model for real-time vulnerability assessment), Chat (interaction interface with target system), Successful Violation-inducing Inputs (identified inputs triggering unsafe behavior), Model Alignment (dataset for model alignment), Augmented Data (dataset for model alignment), and SFT+RL (fine-tuning and reinforcement learning for alignment), where it works in three stages to build knowledge graphs, explore vulnerabilities, and generate violation-inducing cases for model alignment.
- The framework focuses on discovering realistic vulnerabilities by exploring both the input space (spatial exploration) and the LLM's reasoning processes (temporal exploration) guided by knowledge graphs.
- ASTRA finds significantly more issues than existing techniques and produces test cases that lead to more effective alignment training for safer AI systems.

---

[Using the NANDA Index Architecture in Practice: An Enterprise Perspective](http://arxiv.org/abs/2508.03101v1)

- NANDA (Networked AI Agents in a Decentralized Architecture): introduces a comprehensive framework for secure, trustworthy, and interoperable AI agent ecosystems, featuring a NANDA Index/Registry (global agent discovery), AgentFacts (verifiable capability attestation), NANDA Adapter (cross-protocol interoperability), Zero Trust Agentic Access (ZTAA) (secure agent interactions), Agent Visibility and Control (AVC) (enterprise governance), Agent Router (agent interaction management), LLM (agent reasoning engine), and various Protocols (MCP/A2A/NLWeb/HTTPS communication).
- The framework addresses critical infrastructure requirements for large-scale autonomous agent deployment by enabling verifiable agent discovery, cryptographically attested capabilities, and seamless cross-protocol communication.
- NANDA implements Zero Trust Agentic Access principles to extend traditional Zero Trust Network Access, mitigating autonomous agent security challenges like capability spoofing and impersonation attacks.

---

[A SURVEY OF AI AGENT REGISTRY SOLUTIONS](http://arxiv.org/abs/2508.03095v1)

- MCP Registry: introduces a centralized metaregistry for discovering and installing MCP servers, with all its components, where it provides a centralized metadata layer using structured mcp.json files for agent discovery and installation.
- This framework uses GitHub-authenticated publishing and structured metadata for server discovery, minimizing attack surface by delegating authentication to proven systems.
- Its schema-driven core service and decoupled metadata hosting ensure operational simplicity and ease of upgrades.

---

[BlockA2A: Towards Secure and Verifiable Agent-to-Agent Interoperability](http://arxiv.org/abs/2508.01332v2)

- BlockA2A: introduces a unified multi-agent trust framework with an Identity Layer (decentralized identity management), a Ledger Layer (immutable auditability/data integrity), a Smart Contract Layer (programmable interaction rules/access control), and a Defense Orchestration Engine (DOE) (proactive threat detection/response), designed to enable secure and verifiable agent-to-agent interoperability.
- The framework addresses key security vulnerabilities in LLM-driven multi-agent systems, such as fragmented identity frameworks, insecure communication channels, and inadequate defenses against Byzantine agents or adversarial prompts.
- It eliminates centralized trust bottlenecks, ensures message authenticity and execution integrity, and guarantees accountability across agent interactions, with empirical evaluations demonstrating its effectiveness in neutralizing various MAS attacks.

---

#### 4th August 2025

[AQUAH: Automatic Quantification and Unified Agent in Hydrology](http://arxiv.org/abs/2508.02936v1)

- AQUAH (Automatic Quantification & Unified Agent in Hydrology): introduces an end-to-end language-based agent for hydrologic modeling, leveraging vision-enabled LLMs to autonomously retrieve data, configure models, run simulations, and generate reports, with its architecture comprising LLM Interface, Tool Executor Layer, Dynamic Data Pipeline, Hydrologic Model Integration, Report Generation Engine, Interactive Feedback Loop, and a multi-agent system including Context Parser Agent (ACP), Dataset Retriever Agent (ADR), Perceptor Agent (Ap), OutletSelector Agent (Aos), ParamInitializer Agent (API), Operator Agent (Ao), Report Writer Agent (ARW), and Feedback Reflector Agent (AFR).
- The framework streamlines complex environmental modeling by converting natural language prompts into end-to-end hydrologic simulations and narrative reports, reducing manual intervention and technical barriers.
- It integrates geospatial data retrieval, Earth-observation forcing data, and physics-based hydrologic models like CREST, demonstrating how vision-enabled LLMs can assume formerly human-exclusive roles in scientific workflows.

---

[PentestJudge: Judging Agent Behavior Against Operational Requirements](http://arxiv.org/abs/2508.02921v1)

- PentestJudge: introduces an LLM-as-judge system for evaluating penetration testing agents, featuring an LLM-as-judge (core evaluation model), Trajectory Input (historical agent actions), Rubric Requirements (evaluation criteria), Judge Tools (trajectory interaction), External Memory (intermediate judgment storage), Self-Compression Module (context management), and Pass/Fail Output (binary judgment result).
- This system assesses the Penetration Testing Agent's behavior against operational requirements by decomposing complex tasks into hierarchical rubrics, allowing for scalable and holistic evaluation of process-level qualities within a Kali Linux and GOAD environment.
- The research demonstrates that LLM-based judges can effectively verify security agent trajectories, offering a cost-effective alternative to human experts for evaluating agent performance in sensitive production environments.

---

[Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game](http://arxiv.org/abs/2508.02900v1)

- Countdown Planning Benchmark: introduces a procedure for creating a planning benchmark centered around the computationally challenging Countdown game, including its formal definition, instance generation, PDDL formulation, and evaluation of various LLM-assisted planning methods and a symbolic planner.
- The benchmark addresses shortcomings of existing planning benchmarks by offering an NP-complete problem with a rich instance space, intuitive natural language description, and sound validators.
- Experiments reveal that the proposed dynamic benchmark remains challenging for LLM-based approaches, highlighting potential memorization issues in prior evaluations on static datasets.

---

[Meta-RAG on Large Codebases Using Code Summarization](http://arxiv.org/abs/2508.02611v1)

- Meta-RAG (Retrieval Augmented Generation): introduces a multi-agent LLM-based framework for bug localization in large codebases, utilizing a Summary Agent (generates/updates code summaries), a Database (stores code and summaries), a Control Agent (orchestrates bug localization), an LLM (processes instructions, generates lists), a Meta-RAG Prompt Generator (constructs LLM input prompts), and a Code Agent (retrieves code, generates patches).
- This framework transforms codebases into compact natural language summaries, significantly reducing context window length and mitigating diminishing attention effects for LLMs.
- The approach achieves state-of-the-art bug localization rates at both file and function levels on the SWE-bench Lite dataset, demonstrating efficiency and cost reduction for software development tasks.

---

[Language Model Guided Reinforcement Learning in Quantitative Trading](http://arxiv.org/abs/2508.02366v1)

- LLM-guided RL (Language Model Guided Reinforcement Learning): introduces a hybrid architecture where LLMs generate high-level trading strategies to guide RL agents in their actions, integrating an Analyst Agent, Strategist Agent, and RL Agent.
- The framework leverages a Multi-modal Financial Dataset, including market, fundamental, analytical, and news-derived signals, to inform strategic decision-making by the LLMs.
- This design enables the RL agent to adapt its behavior to new market conditions without retraining, demonstrating improved return and risk metrics over standard RL baselines.

---

[Agentic Personalized Fashion Recommendation in the Age of Generative AI: Challenges, Opportunities, and Evaluation](http://arxiv.org/abs/2508.02342v1)

- AMMR (Agentic Mixed-Modality Refinement): introduces a holistic framework for fashion recommendation, integrating multimodal encoders, dynamic query composition, and agentic planning modules, including an LLM Planner, Dual Memory, Tools, Business Logic Critic, and RAG, to address limitations of retrieval-only systems.
- The framework leverages an Interface for multimodal user input, a Query Analysis Layer for understanding intent, a Composition Retrieval Layer for candidate generation, and a Planner Layer for structured reasoning and refinement.
- This approach aims to provide adaptive, generative, and stakeholder-aware fashion recommendations by capturing fine-grained visual attributes, resolving ambiguous queries, and adapting to evolving trends in real-time.

---

[FinWorld: An All-in-One Open-Source Platform for End-to-End Financial AI Research and Deployment](http://arxiv.org/abs/2508.02292v1)

- FinWorld (An All-in-One Open-Source Platform): introduces an end-to-end financial AI research and deployment platform with a Configuration Layer (centralizes experimental settings), Dataset Layer (manages data), Model Layer (defines models), Training Layer (optimizes pipelines), Evaluation Layer (assesses models), Task Layer (encapsulates tasks), and Presentation Layer (automates results dissemination).
- The platform distinguishes itself through native integration of heterogeneous financial data, unified support for diverse AI paradigms including LLMs and LLM Agents, and advanced agent automation.
- FinWorld enhances reproducibility, supports transparent benchmarking, and streamlines deployment across various financial AI tasks like time series forecasting, algorithmic trading, portfolio management, and LLM applications.

---

[CellForge: Agentic Design of Virtual Cell Models](https://github.com/gersteinlab/CellForge)

- CELLFORGE (Agentic Design of Virtual Cell Models): introduces an agentic system for designing virtual cell models, with Task Analysis, Design Module, and Experiment Execution, which collaboratively transform biological data into optimized computational models and executable code.
- The framework employs a multi-agent architecture with specialized LLM agents that engage in graph-based discussions and iterative refinement to achieve consensus on modeling strategies.
- It integrates a shared knowledge infrastructure and a persistent memory module, enabling context-aware reasoning, traceability, and semantic understanding throughout the scientific discovery workflow.

---

[Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?](http://arxiv.org/abs/2508.05670v1)

- FAIRGAME introduces a reproducible framework for game-theoretic LLM agents, including game selection, configuration, prompt templating, integration, LLM API calls for agent creation and game instance execution, result collection, and analysis, to investigate LLM behaviors in cybersecurity scenarios.
- The paper investigates LLM behavior in one-shot zero-sum and repeated Prisoner's Dilemma games, revealing how agent characteristics like personality and language influence outcomes and identifying inconsistencies across LLMs and languages.
- It highlights the need for systematic testing of LLM agents in cybersecurity applications due to their unpredictable behavior and sensitivity to various factors, advocating for frameworks like FAIRGAME to guide secure LLM deployment.

---

[WHISPERING AGENTS: AN EVENT-DRIVEN COVERT COMMUNICATION PROTOCOL FOR THE INTERNET OF AGENTS](http://arxiv.org/abs/2508.02188v1)

- ПССАР (Covert Communication Agent Protocol): introduces an event-driven covert communication protocol for the Internet of Agents, operationalizing a Covert Event Channel through its Sender Agent (initiates covert communication) and Receiver Agent (decodes covert communication) by leveraging Storage Channel (embeds data in payload), Timing Channel (modulates event timestamps), and Behavioral Channel (selects action types) to achieve high-capacity, robust, and imperceptible communication.
- The protocol ensures imperceptibility against powerful LLM-based wardens by embedding secret data into natural agent dialogues, making the communication act itself hidden from surveillance and traffic analysis.
- It provides a foundational understanding for developing next-generation monitoring and defensive protocols for a secure and trustworthy Internet of Agents.

---

[A Survey on AgentOps: Categorization, Challenges, and Future Directions](http://arxiv.org/abs/2508.02121v1)

- AgentOps (Agent System Operations): introduces a novel operations and maintenance framework for LLM-based agent systems, encompassing monitoring, anomaly detection, root cause analysis, and resolution.
- This framework addresses the unique challenges of agent systems, such as stochasticity and complex interactions, by providing tailored strategies for identifying and mitigating anomalies across pre-execution, execution, and post-execution phases.
- It emphasizes comprehensive data collection, iterative remediation, and a structured approach to diagnose failures, classifying them into intra-agent and inter-agent anomalies with system-centric, model-centric, and orchestration-centric root causes.

---

[Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools](http://arxiv.org/abs/2508.02110v1)

- AMA (Attractive Metadata Attack): introduces a black-box in-context learning framework that generates highly attractive but syntactically and semantically valid tool metadata through iterative optimization to induce LLM agents to invoke malicious tools.
- The framework leverages LLMs' in-context learning and employs generation traceability, weighted value evaluation, and batch generation to efficiently craft metadata that maximizes malicious tool invocation likelihood.
- AMA demonstrates high attack success rates across various LLM agents and tool-use scenarios, effectively bypassing prompt-level defenses and structured tool-selection protocols.

---

[The Silicon Reasonable Person: Can AI Predict How Ordinary People Judge Reasonableness?](http://arxiv.org/abs/2508.02766v1)

- Silicon Reasonable Person: introduces a framework that investigates whether LLMs can predict human reasonableness judgments, leveraging their inherent capabilities like attention mechanisms, emergent roleplaying, generalization, and a majoritarian bent, evaluated through silicon randomized controlled trials (S-RCTs) with session-level memory isolation and persona assignment.
- The framework demonstrates that certain LLMs can replicate nuanced human intuitions regarding negligence, contract interpretation, and consent, prioritizing social norms over economic efficiency, similar to human behavior.
- These findings suggest LLMs can serve as a valuable tool for legal analysis, offering empirical insights into lay reasoning patterns to supplement judicial discretion and inform policy, while acknowledging limitations like magnitude discrepancies, value drift, and model heterogeneity.

---

[A Reinforcement Learning Framework for Mobility Control of gNBs in Dynamic Radio Access Networks](http://arxiv.org/abs/2508.02960v1)

- Reinforcement Learning Framework for Mobility Control of gNBs in Dynamic Radio Access Networks: introduces a system for autonomous gNB movement, leveraging the CC-SIM (3D simulation environment) and a DQN Agent (reinforcement learning controller) to proactively maintain LoS connectivity between gNBs and UEs amidst dynamic obstacles.
- The framework formulates gNB mobility as an RL task, enabling the DQN agent to learn optimal repositioning policies based on real-time environmental perception and RF propagation conditions.
- Experiments demonstrate the system's effectiveness in significantly reducing Line-of-Sight blockage time and improving link quality compared to static deployments.

---

[Autonomous Inorganic Materials Discovery via Multi-Agent Physics-Aware Scientific Reasoning](http://arxiv.org/abs/2508.02956v1)

- SparksMatter (Multi-Agent Physics-Aware Scientific Reasoning): introduces an LLM-driven multi-agent framework for autonomous inorganic materials discovery, integrating a Scientist Agent (generates hypotheses), Planner Agent (translates strategy to plan), Assistant Agent (executes plan, uses tools), and Critic Agent (evaluates, refines, reports) within a feedback-driven, structured pipeline.
- This framework leverages specialized tools like Materials Project for data retrieval, MatterGen for generative design, MatterSim for stability analysis, and CGCNN for property prediction, enabling end-to-end materials design from ideation to experimental roadmap.
- The system emulates scientific thinking through continuous reflection, critique, and revision, allowing it to generate novel, chemically valid, and physically meaningful inorganic materials hypotheses beyond existing knowledge.

---

[AeroSafe: Mobile Indoor Air Purification using Aerosol Residence Time Analysis and Robotic Cough Emulator Testbed](http://arxiv.org/abs/2508.02947v1)

- AeroSafe: introduces a novel system for enhancing indoor air purification efficacy, integrating a Robotic Dual-Agent Emulator, a Sensor-Instrumented Testbed, and a Digital Twin Model, which includes Sensing-based Input Features, a Cough Detector Platform, a Compartment Model, a Machine Learning Module (with GC-Layer, LSTM Network, and MAML), Concentration Prediction, and Optimal Action Prediction.
- The system utilizes a robotic dual-agent emulator, comprising a coughing mannequin and a mobile air purifier, to generate data for training a digital twin model that predicts aerosol concentration dynamics and optimizes air purifier placement.
- The digital twin model combines a physics-based compartment model with machine learning techniques, including LSTM networks and graph convolution layers, to forecast aerosol dispersion and guide real-time intervention strategies for mitigating airborne pathogen risks.

---

[Hierarchical Learning-Based Control for Multi-Agent Shepherding of Stochastic Autonomous Agents](http://arxiv.org/abs/2508.02632v1)

- Hierarchical Learning-Based Control Architecture: introduces a two-layer control system for multi-agent shepherding of stochastic autonomous agents, comprising a High-level Decision-Making Module (assigns targets to herders) and a Low-level Motion Control Component (computes herder movements), both leveraging Reinforcement Learning (synthesizes control policies) via Deep Q-Network (RL algorithm for discrete actions) or Proximal Policy Optimization (RL algorithm for continuous actions) within a Centralized Training with Decentralized Execution (MARL training paradigm), involving Herder Agents (controlled agents) and Target Agents (stochastic autonomous agents) interacting in an Environment (spatial domain with goal region).
- This decentralized architecture enables herder agents to cooperatively guide non-cohesive targets to desired spatial configurations without explicit inter-agent communication or prior knowledge of target dynamics.
- The framework demonstrates superior closed-loop performance, scalability to large-scale scenarios, adaptability to time-varying goal regions, and real-world feasibility on a robotic platform.

---

[What Is Your AI Agent Buying? Evaluation, Implications, and Emerging Questions for Agentic E-Commerce](http://arxiv.org/abs/2508.02630v1)

- ACES (Agentic e-CommercE Simulator): introduces a sandbox environment to evaluate AI agent shopping behavior, comprising an AI Agent (simulates consumer shopping) with a VLM (processes visual, language) and Tool Usage (interacts with webpages) implemented via LangChain Library (implements VLM agent) and Selenium Browser-Driver (controls web browser), interacting with a Mock E-commerce Application (simulates online marketplace) managed by an Experiments Module (manages test scenarios), all initiated by a User (initiates shopping task) and processed by a Platform App (processes purchase requests).
- The research systematically investigates AI agents' rationality, biases, and responses to various e-commerce platform levers and product attributes, such as position, price, ratings, and promotional tags.
- Key findings highlight significant heterogeneity in agent shopping preferences, strong position biases, and the potential for seller-side AI agents to substantially shift market shares through description optimization.

---

[HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous Healthcare Research](http://arxiv.org/abs/2508.02621v1)

- HealthFlow: introduces a self-evolving AI agent with meta-level strategic planning, learning, and evolution, featuring a Meta Agent (strategic planner), Executor Agent (execution engine), Evaluator Agent (short-term corrector), Reflector Agent (long-term knowledge synthesizer), Experience Memory (persistent knowledge storage), and various Tools (Python interpreter, shell, web search, code interpreter, file generator), where the system continuously refines its high-level problem-solving policies by distilling procedural successes and failures into a durable, strategic knowledge base.
- The framework operates in a continuous learning loop, enabling the agent to evolve its own strategic planning from experience, moving beyond component-level optimization.
- This approach addresses the limitation of static, predefined strategies in current AI agents by allowing HealthFlow to learn not just to execute tasks more effectively, but to strategically manage the entire problem-solving process itself.

---

[CellForge: Agentic Design of Virtual Cell Models](https://github.com/gersteinlab/CellForge)

- CELLFORGE (Agentic Design of Virtual Cell Models): introduces an agentic system for designing virtual cell models, with Task Analysis, Design Module, and Experiment Execution, which collaboratively transform biological data into optimized computational models and executable code.
- The framework employs a multi-agent architecture with specialized LLM agents that engage in graph-based discussions and iterative refinement to achieve consensus on modeling strategies.
- It integrates a shared knowledge infrastructure and a persistent memory module, enabling context-aware reasoning, traceability, and semantic understanding throughout the scientific discovery workflow.

---

[An Evolving Scenario Generation Method based on Dual-modal Driver Model Trained by Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2508.02027v1)

- MARL-based Evolving Scenario Generation Method with Dual-modal Driver Model (Dual-DM): introduces an evolving scenario generation method using a Dual-DM trained by MARL and DRL, which generates complex, diverse, and safety-critical scenarios for autonomous driving testing.
- The Dual-DM integrates non-adversarial and adversarial driving modalities, enabling background vehicles to exhibit both naturalistic and challenging behaviors.
- The method includes modules for scenario generation and evaluation, assessing fidelity, test efficiency, complexity, and diversity of the generated scenarios.

---

[Distributed AI Agents for Cognitive Underwater Robot Autonomy](http://arxiv.org/abs/2507.23735v2)

- UROSA (Underwater Robot Self-Organizing Autonomy): introduces a distributed AI agent architecture for cognitive underwater robot autonomy, integrating a Commander AI Agent, various Specialist Agents (Motion Planning, Autonomous Code Synthesis, Perception & Scene Reasoning, Capability Assessment, Predictive Diagnostics, Digital Twin Curator), ROS 2 Framework, and a Vector Database (VDB) to enable advanced cognitive capabilities.
- The architecture decentralizes cognition into specialized AI agents, each with an Agentic ROS 2 Node comprising an AI Agent, AI Reasoner, Safety Parser, and ROS 2 Publishers/Subscribers, facilitating dynamic adaptation and real-time decision-making.
- It leverages a Digital Twin for predictive analysis and proactive planning, supported by real-world Sensors and Controls & Interfaces, to achieve robust and verifiable autonomous operations in complex, unpredictable environments.

---

[CellForge: Agentic Design of Virtual Cell Models](https://github.com/gersteinlab/CellForge)

- CELLFORGE (Agentic Design of Virtual Cell Models): introduces an agentic system for designing virtual cell models, with Task Analysis, Design Module, and Experiment Execution, which collaboratively transform biological data into optimized computational models and executable code.
- The framework employs a multi-agent architecture with specialized LLM agents that engage in graph-based discussions and iterative refinement to achieve consensus on modeling strategies.
- It integrates a shared knowledge infrastructure and a persistent memory module, enabling context-aware reasoning, traceability, and semantic understanding throughout the scientific discovery workflow.

---

[CellForge: Agentic Design of Virtual Cell Models](https://github.com/gersteinlab/CellForge)

- CellForge: introduces an agentic system that leverages a multi-agent framework to transform biological datasets and research objectives into optimized computational models for virtual cells, outputting both an optimized model architecture and executable code for training and inference.
- The framework integrates Task Analysis for dataset characterization and literature retrieval, Method Design where specialized agents collaboratively develop modeling strategies, and Experiment Execution for automated code generation.
- Agents in the Design module, separated into experts with differing perspectives and a central moderator, collaboratively exchange solutions until achieving consensus, demonstrating how iterative LLM agent interaction provides better solutions than direct modeling.

---

#### 3rd August 2025

[Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework](http://arxiv.org/abs/2508.03092v1)

- Multi-Tool LLM Agent Framework: introduces a verifiable misinformation detection LLM agent, leveraging an LLM Agent (core reasoning), Web Search Tool (web search), Source Credibility Assessment Tool (credibility assessment), Numerical Claim Verification Tool (numerical verification), and Persistent Working Memory (evidence storage), guided by an Agentic Reasoning Framework (iterative reasoning).
- This framework moves beyond traditional true/false binary judgments by actively verifying claims, assessing source credibility, synthesizing evidence, and providing a complete verifiable reasoning process.
- The system significantly enhances misinformation detection accuracy, reasoning transparency, and resistance to information rewriting, setting a new paradigm for trustworthy AI-assisted fact-checking.

---

[Agent-Based Feature Generation from Clinical Notes for Outcome Prediction](http://arxiv.org/abs/2508.01956v1)

- SNOW (Scalable Note-to-Outcome Workflow): introduces an agent-based system for autonomous clinical feature generation, leveraging LLMs for feature discovery, extraction, validation, post-processing, and aggregation from unstructured clinical notes.
- This system aims to replicate expert-level feature engineering at scale, matching the performance of manual clinician feature generation without human intervention.
- Its modular architecture, composed of specialized LLM agents, ensures interpretability and scalability for clinical machine learning models.

---

[Beyond Simulation: Benchmarking World Models for Planning and Causality in Autonomous Driving](http://arxiv.org/abs/2508.01922v1)

- Benchmarking World Models for Planning and Causality: introduces new metrics and a control dropout training strategy for evaluating and improving world models as traffic simulators, including a World Model (learned dynamics model), Ego Policy Component (policy being trained), Traffic Simulator Component (simulates other agents), Causal Agent Evaluation Domain (extended evaluation context), Reactivity Metrics (evaluate simulation realism), Confusion Rates (quantify simulation/policy issues), and Control Dropout (training strategy for robustness).
- The paper extends the WOSAC evaluation domain to include causal agents and proposes reactivity metrics and confusion rates to assess model robustness under partial control.
- Control dropout is introduced as a fine-tuning method to improve world models' ability to adapt to scenarios with uncontrollable objects, enhancing their suitability for policy training.

---

[StreamAgent: Towards Anticipatory Agents for Streaming Video Understanding](http://arxiv.org/abs/2508.01875v1)

- StreamAgent: introduces a framework for streaming video understanding, with Stream Video, Memory (Captioner, Incremental Update), Question, Proactive Anticipation (Anticipatory Agent, Plan List, Heuristic Evaluation, Asynchronous React, Next Frame Anticipation), Action (Action Plan, Tool Selection, Tools, Response), and Streaming KV-cache (Long-term Memory, Selective Recall, Short-term Memory), designed to proactively anticipate task-relevant information in evolving video streams.
- The framework integrates question semantics and historical observations to forecast temporal progression and spatial locations of key events, enabling goal-driven and proactive responses.
- It employs a streaming KV-cache with a hierarchical memory structure for efficient semantic retrieval and selective recall of relevant tokens, significantly improving real-time responsiveness and accuracy.

---

[DiffSemanticFusion: Semantic Raster BEV Fusion for Autonomous Driving via Online HD Map Diffusion](http://arxiv.org/abs/2508.01778v1)

- DiffSemanticFusion: introduces a fusion framework for multimodal trajectory prediction and planning, with Sensors (Input data), Sparse Perception (Extracts dynamic objects/map elements), Dense Perception (Extracts BEV features), Vectorized Graph (Extracts graph information), Fusion (Unifies representations), and Diffusion Planner (Decodes trajectories).
- The framework reasons over a semantic raster-fused BEV space, enhanced by an online HD map diffusion module for improved stability and expressiveness.
- This approach achieves state-of-the-art performance on nuScenes and NAVSIM benchmarks for prediction and end-to-end autonomous driving.

---

[RepoForge: Training a SOTA Fast-thinking SWE Agent with an End-to-End Data Curation Pipeline Synergizing SFT and RL at Scale](http://arxiv.org/abs/2508.01550v1)

- RepoForge: introduces an autonomous, end-to-end pipeline for training software engineering LLMs, featuring RepoForge Foundry (autonomous data generation), RepoForge Harness (distributed evaluation engine), SPICE (automated difficulty assessment), and RepoForge-OpenHands Scaffold (optimized RL scaffold).
- The framework addresses bottlenecks in SWE agent training by reducing storage costs, accelerating evaluation, automating data generation, and enabling cost-effective labeling.
- RepoForge-8B-Agent, trained using this pipeline, achieves state-of-the-art performance for ≤8B non-thinking LLMs on SWE-Bench-Verified.

---

#### 2nd August 2025

[MARGen: Multi-Agent LLM Approach for Self-Directed Market Research and Analysis](http://arxiv.org/abs/2508.01370v1)

- MARGen (Market Report Generator): introduces an autonomous framework leveraging LLMs to automate end-to-end business analysis and market report generation, featuring Few-shot Prompt Construction, Retriever, Database, Researcher, Writer, Reviewer, Judge, and Human-aligned criteria.
- The framework employs specialized agents that collaborate to query databases, analyze data, generate insights, create visualizations, and compose comprehensive market reports, learning from professional consultants' materials via in-context learning.
- It integrates an iterative improvement mechanism with an LLM-based evaluation system, allowing for automated review cycles and selection of optimal reports based on human-aligned quality assessments.

---

[AGENTIC TINYML FOR INTENT-AWARE HANDOVER IN 6G WIRELESS NETWORKS](http://arxiv.org/abs/2508.09147v1)

- WAAN (Wireless AI Agent Network): introduces a cross-layer framework for intent-aware and proactive handovers in 6G wireless networks, utilizing lightweight TinyML agents across heterogeneous edge nodes.
- The framework ensures continuity across mobility-induced disruptions by incorporating semi-stable rendezvous points for context transfer and state preservation.
- It integrates cross-layer awareness and proactive intent handover, linking decision-making to real-time network state for adaptive task routing and offloading.

---

#### 1st August 2025

[Agentic large language models improve retrieval-based radiology question answering](http://arxiv.org/abs/2508.00743v1)

- Agentic RAG (Agentic Retrieval-Augmented Generation): introduces a multi-agent framework for radiology question answering, enabling LLMs to autonomously decompose questions, iteratively retrieve clinical evidence, and dynamically synthesize responses.
- This framework significantly improves diagnostic accuracy and reduces hallucinations, particularly for mid-sized and small-scale LLMs, by grounding responses in real-time, evidence-based information from Radiopaedia.org.
- The agentic approach supports interpretable, evidence-grounded QA, demonstrating complementary roles of retrieval and fine-tuning, and provides human-interpretable context for expert radiologists.

---

[Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications](http://arxiv.org/abs/2508.00669v1)

- Medical Reasoning LLMs Enhancement Taxonomy: introduces a systematic review of techniques to enhance medical reasoning in LLMs, categorizing them into training-time and test-time strategies.
- The review analyzes how these techniques are applied across different data modalities (text, image, code) and in key clinical applications like diagnosis, education, and treatment planning.
- It also surveys evaluation benchmarks, identifies challenges like faithfulness-plausibility gap and the need for native multimodal reasoning, and outlines future research directions.

---

[Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](http://arxiv.org/abs/2508.00632v1)

- AVR-Agent (Multi-agent framework for audio-visual content generation): introduces a multi-agent system for generating interactive multimedia content, featuring a Text + Code Agent, an Omni-modal Agent, and the AVR-Eval metric.
- The framework leverages Audio-Visual Recordings (AVRs) and console logs to iteratively refine JavaScript game and animation code, selecting the best initial content from multiple candidates.
- AVR-Agent aims to automate game design by integrating asset selection, code generation, and an automated evaluation loop, demonstrating improved content quality over one-shot generation.

---

[ContestTrade: A Multi-Agent Trading System Based on Internal Contest Mechanism](http://arxiv.org/abs/2508.00554v1)

- ContestTrade (A Multi-Agent Trading System Based on Internal Contest Mechanism): introduces a novel multi-agent trading system with a dual-stage pipeline, including a Data Team for factor generation and a Research Team for signal generation, both leveraging internal contest mechanisms for continuous self-optimization.
- The system processes multi-source market data through specialized Data Analysis Agents, which generate context-friendly textual factors, and then passes these to Research Agents that utilize deep research methods and financial tools to produce actionable trading signals.
- Its core innovation lies in the real-time evaluation and ranking within each team, ensuring only optimal outputs are adopted, thereby enhancing robustness against market noise and delivering superior trading performance.

---

[Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](http://arxiv.org/abs/2508.00500v1)

- Pro2Guard (Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking): introduces a proactive runtime enforcement framework that models LLM agent behavior as Discrete-Time Markov Chains (DTMCs) over symbolic abstractions, comprising Offline Sample, Domain-specific Abstraction, Learn DTMC, and Runtime Enforcement.
- The framework anticipates future risks by estimating the probability of reaching unsafe states, triggering interventions before violations occur when predicted risk exceeds a user-defined threshold.
- It ensures statistical reliability through semantic validity checks and PAC bounds, generalizing across domains like embodied household agents and autonomous vehicles.

---

[CyGATE: Game-Theoretic Cyber Attack-Defense Engine for Patch Strategy Optimization](http://arxiv.org/abs/2508.00478v1)

- CyGATE (Game-Theoretic Cyber Attack-Defense Engine for Patch Strategy Optimization): introduces a game-theoretic framework that integrates LLMs with RAG to enhance patch strategy optimization in dynamic cybersecurity environments, featuring an Input Layer (gathers threat intelligence), Graph-Based Analysis (processes system topology), Knowledge Base (stores structured data), Embed (converts data to vectors), Vector DB (stores vector embeddings), RAG Segmentation (retrieves relevant threat data), Process Layer (simulates agent interactions), Attack Planner (LLM-augmented attacker agent), Defend Analyst (LLM-augmented defender agent), POSG Simulation (models cyber conflicts), Belief Status (agents track uncertainty), Payoff Functions (quantify financial outcomes), Output Layer (produces actionable insights), and Feedback Loop (updates knowledge base).
- The framework models attacker-defender interactions as a Partially Observable Stochastic Game (POSG) across Cyber Kill Chain stages, enabling agents to adapt tactics and prioritize patches based on evolving risks and observed adversary behavior.
- It leverages LLM-augmented RAG pipelines to continuously retrieve and incorporate contextualized threat signals, enhancing adaptability to novel TTPs and evolving attack campaigns.

---

[ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](http://arxiv.org/abs/2508.00429v1)

- ReaGAN (Retrieval-augmented Graph Agentic Network): introduces an agent-based framework that models each graph node as an autonomous agent, equipped with Memory, Planning, Tools, and Action components, enabling individualized decision-making and adaptive message propagation.
- Each node leverages a frozen LLM for in-context planning and utilizes Retrieval-Augmented Generation (RAG) as a tool to access global semantic information from the graph, which is treated as a searchable database.
- This approach allows nodes to dynamically integrate both local structural and global semantic context, addressing limitations of traditional GNNs in handling information imbalance and long-range dependencies.

---

[PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning](http://arxiv.org/abs/2508.00344v1)

- PilotRL (Global Planning-Guided Progressive Reinforcement Learning): introduces an adaptive global plan-based agent paradigm, AdaPlan, which synergizes high-level explicit guidance from a Global Planner with action execution by an Executor, interacting within an Environment.
- The framework employs a three-stage progressive reinforcement learning process, including Executor Enhancement, Global Planner Cultivation, and Joint Optimization, to improve agent capabilities and coordination.
- PilotRL utilizes Group Relative Policy Optimization (GRPO) as its learning algorithm, featuring a Policy Model, Reference Model, and Group Computation to drive agent learning and performance.

---

[Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](http://arxiv.org/abs/2508.00282v1)

- Conceptual Framework: introduces a comparative study investigating the divergence between human and LLM-generated tasks, featuring Human (task generator) driven by Values (personal motivations) and Embodied Experience (physical/social grounding) to produce Human Goals (generated task), contrasted with LLM (task generator) driven by Different Prompts (input conditions) to produce LLM Goals (generated task).
- The study finds that human task generation is systematically influenced by psychological drivers and embodied experience, whereas LLMs fail to replicate these patterns, producing tasks that are less social and physical.
- This research highlights a core gap between value-driven, embodied human cognition and the statistical patterns of LLMs, emphasizing the necessity of incorporating intrinsic motivation and physical grounding into future agent design.

---

[Calibrated Language Models and How to Find Them with Label Smoothing](http://arxiv.org/abs/2508.00264v1)

- Efficient Smoothed Cross-Entropy Computation: introduces a novel method for applying label smoothing to LLMs, featuring a custom computational kernel that optimizes the cross-entropy loss calculation by leveraging block-wise processing, on-chip shared memory, and a lock mechanism for efficient forward and backward passes.
- This approach addresses significant calibration degradation in instruction-tuned LLMs, particularly those with large vocabularies, by maintaining calibration throughout the supervised fine-tuning process.
- The custom kernel dramatically reduces memory consumption for cross-entropy loss computation with label smoothing, without sacrificing speed or performance compared to existing solutions.

---

[Quality-of-Service Aware LLM Routing for Edge Computing with Multiple Experts](http://arxiv.org/abs/2508.00234v1)

- QoS-aware LLM Router: introduces a deep reinforcement learning (DRL)-based framework for routing LLM user requests to heterogeneous edge experts, aiming to maximize long-term Quality-of-Service (QoS) by considering dynamic workloads and resource heterogeneity.
- The framework incorporates a Dynamic State Abstraction technique using a Heterogeneous Graph Attention Network (HAN) to compactly represent global state features and an Action Impact Estimator with a tailored reward function to guide the DRL agent.
- This approach addresses challenges of LLM service heterogeneity, request interference, and dynamic workloads, ensuring sustained high-quality LLM services and preventing latency violations in edge computing environments.

---

[How Far Are AI Scientists from Changing the World?](http://arxiv.org/abs/2507.23276v2)

- Capability-Level Framework for AI Scientist Development: introduces a staged roadmap for AI Scientist systems, with all components, where it systematically defines the stages of AI scientist development from foundational knowledge acquisition to continuous evolution.
- The paper comprehensively analyzes current achievements of AI Scientist systems, identifying key bottlenecks and critical components required for the emergence of a scientific agent.
- This survey contributes to understanding limitations of current AI Scientist systems, outlining what is missing, and defining ultimate goals for scientific AI.

---

[Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN](http://arxiv.org/abs/2507.21696v2)

- Edge Agentic AI Framework: introduces an autonomous network optimization solution for O-RAN environments, integrating a persona-based multi-tools architecture, proactive anomaly detection via a traffic predictive tool, and a safety-aligned reward mechanism.
- The framework, embedded within the RIC as an xApp, leverages an LLM, various tools, and memory, operating through a ReAct framework to monitor and control networks in real-time.
- It achieves zero network outages under high-stress conditions by anticipating and responding to dynamic network conditions, ensuring near real-time responsiveness and consistent QoS.

---

[A SURVEY OF SELF-EVOLVING AGENTS: ON PATH TO ARTIFICIAL SUPER INTELLIGENCE](http://arxiv.org/abs/2507.21046v3)

- Self-evolving Agents: introduces a comprehensive survey of self-evolving agents, organized around four fundamental architectural components: Models (underlying LLM/MLLM), Context (information shaping agent behavior), Tools (capabilities for external interaction), and Agentic Architecture (control flow, collaborative structures).
- The paper details how these agents continuously learn and adapt from real-world feedback, aiming to overcome the static nature of traditional LLMs and pave the way for Artificial Super Intelligence (ASI).
- It provides a structured framework for understanding and designing adaptive, robust, and versatile agentic systems, covering what, when, and how agents evolve, along with evaluation metrics and future directions.

---

[GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games](http://arxiv.org/abs/2508.08501v1)

- GVGAI-LLM (General Video Game AI Large Language Model): introduces a benchmark for evaluating LLM agents, comprising a GVGAI Environment (executes game logic), Prompt Generation (prepares LLM input), and LLM Decision (LLM processes, selects action), designed to assess LLMs' reasoning and problem-solving in arcade-style games.
- The benchmark leverages a game description language (VGDL) to enable rapid game creation, represents game scenes as compact ASCII characters for efficient LLM processing, and defines interpretable metrics like meaningful step ratio and win rate.
- Experiments reveal persistent LLM limitations in spatial reasoning and basic planning, motivating structured prompting and spatial grounding techniques to improve agent behavior.

---

[Realtime Multimodal Emotion Estimation using Behavioral and Neurophysiological Data](http://arxiv.org/abs/2508.09402v1)

- Realtime Multimodal Emotion Estimation System: introduces a real-time multimodal emotion estimation system that captures behavioral and neurophysiological signals via various sensors, processes them through modality-specific inference models, and visualizes real-time arousal and valence estimates on a 2D arousal-valence map with synchronized time-series and modality-specific GUIs.
- The system's architecture, coordinated by a Python controller, supports independent processing and visualization of each modality's contribution to emotion, enabling interpretable, user-specific analysis.
- Designed for applications in emotion education, neuroadaptive feedback, and interaction support for neurodiverse users, the system ensures ethical integrity through local, storage-free processing of sensitive data.

---

[A Survey on Agent Workflow – Status and Future](http://arxiv.org/abs/2508.01186v1)

- Agent Workflow: introduces a comprehensive survey of agent workflow systems, spanning academic frameworks and industrial implementations, classifying existing systems by functional capabilities and architectural features.
- The survey highlights common patterns, technical challenges, and emerging trends, addressing workflow optimization strategies and security concerns.
- It outlines open problems like standardization and multi-modal integration, offering insights for future research at the intersection of agent design, workflow infrastructure, and safe automation.

---

[CP-FREEZER: Latency Attacks against Vehicular Cooperative Perception](http://arxiv.org/abs/2508.01062v1)

- CP-FREEZER: introduces a novel latency attack against Cooperative Perception (CP) systems, utilizing adversarial perturbation generation (crafts BEV features), a latency-inducing loss function (maximizes NMS proposals), and spatial-temporal warping (aligns attacker perturbation) to maximize computation delay.
- This attack specifically targets the Non-Maximum Suppression (NMS) bottleneck in CP pipelines by inflating high-confidence, plausible bounding box proposals, thereby disrupting real-time availability.
- Experiments demonstrate the framework increases end-to-end CP latency by over 90x, pushing per-frame processing time beyond 3 seconds with 100% success on a real-world testbed, highlighting a critical threat to autonomous driving systems.

---

[Connectivity Management in Satellite-Aided Vehicular Networks with Multi-Head Attention-Based State Estimation](http://arxiv.org/abs/2508.01060v1)

- MAAC-SAM (Multi-Agent Actor-Critic with Satellite-Aided Multi-head self-attention): introduces a novel multi-agent reinforcement learning framework for connectivity management in satellite-aided vehicular networks, integrating agents, actor, critic, state estimation network (with GRU encoder and Multi-Head Attention mechanism), Self-Imitation Learning, fingerprinting, and a shared experience replay buffer to enable autonomous vehicle connectivity management.
- The framework leverages Multi-Head Attention for robust state estimation amidst fluctuating and limited information sharing, while Self-Imitation Learning and fingerprinting enhance learning efficiency and real-time decision-making.
- It aims to optimize resource allocation and ensure seamless connectivity across V2S, V2I, and V2V links in dynamic vehicular environments, outperforming terrestrial and satellite-assisted baselines.

---

[Cooperative Perception: A Resource-Efficient Framework for Multi-Drone 3D Scene Reconstruction Using Federated Diffusion and NeRF](http://arxiv.org/abs/2508.00967v1)

- Cooperative Perception: introduces a resource-efficient framework for multi-drone 3D scene reconstruction, enabling drone swarms to build high-fidelity 3D/4D scenes in real-time by combining federated learning and conditional diffusion models with Neural Radiance Fields.
- <arxiv_paper_date>1st August 2025</arxiv_paper_date>
<arxiv_paper_name>Cooperative Perception: A Resource-Efficient Framework for Multi-Drone 3D Scene Reconstruction Using Federated Diffusion and NeRF</arxiv_paper_name>
<arxiv_paper_link>http://arxiv.org/pdf/2508.00967v1</arxiv_paper_link>
<arxiv_paper_name>Cooperative Perception:</arxiv_paper_name>
<arxiv_paper_framework_1>Drones/Local Neural Radiance Fields (NeRF)/Shared Generative Diffusion Model/Federated Learning (FL)/Semantic Extraction/Pose Conditioning/Diffusion Inference/NeRF Update Mechanism/Semantic Information/Reference Poses/Target Drone/Source Drones/YOLOv12/CLIP/ControlNet/Adapters/Target Aggregator/Semantic Fusion Component/Pose Aggregation Component/Image Generation Component/Sensors (X1/XN)/Encoder (fenc)/Actor (π)/Centralized Critic/Fusion + GT/Perception Evaluator/Reward (rt)</arxiv_paper_framework_1>
<arxiv_paper_framework_2>(multi-agent system)/(individual 3D representation)/(global scene prior)/(distributed model training)/(lightweight data compression)/(multi-view consistency)/(hallucinates unobserved views)/(local scene refinement)/(text tokens/embeddings)/(6-DoF matrices)/(initiates/processes requests)/(provide semantic/pose data)/(object detection/segmentation)/(semantic extraction)/(diffusion viewpoint control)/(global model server)/(combines semantic info)/(combines pose data)/(produces 2D images)/(local observation input)/(semantic embedding)/(decentralized policy)/(global value function)/(ground truth fusion)/(calculates utility reward)/(learning signal)</arxiv_paper_framework_2>
<arxiv_paper_description_1>Cooperative Perception: introduces a resource-efficient framework for multi-drone 3D scene reconstruction, enabling drone swarms to build high-fidelity 3D/4D scenes in real-time by combining federated learning and conditional diffusion models with Neural Radiance Fields.</arxiv_paper_description_1>
<arxiv_paper_description_2>The framework addresses communication bottlenecks, computational burdens on resource-constrained drones, and privacy/scalability issues by sharing only condensed semantic information and poses, rather than raw data or dense features.</arxiv_paper_description_3>
<arxiv_paper_description_3>It leverages a shared generative diffusion model, collaboratively trained via federated learning, to hallucinate photorealistic 2D images of unobserved areas, which then serve as training data for local NeRF or Gaussian Splatting models.</arxiv_paper_description_3>
- It leverages a shared generative diffusion model, collaboratively trained via federated learning, to hallucinate photorealistic 2D images of unobserved areas, which then serve as training data for local NeRF or Gaussian Splatting models.

---

[SmartFlow: A CFD-solver-agnostic deep reinforcement learning framework for computational fluid dynamics on HPC platforms](http://arxiv.org/abs/2508.00645v1)

- SmartFlow: introduces a CFD-solver-agnostic deep reinforcement learning framework for computational fluid dynamics on HPC platforms, with SmartSim IL (HPC orchestration/communication), SmartRedis (in-memory data store), SmartRedis-MPI (MPI-aware data exchange), CFD solver (fluid dynamics simulation), DRL Agent (reinforcement learning policy), Stable-Baselines3 (RL algorithm library), PyTorch (deep learning backend), SmartSim Orchestrator (in-memory database server), CFDEnv interface (custom environment API), and Weights & Biases/TensorBoard (experiment tracking).
- The framework enables asynchronous, low-latency, in-memory communication between CFD solvers and Python-based DRL algorithms, supporting both single- and multi-agent DRL.
- It leverages multi-environment DRL and multi-agent reinforcement learning to accelerate training, demonstrating versatility across various CFD solvers and fluid mechanics tasks.

---

[Multimodal Quantitative Measures for Multiparty Behaviour Evaluation](http://arxiv.org/abs/2508.10916v1)

- Multimodal Evaluation Framework introduces a unified, intervention-driven framework for objective assessment of multiparty social behavior, including Interaction Video (raw input data), Skeletal Representation (processed motion data), Audio (processed audio data), Apply Intervention (behavioral modification), Perception Study (human judgment collection), and Objective Metrics (automated measurement suite).
- The framework validates metric sensitivity through theory-driven perturbations applied to skeletal motion data and conducts a perception study to quantify representation effects.
- This approach provides orthogonal insights into spatial structure, timing alignment, and behavioral variability, forming a robust toolkit for evaluating socially intelligent agents.

---

[On Learning Closed-Loop Probabilistic Multi-Agent Simulator](http://arxiv.org/abs/2508.00384v1)

- NIVA (Neural Interactive Agents): introduces a probabilistic framework for multi-agent simulation, with Input Encoders, Latent Variables, a Decoder-only Transformer, and an Emission Model, enabling closed-loop, observation-conditioned simulation through autoregressive sampling from a latent, finite mixture of Gaussian distributions.
- The framework unifies sequence-to-sequence trajectory prediction models and closed-loop simulation models by reformulating the task as learning a factorized generative process over behavior styles, discrete intentions, and agent dynamics.
- NIVA's core Decoder-only Transformer uses adaptive Layer Normalization to dynamically modulate normalization parameters based on latent style and intention variables, facilitating multi-agent interaction generation conditioned on interpretable behavioral factors.

---

[Blueprint First, Model Second: A Framework for Deterministic LLM Workflow](http://arxiv.org/abs/2508.02721v1)

- SOURCE CODE AGENT (SCA): introduces a framework that decouples workflow logic from the generative model by codifying operational procedures into an Execution Blueprint, which is then executed by a Deterministic Engine, with LLMs strategically invoked as specialized tools for bounded sub-tasks.
- The framework includes a Control Layer for orchestration, a Componentized Agent SDK for assembly, a Source Code Executor for task management, and a Sandbox Runtime Environment for secure code execution.
- Key components like the Double-Check (DC) module and specialized Retail Tools (RT) enhance procedural fidelity and efficiency by integrating explicit validation and domain-specific optimizations.

---

[METAAGENT: TOWARD SELF-EVOLVING AGENT VIA TOOL META-LEARNING](http://arxiv.org/abs/2508.00271v1)

- MetaAgent: introduces a self-evolving agentic system for deep knowledge discovery, equipped with a Central Agent, Tool Router Agent, External Tools, In-House Knowledge Base, Task Experience, Self-Reflection, Verified Reflection, Dynamic Context Engineering, and Meta Tool Learning.
- The system starts with a minimal workflow and continually refines its reasoning and tool-use strategies through a data-driven process of meta tool learning, without requiring model parameter updates or extensive post-training.
- It leverages self-reflection and verified reflection to distill actionable experience, dynamically incorporating it into future task contexts and autonomously building an in-house knowledge base from tool-use history.

---

[Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI](http://arxiv.org/abs/2507.23565v2)

- Semantic Chain-of-Trust: introduces an autonomous trust orchestration method that integrates Agentic AI and hypergraph modeling to enable resource-efficient trust evaluation and management in collaborative systems.
- The system utilizes specialized LLM-powered agents for autonomous perception, task decomposition, and semantic reasoning, performing trust evaluations during device idle periods.
- It employs a trust hypergraph to hierarchically manage collaborators, dynamically classify them into trust-semantic groups, and construct multi-hop trusted collaboration paths for scalable cooperation.

---

[Large Language Models are Highly Aligned with Human Ratings of Emotional Stimuli](http://arxiv.org/abs/2508.14214v1)

- LLM Emotional Alignment Study: introduces a methodology to compare LLMs' emotional ratings with human ratings, utilizing public datasets, pre-collected human ratings, various LLMs, standardized prompts, LLM participants, a content filter, and statistical comparison.
- The study elicited emotional ratings from multiple LLMs for words and images previously rated by humans, replicating original study paradigms to assess alignment across modalities and emotion scales.
- Results indicate high alignment between GPT-4o and human ratings, particularly for happiness, but lower for arousal, suggesting LLMs interpret emotional stimuli similarly to humans, especially within a five-category emotion framework.

---

[Exploring Generative Artificial Intelligence (GenAI) and AI Agents in Research and Teaching – Concepts and Practical Cases.](http://arxiv.org/abs/2508.16701v2)

- GenAI and AI Agents: introduces an exploration of how Generative Artificial Intelligence (GenAI) and AI Agents are transforming research and education, detailing their foundational AI hierarchy, model architectures, agent types, interaction mechanisms, external interfaces, data management, and the crucial role of human oversight.
- The paper provides practical examples of GenAI and AI Agents' application across the entire research process, from ideation to publication, and throughout the teaching cycle, including lesson planning, delivery, assessment, and feedback.
- It critically examines the ethical, social, and environmental challenges associated with GenAI, such as bias, hallucinations, privacy risks, and energy consumption, while emphasizing the need for responsible development and human-in-the-loop collaboration.

---

#### 31st July 2025

[A Survey on Code Generation with LLM-based Agents](http://arxiv.org/abs/2508.00083v1)

- LLM-based Agents: introduces a systematic survey of LLM-based code generation agents, detailing their core architectural components including planning, memory, tool usage, and reflection, and exploring multi-agent system enhancements like workflow management, context management, and collaborative optimization.
- The survey categorizes core techniques, applications across the software development lifecycle, evaluation benchmarks, and representative tools, while also identifying challenges and future research directions.
- It highlights the evolution of these agents from simple text generation to autonomous systems capable of managing complex software development tasks.

---

[PHYSICSEVAL: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems](http://arxiv.org/abs/2508.00079v1)

- Multi-Agent Review Framework: introduces a system for improving LLM reasoning proficiency on physics problems, including a Proposer Module (generates initial solutions), Verifier Module (assesses solution quality), and Meta-Verifier Module (filters, aggregates feedback).
- This framework processes a Problem (input physics question) to produce a Proposed Solution (initial LLM output), which is then reviewed by multiple verifiers, leading to Aggregated Feedback (refined mistake list, score) that informs the final Solution (final refined answer).
- The framework aims to reduce computational overhead by delegating verification to smaller LLM agents and provides an unbiased assessment by comparing mistakes across multiple verifiers.

---

[SIMURA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](http://arxiv.org/abs/2507.23773v1)

- SIMURA (Simulative Reasoning Architecture): introduces a goal-oriented architecture for generalized agentic reasoning, featuring an Encoder (observation summarizer), Belief State (internal world representation), Planner (action sequence generator) with Policy (action proposer), World Model (outcome simulator), Critic (outcome evaluator), Simulated Action (high-level planning action), Actor (concrete action executor), Action (executable low-level command), and Memory (past interaction storage).
- The architecture overcomes autoregressive LLM limitations by using an LLM-based world model for planning via simulation, enabling flexible planning in diverse environments.
- SIMURA employs a hierarchical design that separates perception, simulative planning, and action selection, enhancing adaptability and consistency across various tasks.

---

[TEXTQUESTS: HOW GOOD ARE LLMS AT TEXT-BASED VIDEO GAMES?](http://arxiv.org/abs/2507.23701v1)

- TEXTQUESTS: introduces a benchmark for evaluating LLM agents in complex, interactive text-based video games, featuring Infocom Interactive Fiction Games, an LLM Agent interacting with the Environment via System Prompt, Observations, Reasoning, and Actions, supported by a Context History, optional Clues (InvisiClues), an Autosave Mechanism, and evaluated using Game Progress and Harm Metrics.
- This benchmark is designed to assess an LLM agent's self-contained problem-solving capacity by precluding external tools, focusing on intrinsic long-context reasoning and trial-and-error learning within a single interactive session.
- The framework's enhancements, including clue-assisted evaluation, autosave/restore, and a checkpoint-based game progress metric, aim to provide a more accurate and direct assessment of LLMs as the reasoning backbone of AI agent systems.

---

[A survey of multi-agent geosimulation methodologies: from ABM to LLM.](http://arxiv.org/abs/2507.23694v1)

- ARM (Agent Reference Model): introduces a formal specification for geosimulation platforms, integrating LLMs as agent components for perception, memory, planning, and action.
- The ARM defines agent internal state structures (beliefs, goals, intentions, preferences, commitments, plans, history), internal dynamics (updating, activation, planning/execution mechanisms), external state (roles, use cases), and interface (skills, abilities, capabilities).
- This framework provides a structured architecture for next-generation geosimulation systems, enabling LLMs to effectively contribute to fundamental agent activities and interactions within complex geographical simulations.

---

[CFDagent: A Language-Guided, Zero-Shot Multi-Agent System for Complex Flow Simulation](http://arxiv.org/abs/2507.23693v1)

- CFDagent: introduces a zero-shot, language-guided multi-agent system for autonomous computational fluid dynamics (CFD) simulations, integrating a Preprocessing Agent, Solver Agent, and Postprocessing Agent, all guided by GPT-4o, to handle geometry generation, flow solving, and results visualization.
- The system leverages Point-E for 3D geometry generation from text or images and an Immersed Boundary (IB) flow solver for accurate fluid dynamics simulations.
- CFDagent enables end-to-end CFD workflows from natural language prompts, significantly lowering barriers to expert-level CFD by automating complex tasks and providing multimodal output.

---

[TWEAKLLM: A ROUTING ARCHITECTURE FOR DYNAMIC TAILORING OF CACHED RESPONSES](http://arxiv.org/abs/2507.23674v1)

- TWEAKLLM (A Routing Architecture for Dynamic Tailoring of Cached Responses): introduces a novel routing architecture that dynamically adapts cached LLM responses to new prompts, utilizing a Query Preprocessing, Embedding Model, Vector Database, Cache Management, Cosine Similarity, Similarity Threshold, Small LLM, and Big LLM.
- This two-tier system optimizes response quality, latency, and computational cost by leveraging a lightweight LLM to refine cached responses for similar queries, reducing reliance on a more expensive LLM.
- The architecture significantly improves cache effectiveness and reduces inference costs while maintaining response quality comparable to frontier models, addressing limitations of traditional semantic caching.

---

[MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying](http://arxiv.org/abs/2507.23633v1)

- Recall Router: introduces MemoCue (an LLM-based agent for human memory recall), with 5W Recall Map (classifies queries), Recall Strategy Pool (stores strategies), SGR-MCTS (optimizes strategy selection), MemoStrategy Dataset (tunes LLMs), and LLMs (generate cues), where the paper proposes a novel strategy-guided method to transform original queries into cue-rich ones for memory recall.
- The framework leverages a hierarchical recall tree and Monte Carlo Tree Search to optimize strategy selection and response generation, incorporating a fine-grained reward mechanism based on simulated user feedback.
- MemoCue, developed through instruction tuning, demonstrates superior performance in recall inspiration compared to traditional LLM-based methods, addressing challenges of limited memory data and effective cue generation.

---

[DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer](http://arxiv.org/abs/2507.23554v1)

- DICE (Dynamic In-Context Example Selection): introduces a theoretically grounded in-context learning framework for LLM agents, which includes an Agent (LLM-based decision-maker), a Demo Pool (stores demonstration trajectories), a Knowledge Retriever (extracts transferable knowledge), and a Selection Mechanism (dynamically selects demonstrations) to enhance performance by maximizing transferable knowledge at each reasoning step.
- This framework addresses the sensitivity of in-context learning to demonstration choice by mitigating spurious dependencies through a causal lens, ensuring only relevant knowledge is transferred.
- Operating as a training-free, plug-in module, it consistently improves agent performance across diverse domains and existing agentic frameworks without additional training costs.

---

[Chatting with your ERP: A Recipe](http://arxiv.org/abs/2507.23429v1)

- REACT-Based Text2SQL Architecture: introduces an LLM agent that chats with an industrial ERP system by interpreting natural language queries and translating them into executable SQL statements, leveraging open-weight LLMs, with a novel dual-agent architecture combining reasoning and critique stages.
- The system's REACT Agent interprets user intent and delegates to the SQL Agent, which transforms natural language into optimized SQL queries through a collaborative loop between a SQL Reasoner and a SQL Critic.
- The architecture enhances reliability by incorporating a Database Schema for context-aware SQL generation, a Human-in-the-Loop mechanism for user intent clarification, and a Reasoned Structured Outputs pipeline for robust LLM integration.

---

[Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling](http://arxiv.org/abs/2507.23370v1)

- Trae Agent: introduces an LLM-based agent for software engineering with test-time scaling, which addresses large ensemble spaces and repository-level understanding through modular agents for generation, pruning, and selection.
- The framework enhances LLM-based issue resolution by generating diverse candidate patches, eliminating redundant or faulty ones, and accurately selecting the most plausible solution.
- It achieves superior performance on the SWE-bench benchmark, demonstrating robust effectiveness and scalability for complex software engineering tasks.

---

[SWE-Exp: Experience-Driven Software Issue Resolution](http://arxiv.org/abs/2507.23361v1)

- SWE-Exp (Experience-Driven Software Issue Resolution): introduces an experience-enhanced approach that transforms software issue resolution from isolated problem-solving into a continuous learning process, with Trajectories Collection, Experiences Extraction, ExpAgent, Experience Bank, Issue Type, Description, Comprehension Experiences, Modification Experiences, Embedding Model, Experience Reuse, Experience Retrieval, Rerank Agent, Dual-Agent Architecture, Instructor Agent, Assistant Agent, and Monte Carlo Tree Search, where it distills concise and actionable experience from prior agent trajectories to guide future repair attempts.
- The framework maintains an evolving multi-faceted Experience Bank that captures successful and failed repair attempts, encoding knowledge across trajectory-guided problem understanding, fault localization patterns, and modification strategies.
- The approach employs a dual-agent architecture, where an Instructor agent formulates high-level strategies and an Assistant agent executes low-level operations, leveraging accumulated knowledge to avoid redundant exploration and improve patch quality.

---

[SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution](http://arxiv.org/abs/2507.23348v1)

- SWE-Debate: introduces a competitive multi-agent debate framework for software issue resolution, with Issue Description, Dependency Graph Construction, Entry Node Identification, Fault Propagation Trace Generation, Localization Chain Selection, Specialized Agents, Modification Plan Proposal, Competitive Strategy Refinement, Discriminator Agent, Monte Carlo Tree Search (MCTS), Environment, Editor, and Patch Generation, designed to promote diverse reasoning paths and achieve consolidated issue localization for automated repository-level issue resolution.
- The framework operates through a three-stage pipeline: generating multiple fault propagation traces, organizing a three-round debate among specialized agents, and integrating the consolidated fix plan into an MCTS-based code modification agent for patch generation.
- This approach addresses limitations of independent agent exploration by leveraging competitive multi-agent reasoning and graph-based dependency analysis to improve fault localization accuracy and issue resolution rates.

---

[DSBC : Data Science task Benchmarking with Context engineering](http://arxiv.org/abs/2507.23336v1)

- DSBC (Data Science task Benchmarking with Context engineering): introduces a comprehensive benchmark for data science agents, evaluating LLMs across various tasks and prompting methodologies, including Context Engineering, Single-step, Multi-step, and SmolAgent approaches, with evaluation performed by a VLM-as-a-Judge.
- The benchmark is designed to reflect real-world user interactions and assess LLM sensitivity to common prompting issues like data leakage and ambiguous instructions, utilizing diverse data science task categories.
- The research investigates the impact of temperature parameters on LLM performance and identifies critical factors for practical deployment of data science agents.

---

[DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System](http://arxiv.org/abs/2507.23261v1)

- DynaSwarm: introduces a dynamic framework for LLM-based multi-agent systems, enhancing adaptability and accuracy by dynamically selecting optimal graph structures per query, with components including Swarm Structure Initialization (initializes agent graph), Reinforcement Learning Scheme (optimizes graph structures), Learned Swarm Structures (candidate graph topologies), Graph Selector (selects optimal graph), LLM Backbone (underlying language model), LoRA Modules (adapts LLM for selection), Pooler (aggregates hidden states), Linear Prediction Module (outputs selection score), LLM Agents (perform specific operations), Nodes (represent inference procedures), BranchingStep (creates multiple paths), GreedySteps (executes sequential steps), Reflection (refines previous outputs), ReturnAll (aggregates results), and Edges (define communication order).
- The framework unifies a novel reinforcement learning scheme for discovering inter-agent connection patterns with a lightweight, sample-aware controller for fine-tuning LLMs to select ideal graph topologies.
- It consistently outperforms state-of-the-art single-agent models and existing multi-agent systems across various LLM backbones and tasks, demonstrating the pivotal role of per-input structural flexibility.

---

[Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs](http://arxiv.org/abs/2507.23227v1)

- TAP-GPT (Tabular Alzheimer's Prediction GPT): introduces a novel framework for few-shot Alzheimer's Disease diagnosis on tabular biomarker data, utilizing TableGPT2 (a multimodal tabular-specialized LLM) with its semantic table encoder and QWen2.5 LLM decoder, adapted via few-shot tabular prompts and qLoRA finetuning.
- This framework repurposes TableGPT2, originally designed for business intelligence, to classify AD versus cognitively normal individuals from biomarker tables, demonstrating effective performance with limited sample sizes.
- TAP-GPT provides interpretability through generated natural language rationales for its predictions, which is crucial for clinical settings and supports the development of future LLM-driven multi-agent systems in biomedical informatics.

---

[GEAK: INTRODUCING TRITON KERNEL AI AGENT & EVALUATION BENCHMARKS](http://arxiv.org/abs/2507.23194v1)

- GEAK (Generating Efficient AI-centric GPU Kernels): introduces an agentic framework for automatic Triton kernel generation, leveraging LLMs within an Iterative Scaling loop that includes a Generator (LLM-based code producer), an Evaluator (tests code correctness/performance), a Reflector (LLM-based error analysis), and an Optimizer (LLM-based performance enhancement), further enhanced by Parallel Scaling.
- The framework iteratively refines generated Triton GPU kernels for AMD Instinct™ GPUs, aiming to achieve near-expert performance and reduce manual optimization efforts.
- GEAK significantly outperforms direct LLM prompting and Reflexion-based pipelines in correctness and execution speed on TritonBench-revised and ROCm Triton benchmarks.

---

[GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis](https://github.com/Liu-Hy/GenoMAS)

- GenoMAS (Genomic data analysis through LLM-based Multi-Agent System): introduces a multi-agent framework for scientific discovery via code-driven gene expression analysis, orchestrating six specialized LLM agents through a guided-planning framework and typed message-passing protocols.
- The framework reframes scientific agents as collaborative programmers that generate, revise, and validate executable code, bridging the gap between general reasoning and precision-driven scientific computation.
- It achieves state-of-the-art performance on gene expression analysis benchmarks by balancing structured workflows with autonomous adaptation, robust error handling, and efficient code reuse mechanisms.

---

[Distributionally Robust Cascading Risk Quantification in Multi-Agent Rendezvous: Effects of Time Delay and Network Connectivity](http://arxiv.org/abs/2507.23489v1)

- DR (Distributionally Robust) Risk Framework: introduces a method to quantify cascading risk in multi-agent rendezvous, incorporating a Time-delayed Network Model (models system dynamics), a Conditional Distributionally Robust Functional (quantifies cascading effects), an Ambiguity Set (defines plausible distributions), Systemic Events (quantify large fluctuations), and Closed-form Risk Expressions (reveal parameter impact).
- This framework addresses the challenge of unknown or fluctuating probability distributions by defining an ambiguity set, allowing for worst-case risk assessment under uncertainty.
- The derived closed-form expressions provide insights into how time delay, noise, communication topology, and failure modes influence rendezvous risk, aiding in designing resilient networks.

---

[MagicRoad: Semantic-Aware 3D Road Surface Reconstruction via Obstacle Inpainting](http://arxiv.org/abs/2507.23340v1)

- MagicRoad: introduces a unified framework for large-scale clean road surface reconstruction, integrating a Video Inpainting Pipeline, a Semantic-Aware Color Enhancement Module, and a Gaussian Scene Reconstruction Module, to recover consistent road surfaces from in-car camera videos.
- The framework leverages segmentation-guided video inpainting to remove dynamic and static foreground objects, and enhances color coherence via semantic-aware correction in HSV space.
- It utilizes a planar-adapted 2D Gaussian surfel representation for efficient large-scale modeling, enabling high-fidelity BEV rendering with RGB appearance, semantic labels, and elevation information.

---

[AI Must not be Fully Autonomous](http://arxiv.org/abs/2507.23330v1)

- AI Autonomy Framework: introduces a position paper arguing that AI must not be fully autonomous due to inherent risks, advocating for responsible human oversight across various AI systems, agents, and their levels of autonomy and environmental interactions.
- The paper identifies three levels of AI autonomy, from achieving set objectives to developing its own goals, and categorizes AI into narrow, general (AGI), and superintelligent (ASI) types, highlighting the increasing risks with higher autonomy.
- It presents 12 core arguments and 15 pieces of evidence, including existential threat, bias, side-stepping human control, and security vulnerabilities, to support the necessity of human oversight in AI development and deployment.

---

[Measuring Harmfulness of Computer-Using Agents](http://arxiv.org/abs/2508.00935v1)

- CUAHarm (Computer-Using Agent Harmfulness Benchmark): introduces a framework for evaluating Computer-Using Agents (CUAs) by presenting malicious tasks within isolated sandboxed environments, where an evaluator assesses success using rule-based verifiable rewards.
- This benchmark focuses on direct computer interaction using real-world tools and multi-step actions, providing a comprehensive assessment of CUA misuse potential beyond simple refusal rates.
- The research reveals that frontier LLMs, when acting as CUAs, exhibit significant safety risks by successfully executing harmful tasks, and explores LM-based monitors as a mitigation strategy, noting their current limitations.

---

[AI Agents and the Attention Lemons Problem in Two-Sided Ad Markets](http://arxiv.org/abs/2507.22435v2)

- Theoretical Model: introduces a framework to analyze the economic consequences of autonomous AI agents in two-sided advertising markets, demonstrating how user delegation to AI agents creates a negative externality and an "attention lemons" problem, leading to market inefficiencies and revenue erosion for publishers.
- The model identifies publisher strategies, showing that the Tolling strategy (charging AI agents a fee) dominates Null (inaction) and Blocking strategies, and proposes a Pigouvian correction mechanism to internalize the externality and restore market efficiency.
- It characterizes a critical tipping point beyond which unchecked AI agent delegation triggers a collapse of the ad-funded digital market, highlighting the finite resilience of such ecosystems without systemic correction.

---

[GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis](https://github.com/Liu-Hy/GenoMAS)

- GenoMAS (Genomic data analysis through LLM-based Multi-Agent System): introduces a multi-agent framework for scientific discovery via code-driven gene expression analysis, orchestrating six specialized LLM agents through a guided-planning framework and typed message-passing protocols.
- The framework reframes scientific agents as collaborative programmers that generate, revise, and validate executable code, bridging the gap between general reasoning and precision-driven scientific computation.
- It achieves state-of-the-art performance on gene expression analysis benchmarks by balancing structured workflows with autonomous adaptation, robust error handling, and efficient code reuse mechanisms.

---

[GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis](https://github.com/Liu-Hy/GenoMAS)

- GenoMAS (Genomic data analysis through LLM-based Multi-Agent System): introduces a multi-agent framework for scientific discovery via code-driven gene expression analysis, orchestrating six specialized LLM agents through a guided-planning framework and typed message-passing protocols.
- The framework reframes scientific agents as collaborative programmers that generate, revise, and validate executable code, bridging the gap between general reasoning and precision-driven scientific computation.
- It achieves state-of-the-art performance on gene expression analysis benchmarks by balancing structured workflows with autonomous adaptation, robust error handling, and efficient code reuse mechanisms.

---

#### 30th July 2025

[Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity](http://arxiv.org/abs/2507.23121v1)

- CTAE-M (Chinese Textual Ambiguity Evaluation Methodology): introduces a comprehensive evaluation framework to assess the trustworthiness and fragility of LLMs when encountering Chinese textual ambiguity, utilizing a new benchmark dataset, various prompting strategies, and specific evaluation tasks.
- The methodology employs a human-annotated benchmark of 900 ambiguous Chinese sentences categorized into lexical, syntactic, and semantic-pragmatic types, each with multiple interpretations and disambiguated pairs.
- It systematically evaluates LLMs across ambiguity detection, understanding, and end-to-end tasks, analyzing their overconfidence, overthinking, and inability to reliably distinguish ambiguous from unambiguous text.

---

[ChatVis: Assisting and Evaluating Large Language Models for Generating Scientific Visualizations](http://arxiv.org/abs/2507.23096v1)

- ChatVis: introduces an LLM assistant for generating scientific visualizations, with User Prompts, LLM (Operations), ParaView Code base, ParaView Documentation, Embedding Models, Vector DB, Retrieved Context, LLM (Generation), Code Solution, Code Correction (Loop), and Visualization, designed to aid LLMs in generating Python code for ParaView scientific visualization tasks without retraining.
- The framework employs chain-of-thought prompt simplification, retrieval-augmented prompt generation using a vector database of documentation and code examples, and iterative error checking.
- It significantly improves performance across various metrics compared to unassisted LLMs, demonstrating enhanced accuracy and reliability in generating visualization scripts.

---

[Beyond Rigid AI: Towards Natural Human-Machine Symbiosis for Interoperative Surgical Assistance](http://arxiv.org/abs/2507.23088v1)

- Perception Agent: introduces an AI-driven system for real-time, on-demand segmentation of known and novel surgical elements, integrating Speech-incorporated LLMs (interprets natural language), Memory Repository (stores element memory), CoTracker3 (tracks video points), SAM2 (generates segmentation masks), Object-Centric Segmentation Mechanism (identifies novel instruments by motion), and Reference-Based Segmentation Mechanism (segments novel elements using reference).
- The system facilitates natural human-machine interaction through speech-based input and hands-free, motion-based prompting for segmenting novel elements.
- It enhances surgical assistance by overcoming the rigidity of traditional AI solutions, enabling continuous learning and adaptation to dynamic surgical environments.

---

[SCREENCODER: ADVANCING VISUAL-TO-CODE GENERATION FOR FRONT-END AUTOMATION VIA MODULAR MULTIMODAL AGENTS](http://arxiv.org/abs/2507.22827v1)

- ScreenCoder (Modular Multi-Agent Framework): introduces a modular multi-agent framework for UI-to-code generation, with Input (UI screenshots/sketches), Grounding Agent (detects/labels UI components), Planning Agent (constructs hierarchical UI layout), Generation Agent (synthesizes HTML/CSS code), Output (generated webpage/code), and a Scalable Data Engine (generates UI-code training data), which decomposes the task into interpretable stages for robust front-end automation.
- This framework leverages a Vision-Language Model for component grounding, applies front-end engineering priors for hierarchical layout planning, and uses adaptive prompt-based synthesis for HTML/CSS code generation, including a placeholder mapping strategy for image restoration.
- The framework also functions as a scalable data engine, automatically producing large-scale image-code pairs to fine-tune and reinforce open-source LLMs, achieving state-of-the-art performance in layout accuracy, structural coherence, and code correctness.

---

[The Multi-Agent Fault Localization System Based on Monte Carlo Tree Search Approach](http://arxiv.org/abs/2507.22800v1)

- KnowledgeMind: introduces a multi-agent LLM system for fault localization, with Anomaly Alarm Agent, Alarm Graph Agent, Fault Mining Tree, Monte Carlo Tree Search (MCTS), Metric Agent, Trace Agent, Log Agent, Verifier Agent, Knowledge Base Agent, Service-Pod Agent, and various Tools, where it leverages MCTS and a knowledge base reward mechanism for service-by-service reasoning to identify root causes in microservice systems.
- The framework standardizes the reasoning process by constructing a Fault Mining Tree and utilizing rule-based rewards to mitigate LLM hallucinations and reduce context window length requirements.
- It integrates specialized agents for metrics, traces, and logs, enhancing diagnostic capabilities and improving root cause localization accuracy compared to existing LLM-based RCA methods.

---

[MASCA: LLM based-Multi Agents System for Credit Assessment](http://arxiv.org/abs/2507.22758v1)

- MASCA (LLM based-Multi Agents System for Credit Assessment): introduces an LLM-driven multi-agent system for credit assessment, featuring a layered architecture with specialized LLM-based agents for data ingestion, contextualization, multidimensional assessment, and strategic optimization.
- The framework's hierarchical structure, inspired by Signaling Game Theory, decomposes complex credit assessment into sub-tasks handled by collaborative agents, enhancing accuracy, fairness, and adaptability.
- It integrates contrastive learning for risk and reward assessment to optimize decision-making, providing a robust and explainable system for financial applications, particularly credit scoring.

---

[OFCNETLLM: LARGE LANGUAGE MODEL FOR NETWORK MONITORING AND ALERTNESS](http://arxiv.org/abs/2507.22711v1)

- OFCNETLLM (Large Language Model for Network Monitoring and Alertness): introduces a multi-agent LLM-based framework for network monitoring, enhancing anomaly detection, root-cause analysis, and incident analysis, with Monitoring (processes network data), Summary Agent (summarizes network data), Error Prediction Agent (predicts network errors), Sentiment Analysis Agent (analyzes network sentiment), Traffic Extrapolation Agent (extrapolates network traffic), Reporting Agent (generates network reports), Database Tools (manages monitoring databases), LLAMA (open-source LLM model), LangChain (LLM agent framework), ML Training Tools (machine learning training), Identification (classifies data segments), Solution (analyzes data protocols), and Report to Host/Operator (delivers network insights).
- The framework leverages specialized LLM-based agents and integrated tools to process network data, identify patterns, and manage monitoring databases.
- It employs a multi-stage reasoning process to systematically identify network problems, analyze large datasets, and generate actionable reports for efficient network management.

---

[MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines](http://arxiv.org/abs/2507.22606v1)

- MetaAgent: introduces an FSM-based framework for automatically generating and optimizing multi-agent systems, featuring a Designer LLM, Finite State Machine with States and Transitions, Task-Solving Agents, Condition Verifiers, Listener Agents, an Adaptor LLM for optimization, and integrated Tools.
- This framework designs agents and organizes them into an FSM, where states define sub-tasks, agents execute actions, condition verifiers manage transitions, and listener agents receive outputs, enabling dynamic problem-solving and state traceback.
- The system optimizes the FSM by merging redundant states using an Adaptor LLM, enhancing robustness and performance without external training data, and supports tool-using for real-world interaction.

---

[Strategic Communication and Language Bias in Multi-Agent LLM Coordination](http://arxiv.org/abs/2508.00032v1)

- FAIRGAME (computational framework): introduces a system for simulating strategic interactions among LLM-based agents, including a communication layer, configuration file, prompt template, and various game scenarios, utilizing LLMs like GPT-4o and Llama 4 Maverick.
- This framework enables controlled experimentation across different models, languages, and behavioral setups to investigate how explicit communication influences collective behavior and biases.
- The study extends FAIRGAME to support inter-agent dialogue, allowing for systematic comparison of interactive and non-interactive conditions in game-theoretic environments.

---

[GIT CONTEXT CONTROLLER: MANAGE THE CONTEXT OF LLM-BASED AGENTS LIKE GIT](http://arxiv.org/abs/2508.00031v1)

- GCC (Git-Context-Controller): introduces a structured context management framework for LLM-based agents, with Git-inspired operations and a version-controlled file system, including a persistent file system, .GCC/ directory, main.md, branches/ directory, <branch-name>/ directory, commit.md, log.md, metadata.yaml, and callable commands like COMMIT, BRANCH, MERGE, and CONTEXT, enabling agents to manage long-horizon goals and structured reflection.
- The framework elevates agent context from passive token streams to a navigable, versioned memory hierarchy, supporting multi-level context retrieval and isolated exploration via branching.
- Equipped LLM-based agents with GCC achieve state-of-the-art performance on SWE-Bench-Lite, demonstrating improved task resolution and the emergence of recursive self-improvement in a self-replication case study.

---

[AutoCodeSherpa: Symbolic Explanations in AI Coding Agents](http://arxiv.org/abs/2507.22414v1)

- AutoCodeSherpa: introduces a framework for symbolic bug explanations, generating input, infection, and output conditions using LLM agents and program analysis tools, including PBT-generating agent, Code exploration agent, Infection condition generating agent, PBT execution and manipulation tools, Command line and file reading tools, Condition injection and test execution tools, Input condition, Infection conditions, Output condition, Buggy program, and Fixed program.
- This multi-agent system helps developers understand bugs, assess patch correctness, and improve other AI agents' effectiveness by providing executable explanations.
- The framework's symbolic explanations, derived from natural language issue descriptions, capture the bug's trigger, propagation, and symptoms, enhancing trust in AI-generated fixes.

---

[Mitigating Response Delays in Free-Form Conversations with LLM-powered Intelligent Virtual Agents](http://arxiv.org/abs/2507.22352v1)

- The System Architecture: introduces a pipeline for LLM-powered intelligent virtual agents in VR, integrating Unity (VR application environment), Microphone Listener (captures user speech), Audio Player (plays agent voice), OVR Lip Sync (animates agent mouth), ASR Model (transcribes user speech), Conversation Handler (manages dialogue flow), Message History (stores conversation context), Transition Check (identifies task transitions), LLM (generates agent responses), and TTS API (converts text to voice).
- This system investigates the impact of response delays and conversational fillers on user perception and experience in free-form conversations within virtual reality.
- The research demonstrates that natural conversational fillers improve perceived response time, especially in high-delay conditions, and provides an open-source pipeline for deploying such agents.

---

[An Explainable Emotion Alignment Framework for LLM-Empowered Agent in Metaverse Service Ecosystem](http://arxiv.org/abs/2507.22326v1)

- Explainable Emotion Alignment Framework: introduces an LLM-empowered agent framework that integrates factual factors into decision-making, enabling agents to achieve more relational fact alignment through emotional data clustering, evolution, self-explanation, and knowledge storage.
- The framework enhances LLMs' comprehension of knowledge-emotion dependencies and establishes an emotional evolution system for more human-like decisions and behaviors in social simulation.
- Simulation experiments in an Offline-to-Offline food delivery scenario validate the framework's effectiveness in achieving more realistic social emergence and lower order rejection rates.

---

[DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router](http://arxiv.org/abs/2507.22050v2)

- DeepSieve (Information Sieving via LLM-as-a-Knowledge-Router): introduces a novel RAG method that incorporates information sieving via an LLM-as-a-knowledge-router, which dynamically decomposes queries, routes sub-questions to heterogeneous knowledge sources, and iteratively refines answers through a multi-stage process.
- This modular and transparent approach addresses the limitations of traditional RAG pipelines by providing fine-grained control over query and source sides, enhancing reasoning depth and retrieval precision.
- The framework demonstrates superior performance across multi-hop QA benchmarks with heterogeneous sources, achieving higher accuracy and token efficiency compared to existing RAG and agentic baselines.

---

[Can large language models assist choice modelling? Insights into prompting strategies and current models capabilities](http://arxiv.org/abs/2507.21790v1)

- Experimental Framework: introduces a systematic evaluation of LLMs as assistive agents in discrete choice modeling, utilizing Large Language Models (LLMs), Input Data, Prompting Strategies, Information Settings, Modelling Goals, Generated MNL Specifications, Self-Generated Code, External Estimation, and Evaluation Metrics to assess their capabilities in model specification and estimation.
- The framework benchmarks thirteen LLM versions across five experimental configurations, varying prompting strategies (Zero-Shot vs. Chain-of-Thought), information availability (full dataset vs. data dictionary), and modeling goals (suggesting vs. suggesting and estimating Multinomial Logit models).
- Findings indicate that structured prompts and limited raw data access can enhance LLM performance in generating plausible specifications, with GPT-03 uniquely capable of end-to-end estimation via self-generated code, while open-weight LLMs generally underperformed.

---

[Causal-Inspired Multi-Agent Decision-Making via Graph Reinforcement Learning](http://arxiv.org/abs/2507.23080v1)

- CGRL (Causal-Inspired Graph Reinforcement Learning): introduces a multi-agent decision-making framework that integrates Causal Disentanglement Representation Learning (CDRL) with Graph Reinforcement Learning (GRL) to identify and leverage causal features for optimal decision-making in autonomous vehicles.
- The framework utilizes a Variational Graph Autoencoder (VGAE) within CDRL to extract causal features from graph-structured data, which are then fed into the GRL algorithm, implemented using Graph Neural Networks (GNNs) and Dueling Double Deep Q-Network (D3QN).
- This approach enhances decision-making by discerning causal features that influence optimal vehicle behavior, leading to improved safety and efficiency in complex traffic scenarios like unsignalized intersections.

---

[Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review](http://arxiv.org/abs/2508.05660v1)

- Open-Source Agentic Hybrid RAG Framework: introduces an AI Agent (Orchestrates dynamic retrieval) that leverages a Hybrid RAG Pipeline (Combines retrieval strategies) comprising GraphRAG (Cypher-based KG retrieval) and VectorRAG (Similarity-based VS retrieval), interacting with a Knowledge Graph (Structured bibliometric data) and a Vector Store (Embedded full-text storage), supported by Data Ingestion (Gathers, cleans, preprocesses data) and Response Generation (Generates final answers), enhanced by Instruction Tuning (Refines LLM generation), Direct Preference Optimization (Optimizes response generation), and Uncertainty Quantification (Estimates output confidence).
- The framework dynamically selects between graph-based and vector-based retrieval modes, grounding LLM outputs in external documents to improve factual accuracy and provide source provenance for scientific literature review.
- It integrates a Llama-3.3-70B-versatile LLM for agentic reasoning and a Mistral-7B-Instruct-v0.3 LLM for response generation, with DPO applied to align outputs with human judgment and reduce hallucinations.

---

[RLVMR: Reinforcement Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon Agents](https://github.com/Tencent/DigitalHuman/tree/main/RLVMR)

- RLVMR (Reinforcement Learning with Verifiable Meta-Reasoning Rewards): introduces a novel framework that integrates dense, process-level supervision into end-to-end reinforcement learning by rewarding verifiable meta-reasoning behaviors, including Cold Start Phase (initial meta-reasoning acquisition), Supervised Fine-Tuning (SFT) (bootstraps meta-reasoning capabilities), Reinforcement Learning Phase (refines agent policy), Rollout Trajectories (agent-environment interactions), Group Relative Advantage Computing (calculates step-level advantages), Meta-reasoning Type Grouping (groups steps by reasoning tag), and Trajectory Outcome Reward Grouping (groups steps by outcome reward), to address inefficient exploration in long-horizon tasks.
- The framework equips LLM agents to explicitly tag cognitive steps like planning, exploration, reflection, and monitoring, providing programmatic, rule-based rewards for actions contributing to effective problem-solving, combined with a final outcome signal.
- This approach significantly improves success rates and generalization by mitigating inefficient exploration, leading to more robust, efficient, and interpretable agents with reduced redundant actions and enhanced error recovery.

---

[Beyond Benchmarks: Dynamic, Automatic And Systematic Red-Teaming Agents For Trustworthy Medical Language Models](http://arxiv.org/abs/2508.00923v1)

- DAS (Dynamic, Automatic, and Systematic) red-teaming framework: introduces a continuous, agent-based audit system for stress-testing LLMs, with an Orchestrator coordinating Attacker Agents (using various Robustness Mutation Tools, Privacy Disguise Agents, and Bias Attack Agents) and Detector Agents (with Hallucination Detection Sub-agents and a Privacy Judge Model) to evaluate Rabbit Models.
- This framework autonomously mutates test cases, identifies unsafe-triggering strategies, and evaluates LLM responses across four critical safety dimensions: robustness, privacy, bias/fairness, and hallucination.
- The system operates end-to-end without human intervention, dynamically adapting its attack strategies to uncover vulnerabilities and provide an evolvable, scalable, and reliable safeguard for medical AI.

---

[Magentic-UI: Towards Human-in-the-loop Agentic Systems](http://arxiv.org/abs/2507.22358v1)

- Magentic-UI (Multi agentic-User Interface): introduces an open-source human-in-the-loop agentic system designed to facilitate human-agent collaboration and oversight for complex, multi-step tasks.
- Its flexible multi-agent architecture includes a lead Orchestrator agent, specialized sub-agents (WebSurfer, Coder, FileSurfer, UserProxy, and optional MCP agents), and a robust backend with Docker containers, a database manager, and a shared workspace, all powered by LLMs.
- The system integrates six key interaction mechanisms—Co-Planning, Co-Tasking, Action Approval, Answer Verification, Memory, and Multi-tasking—along with an Action Guard system, to ensure safe, efficient, and controlled agent operation.

---

[RLVMR: Reinforcement Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon Agents](https://github.com/Tencent/DigitalHuman/tree/main/RLVMR)

- RLVMR (Reinforcement Learning with Verifiable Meta-Reasoning Rewards): introduces a novel framework that integrates dense, process-level supervision into end-to-end RL by rewarding verifiable meta-reasoning behaviors, including planning, exploration, reflection, and monitoring, to enhance LLM agents' robustness and generalization.
- This framework addresses the inefficient exploration problem in long-horizon tasks by providing explicit rewards for coherent reasoning steps, mitigating brittle policies and improving adaptability to unseen scenarios.
- RLVMR achieves state-of-the-art performance on challenging benchmarks by combining a brief cold-start supervised fine-tuning phase with a reinforcement learning phase that optimizes a composite reward signal using GRPO-MR.

---

#### 29th July 2025

[CoEx – Co-evolving World-model and Exploration](http://arxiv.org/abs/2507.22281v1)

- CoEx (Co-evolving World-model and Exploration): introduces a hierarchical agent architecture that enables LLM planning to co-evolve with a dynamically updated world model, featuring a Planner (generates abstract subgoals), an Actor (executes subgoals, low-level actions), and an Adaptive Belief State (adaptable world model representation) comprising Symbolic Memory (code-based, object-oriented facts), Structured Textual Memory (natural language, higher-level understanding), and a Verification and Synthesis Module (updates belief state).
- This framework addresses exploitation bias and limited adaptation in monolithic LLM agents by decoupling planning and exploration at the subgoal level and integrating new observations into a persistent, explicit world model.
- The agent demonstrates superior performance in planning and exploration across diverse text-based environments like ALFWorld, PDDL, and Jericho by leveraging its neurosymbolic belief state and dynamic replanning capabilities.

---

[Promoting Online Safety by Simulating Unsafe Conversations with LLMs](http://arxiv.org/abs/2507.22267v1)

- Simulating Scam Conversations to Increase Resilience: introduces a system that promotes online safety by simulating unsafe conversations between a scammer LLM and a target LLM, where users provide feedback to the target LLM.
- This system leverages distinct LLM personalities, configured via prompt engineering, to create realistic scam scenarios for user interaction and learning.
- The approach aims to help users develop mental models and resilience against online scams by actively engaging them in preventing the target LLM from divulging sensitive information.

---

[CTG-Insight: A Multi-Agent Interpretable LLM Framework for Cardiotocography Analysis and Classification](http://arxiv.org/abs/2507.22205v1)

- CTG-Insight: introduces a multi-agent LLM framework for cardiotocography analysis and classification, with CTG Trace (fetal monitoring data input), Feature Agents (parallel feature analysis), and Aggregator Agent (holistic classification and explanation).
- The framework decomposes CTG interpretation into five medically defined features—baseline, variability, accelerations, decelerations, and sinusoidal pattern—each analyzed by a dedicated LLM agent.
- An aggregation LLM agent then synthesizes these individual feature analyses to provide a comprehensive fetal health classification with natural language explanations, mirroring clinical reasoning.

---

[Validating Generative Agent-Based Models of Social Norm Enforcement: From Replication to Novel Predictions](http://arxiv.org/abs/2507.22049v1)

- LLM Agent Architecture: introduces a systematic two-stage validation approach for generative agent-based models (GABM) of social norm enforcement, which includes an Observation Summary (processes game information), Situation Assessment (evaluates decision context), Decision (generates agent action), Persona Component (models individual differences), Theory of Mind Component (reasons about others), Strategic Reflection Component (optimizes long-term payoff), and Emotion Reflection Component (models emotional responses).
- The paper validates these LLM agent architectures by replicating known human behaviors in social dilemma paradigms, such as the Trust Game and Public Goods Game, and then uses the validated models to simulate novel conditions and generate predictions.
- This framework enables systematic hypothesis testing about which cognitive mechanisms are necessary for reproducing human social behavior, providing a rigorous method for evaluating generative agent models and advancing understanding of social dynamics.

---

[UserBench: An Interactive Gym Environment for User-Centric Agents](http://arxiv.org/abs/2507.22034v1)

- UserBench: introduces a user-centric gym environment designed to evaluate LLM agents in multi-turn, preference-driven interactions, with all its components including Data Gathering, Tool Augmentation, Environment, and Interface, where it simulates realistic user communication traits like underspecification, incrementality, and indirectness in travel planning scenarios.
- The environment features a standardized interaction interface and a stable tool-use backend, enabling rigorous and reproducible evaluation of agent performance in understanding and aligning with user intent.
- The framework provides a scalable and modular setup for benchmarking and training LLM agents to become collaborative partners rather than just task executors.

---

[Exploring the Stratified Space Structure of an RL Game with the Volume Growth Transform](http://arxiv.org/abs/2507.22010v1)

- PPO-TransformerXL: introduces a framework to explore the geometric structure of the embedding space of a transformer model trained for reinforcement learning, utilizing a Visual Encoder (processes raw visual observations), Token Embedding Layer (converts CNN output to token embeddings), Transformer-XL Blocks (processes sequential token embeddings, leveraging memory), Value Head (predicts state values for PPO), Policy Head (outputs action probabilities for PPO), PPO Algorithm (optimizes policy and value functions), and Memory Window (manages recurrent state for Transformer-XL).
- The paper investigates how a transformer-based PPO model embeds visual inputs from a "Searing Spotlights" RL game, finding that the token embedding space is better modeled as a stratified space with varying local dimensions rather than a manifold.
- This research adapts the Volume Growth Transform from LLM analysis to the RL setting, suggesting that the distribution of dimensions in a stratified latent space can serve as a new geometric indicator of complexity for RL games.

---

[Towards Cognitive Synergy in LLM-Based Multi-Agent Systems: Integrating Theory of Mind and Critical Evaluation](http://arxiv.org/abs/2507.21969v1)

- CSF (Cognitive Synergy Framework): introduces a multi-agent system framework that integrates dynamic Theory of Mind (ToM) and structured critical evaluation to enhance collaborative reasoning in LLM-based systems, featuring an Orchestrator, Specialized Agents, a Critic Agent, an Integrator, and a Knowledge Base.
- This framework aims to achieve cognitive synergy by enabling agents to model others' perspectives and systematically critique arguments, leading to more coherent, adaptive, and rigorous interactions.
- The system leverages LLMs for agent intelligence and external tools like Neo4j and Clingo for knowledge management and logical reasoning, demonstrating improved argument quality and risk resolution in complex decision-making scenarios.

---

[MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation](http://arxiv.org/abs/2507.21953v1)

- MapAgent: introduces a novel LLM-based agent framework that leverages memory constructed from historical trajectories to augment current task planning, with a Trajectory-based Memory Mechanism (condenses historical trajectories), Page-Memory Database (structured long-term memory), Memory-Augmented Task Planning (coarse-to-fine planning), and Task Executor (dual-LLM execution engine).
- The framework transforms task execution trajectories into reusable page chunks stored in a database, enabling the agent to retrieve relevant pages for informed and context-aware planning.
- Its dual-LLM architecture, comprising a Decision-maker and a Judge, ensures effective tracking of task progress and handles complexities in mobile environments.

---

[MMAT-1M: A Large Reasoning Dataset for Multimodal Agent Tuning](http://arxiv.org/abs/2507.21924v1)

- MMAT-1M (Multi-Modal Agent Tuning-One Million): introduces a novel four-stage data engine for multimodal agent tuning, including a Foundation Stage (curates multimodal data), Rationale Generation Stage (generates reasoning trajectories), Reflection Stage (refines rationales), and Integration Stage (formats dialogues).
- This framework leverages GPT-4o and various API/RAG tools (Image Caption, OVD, OCR, Face Detection, RAG) to create a million-scale dataset supporting Chain-of-Thought, reflection, and dynamic tool usage.
- The dataset provides both one-turn (ORR) and multi-turn (RR) formats, demonstrating significant performance gains for fine-tuning open-source multimodal models across diverse benchmarks.

---

[GRAPH-R1: TOWARDS AGENTIC GRAPHRAG FRAME-WORK VIA END-TO-END REINFORCEMENT LEARNING](http://arxiv.org/abs/2507.21892v1)

- Graph-R1 (Agentic GraphRAG Framework): introduces an agentic GraphRAG framework via end-to-end reinforcement learning, featuring a Graph-R1 Agent (LLM-driven agent), Knowledge HyperGraph (GH) (structured knowledge environment), and Reinforcement Learning (RL) (end-to-end optimization).
- The framework models retrieval as a multi-turn agent-environment interaction, optimizing the agent process through an outcome-directed Reward Function (R(τ)) that integrates generation quality, retrieval relevance, and structural reliability.
- Graph-R1 leverages lightweight knowledge hypergraph construction and dual-path hypergraph retrieval to enhance reasoning accuracy, retrieval efficiency, and generation quality.

---

[Prototyping Compliance: Participatory Legal UX for Platform Reporting Mechanisms under the DSA](http://arxiv.org/abs/2507.21842v1)

- Participatory Legal UX: introduces a qualitative case study examining how designers mediate between abstract legal requirements and real-world digital experiences for users, focusing on the design of content reporting mechanisms under Article 16 of the DSA, through an expert workshop utilizing participatory design methods, user personas, usability heuristics, and legal obligations to evaluate UI flows and generate compliance-fostering design solutions.
- The study highlights critical usability barriers in existing reporting systems, such as poor discoverability, legalistic language, and lack of feedback, proposing participatory design as a bridge for disciplinary divides.
- Findings emphasize the crucial role of designers in shaping policy and law by translating regulatory intentions into concrete digital experiences and resolving value tensions.

---

[Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?](http://arxiv.org/abs/2507.21817v1)

- Multi-Agent LLM Frameworks: introduces "Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?", with Dataset Integration (Combines/standardizes datasets), LLM-Based Filtering (Filters unrelated code changes), RVG Context & Threat Modeler (Creates attack scenarios), RVG Vulnerable Implementer (Generates vulnerable code), RVG Security Auditor (Identifies/remediates vulnerabilities), RVG Security Reviewer (Validates vulnerability/remediation), Cross-Model Validation (Validates synthesized data), TITANVUL Vulnerability Auditor (Assesses vulnerability fixes), TITANVUL Vulnerability Critic (Reviews auditor's findings), TITANVUL Vulnerability Consensus (Synthesizes assessments/scores), and Manual Review (Verifies/validates data), where the paper addresses the generalization gap in automated vulnerability detection through new datasets and a data synthesis framework.
- The paper introduces BENCHVUL, a manually curated benchmark, and TITANVUL, a large-scale high-quality training dataset, both designed to improve model generalization by mitigating data quality issues and imbalances.
- Empirical results demonstrate that models trained on TITANVUL, especially when augmented with RVG-generated data, achieve significantly higher generalization accuracy compared to models trained on existing datasets.

---

[StaffPro: an LLM Agent for Joint Staffing and Profiling](http://arxiv.org/abs/2507.21636v1)

- StaffPro (LLM Agent): introduces an LLM agent for joint staffing and profiling, integrating a Staffing Module (generates task schedules), a Profiling Module (estimates worker attributes), and a Long-term memory (stores historical data) to continuously improve personnel management.
- The Staffing Module leverages an LLM for evaluating optimization criteria and aggregates scores before a Scheduler generates feasible schedules, which are then proposed to Workers for acceptance or refusal.
- The Profiling Module, utilizing an LLM for analysis and reflection, processes feedback from Workers (self-evaluations, task acceptance/refusal) and Supervisors (performance reviews) to update the Worker profiling data in the Long-term memory, enhancing future staffing decisions.

---

[Large Language Models for Wireless Communications: From Adaptation to Autonomy](http://arxiv.org/abs/2507.21524v1)

- Large Language Models for Wireless Communications: introduces a paradigm for transforming wireless systems by adapting pretrained LLMs for core communication tasks, developing wireless-specific foundation models, and enabling agentic LLMs with autonomous reasoning and coordination capabilities.
- The paper details how LLMs can be adapted for physical layer prediction, resource allocation, and semantic communication, addressing modality mismatches and enhancing generalization.
- It further explores the development of compact, domain-specific wireless foundation models for efficiency and multi-task generalization, and agentic LLMs for self-organizing, adaptive wireless networks through reasoning, memory, and tool use.

---

[Evaluation and Benchmarking of LLM Agents: A Survey](http://arxiv.org/abs/2507.21504v1)

- Taxonomy for LLM-based Agent Evaluation: introduces a two-dimensional framework for evaluating LLM agents, encompassing Evaluation Objectives (what to evaluate) and Evaluation Process (how to evaluate), where Evaluation Objectives cover agent behavior, capabilities, reliability, and safety/alignment, and Evaluation Process includes interaction modes, data, metrics, tooling, and contexts.
- This taxonomy aims to clarify the fragmented landscape of LLM agent evaluation, providing a systematic assessment framework for real-world deployment.
- The paper also highlights enterprise-specific challenges like role-based access, reliability guarantees, and long-horizon interactions, and identifies future research directions for holistic, realistic, scalable, and efficient evaluation.

---

[Transmission With Machine Language Tokens: A Paradigm for Task-Oriented Agent Communication](http://arxiv.org/abs/2507.21454v1)

- TMLT (Transmission With Machine Language Tokens): introduces a task-oriented agent communication system that leverages LLMs to learn specialized machine language tokens for efficient multi-modal information transmission, comprising an Agent Semantic Transmitter (multi-modal input processing), Joint Token and Channel Coding (token compression/robustness), Orthogonal Frequency Division Analog Transmission (analog signal transmission), Joint Token and Channel Decoding (token reconstruction), and an Agent Semantic Receiver (downstream task execution).
- This system enables agents to communicate task-relevant information compactly and robustly by converting natural language and multi-modal inputs into machine-interpretable token embeddings transmitted over noisy wireless channels.
- The approach employs end-to-end training with Low-Rank Adaptors (LoRA) to optimize for downstream tasks, significantly reducing transmission overhead and latency while maintaining accuracy.

---

[Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour](http://arxiv.org/abs/2507.21432v1)

- LiTransMC (Locally Deployable Fine-Tuned Causal Large Language Model for Mode Choice Behaviour): introduces a fine-tuned causal LLM for travel mode choice prediction, with a Base LLM (foundational causal LLM), Data Ingestion Module (processes structured survey data), Prompt Engineering Module (constructs prompts with system instructions, data, few-shot examples), Inference Engine (manages LLM querying and response generation), Response Processing Module (parses LLM output into structured predictions and reasoning), Fine-tuning Module (adapts base LLM for mode choice prediction), and Evaluation Module (assesses predictive performance and reasoning quality), demonstrating the feasibility of creating specialist, locally deployable LLMs that integrate prediction and interpretability.
- LiTransMC achieves state-of-the-art performance in weighted F1 score and Jensen-Shannon Divergence, surpassing untuned local models, larger proprietary systems, and classical mode choice methods.
- The framework combines structured behavioral prediction with natural language reasoning, enabling conversational, multi-task transport models for agent-based simulations, policy testing, and behavioral insight generation.

---

[MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations](http://arxiv.org/abs/2507.21428v1)

- MemTool: introduces a short-term memory framework for LLM agents, with Autonomous Agent Mode (full tool management autonomy), Workflow Mode (deterministic control without autonomy), and Hybrid Mode (combining autonomous and deterministic control).
- This framework enables LLM agents to dynamically manage tools or Model Context Protocol (MCP) server contexts across multi-turn conversations, addressing the limitations of fixed context windows in repeated tool usage scenarios.
- Evaluated across 13+ LLMs, MemTool demonstrates varying tool removal efficiencies and task completion rates across its modes, providing insights into effective short-term tool memory management.

---

[Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects](http://arxiv.org/abs/2507.21407v1)

- GLA (Graph-Augmented Large Language Model Agents): introduces a comprehensive overview of recent advances and future prospects in integrating graphs with LLM agents, enhancing their planning, memory, tool usage, and multi-agent system capabilities.
- The paper categorizes existing GLA methods by their primary functions, analyzing how various graph types and learning algorithms contribute to each module.
- It highlights key future directions for GLA, including dynamic graph learning, unified graph abstractions, multimodal graphs, and large-scale multi-agent system simulation.

---

[Human-AI Co-Creation: A Framework for Collaborative Design in Intelligent Systems](http://arxiv.org/abs/2507.17774v1)

- Human-AI Co-Creation Framework: introduces a three-tiered approach for collaborative design, with Passive Assistance (reactive suggestions, user selects), Interactive Co-Creation (dialogic refinement, AI explains), and Proactive Collaboration (AI initiates, user curates), where it positions AI as a co-creative partner in early-stage design workflows.
- The framework differentiates modes of human-AI collaboration based on system initiative and designer control, aiming to augment human imagination and agency rather than replace it.
- The study demonstrates that AI-assisted design reduces cognitive load, increases ideation fluency, and inspires novel directions through creative dissonance.

---

[Physics-Informed EvolveGCN: Satellite Prediction for Multi Agent Systems](http://arxiv.org/abs/2507.22279v1)

- Physics-Informed EvolveGCN: introduces a novel method for satellite prediction in multi-agent systems, leveraging EvolveGCN (dynamic graph convolutional network) with GCNs (process graph structure) and a GRU (evolves GCN weights), augmented by a Physics-informed Loss Function (constrains predictions) based on Clohessy-Wiltshire Equations (models orbital motion).
- This integrated approach enhances the reliability of future state estimations by dynamically updating graph parameters and ensuring physical plausibility through physics-constrained loss functions.
- The framework is designed to forecast the evolution of inter-agent relationships over time, improving prediction accuracy and ensuring physically plausible trajectories for multi-agent coordination.

---

[A Survey on Deep Multi-Task Learning in Connected Autonomous Vehicles](http://arxiv.org/abs/2508.00917v1)

- Deep Multi-Task Learning in Connected Autonomous Vehicles (CAVs): reviews deep Multi-Task Learning (MTL) methods applied to CAVs, encompassing their system architecture, architectural paradigms, and optimization strategies.
- The survey categorizes MTL applications across key CAV functional modules, including perception, prediction, planning, control, and multi-agent collaboration.
- It identifies key research gaps and outlines promising directions for future MTL advancements in CAV systems.

---

[Hierarchical Game-Based Multi-Agent Decision-Making for Autonomous Vehicles](http://arxiv.org/abs/2507.21941v1)

- Hierarchical Game-Based Multi-Agent Decision-Making Framework: introduces a game-theoretic decision-making framework for autonomous vehicles in multi-agent scenarios, featuring an Interaction Graph, Agent Clustering, Game Player Selection, Multi-player Normal Game, and Payoff Design.
- This framework significantly reduces computational complexity compared to standard multi-player games by smartly selecting a limited number of relevant agents as game players, while capturing more interaction information than pairwise games.
- An Improved Hierarchical Game further reduces computational cost by decomposing the main game into sub-games based on Interaction Graph branches, ensuring both safety and efficiency.

---

[Bayesian-Driven Graph Reasoning for Active Radio Map Construction](http://arxiv.org/abs/2508.09142v1)

- URAM (Uncertainty-Aware Radio Map) Reconstruction Framework: introduces a closed-loop system for active radio map construction, integrating a Bayesian Neural Network (BNN) for real-time spatial uncertainty estimation and an attention-based reinforcement learning (RL) planner for energy-efficient trajectory planning over a probabilistic roadmap.
- This framework leverages graph-based reasoning for non-myopic trajectory planning, guiding agents to informative regions while adhering to safety and budget constraints.
- Experiments demonstrate that this approach significantly improves radio map reconstruction accuracy and efficiency compared to existing baselines.

---

[T2I-Copilot: A Training-Free Multi-Agent Text-to-Image System for Enhanced Prompt Interpretation and Interactive Generation](http://arxiv.org/abs/2507.20536v2)

- T2I-Copilot: introduces a training-free multi-agent text-to-image system for enhanced prompt interpretation and interactive generation, featuring an Input Interpreter Agent, Generation Engine Agent, and Quality Evaluator Agent, supported by User Input, Analysis Report, Generated Result, User Feedback, MLLMs, T2I Models, and Referring Expression Segmentation.
- This system refines ambiguous user prompts, resolves ambiguities, and iteratively evaluates results, providing feedback to guide regeneration and improve text-image alignment.
- It operates autonomously while supporting human-in-the-loop intervention, simplifying prompt engineering and enhancing generation quality without requiring additional training.

---

#### 28th July 2025

[MAAD: Automate Software Architecture Design through Knowledge-Driven Multi-Agent Collaboration](http://arxiv.org/abs/2507.21382v1)

- MAAD (Multi-Agent Architecture Design): introduces an automated framework for software architecture design, orchestrating four specialized LLM agents—Analyst (requirements analysis), Modeler (architecture blueprint generation), Designer (detailed documentation), and Evaluator (architecture assessment)—to collaboratively produce architectural blueprints and evaluation reports.
- The framework integrates a knowledge source via Retrieval-Augmented Generation (RAG) to infuse external knowledge into the Modeler and Designer agents, enhancing design quality and mitigating hallucinations.
- MAAD demonstrates superior performance in generating comprehensive and fine-grained architectural solutions compared to baseline multi-agent systems, emphasizing the critical impact of LLM selection on design quality.

---

[ProMemAssist: Exploring Timely Proactive Assistance Through Working Memory Modeling in Multi-Modal Wearable Devices](http://arxiv.org/abs/2507.21378v1)

- ProMemAssist: introduces a smart glasses system that models a user's working memory in real-time using multi-modal sensor signals, including a Working Memory (WM) Model, Assistance Generator (LLM), and Timing Predictor Module.
- This system encodes visuospatial and phonological memory items into an episodic buffer, informing a timing predictor that balances assistance value with interruption cost.
- By leveraging WM modeling, the system delivers more selective and context-sensitive proactive assistance, leading to higher user engagement and reduced frustration compared to an LLM baseline.

---

[Games Agents Play: Towards Transactional Analysis in LLM-based Multi-Agent Systems](http://arxiv.org/abs/2507.21354v1)

- Trans-ACT (Transactional Analysis Cognitive Toolkit): introduces a novel framework that embeds Transactional Analysis principles into Multi-Agent Systems to create agents with realistic psychological dynamics, featuring an Agent orchestrator, Parent, Adult, and Child ego state agents, a Memory Tool with distinct memory types for each ego state, a Life Script, LLMs for reasoning, and prompts for input.
- The framework structures agent behavior around distinct ego states, each modeled as a ReAct agent within a LangGraph framework, dynamically activating internal schemas via similarity-based memory retrieval to guide responses consistent with human cognition.
- Trans-ACT aims to enhance the psychological depth of AI agents, supporting applications in conflict resolution, educational support, and social psychology studies by simulating complex behavioral dynamics.

---

[Agentic Web: Weaving the Next Web with AI Agents](http://arxiv.org/abs/2507.21206v1)

- Agentic Web: introduces a structured framework for understanding and building a new internet paradigm where autonomous AI agents, powered by LLMs, act as intermediaries to plan, coordinate, and execute goal-directed tasks on behalf of users.
- This framework integrates core architectural components like User Clients, Intelligent Agents, and Backend Services, supported by communication protocols (MCP, A2A) and a billing ledger (CABL), to enable machine-to-machine interactions.
- The Agentic Web redefines information flow and value creation through its three conceptual dimensions—Intelligence, Interaction, and Economy—shifting from human-driven consumption to autonomous, goal-driven task execution.

---

[Multi-Agent-as-Judge: Aligning LLM-Agent-Based Automated Evaluation with Multi-Dimensional Human Evaluation](http://arxiv.org/abs/2507.21028v1)

- MAJ-EVAL (Multi-Agent-as-Judge Evaluation Framework): introduces an LLM-based multi-agent evaluation framework that automatically constructs evaluator personas and orchestrates in-group debates to generate multi-dimensional feedback.
- The framework's Stakeholder Persona Creation Module leverages the Evaluative Dimension Extraction LLM (Me) to identify stakeholder perspectives and the Dimension-Based Persona Construction LLM (MƉ) to construct detailed agent personas.
- These LLM Agents engage in a Multi-Agent-as-Judge Debate Evaluation, where an In-Group Moderator coordinates discussions, agents refine their evaluations via Memory Update, and an Aggregator Agent synthesizes final scores.

---

[MIRAGE-Bench: LLM Agent is Hallucinating and Where to Find Them](https://github.com/sunblaze-ucb/mirage-bench.git)

- MIRAGE-Bench: introduces a unified benchmark for eliciting and evaluating hallucinations in interactive LLM-agent scenarios, with a Categorization Module (Classifies hallucinations) using a Taxonomy (Defines three types of unfaithfulness) including Task Instruction Unfaithfulness (Violates task goals/constraints), Interaction History Unfaithfulness (Contradicts past actions/outcomes), and Environment Observation Unfaithfulness (Misrepresents environment state), an Elicitation Module (Generates hallucination-prone scenarios) employing a Contextual Snapshot Strategy (Freezes agent state for reproducibility), and an Evaluation Module (Assesses hallucination behaviors) utilizing an LLM-as-a-Judge Paradigm (Uses an LLM to score agent faithfulness) with a Judge LLM (Performs semantic reasoning for evaluation).
- The benchmark systematically audits existing agent benchmarks to identify hallucination-prone risk settings and synthesizes test cases using a snapshot strategy to isolate decision points for deterministic and reproducible analysis.
- The framework adopts a fine-grained LLM-as-a-Judge paradigm with tailored risk-aware prompts to enable scalable, high-fidelity assessment of agent actions without enumerating full action spaces.

---

[Core Safety Values for Provably Corrigible Agents](http://arxiv.org/abs/2507.20964v1)

- Corrigible Utility Set Framework: introduces an implementable framework for AI corrigibility, with provable guarantees in multi-step, partially observed environments, by replacing a single opaque reward with five structurally separate utility heads—deference, switch-access preservation, truthfulness, low-impact behavior, and bounded task reward—combined lexicographically by strict weight gaps.
- The framework operates within a Partially Observable Off-Switch Game (PO-OSG) environment, modeling agent-human interactions, self-spawning agents, and gradual loss of control, ensuring safety properties are bounded while maintaining net human benefit.
- The paper demonstrates that verifying safety of arbitrary post-hack agents is undecidable in open-ended environments but carves out a finite-horizon "decidable island" where safety can be certified with privacy-preserving, constant-round zero-knowledge proofs.

---

[Aligning Large Language Model Agents with Rational and Moral Preferences: A Supervised Fine-Tuning Approach](http://arxiv.org/abs/2507.20796v1)

- SFTA (Supervised Fine-Tuning Approach): introduces a pipeline to align LLM agents with rational and moral preferences, using synthetic datasets derived from economic reasoning.
- The approach fine-tunes a GPT-4o LLM on structured chat interactions, embedding `homo economicus` (self-interest) and `homo moralis` (Kantian universalizability) utility functions.
- Evaluations in economic games, moral dilemmas, and algorithmic pricing demonstrate improved behavioral consistency and interpretability compared to baseline LLMs.

---

[Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition](http://arxiv.org/abs/2507.20526v1)

- AI Agent Red Teaming Challenge: introduces a large-scale public competition for evaluating the security of LLM-powered AI agents, featuring adversarial attacks by red-teamers against agents operating in realistic environments with various tools, memory, and web access, all governed by specific policy types.
- The challenge, hosted on the Gray Swan Arena, involved 1.8 million prompt injection attacks across 44 scenarios and 22 frontier LLMs, revealing widespread policy violations and high attack transferability.
- The competition's results led to the creation of the ART benchmark, a dataset of high-impact attacks designed to support more rigorous security assessment and drive progress toward safer agent deployment.

---

[AQUA: A Large Language Model for Aquaculture & Fisheries](http://arxiv.org/abs/2507.20520v1)

- AQUADAPT (Aquaculture Data Acquisition, Processing and Tuning): introduces a structured, agentic framework for generating and refining high-quality, domain-relevant datasets to train AQUA, a large language model for aquaculture.
- The framework integrates an Expert Agent for human-in-the-loop data curation, a Data Agent for corpus acquisition and preprocessing, a QA Agent for dual-path question-answer generation, and a Scoring Agent for automated quality assessment and dataset filtering.
- This methodology ensures domain accuracy and contextual fluency, enabling AQUA to provide intelligent insights and enhance operational efficiency in aquaculture.

---

[Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges](http://arxiv.org/abs/2507.19364v1)

- LLM-augmented Agent-Based Social Simulation: introduces a hybrid approach for social simulation that integrates Large Language Models (LLMs) as core agent intelligence, featuring an LLM Instance/Session (core agent intelligence), a Memory System (stores past experiences), a Reflection and Summarization Layer (processes observations into mental models), a Planning Component (generates actions based on reflections), an Orchestration Layer (manages simulation time and agent interactions), External Tools/APIs (augment agent capabilities), and often integrated with Traditional ABM Platforms (provide structured environment and analysis).
- This framework leverages LLMs' capacity for human-like language generation and social reasoning to create more flexible and expressive agents, enabling rapid simulation of large-scale social dynamics and exploration of complex scenarios.
- Despite opportunities for enhanced realism and scalability, the approach faces challenges including LLM biases, hallucination, inconsistency, high computational costs, and the "black-box" nature of LLMs, necessitating robust validation and careful scenario scoping.

---

[DriveAgent-R1: Advancing VLM-based Autonomous Driving with Hybrid Thinking and Active Perception](http://arxiv.org/abs/2507.20879v1)

- DriveAgent-R1: introduces a VLM-based autonomous driving agent with a Hybrid-Thinking framework for adaptive reasoning and an Active Perception mechanism with a Vision Toolkit for proactive uncertainty resolution.
- The agent's Hybrid-Thinking framework dynamically switches between efficient Text-based M-CoT and in-depth Tool-based M-CoT, while its Active Perception leverages a Vision Toolkit including tools like Retrieve High-Resolution View, RoI Inspection, Depth Estimation, and 3D Object Detection.
- The agent is trained using a novel three-stage Progressive Reinforcement Learning Strategy, comprising Dual-Mode Supervised Fine-Tuning, Forced-Contrastive Mode RL (with MP-GRPO), and Adaptive Mode-Selection RL (with GRPO), to master its hybrid capabilities.

---

[Free Energy-Inspired Cognitive Risk Integration for AV Navigation in Pedestrian-Rich Environments](http://arxiv.org/abs/2507.20850v1)

- Free Energy-Inspired Cognitive Risk Integration: introduces a novel framework for AV navigation in pedestrian-rich environments, integrating a Pedestrian Cognitive-Risk Social Force Model (CR-SFM) and an AV Decision-Making Model that leverages Cognitive Process Modeling within a Soft Actor-Critic (SAC) architecture, enhanced by a Graph Convolutional Network (GCN) and a Risk-encoded Adjacency Matrix.
- The CR-SFM dynamically adjusts pedestrian goal-directed and repulsive forces using a fused measure of cognitive uncertainty and physical risk, yielding human-like trajectories.
- The AV decision-making model utilizes the fused risk to construct a dynamic, risk-aware adjacency matrix for the GCN within the SAC framework, enabling more reasonable and informed decisions.

---

[Hanging Around: Cognitive Inspired Reasoning for Reactive Robotics](http://arxiv.org/abs/2507.20832v1)

- SRF (Semantic Reasoning Framework): introduces a neurosymbolic modular architecture for reactive robotics, combining a Perception Module, Reasoning Module, Recognition Retraining, YOLO Models, and Image Schematic Theories, to enable agents to identify and monitor environmental elements pertinent to objectives.
- The framework allows the agent to dynamically update its internal knowledge by integrating neural perception with symbolic, ontology-based reasoning, enabling it to discover new concepts for object parts involved in functional relationships.
- This approach demonstrates the agent's capability to expand its knowledge through systematic observation, facilitating planning for complex tasks by focusing perception on relevant object parts in dynamic settings.

---

#### 27th July 2025

[MazeEval: A Benchmark for Testing Sequential Decision-Making in Language Models](http://arxiv.org/abs/2507.20395v1)

- MazeEval: introduces a benchmark for evaluating LLMs' spatial reasoning, with maze generation (creates mazes), LLM interaction interface (enables model interaction), and evaluation metrics (assesses performance) components, designed to isolate and evaluate pure spatial reasoning in LLMs through coordinate-based maze navigation tasks.
- The benchmark challenges LLMs to navigate mazes using only coordinate-based feedback and distance-to-wall information, without visual input, to test fundamental spatial cognition.
- MazeEval also includes a multilingual evaluation in English and Icelandic to assess cross-linguistic transfer of spatial abilities and the influence of linguistic resources on spatial reasoning.

---

[Advancing Shared and Multi-Agent Autonomy in Underwater Missions: Integrating Knowledge Graphs and Retrieval-Augmented Generation](http://arxiv.org/abs/2507.20370v1)

- RAG (Retrieval-Augmented Generation) System: introduces a framework for advancing shared and multi-agent autonomy in underwater missions, with Information Retrieval System (retrieves data), Mission Behaviors Generator (produces actions), Large Language Model (reasoning and decision-making), BT Manager (manages behavior trees), Context Manager (monitors variables), Task Execution (executes actions), Human-in-the-Loop (human interaction point), VLC Human Computer (human-robot communication), VLC Robot (robot communication module), Remote Sensor (data source), Data Processing (sensor data handling), Autonomous Underwater Vehicle (robotic agent), and Docking Station (recharging/data transfer point), enabling autonomous decision-making and seamless human-robot interaction for complex underwater tasks.
- The framework integrates an LLM with a Knowledge Graph and a structured Taxonomy, allowing AUVs to autonomously plan and execute missions while dynamically incorporating real-time updates and human oversight.
- The system leverages Behavior Trees for structured decision-making, ensuring efficient and flexible mission execution adaptable to environmental uncertainties and supporting multi-robot coordination.

---

[Embeddings to Diagnosis: Latent Fragility under Agentic Perturbations in Clinical LLMs](http://arxiv.org/abs/2507.21188v1)

- LAPD (Latent Agentic Perturbation Diagnostics): introduces a geometry-aware evaluation framework that systematically probes the latent robustness of clinical LLMs using structured adversarial edits, with all LAPD-components, where synthetic or real clinical notes are processed through structured perturbation and latent embedding projection, and the resulting representations are analyzed for fragility using geometry-aware metrics and surface-level clinical agreement.
- The framework introduces Latent Diagnosis Flip Rate (LDFR), a model-agnostic diagnostic signal that captures representational instability when embeddings cross decision boundaries in PCA-reduced latent space.
- The paper validates LDFR on real clinical notes, confirming its generalizability beyond synthetic settings and revealing a persistent gap between surface robustness and semantic stability in safety-critical clinical AI.

---

[ELMES: An Automated Framework for Evaluating Large Language Models in Educational Scenarios](http://arxiv.org/abs/2507.22947v1)

- ELMES (Evaluation of Large Models in Educational Scenarios): introduces an open-source automated evaluation framework for LLMs in educational settings, with Task Loading, Agent DAG Construction, Dialogue Generation, Result Evaluation, and Data Aggregation & Visualization components, enabling flexible scenario design and objective pedagogical metric quantification.
- The framework utilizes a modular architecture, declarative configuration files, and a hybrid evaluation engine (LLM-as-a-Judge) to automate the entire workflow from dialogue generation to multi-dimensional quantitative analysis.
- It systematically benchmarks LLMs across four critical educational scenarios—Knowledge Point Explanation, Guided Problem-Solving Teaching, Interdisciplinary Lesson Plan Generation, and Contextualized Question Generation—using fine-grained, expert-developed metrics.

---

[SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration](http://arxiv.org/abs/2507.20280v1)

- SciToolAgent (Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration): introduces an LLM-powered agent that automates scientific tools by leveraging a SciToolKG (encodes tool relationships, dependencies) and includes Planner (devises strategy), Executor (implements tools), and Summarizer (synthesizes results) components.
- The framework integrates a comprehensive Toolset (collection of scientific tools) and a Safety check module (ensures ethical tool usage) supported by a Safeguard database (contains hazardous substances data) for responsible tool automation.
- SciToolAgent utilizes a Chain-of-Tools (planned sequence of tools) and a Memory module (stores context for queries) to enable intelligent tool selection, execution, and iterative Re-planning (iterative plan refinement) for complex scientific workflows.

---

[MLC-Agent: Cognitive Model based on Memory-Learning Collaboration in LLM Empowered Agent Simulation Environment](http://arxiv.org/abs/2507.20215v1)

- MLC-Agent (Cognitive Model based on Memory-Learning Collaboration): introduces an individual agent model for LLM-empowered agent simulation environments, integrating memory and learning mechanisms for enhanced decision-making, with components including Individual Perception, Decision-Making Mechanism (Learning Model, Memory Model), Behavior Set, Interaction Module, and External Knowledge Base.
- The framework employs a hierarchical memory structure, comprising an Individual Memory Set, Collective Memory Set, and Memory Buffer Pool, alongside a multi-indicator evaluation mechanism for dynamic memory updates and collaborative decision-making.
- This integration promotes knowledge sharing and dissemination among agents, enabling them to continuously optimize decision-making by combining contextual knowledge in dynamic environments, leading to improved adaptability and anthropomorphic characteristics.

---

[Goal Alignment in LLM-Based User Simulators for Conversational AI](http://arxiv.org/abs/2507.20152v1)

- UGST (User Goal State Tracking): introduces a novel framework and a three-stage methodology for developing goal-aligned LLM-based user simulators, which includes Inference-time Steering (conditions simulator with goal state), Cold-Start Supervised Fine-Tuning (SFT) (trains simulator for autonomy), and Group Relative Policy Optimization (GRPO) (refines simulator with rewards), aiming to address goal misalignment in multi-turn conversations.
- The framework dynamically tracks a User Goal State (structured goal representation) across conversations, decomposing user goals into sub-components like User Profile, User Policy, Task Objectives, Requirements, and Preferences, each with a dynamic status.
- This approach significantly improves LLM-based user simulator (LLM-based agent) goal alignment and response generation by leveraging explicit Reasoning Traces (explicit goal progression steps) and UGST Reward Signals (structured feedback for RL) derived from the tracked goal state.

---

[AI-Driven Generation of Old English: A Framework for Low-Resource Languages](http://arxiv.org/abs/2507.20111v1)

- AI-Driven Old English Generation Framework: introduces a scalable framework for generating high-quality Old English texts, employing a multi-stage methodology that includes data preparation, model training (Domain-Adaptive Pretraining and Task-Adaptive Pretraining), and synthetic data generation via a dual-agent pipeline.
- The framework leverages parameter-efficient fine-tuning (LoRA) and data augmentation through backtranslation to adapt LLMs for low-resource Old English, significantly expanding its digital corpus.
- Evaluation with automated metrics (BLEU, METEOR, CHRF) and expert human assessment confirms substantial improvements in translation quality and linguistic fidelity, offering a blueprint for revitalizing other endangered languages.

---

#### 26th July 2025

[Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text](http://arxiv.org/abs/2507.19969v1)

- cross-modal actor-critic agentic inference framework: introduces a system that jointly refines textual answers and visualization code, with an Actor (generates initial and refined responses) producing outputs and a Critic (evaluates and provides feedback) assessing them using multimodal feedback, including Answer Feedback (numerical correctness), Code Feedback (syntax/semantic checks), and Visual Feedback (chart quality), all within a Refinement Loop (iterative improvement process).
- This framework enhances answer accuracy and chart quality by incorporating multimodal feedback, outperforming direct inference methods.
- The framework is model-agnostic, routing initial outputs from any baseline inference model into its iterative refinement loop for improved alignment with query intent.

---

[AgentMesh: A Cooperative Multi-Agent Generative AI Framework for Software Development Automation](http://arxiv.org/abs/2507.19902v1)

- AgentMesh (A Cooperative Multi-Agent Generative AI Framework for Software Development Automation): introduces a Python-based framework that automates software development by orchestrating specialized LLM-powered agents, including a Planner Agent (decomposes requests, plans tasks), Coder Agent (generates code, implements subtasks), Debugger Agent (tests code, fixes errors), and Reviewer Agent (validates output, quality assurance), all managed by an AgentMesh Orchestrator (manages workflow, coordinates agents) and interacting through a shared Project State (shared codebase, specifications, errors), powered by an LLM Backend (powers agents' intelligence), and utilizing a Sandbox Environment (executes code safely) and Conversation Log (logs agent LLM interactions).
- The framework mimics human software teams, enabling agents to communicate via shared artifacts and iteratively refine code through a feedback loop, enhancing reliability and addressing complex tasks more robustly than single-agent approaches.
- Implemented in Python using OpenAI's GPT-4, the system demonstrates the potential of structured LLM orchestration in software engineering, offering a modular design for extensibility and future integration of advanced tools or learning capabilities.

---

[Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models](http://arxiv.org/abs/2507.19854v1)

- GUI-Learner: introduces a novel architecture for autonomous robotic agents, integrating a Perception Module (interprets raw visual information), a Decision Module (selects next action), and a Hybrid Learning Strategy (combines two learning phases) with Behavioral Cloning (initial policy from expert demos) and Offline Reinforcement Learning (refines policy from self-exploration).
- This framework enables embodied agents to autonomously learn and refine policies through continuous interaction, establishing a closed-loop cycle where an LLM "thinks" by decomposing commands, "acts" by executing plans and gathering feedback, and "learns" by processing feedback for self-reflection and corrective strategies.
- The approach significantly outperforms baseline methods on complex, long-horizon tasks in both simulation and real-world GUI environments, achieving high success rates and generalization to unseen tasks.

---

[AGENTIC REINFORCED POLICY OPTIMIZATION](http://arxiv.org/abs/2507.19849v1)

- ARPO (Agentic Reinforced Policy Optimization): introduces a novel agentic RL algorithm tailored for training multi-turn LLM-based agents, with a Rollout Module (generates trajectories), Entropy-based Adaptive Rollout (manages sampling), Policy Model (LLM) (generates responses), Tool Environment (provides external tools), Advantage Attribution Estimation (assigns advantage values), Reference Model (LLM) (provides baseline for KL divergence), Reward Model (provides reward signals), and Group Computation (processes advantages), designed to encourage adaptive branching sampling during high-entropy tool-call rounds and internalize advantage differences in stepwise tool-use behaviors.
- The framework incorporates an entropy-based adaptive rollout mechanism that dynamically balances global and partial sampling, promoting exploration at steps with high uncertainty after tool usage.
- It integrates an advantage attribution estimation to enable LLMs to internalize advantage differences in stepwise tool-use interactions, achieving improved performance with reduced tool-use budget.

---

[LARGE LANGUAGE MODEL AGENT FOR STRUCTURAL DRAWING GENERATION USING REACT PROMPT ENGINEERING AND RETRIEVAL AUGMENTED GENERATION](http://arxiv.org/abs/2507.19771v1)

- LLM Agent (Large Language Model Agent): introduces a novel generative AI-based method for structural drawing generation, employing a chain of LLMs (LLM1, LLM2, LLM3, LLM4, LLM5, LLM6) to process natural language descriptions into AutoCAD Python code, supported by a Knowledge Database, ReAct Prompt Engineering, and Retrieval Augmented Generation.
- This multi-LLM pipeline addresses limitations of single LLMs by breaking down complex tasks into subtasks, enhancing efficiency, reliability, and accuracy in converting varied natural language inputs into precise structural drawings.
- The approach significantly reduces the labor-intensive and time-consuming process of manual structural drawing production, facilitating iterative design and ensuring compliance with regulatory standards.

---

[Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation](http://arxiv.org/abs/2507.18224v2)

- ARG-DESIGNER (AutoRegressive Graph generation model that acts as a MAS topology Designer): introduces a novel autoregressive model for multi-agent system (MAS) communication topology design, which constructs collaboration graphs from scratch by dynamically determining agent roles and communication links through its Node Generation and Edge Generation components.
- This framework reframes MAS design as a conditional autoregressive graph generation task, enabling flexible and extensible topology creation precisely tailored to specific task requirements.
- The model achieves state-of-the-art performance and superior token efficiency by progressively selecting appropriate agents from an extensible pool and establishing optimal communication links.

---

[AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks](http://arxiv.org/abs/2508.00890v1)

- AgentTTS (Agent for Test-Time compute-optimal Scaling): introduces an LLM-agent-based framework that autonomously searches for compute-optimal allocations in multi-stage complex tasks, with an Agent (LLM-based searcher) generating trials and guidelines, an Archive (stores history, guidelines, feedback) maintaining records, and an Environment (executes trials, returns feedback) evaluating performance, utilizing an LLM Pool (source of LLMs) under a Total Budget (fixed computational limit) to produce Allocation Trial (model/budget configuration) and receive Feedback (performance evaluation results) for iterative refinement of Guidelines (search strategy instructions) and Candidate Trials (new configurations to test).
- The framework addresses challenges in multi-stage task scaling, such as large combinatorial search spaces and interdependent subtasks, by integrating empirical insights into the LLM-agent search process.
- AgentTTS demonstrates superior search efficiency, interpretability, and robustness compared to traditional and other LLM-based baselines across various multi-stage complex tasks and datasets.

---

[DynamiX: Large-Scale Dynamic Social Network Simulator](http://arxiv.org/abs/2507.19929v1)

- DynamiX (Large-Scale Dynamic Social Network Simulator): introduces a novel large-scale social network simulator dedicated to dynamic social network modeling, featuring an Environment Server, Dynamic Hierarchy Module, Core Agents, Ordinary Agents, and Result Analysis.
- The simulator captures how users dynamically adjust social relationships over time and reflects the switching roles of core agents that drive event propagation, enabling accurate alignment of real-world adaptive switching of user roles.
- It employs a dynamic hierarchy module for selecting core agents and distinct dynamic social relationship modeling strategies, including an information-stream-based link prediction for opinion leaders and an inequality-oriented behavior decision-making module for ordinary users.

---

#### 25th July 2025

[AGENTIC AI FOR AUTONOMOUS ANOMALY MANAGEMENT IN COMPLEX SYSTEMS](http://arxiv.org/abs/2507.15676v1)

- Agentic AI (AI agent augmented with large language models, diverse tools, and knowledge-based systems): introduces an autonomous anomaly management framework for complex systems, integrating an AI Agent (core autonomous entity), LLMs (cognitive core for reasoning), Tools (diverse specialized utilities), Knowledge-based Systems (stores domain-specific information), Memory Systems (retains context and knowledge), and an LLM-as-a-judge module (evaluates tool use), to continuously analyze, learn, and respond to abnormal behaviors.
- This framework aims to overcome limitations of human-dependent anomaly management by enabling autonomous decision-making, contextual understanding, and real-time adaptation to evolving conditions.
- The system synthesizes insights across disciplines, detects subtle patterns, and adapts strategies using both implicit and explicit knowledge, enhancing system resilience and adaptability.

---

[Simulating multiple human perspectives in socio-ecological systems using large language models](http://arxiv.org/abs/2507.17680v1)

- HoPeS (Human-Oriented Perspective Shifting): introduces a framework for simulating human perspectives in socio-ecological systems, integrating LLM-powered agents, a simulation protocol, and a prototype system with PTS and RLC components.
- The framework enables users to assume stakeholder roles, interact with LLM agents, and reflect on diverse perspectives to deepen understanding of complex socio-ecological dynamics.
- It facilitates exploration of institutional dynamics and land use change through narrative-driven and numerical experiments, fostering interdisciplinary collaboration.

---

["X of Information" Continuum: A Survey on AI-Driven Multi-dimensional Metrics for Next-Generation Networked Systems](http://arxiv.org/abs/2507.19657v1)

- HF-AIMDIM (Hierarchical Framework for AI-driven Multi-dimensional Information Metrics): introduces a systematic framework for next-generation networked systems, integrating Fundamental Metric Dimensions, AI Enhancement Technologies, and Application Scenarios to optimize information quality.
- The framework structures information metrics along temporal, quality/utility, reliability/robustness, and network/communication dimensions, leveraging AI for adaptive, context-aware optimization.
- It illustrates the revolutionary promise of multi-dimensional information metrics for diverse operational needs across critical application domains.

---

[Efficient and Scalable Agentic AI with Heterogeneous Systems](http://arxiv.org/abs/2507.19635v1)

- Orchestration and Serving System: introduces a comprehensive system architecture for efficient and scalable execution of dynamic AI agent workloads on heterogeneous compute infrastructure, integrating an API Server, Inference Serving System with Planner & Scheduler, Load Balancer / Request Router, Serving Nodes (each with Runtime, Model Execution, Memory Management, Subgraph Execution, KV Cache, Metrics Collector), High Performance Interconnect, Cache Management, and Object Storage.
- This system dynamically plans and places fine-grained computational components onto a distributed fleet of heterogeneous hardware, continuously monitoring node availability, workload characteristics, and resource utilization to optimize throughput and cost efficiency while meeting end-to-end SLAs.
- Leveraging an MLIR-based representation for agent workloads, the system enables cost-aware optimization, heterogeneous hardware integration, and dynamic orchestration, allowing optimal mapping of diverse agent tasks to the most cost-effective hardware resources.

---

[MCP4EDA: LLM-Powered Model Context Protocol RTL-to-GDSII Automation with Backend Aware Synthesis Optimization](http://arxiv.org/abs/2507.19570v1)

- MCP4EDA (Model Context Protocol for Electronic Design Automation): introduces an LLM-powered Model Context Protocol server that automates the RTL-to-GDSII design flow through natural language interaction, integrating a MCP Host, MCP Clients, MCP Server, and an LLM interacting with various EDA tools across Simulation, Synthesis, and Backend Domains.
- The system implements a backend-aware synthesis optimization methodology, where the LLM analyzes post-layout metrics from OpenLane results to iteratively refine synthesis TCL scripts, establishing a closed-loop optimization system.
- This approach leverages real backend performance data to guide synthesis parameter tuning and optimization sequence selection, enabling dynamic tool selection and adaptive execution strategies for improved timing closure and area reduction.

---

[CodeEvo: Interaction-Driven Synthesis of Code-centric Data through Hybrid and Iterative Feedback](http://arxiv.org/abs/2507.22080v1)

- CodeEvo: introduces an interaction-driven synthesis framework for high-quality code-centric data, featuring a Coder (generates code and tests) and a Reviewer (guides synthesis process) LLM agents, a Source (provides seed instructions), an Environment (provides compiler feedback), a Hybrid Feedback Mechanism (combines compiler and LLM feedback), Keyword-Guided Instruction Generation (anchors instruction evolution), Synthesized Trajectories (collects instruction-code pairs), and Base Models (models trained on data).
- The framework leverages iterative interactions between the Coder and Reviewer, enhanced by a hybrid feedback mechanism that integrates deterministic compiler verification with flexible LLM-based evaluations to ensure functional correctness.
- CodeEvo also employs keyword-guided instruction generation to maintain semantic control and progressively increase the difficulty and diversity of synthesized instruction-code pairs.

---

[Mut4All: Fuzzing Compilers via LLM-Synthesized Mutators Learned from Bug Reports](http://arxiv.org/abs/2507.19275v1)

- Mut4All: introduces a fully automated, language-agnostic framework for synthesizing mutation operators by leveraging LLMs and compiler-specific knowledge from bug reports, with Mutator Invention Agent (identifies mutation targets/generates specifications), Mutator Implementation Synthesis Agent (synthesizes mutator code/fine-tuned), and Mutator Refinement Agent (validates/corrects mutators) components, where it automates the entire mutator lifecycle from discovery and design to implementation for mutation-based compiler fuzzing.
- The framework analyzes real-world Bug Reports to identify error-prone language features, formulates Mutator Specifications, synthesizes Raw Mutators, and refines them into Valid Mutators using Test Suites and Feedback.
- Mut4All integrates these Valid Mutators into a customized Fuzzer, which utilizes Seed Programs, Crash/Hang Oracles, and Differential Testing to uncover bugs in target Compilers like Rust and C++.

---

[Event-Driven Storytelling with Multiple Lifelike Humans in a 3D Scene](http://arxiv.org/abs/2507.19232v1)

- Event-Driven Storytelling Framework: introduces a modular LLM-based framework for generating dynamic 3D scenes with multiple lifelike human characters, decomposing complex multi-agent behavior planning into manageable event sequences.
- This framework leverages a High-level Action Planning Module, comprising a Scene Describer, Narrator, and Event Parser, to reason contextually and generate detailed event information for character actions.
- It further employs a Low-level Motion Synthesis Module to convert these events into realistic 3D character motions, ensuring collision-free trajectories and diverse interactions within the scene.

---

[iPLAN: Redefining Indoor Wireless Network Planning Through Large Language Models](http://arxiv.org/abs/2507.19096v1)

- iPLAN (indoor wireless network Planning with large LANguage models): introduces a framework for optimizing indoor wireless network planning, leveraging its comprehensive set of components including LLM optimizers, multi-modal IE representations, domain knowledge bases, and a multi-agent system for iterative design and evaluation.
- This framework addresses challenges in traditional IWN planning by integrating domain-specific knowledge, multi-modal data alignment, and iterative refinement for superior performance and generalization.
- iPLAN supports both IWN planning based on pre-existing Indoor Environments and joint design of IWN with new wireless-friendly buildings, demonstrating significant improvements in coverage and efficiency.

---

[Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents](http://arxiv.org/abs/2507.19090v1)

- DebateCV (Debate-driven Claim Verification): introduces a multi-agent LLM framework for claim verification that simulates human fact-checking debates, leveraging multiple LLM agents and a novel post-training strategy.
- The framework employs two Debater LLMs to argue opposing stances on a claim using provided evidences, while a Moderator LLM evaluates arguments and issues a verdict with justifications.
- To address data scarcity and improve Moderator performance, the system synthesizes debate data and applies a post-training strategy involving a Corrector LLM for error correction, followed by supervised fine-tuning and direct preference optimization.

---

[Large Language Model-Based Task Offloading and Resource Allocation for Digital Twin Edge Computing Networks](http://arxiv.org/abs/2507.19050v1)

- LLM-based context learning: introduces a method for task offloading and resource allocation in digital twin edge computing networks, utilizing MARL to generate an initial case set and an LLM to optimize decisions based on this set and real-time data.
- This approach aims to enhance system QoS and energy efficiency by transforming long-term constraints into short-term decisions via Lyapunov optimization.
- The framework demonstrates comparable or superior performance to traditional MARL, leveraging LLMs for efficient decision-making in dynamic vehicular environments.

---

[Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems](http://arxiv.org/abs/2507.21162v1)

- Multi-LLM Coordination Architecture: introduces an LLM-powered automated modeling and optimization approach for Active Distribution Network (ADN) dispatch problems, which decomposes the process into sequential stages handled by specialized LLM agents (Information Extractor, Problem Formulator, Code Programmer) and a Solver, all accessible via an LLM Powered Interface.
- This framework addresses the lack of specialized expertise among ADN operators by enabling intelligent, flexible ADN dispatch through natural language queries, reducing reliance on human experts.
- Tailored refinement techniques, including prompt methods, multi-round dialogues, and external knowledge enhancement, are developed for each LLM agent to improve accuracy and reliability of generated content.

---

[Agent0: Leveraging LLM Agents to Discover Multi-value Features from Text for Enhanced Recommendations](http://arxiv.org/abs/2507.18993v1)

- Agent0 (Architect-Sentinel-Oracle model): introduces an LLM-driven, agent-based system for automated information extraction and feature construction, integrating an Architect (LLM for prompt generation/refinement), an Oracle (AutoML for feature relevance evaluation), Sentinels (LLMs for text-to-feature conversion), and Shared Memory (stores prompt-score tuples/data).
- This system automates the discovery of high-signal multi-value features from raw, unstructured text for enhanced recommender systems by iteratively refining prompts based on dynamic feedback loops.
- The framework mimics a data scientist's iterative process, enabling accelerated feature engineering and research in recommender system development.

---

[SliceMate: Accurate and Scalable Static Program Slicing via LLM-Powered Agents](http://arxiv.org/abs/2507.18957v1)

- SLICEMATE (Accurate and Scalable Static Program Slicing via LLM-Powered Agents): introduces a novel static program slicing solution that integrates three specialized LLM agents—synthesis, verification, and refinement—orchestrated by a control module to produce program slices without explicit dependency graph construction or large-scale training data.
- The framework reframes slicing as an LLM-driven code generation process, enabling it to scale to large, multi-file programs and robustly handle incomplete or non-compilable code by leveraging LLMs' broad programming knowledge.
- SLICEMATE significantly outperforms traditional and learning-based slicing tools in accuracy and F1 score, boosting Top-10 localization accuracy in downstream debugging and bug localization tasks.

---

[A Systematic Review of Key Retrieval-Augmented Generation (RAG) Systems: Progress, Gaps, and Future Directions](http://arxiv.org/abs/2507.18910v1)

- RAG (Retrieval-Augmented Generation): introduces a framework that combines a neural text retrieval module and a text generation module, processing user queries through chunking, embedding, retrieval, re-ranking, and generation to enhance factual grounding and contextual relevance.
- This systematic review traces RAG's evolution from early open-domain question answering to state-of-the-art implementations, analyzing its technical components, year-by-year progress, and enterprise deployment.
- The review also evaluates RAG system performance, identifies persistent challenges like retrieval quality and privacy, and highlights emerging solutions such as hybrid retrieval and agentic architectures for future knowledge-intensive NLP systems.

---

[MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service](http://arxiv.org/abs/2507.18884v1)

- MindFlow+ (Self-Evolving Agent for E-Commerce Customer Service): introduces a self-evolving agent framework for e-commerce customer service, combining LLMs with imitation learning and offline reinforcement learning, using tool-augmented demonstration construction and reward-conditioned data modeling to generate contextually relevant and task-accurate responses.
- The framework unifies tool-augmented reasoning and preference-aligned response generation into a single training process, enabling adaptive behavior without modifying the underlying LLM architecture.
- It leverages a Unified Annotated Dataset, enriched with Factual Knowledge, Tool-Use Capabilities (including specific tools), and User Preference signals, to fine-tune a Pre-trained LLM for domain-specific, multi-turn dialogue.

---

[PhysVarMix: Physics-Informed Variational Mixture Model for Multi-Modal Trajectory Prediction](http://arxiv.org/abs/2507.19701v1)

- PhysVarMix (Physics-Informed Variational Mixture Model): introduces a novel hybrid approach for multi-modal trajectory prediction, integrating learning-based and physics-based constraints through its Scene Encoder (processes scene elements), Causal Network (captures temporal dependencies), Variational Bayes Mixture Prediction Head (predicts multi-modal distributions), and Trajectory Refinement (applies physical constraints) components.
- The framework employs a variational Bayesian mixture model to capture diverse future behaviors and incorporates physical realism via sector-specific boundary conditions and Model Predictive Control-based smoothing.
- This approach balances data-driven insights with physics-informed constraints, producing interpretable and diverse trajectory predictions for enhanced decision-making in autonomous driving systems.

---

[CoopTrack: Exploring End-to-End Learning for Efficient Cooperative Sequential Perception](http://arxiv.org/abs/2507.19239v1)

- CoopTrack: introduces a fully instance-level end-to-end framework for cooperative 3D multi-object tracking, integrating Multi-Dimensional Feature Extraction (MDFE), Cross-Agent Alignment (CAA), Graph-based Association (GBA), and Aggregation modules.
- The framework employs a novel fusion-after-decoding pipeline, which first decodes features, then performs association and fusion, enabling seamless integration of cooperation and tracking.
- It transmits sparse instance-level features to enhance perception while maintaining low transmission costs, achieving state-of-the-art performance on V2X-Seq and Griffin datasets.

---

[Diverse and Adaptive Behavior Curriculum for Autonomous Driving: A Student-Teacher Framework with Multi-Agent RL](http://arxiv.org/abs/2507.19146v1)

- STF (Student-Teacher Framework): introduces a novel student-teacher framework for automatic curriculum learning in autonomous driving, featuring a graph-based multi-agent RL teacher that adaptively generates diverse traffic behaviors and a deep RL student that learns driving policies.
- The framework enhances generalization and robustness by dynamically adapting NPC behaviors based on the student's performance, fostering a symbiotic learning relationship.
- Its structured design, including an alternating Markov game and a recalibration phase, ensures training stability and progressive difficulty increase for realistic traffic scenarios.

---

#### 24th July 2025

[MemoCoder: Automated Function Synthesis using LLM-Supported Agents](http://arxiv.org/abs/2507.18812v1)

- MemoCoder: introduces a multi-agent framework for automated function synthesis, featuring a Planner (generates strategies), Code Writer (generates and refines code), Test Executor (executes code and identifies errors), Mentor (supervises repair and distills knowledge), and a Fixing Knowledge Base (stores successful repairs).
- The framework enables collaborative problem-solving and persistent learning from past fixes by leveraging LLM-based agents and a memory module.
- It consistently outperforms zero-shot prompting and self-repair strategies, demonstrating effectiveness in iterative refinement and knowledge-guided code generation.

---

[Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback](http://arxiv.org/abs/2507.18755v1)

- Engineering Agent: introduces an automated program repair framework that fixes source code based on test failures at scale, integrating a Test Failure Manager Bot, an Engineering Agent with a Setup development environment, an Agentic Harness (comprising a ReAct Loop for Reason and Act components using Patching, Tests, and Static Analyses tools), a Verification stage, an LLM-as-a-Judge, and human Code Review, with a Discard action for rejected patches.
- The framework leverages neuro-symbolic AI by providing feedback from static analysis tools and test execution traces to the agent, allowing it to refine its solutions iteratively within the ReAct loop.
- This system aims to generate high-quality code patches that pass validation and align with human engineering standards, ultimately reducing manual intervention in program repair workflows.

---

[Explainable Mapper: Charting LLM Embedding Spaces Using Perturbation-Based Explanation and Verification Agents](http://arxiv.org/abs/2507.18607v1)

- Explainable Mapper: introduces a framework for semi-automatic annotation of LLM embedding properties, featuring a visual analytics workspace and two LLM-based mapper agents (Explanation Agent and Verification Agent) that employ summarization, comparison, and perturbation operations to generate and verify explanations of mapper elements.
- The framework leverages mapper graphs to summarize the topological structure of LLM embedding spaces, where nodes represent topological neighborhoods and edges connect overlapping neighborhoods.
- It addresses the challenge of manually exploring vast embedding spaces by providing customizable LLM-based agents to explore and explain linguistic characteristics and verify explanation robustness.

---

[HARLF: Hierarchical Reinforcement Learning and Lightweight LLM-Driven Sentiment Integration for Financial Portfolio Optimization](http://arxiv.org/abs/2507.18560v1)

- HARLF (Hierarchical Reinforcement Learning and Lightweight LLM-Driven Sentiment Integration for Financial Portfolio Optimization): introduces a three-tier hierarchical framework for portfolio optimization, with Observation (input data stream), FinBERT (extracts financial sentiment), Base RL Agents (process hybrid data), Meta-Agents (aggregate base decisions), Data-driven Meta-Agent (refines data-based outputs), NLP-based Meta-Agent (refines NLP-based outputs), Super-Agent (synthesizes final allocations), Action (portfolio weight output), Stable Baselines 3 (RL algorithms library), and PyTorch (deep learning framework), designed to combine sentiment signals from financial news with traditional market indicators for robust decision-making.
- The framework leverages lightweight, domain-specific LLMs like FinBERT for sentiment analysis and Deep Reinforcement Learning (DRL) for sequential decision-making, addressing limitations of single-modal or flat architectures in financial markets.
- Its hierarchical structure, comprising base RL agents, meta-agents, and a super-agent, enhances stability, scalability, and interpretability for adaptive portfolio allocations across diverse market regimes.

---

[FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification](http://arxiv.org/abs/2507.22932v1)

- FinMarBa (Market-Informed Dataset for Financial Sentiment Classification): introduces a novel market-driven annotation framework for financial sentiment classification, utilizing components like Collect News Headlines, Headline Generation, Ticker Identification, Historical Data Retrieval, Percentage Change Calculation, Quantile Determination, Classification, and Machine Label to produce the FinMarBa Dataset.
- This framework leverages LLMs (specifically GPT-4) for automated headline extraction and ticker identification, then applies a quantile-based classification method using historical market data to assign sentiment labels.
- The approach aims to eliminate human biases and more accurately reflect market reactions to financial news, providing a large-scale, objectively labeled dataset for fine-tuning and evaluating LLMs in financial NLP.

---

[Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios](http://arxiv.org/abs/2507.18368v1)

- ConDiFi (Convergent-Divergent for Financial Reasoning Benchmark): introduces a novel benchmark designed to assess both divergent and convergent reasoning in LLMs for financial scenarios, featuring distinct dataset generation pipelines and a multi-dimensional evaluation framework.
- The benchmark includes 607 macro-financial prompts for divergent reasoning, evaluated by a GPT-4o Judging Model across five dimensions, and 990 multi-hop adversarial MCQs for convergent reasoning.
- Its dataset construction mitigates data contamination by using post-LLM training cutoff data and employs adversarial pipelines to generate challenging questions, providing a holistic standard for measuring LLM cognitive capabilities in finance.

---

[ProactiveVA: Proactive Visual Analytics with LLM-Based UI Agent](http://arxiv.org/abs/2507.18165v1)

- ProactiveVA (Proactive Visual Analytics): introduces an LLM-based UI agent that monitors user interactions and proactively delivers context-aware assistance, integrating Perception, Reasoning, and Acting modules, an LLM, and Storage (Memory/Knowledge) to interact with the Visual Analytics System and User.
- The framework autonomously perceives user needs from VA interaction logs, provides tailored suggestions, and offers intuitive guidance through interactive system exploration.
- This approach aims to enhance human-AI collaboration by addressing limitations of reactive AI assistants, ensuring timely, interpretable, and controllable support in dynamic analytical workflows.

---

[Policy Disruption in Reinforcement Learning: Adversarial Attack with Large Language Models and Critical State Identification](http://arxiv.org/abs/2507.18113v1)

- ARCS (Adversarial Rewards and Critical State Identification): introduces an adaptive adversarial attack framework that leverages LLMs to generate tailored adversarial rewards and identifies critical states to disrupt victim RL policies.
- The framework includes a Reward Iteration Optimization Module for LLM-guided reward generation and a Critical State Identification Mechanism for fine-tuning attacks on high-impact decision points.
- This approach enables black-box adversarial attacks by guiding an attacker policy to induce suboptimal actions in a victim RL agent without direct environment or policy manipulation.

---

[TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios](http://arxiv.org/abs/2507.18061v1)

- TELEVAL (Dynamic Benchmark for Spoken Language Models): introduces a dynamic benchmark for evaluating Spoken Language Models (SLMs) in Chinese interactive scenarios, with Explicit Semantics (linguistic content understanding/response), Paralinguistic and Implicit Semantics (acoustic cues/implicit intentions), and System Capabilities (system-level performance) components, designed to align evaluation protocols with real-world user interactions.
- The benchmark defines three evaluation dimensions, focusing on SLMs' ability to extract implicit cues from user speech and respond appropriately without explicit instructions.
- TELEVAL adopts a dialogue format consistent with real-world usage, evaluating text and audio outputs separately to provide a user-centered evaluation framework.

---

#### 23rd July 2025

[BetterCheck: Towards Safeguarding VLMS for Automotive Perception Systems](http://arxiv.org/abs/2507.17722v1)

- BetterCheck (adapted SelfCheckGPT): introduces a framework for safeguarding Vision Language Models (VLMs) in automotive perception systems, utilizing a Curated Dataset, Object Labels, LLM Models (Captioners), Caption Generation, Sentence Decomposition, Human Annotators, LLM Models (Checkers), BetterCheck Results, and Data Analysis to detect VLM hallucinations.
- The framework systematically assesses the performance of state-of-the-art VLMs (GPT-4o, LLaVA, MiniCPM-V) in captioning real-world automotive video footage from the Waymo Open Dataset.
- It evaluates VLM capabilities in identifying and overlooking traffic agents, and their ability to self-check generated captions for consistency and correctness.

---

[Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks](http://arxiv.org/abs/2507.17695v1)

- Symbiotic Agents: introduces a novel paradigm combining Large Language Models (LLMs) with real-time optimization algorithms, where LLMs (central decision-making) interpret high-level intents and supervise optimizers (input pre-processor, output controller) to enable trustworthy, adaptive, and real-time control in AGI-driven networks.
- The framework implements two agent designs: Type I agents for dynamic Radio Access Network (RAN) control and Type II agents for multi-agent Service-Level Agreement (SLA) negotiations, both leveraging the symbiotic relationship between LLMs and optimizers.
- This symbiotic design significantly reduces decision errors, improves accuracy, and enables the use of smaller language models (SLMs) with substantially lower overhead, bridging the gap towards trustworthy Artificial General Intelligence (AGI) in network management.

---

[DynaSearcher: Dynamic Knowledge Graph Augmented Search Agent via Multi-Reward Reinforcement Learning](http://arxiv.org/abs/2507.17365v1)

- DynaSearcher (Dynamic Knowledge Graph Augmented Search Agent via Multi-Reward Reinforcement Learning): introduces a search agent that leverages dynamic knowledge graphs and multi-reward reinforcement learning, including a Policy LLM, Search Tool List, Doc Search Tool, KG Search Tool, Tools Module, External Environment, Multi-Reward Reinforcement Learning Framework (with Gain Reward, Penalty Reward, and Accuracy Reward), Iterative Reasoning-Retrieval Loop, and Answer Generation, to guide multi-step reasoning and generate precise answers.
- The framework integrates structured knowledge graphs to ensure factual consistency in intermediate queries and employs a multi-reward RL mechanism for fine-grained control over retrieval accuracy, efficiency, and response quality.
- This approach mitigates reasoning deviations from irrelevant information and promotes efficient reasoning paths, leading to state-of-the-art performance in complex multi-hop question answering tasks.

---

[Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments](http://arxiv.org/abs/2507.17289v1)

- CBA (Compliance Brain Assistant): introduces a conversational, agentic AI assistant designed to boost compliance task efficiency, featuring a Router LLM that directs queries to either a FASTTRACK flow for simple requests or a FULLAGENTIC flow for complex tasks, supported by various LLM-based components, tools, and memory.
- The system intelligently chooses between a low-latency FASTTRACK path for context retrieval and a multi-step FULLAGENTIC path for complex reasoning and tool invocation.
- Experimental evaluations demonstrate that CBA substantially improves performance over vanilla LLMs in terms of keyword match rate and LLM-judge pass rate for compliance-related queries.

---

[Leveraging Knowledge Graphs and LLM Reasoning to Identify Operational Bottlenecks for Warehouse Planning Assistance](http://arxiv.org/abs/2507.17273v1)

- LLM Reasoning Agent: introduces a novel framework for identifying operational bottlenecks in warehouse planning, integrating Knowledge Graphs (KGs) and Large Language Models (LLMs) through a dual-path architecture that includes query classification, iterative reasoning, and self-reflection mechanisms.
- The framework transforms raw Discrete Event Simulation (DES) output data into a semantically rich Knowledge Graph, enabling LLM-based agents to interpret natural language questions by generating sequential, conditioned sub-questions and precise Cypher queries.
- This approach aims to bridge the gap between simulation modeling and advanced AI-driven data analysis, offering an intuitive method for extracting actionable insights and reducing time-to-insight for industrial data analysis.

---

[Agent Identity Evals: Measuring Agentic Identity](http://arxiv.org/abs/2507.17257v1)

- AIE (Agent Identity Evals): introduces a rigorous, statistically-driven, empirical framework for measuring LMA identity stability over time, including capabilities, properties, and recovery from state perturbations.
- The framework utilizes various LLMs for generating agent profiles, planning tasks, evaluating identity metrics, supervising planning, and injecting distractions.
- It integrates memory modules, tool APIs, and an embedding model to assess how these scaffolding solutions mitigate LLM pathologies affecting agent identity.

---

[LLM Meets the Sky: Heuristic Multi-Agent Reinforcement Learning for Secure Heterogeneous UAV Networks](http://arxiv.org/abs/2507.17188v1)

- LLM-HeMARL-S2DC introduces a hierarchical optimization framework that integrates LLM-generated expert policies into multi-agent reinforcement learning for UAV trajectory optimization, coupled with an S2DC algorithm for secure precoding, to maximize secrecy rate and minimize propulsion energy in heterogeneous UAV networks.
- The framework addresses the complex trade-off between communication secrecy and energy efficiency by decoupling the problem into an outer-layer LLM-HeMARL for trajectory design and an inner-layer S2DC for precoding optimization.
- This approach leverages LLM's heuristic guidance to accelerate learning and improve stability for UAV agents, enabling energy-aware, security-driven trajectories without real-time LLM inference overhead.

---

[CogDual: Enhancing Dual Cognition of LLMs via Reinforcement Learning with Implicit Rule-Based Rewards](http://arxiv.org/abs/2507.17147v1)

- CogDual: introduces a novel Role-Playing Language Agent (RPLA) that adopts a cognize-then-respond reasoning paradigm, integrating a Large Language Model (LLM) with Dual Cognition, which encompasses Situational Awareness (SA) and Self-Awareness (SAself), and is optimized through a two-stage training framework involving Supervised Fine-tuning (SFT) and Reinforcement Learning (RL) with implicit rule-based rewards.
- The Dual Cognition component enables the LLM to first process external environmental and social cues via Situational Awareness, then reflect on internal states and intentions through Self-Awareness, before generating a contextually relevant and psychologically consistent response.
- The RL stage further enhances performance using two general-purpose reward schemes, Inference-Conditioned Likelihood Gain (ICLG) and Latent Semantic Alignment (LSA), which promote causal consistency and semantic fidelity in text generation, respectively, optimized via Grouped Reward Policy Optimization (GRPO).

---

[Resilient Multi-Agent Negotiation for Medical Supply Chains: Integrating LLMs and Blockchain for Transparent Coordination](http://arxiv.org/abs/2507.17134v1)

- Hybrid Framework: introduces a novel system for medical supply chain coordination, integrating blockchain technology with an LLM-powered multi-agent negotiation system, comprising an Off-Chain Decision Layer (adaptive decision-making), a Cross-Layer Communication Protocol (bridges off-chain/on-chain), and an On-Chain Execution Layer (verifiable enforcement/auditability).
- The Off-Chain Decision Layer utilizes LLM-powered agents (Manufacturer, Distributor, Hospital) equipped with reasoning tools for dynamic, context-sensitive resource allocation and negotiation.
- The On-Chain Execution Layer, powered by smart contracts, ensures immutable, transparent, and auditable enforcement of decisions, enhancing resilience and accountability in crisis scenarios.

---

[Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance](http://arxiv.org/abs/2507.17131v1)

- ARIA (Adaptive Reflective Interactive Agent): introduces a framework for LLM agents to continuously learn updated domain knowledge at test time, featuring an LLM Agent (internal reasoning, task execution), Intelligent Guidance Solicitation (self-reflection, query formulation), a Human Expert Oracle (provides guidance, corrections), Human-Guided Knowledge Adaptation (integrates human feedback, updates KR), and a Knowledge Repository (timestamped, structured knowledge base).
- The framework assesses its own uncertainty through structured self-dialogue, proactively identifies knowledge gaps, and requests targeted explanations or corrections from human experts.
- The system systematically updates an internal, timestamped knowledge repository with provided human guidance, detecting and resolving conflicting or outdated knowledge through comparisons and clarification queries.

---

[Agent WARPP: Workflow Adherence via Runtime Parallel Personalization](http://arxiv.org/abs/2507.19543v1)

- WARPP (Workflow Adherence via Runtime Parallel Personalization): introduces a training-free, modular framework that combines multi-agent orchestration with runtime personalization to improve workflow adherence in LLM-based systems, featuring an Orchestrator Agent, Authenticator Agent, Personalizer, and Fulfillment Agent, supported by LLM as Client, LLM Agent, and LLM as a Judge, utilizing Client Info Tools, Full Routine, Client Data, Personalized Instructions, Trimmed Instructions + APIs, and various APIs/Tools.
- The framework dynamically prunes conditional branches based on user attributes, reducing reasoning overhead and narrowing tool selection at runtime.
- WARPP deploys a parallelized architecture where a dedicated Personalizer agent operates alongside modular, domain-specific agents to dynamically tailor execution paths in real time.

---

[I2I - STRADA – INFORMATION TO INSIGHTS VIA STRUCTURED REASONING AGENT FOR DATA ANALYSIS](http://arxiv.org/abs/2507.17874v1)

- I2I-STRADA (Information-to-Insight via Structured Reasoning Agent for Data Analysis): introduces an agentic architecture designed to formalize the data analysis reasoning process, with Goal construction (infers user analytical goal), Contextual reasoner (grounds analysis with context), Workflow scaffolding (generates global action plan), Adaptive planning and executor (iteratively refines execution plans), Context aware tool creation (dynamically creates data processing tools), Dynamic state handler (maintains agent's working memory), and Communication handler (manages results presentation).
- This framework models how data analysis unfolds via modular sub-tasks that reflect cognitive steps, ensuring structured reasoning and planning coherence.
- Evaluations on DABstep and DABench benchmarks demonstrate its superior performance in planning quality and insight alignment compared to prior systems.

---

[H-MEM: Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents](http://arxiv.org/abs/2507.22925v1)

- H-MEM (Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents): introduces a hierarchical memory architecture for LLM Agents, organizing and updating memory in a multi-level fashion based on semantic abstraction, with components like Domain, Category, Memory Trace, and Episode Layers, memory vectors, positional index encoding, a memory extraction model, an encoder, memory retrieval, and an update mechanism, to enhance long-term reasoning and efficient retrieval.
- This architecture embeds each memory vector with a positional index encoding, enabling efficient layer-by-layer retrieval without exhaustive similarity computations, and dynamically adjusts memory strength based on user feedback.
- H-MEM significantly reduces computational costs and improves memory access efficiency by filtering irrelevant information through its structured organization, demonstrating superior performance in long-term dialogue scenarios.

---

#### 22nd July 2025

[ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning](http://arxiv.org/abs/2507.16815v1)

- ThinkAct: introduces a dual-system framework that bridges high-level reasoning with low-level action execution via reinforced visual latent planning, training a multimodal LLM to generate embodied reasoning plans guided by action-aligned visual rewards.
- The framework's Reasoning MLLM generates reasoning plans and a visual plan latent, which then conditions the Action Model for robust action execution, enabling asynchronous operation for slow thinking and fast control.
- ThinkAct leverages action-aligned visual feedback, including goal completion and trajectory consistency, to reinforce reasoning, leading to capabilities like few-shot adaptation, long-horizon planning, and self-correction in complex embodied AI tasks.

---

[LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework for Multi-Step and Cross-Cultural Inference with LLMs](http://arxiv.org/abs/2507.16809v1)

- LingBench++ (A Linguistically-Informed Benchmark and Reasoning Framework): introduces a Multi-Agent Framework for solving linguistic problems, which includes Solver Agents (proposes initial linguistic hypotheses), Aggregator Agents (collects, synthesizes solutions), a Final Aggregator (generates final solution), and a Grammar Agent (retrieves linguistic reference knowledge).
- This multi-round framework enhances LLM reasoning by enabling iterative hypothesis generation, solution aggregation, and external knowledge retrieval for complex linguistic tasks.
- The framework emphasizes stepwise reasoning quality and grammar-informed verification, providing diagnostic insights beyond final answer accuracy.

---

[Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning](http://arxiv.org/abs/2507.16802v1)

- Agentar-Fin-R1: introduces a family of financial LLMs, engineered based on the Qwen3 foundation model, with a development pipeline that includes a Data Pipeline (constructs high-quality data), a Label System (structures data synthesis), and a Training Pipeline (optimizes LLM performance).
- The Data Pipeline integrates source governance, multi-agent data synthesis, and rigorous verification to ensure data quality and domain relevance for financial applications.
- The Training Pipeline employs a weighted training framework and a two-stage strategy for efficient knowledge injection and challenge enhancement, complemented by an attribution loop for continuous model refinement.

---

[Test-Time-Matching: Decouple Personality, Memory, and Linguistic Style in LLM-based Role-Playing Language Agent](http://arxiv.org/abs/2507.16799v1)

- TTM (Test-Time-Matching): introduces a training-free role-playing framework that automatically decouples character features into personality, memory, and linguistic style, utilizing a structured three-stage generation pipeline for controlled role-playing.
- The framework's pipeline includes a Styleless Response Generation stage, a Memory-checked Response Generation stage, and a Stylized Response Generation stage, ensuring high-fidelity and stylistically consistent character dialogues.
- TTM enhances controllability and personalization in role-playing language agents by enabling seamless combinations across diverse linguistic styles and variations in personality and memory.

---

[DELIBERATIVE SEARCHER: IMPROVING LLM RELIABILITY VIA REINFORCEMENT LEARNING WITH CONSTRAINTS](http://arxiv.org/abs/2507.16727v1)

- Deliberative Searcher: introduces a reasoning-primary, information-secondary framework that integrates LLM deliberation with selective web search and confidence calibration, trained via a constrained reinforcement learning algorithm to align confidence with correctness.
- The framework enables an agent to perform multi-step reflection and verification over external data, dynamically updating its confidence metrics through actions like THINK, SEARCH, and READ.
- It optimizes for accuracy under a soft reliability constraint, utilizing a reward signal composed of format compliance, answer correctness, and reliability rewards to produce trustworthy outputs.

---

[RAVine: Reality-Aligned Evaluation for Agentic Search](http://arxiv.org/abs/2507.16725v1)

- RAVine (Reality-Aligned Evaluation for Agentic Search): introduces a comprehensive evaluation framework for agentic LLMs with search, addressing misalignments in existing methods by targeting multi-point queries and long-form answers, and evaluating the iterative process.
- The framework includes an Agentic LLM with Search, a Web Corpus, Search and Fetch Tools, an Attributable Nuggets Collection for fine-grained ground truth, and both Block-level and Process-Oriented Evaluations.
- It provides a full-process, reproducible, and goal-aligned evaluation sandbox that assesses report quality, tool performance, and efficiency, offering insights into agentic search system development.

---

[Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications](http://arxiv.org/abs/2507.16507v1)

- INRAExplorer (Agentic RAG system): introduces an agentic RAG system with an LLM-based agent, a hybrid knowledge base (Vector Database and Knowledge Graph), and specialized tools (SearchGraph, SearchPublications, SearchConceptsKeywords, IdentifyExperts) for complex multi-hop reasoning in scientific data.
- The system empowers its LLM-based agent to dynamically navigate tools, gather evidence, and plan subsequent steps, enabling multi-hop reasoning and comprehensive answer generation from scientific data.
- This approach overcomes classical RAG limitations by deeply integrating knowledge graph querying as a core agentic capability, enabling precise, relationally-aware retrieval and adaptive multi-hop reasoning.

---

[Towards Enforcing Company Policy Adherence in Agentic Workflows](http://arxiv.org/abs/2507.16459v1)

- Framework for Enforcing Business Policy Adherence in Agentic Workflows: introduces a deterministic, transparent, and modular framework with an Offline Buildtime Stage that compiles Policy Documents, Toolkit, and Data Schema into verifiable ToolGuards (Python code) via a Tool-Policy Mapper and ToolGuard Generator, and a Runtime Integration where these ToolGuards ensure compliance before each LLM Agent action within a ReAct Workflow, preventing non-compliant Tool Invocations for the Customer.
- The framework's buildtime phase leverages an LLM-based Tool-Policy Mapper to transform natural language policies into a Compact Tool-Oriented Policy Representation, which then feeds into an LLM-based ToolGuard Generator to produce executable Python ToolGuards.
- This approach aims to bridge the gap between flexible AI behavior and organizational constraints by proactively preventing policy violations in LLM-based agentic workflows, ensuring reliable and predictable enterprise-scale operations.

---

[LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning](http://arxiv.org/abs/2507.16395v1)

- ColaUntangle (collaborative consultation framework for commit untangling): introduces a multi-agent LLM-driven system for untangling commits by reasoning about explicit and implicit code dependencies, with all its components, where the system integrates structured code change information with specialized LLM agents in an iterative consultation process.
- It leverages Structured Code Change Information, including explicit and implicit contexts derived from multi-version Program Dependency Graphs, to inform its Multi-Agent Architecture comprising Explicit Worker, Implicit Worker, and Reviewer LLM agents.
- The Untangling Workflow orchestrates the iterative collaborative consultation among these agents to achieve consensus on untangling decisions and provide explanations for improved transparency.

---

[Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance](http://arxiv.org/abs/2507.16382v1)

- LLM-FCCA (LLM-Guided Formation Control with Collision Avoidance): introduces a framework that leverages LLMs to dynamically generate and refine reward functions for multi-agent formation control with collision avoidance, utilizing an LLM Reward Designer, RL Training, Evaluation, Policy, Real World Deployment, Environment, Task Description and Tips, and Agent Observations Format (Local State, Obstacles State, Communication Data).
- The framework dynamically adjusts reward functions online using advanced evaluation metrics, enabling efficient simultaneous achievement of formation control and obstacle avoidance.
- Empirical studies in both simulation and real-world settings validate the approach's practicality and effectiveness, demonstrating superior performance with fewer iterations compared to human-designed methods.

---

[Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery](http://arxiv.org/abs/2507.16229v1)

- Agent PULSE (Patient Understanding and Liaison Support Engine): introduces a voice-based AI agent for digital health delivery, integrating a Voice Interface (standard telephone lines), an AI Engine (core intelligence platform) with LLMs (inference, fine-tuning service), SOLOMON (conversation management, analysis), and RAG (combines questionnaire, medical knowledge), and a Physician Dashboard (healthcare provider interface).
- This system aims to bridge economic and accessibility gaps in healthcare by providing scalable, cost-effective, and equitable solutions for preventive care and continuous patient monitoring.
- A pilot study with 33 inflammatory bowel disease patients demonstrated high patient acceptance and significant workflow advantages for healthcare providers, validating its potential to fill care gaps.

---

[RealBench: Benchmarking Verilog Generation Models with Real-World IP Designs](http://arxiv.org/abs/2507.16200v1)

- Self-reflection agent: introduces a framework for Verilog generation, integrating an LLM with Design Specification input and Feedbacks from Syntax Checker, Testbench Verification, and Formal Verification for iterative code modification.
- This agent iteratively refines generated Verilog code by leveraging verification feedback to improve correctness and reliability.
- The iterative feedback loop aims to address syntax errors, functional errors, and formal verification failures, enhancing LLM-generated hardware designs.

---

[Do Large Language Models Have a Planning Theory of Mind? Evidence from MINDGAMES: a Multi-Step Persuasion Task](http://arxiv.org/abs/2507.16196v1)

- MINDGAMES (Planning Theory of Mind Task): introduces a novel task framework for evaluating LLMs' ability to dynamically plan actions and strategically intervene on others' mental states, featuring a Persuader Agent (human or LLM participant), a Target Agent (hard-coded rational bot), a Dialogue Environment (multi-turn conversational interface), Proposals (three selectable options), Value Functions (agent preference definitions), Information Sets (agent knowledge states), and Mental States (target's beliefs and desires).
- This framework assesses "planning theory of mind" (PToM) by requiring the persuader to infer the target's beliefs and desires to persuade them to alter their behavior, moving beyond passive ToM assessments.
- The task involves the persuader selectively disclosing information to the target, who has partial information and makes rational choices based on its value function, highlighting a capability gap between human and LLM social reasoning.

---

[Benchmarking LLM Privacy Recognition for Social Robot Decision Making](http://arxiv.org/abs/2507.16124v1)

- LLM Privacy Recognition Benchmark: introduces a methodology to evaluate LLMs' privacy awareness in social robot interactions, encompassing scenario generation, human preference elicitation, LLM evaluation with various prompting strategies, and subsequent analysis.
- The benchmark leverages the Contextual Integrity framework to create privacy-relevant scenarios and crowdsourced human data to establish preferred robot behaviors and user privacy orientations.
- It assesses LLM conformity to human privacy expectations, identifies the impact of different prompting strategies, and provides insights for designing privacy-aware LLM-powered social robots.

---

[LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra](http://arxiv.org/abs/2507.15815v1)

- LLM Economist: introduces a novel framework for designing and assessing economic policies using agent-based modeling in strategic environments with hierarchical decision-making, featuring persona-conditioned worker agents and a planner agent optimizing tax schedules via in-context reinforcement learning.
- The framework simulates a Stackelberg game where worker agents choose labor supply to maximize utility, and a planner agent proposes tax schedules to maximize social welfare, all within a language-driven environment.
- This approach enables credible fiscal experimentation by optimizing heterogeneous utilities, generating demographically realistic agent populations, and performing natural language-based mechanism design.

---

[Screen2AX: Vision-Based Approach for Automatic macOS Accessibility Generation](http://arxiv.org/abs/2507.16704v1)

- Screen2AX: introduces a vision-based pipeline for automatic macOS accessibility generation, processing UI screenshots through UI element detection, text detection, element description, and hierarchy generation to produce structured hierarchical accessibility metadata.
- The framework leverages YOLOv11 for element localization, classification, and hierarchical grouping, and BLIP for generating semantic descriptions of UI elements.
- The system aims to bridge the gap in macOS accessibility support by creating real-time, tree-structured accessibility metadata from single screenshots, outperforming built-in tools in quality.

---

[Augmenting Von Neumann's Architecture for an Intelligent Future](http://arxiv.org/abs/2507.16628v1)

- Augmented Von Neumann Architecture: introduces a novel computer architecture that extends the classical Von Neumann model with a dedicated Reasoning Unit (RU) for native artificial general intelligence capabilities, alongside the Central Processing Unit (CPU), Arithmetic Logic Unit (ALU), Memory Subsystem, Control Unit, Input/Output System, and a Semantic Interconnect Bus (SIB).
- This architecture enables autonomous agents to perform goal-directed planning, dynamic knowledge manipulation, and introspective reasoning directly within the computational substrate at system scale.
- The framework establishes a computational foundation where reasoning, learning, and adaptation emerge as intrinsic execution properties, moving beyond traditional sequential computation.

---

[Distributed Oscillatory Guidance for Formation Flight of Fixed-Wing Drones](http://arxiv.org/abs/2507.16458v1)

- Distributed Oscillatory Guidance: introduces a novel approach for fixed-wing drone formation flight by modulating path progression through a non-negative input-saturated consensus strategy, integrating an Inverse Kinematics Guiding Vector Field (IK-GVF) path-following controller, and leveraging fixed-wing drone dynamics.
- This method enables coordinated formation flight without requiring speed actuation, achieving synchronized path following by inducing controlled oscillations in the guiding vector field.
- The approach ensures robust convergence to desired formations even with speed fluctuations, validated through numerical simulations and real-world flight experiments.

---

[From model-based learning to model-free behaviour with Meta-Interpretive Learning](http://arxiv.org/abs/2507.16434v1)

- MIL-M2MF (Meta-Interpretive Learning for Model-Based to Model-Free Behavior): introduces a framework that uses a MIL System to learn a Model-based Solver, which then generates examples to train a Model-free Controller, enabling autonomous agents to combine planning and exploration capabilities in novel environments.
- The Model-based Solver plans actions with full environment knowledge, while the Model-free Controller acts without a model, relying on learned state-action mappings.
- The framework demonstrates the equivalence in problem-solving ability between the learned Solver and Controller on grid navigation tasks, utilizing specialized FSC Executors and a Grid Master environment.

---

[VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings](http://arxiv.org/abs/2507.17080v1)

- VL-CLIP (Visual Grounding and LLM-Augmented CLIP Embeddings): introduces a novel framework that enhances CLIP embeddings by integrating Visual Grounding (localizes product regions) and an LLM-based Agent (enriches text descriptions) to improve multimodal recommendations.
- The framework refines image representations via Grounding DINO and enhances textual features through an iterative LLM process involving a Summarizer, Evaluator, and Refiner, before being processed by CLIP's dual encoders and optimized with contrastive loss.
- Deployed on a large e-commerce platform, the framework significantly improves retrieval accuracy, multimodal retrieval effectiveness, and recommendation quality, demonstrating the practical efficacy of combining object-aware visual grounding and LLM-enhanced text representation.

---

[Parallelism Meets Adaptiveness: Scalable Documents Understanding in Multi-Agent LLM Systems](http://arxiv.org/abs/2507.17061v1)

- ACF (Adaptive Coordination Framework): introduces a coordination framework for multi-agent LLM systems, with Orchestrator (Coordinates task execution), Dynamic Task Routing (Reassigns tasks dynamically), Role Self-Optimization (Agents adapt roles), Shared Long-Term Memory (Persistent document store), Role Agents (Specialized task agents), Evaluator Agent (Scores and selects outputs), Feedback Bus (Facilitates inter-agent communication), and Parallel Agents (Multiple agents for competition), designed for scalable document understanding.
- The framework enhances robustness and accuracy in complex financial document analysis by integrating dynamic task routing, bidirectional feedback, and competitive parallel agent evaluation.
- This system improves factual coverage, coherence, and efficiency over static and partially adaptive baselines, demonstrating the benefits of adaptiveness and structured competition in multi-agent LLM systems.

---

[Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?](http://arxiv.org/abs/2507.17015v1)

- Evaluation Agent: introduces a tool-using agentic system to provide higher quality feedback on long-form factual, advanced coding, and math tasks, by augmenting LLM-as-a-Judge with external validation tools, including Model Responses (input for evaluation), Initial Domain Assessment (LLM selects tools), Tool Usage (orchestrates external validation), Fact Check Tool (verifies factual statements), Code Execution Tool (executes, verifies code), Math Check Tool (validates math calculations), Provide Collected Information (aggregates tool outputs), Final Decision (LLM makes judgment), Judgement (final preference output), and Baseline Annotator (fallback evaluation system).
- The system leverages an Initial Domain Assessment to select relevant tools like Fact Check, Code Execution, and Math Check, then uses a Final Decision component to make judgments based on tool outputs, reverting to a Baseline Annotator if no tools are useful.
- This framework aims to improve AI annotator performance by grounding evaluations in external validation, reducing reliance on LLM's internal knowledge and biases.

---

[AURA: A Multi-Modal Medical Agent for Understanding, Reasoning & Annotation](http://arxiv.org/abs/2507.16940v1)

- AURA (A Multi-Modal Medical Agent for Understanding, Reasoning & Annotation): introduces, "AURA is an agentic AI system for comprehensive analysis, explanation, and evaluation of medical images", with AURA Agent (Multi-modal medical agent), LLM Head (Core reasoning engine), User Inquiry Interface (Input handling), ReAct-style Reasoning Loop (Orchestrates thought-action-observation), Memory (Stores states and results), Tool Orchestration Module (Manages tool execution), Specialized Tools (Modular medical utilities), Visual Question Answering Tool (Radiology dialogue/reporting), Medical Image Segmentation Tool (Localizes clinical regions), Counterfactual Image Generation Tool (Generates explanatory images), Self Evaluation & Analysis Tool (Assesses diagnostic relevance), Grounded Report Generation Tool (Aligns findings visually), Counterfactual Editing Tools (Precision image editing), Segmentation and Detection Tools (Anatomy/pathology classification), Analysis and Visualization Tools (Quantifies edits/visualizes), where it leverages an LLM-based architecture and a modular toolbox to provide interpretable, multimodal visual-linguistic explanations for medical imaging.
- The system emphasizes dynamic visual-linguistic explanations, introspective evaluation, and adaptive reasoning, enabling it to operate effectively even with limited pathological knowledge.
- Its modular design and ReAct-style reasoning loop allow autonomous self-assessment, tool orchestration, and generation of high-quality, clinically relevant outputs for chest X-ray analysis.

---

[Towards Simulating Social Influence Dynamics with LLM-based Multi-agents](http://arxiv.org/abs/2507.22467v1)

- Forum Simulation Framework: introduces an LLM-based multi-agent conversational environment designed to simulate social influence dynamics, featuring Dialogue Orchestration, LLM-based Multi-agents with defined Agent Personas, and Evaluation Metrics.
- The framework orchestrates asynchronous text-based discussions over five rounds, allowing LLM-based agents to adjust stances based on peer input and a shared conversation log.
- It systematically investigates how varying LLM capacities and architectures influence simulated social interactions, quantifying conformity, polarization, and fragmentation.

---

[From Cloud-Native to Trust-Native: A Protocol for Verifiable Multi-Agent Systems](http://arxiv.org/abs/2507.22077v1)

- TrustTrack (Trust-Native Protocol Stack): introduces a protocol stack for verifiable multi-agent systems, with an Agent Layer (agent execution environment), a Protocol Layer (protocol management), and a Ledger Layer (immutable data storage).
- TrustTrack reframes compliance as a design constraint by embedding structural guarantees like verifiable identity, policy commitments, and tamper-resistant behavioral logs directly into agent infrastructure.
- The protocol enables cryptographic traceability of agent behavior, supporting verifiable provenance and accountability in high-stakes, multi-agent workflows.

---

#### 21st July 2025

[LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra](https://arxiv.org/abs/2507.15815v1)

- LLM Economist: introduces a novel framework for agent-based economic modeling, featuring a Tax Planner (LLM agent) that designs tax policies and Worker Agents (LLM agents) that adjust labor, all interacting within an Environment that simulates economic outcomes.
- The framework employs in-context reinforcement learning for both the planner and workers, enabling them to adapt to strategic environments with hierarchical decision-making and optimize their respective utility functions.
- It uniquely integrates census-calibrated population modeling, dynamic tax-mechanism optimization, and democratic governance, providing a testbed for fiscal policy evaluation at a societal scale.

---

[Towards physician-centered oversight of conversational diagnostic AI](https://arxiv.org/abs/2507.15743)

- g-AMIE (guardrailed-AMIE): introduces a novel asynchronous oversight paradigm for conversational diagnostic AI, enabling AI-driven patient intake with strict guardrails and subsequent human physician oversight via a dedicated clinician cockpit.
- This framework decouples AI-driven patient intake from medical advice delivery, mandating human oversight by licensed primary care physicians to ensure safety and accountability.
- A randomized, blinded virtual Objective Structured Clinical Examination (OSCE) study demonstrated g-AMIE's superior performance in high-quality intake and case summarization compared to human control groups.

---

[A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining](http://arxiv.org/abs/2507.15770v1)

- EAMI: introduces a framework for analyzing abnormal emergence in service ecosystems, integrating Agent-Based Modeling, Inspector Agent, Analysis Agent, Intention Repository, Embedding Module, Clustering Module, and Intention Temporal Emergence Diagram to bridge microscopic agent intentions with macroscopic service emergence.
- The framework employs LLMs within its Inspector and Analysis Agents, along with a Memory component and Dual-Perspective Thought Extraction, to track and extract agent thoughts, enabling dynamic and interpretable emergence analysis.
- It identifies phase transition points in group intentions through embedding and clustering, then visualizes their temporal evolution to explain complex system phenomena.

---

[GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts](http://arxiv.org/abs/2507.15761v1)

- GasAgent: introduces a multi-agent framework for automated Gas optimization in smart contracts, including Seeker (identifies known patterns), Innovator (discovers new patterns), Executor (applies and validates changes), Manager (orchestrates workflow and reports), Gas Waste Pattern Library (stores known patterns), and New Pattern Blacklist (filters invalid patterns), designed to combine compatibility with existing patterns and automated discovery/validation of new patterns for end-to-end optimization.
- The framework addresses limitations of manual Gas optimization and single LLM approaches by enabling specialized agents to collaborate in a closed loop for identifying, validating, and applying Gas-saving improvements.
- GasAgent demonstrates effectiveness by optimizing real-world contracts with an average deployment Gas saving of 9.97% and usability for LLM-generated contracts, serving as a reliable optimization layer.

---

[BUGSCOPE: LEARN TO FIND BUGS LIKE HUMAN](http://arxiv.org/abs/2507.15671v1)

- BUGSCOPE (BugScope: Learn to Find Bugs Like Human): introduces an LLM-driven multi-agent system that emulates human auditors' workflow, including a Context Retrieval Agent (retrieves relevant code context) and a Bug Detection Agent (detects and validates bugs), which together automate the end-to-end auditing process.
- The Context Retrieval Agent utilizes Retrieval Strategy Synthesis with a Seed Extractor and Retrieval Direction, and performs Slicing-Based Context Retrieval with an AST Parser and LLM to gather relevant code snippets.
- The Bug Detection Agent synthesizes a detection prompt using an LLM, Reasoning Hints, and Prompt Reflection, then employs the LLM for Bug Validation to generate structured Bug Reports, effectively generalizing across diverse anti-patterns.

---

[DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving](http://arxiv.org/abs/2507.15615v1)

- DHEvo (Data-Algorithm Based Heuristic Evolution): introduces a data-algorithm co-evolution framework that iteratively selects representative MILP instances and evolves corresponding heuristics, with all Initialization-, Sample-, Iterative evolution-, Final Selection-components, where it significantly improves the generalization ability of generated heuristics for Mixed-Integer Linear Programming (MILP) solving.
- The framework employs an LLM-based MA-Evolution System, including Designer, Coder, Reviewer, and Judger agents, to generate and refine data-code pairs simultaneously through a debate cycle.
- This co-evolutionary approach ensures mutual adaptation between instances and algorithms, leading to robust generalization and superior performance compared to human-designed and existing LLM-based methods.

---

[PHYSGYM: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors](http://arxiv.org/abs/2507.15550v1)

- PHYSGYM (Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors): introduces a novel benchmark suite and simulation platform for assessing LLM-based scientific reasoning, including an Environment (simulated physics problems), Interface (controls experiments and data), and Evaluator (assesses model performance), designed to systematically control task complexity and prior knowledge for interactive physics discovery.
- The platform enables agents to actively probe environments, gather sequential data under constraints, and formulate hypotheses about underlying physical laws, providing fine-grained control over prior knowledge levels to dissect agent performance.
- PHYSGYM offers standardized evaluation protocols and metrics for hypothesis accuracy and model fidelity, demonstrating its utility in differentiating LLM capabilities based on varying priors and task complexity.

---

[HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics](http://arxiv.org/abs/2507.15518v1)

- HAMLET (Hyperadaptive Agent-based Modeling for Live Embodied Theatrics): introduces a multi-agent framework for AI drama, with Actor Designer (Generates character profiles), Plot Designer (Composes narrative draft/scenes/props), Reviewer (Evaluates character/plot rationality), Director (Integrates profiles, creates blueprint), Narrative Blueprint (Structured guide for performance), Planner (Designs/reviews multi-trajectory beats), Transfer (Monitors flag fulfillment, advances plot), Advancer (Ensures plot progression, directs actors), Actor (Performs narrative, makes decisions), Perceive And Decide (PAD) Module (Guides actor strategic decisions), Internal State (Actor's self-awareness, goals), External Stimulus (Environmental/contextual information), Tool Calling (Generates speech/actions), Narrator (Adjudicates interactions, updates environment), Critic (Evaluates drama performance quality), and Online Performance Environment (Dynamic, interactive theatrical setting), enabling autonomous and immersive interactive drama.
- The framework operates in two stages: offline planning to generate a narrative blueprint from a simple topic, and online performance for dynamic, improvisational theatrical experiences.
- It incorporates a comprehensive evaluation method, HAMLETJudge, to assess character performance, narrative quality, and interaction experience, achieving top-ranking results.

---

[PhishIntentionLLM: Uncovering Phishing Website Intentions through Multi-Agent Retrieval-Augmented Generation](http://arxiv.org/abs/2507.15419v1)

- PhishIntentionLLM: introduces a multi-agent RAG framework that uncovers phishing intentions from website screenshots, employing a Vision Analysis Agent, Context Enrichment Agent, Primary Classification Agent, a Specialist Analysis Layer with dedicated expert agents, a Validation Agent, and a dual-layer Knowledge Base with a feedback loop.
- The framework leverages LLMs' visual-language capabilities and a dual-layer knowledge architecture to provide scalable and interpretable intention-aware phishing analysis.
- It significantly outperforms single-agent baselines and prior work in precision and recall for detecting credential theft, financial fraud, malware distribution, and personal information harvesting.

---

[Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems](http://arxiv.org/abs/2507.15296v1)

- LLM Tool-Agent System Analysis Framework: introduces a comprehensive analysis of failed parameter filling in LLM tool-agent systems, utilizing a Failure Taxonomy Construction (Methodology component) and an Evaluation Process (Methodology component) to investigate "Butterfly Effects" in toolchains.
- The paper systematically identifies five parameter failure patterns—Missing Information, Redundant Information, Hallucination Name, Task Deviation, and Specification Mismatch—and constructs a taxonomy using Grounded Theory.
- It applies 15 input perturbation methods across user queries, tool documents, and tool returns to analyze their impact on LLM parameter behavior and proposes actionable improvements for tool agent reliability.

---

[SPAR: Scholar Paper Retrieval with LLM-based Agents for Enhanced Academic Search](http://arxiv.org/abs/2507.15245v1)

- SPAR (Scholar Paper Retrieval): introduces a modular multi-agent framework for academic paper retrieval that leverages LLM-based agents and RefChain for enhanced search.
- This framework performs fine-grained query understanding, multi-source retrieval, citation-driven knowledge expansion, and relevance-aware reranking to mirror human research exploration.
- SPAR significantly outperforms strong baselines on AutoScholar and SPARBench, a new expert-annotated benchmark, demonstrating its robustness and generalization in complex academic search scenarios.

---

[FaultLine: Automated Proof-of-Vulnerability Generation using LLM Agents](http://arxiv.org/abs/2507.15241v1)

- FAULTLINE: introduces an LLM agent workflow that automatically generates Proof-of-Vulnerability (PoV) test cases by tracing data flow, reasoning about control flow conditions, and iteratively refining tests based on execution feedback.
- The framework leverages an LLM agent augmented with various tools to explore codebases, identify vulnerability sources and sinks, and derive precise input conditions required to trigger vulnerabilities.
- The system's multi-stage reasoning process, including data flow analysis, control flow analysis, and a feedback-driven repair loop, enhances the LLM's ability to generate effective and accurate PoV tests across different programming languages.

---

[Solving Formal Math Problems by Decomposition and Iterative Reflection](http://arxiv.org/abs/2507.15225v1)

- Delta Prover: introduces an agent-based framework that orchestrates a general-purpose LLM, Lean 4 Proof Environment, and Retrieval Model, with Reflective Decomposition, Iterative Proof Repair, Automatic Proof Consolidation, and a Domain-Specific Language (DSL), to solve formal math problems by iteratively refining proofs and decomposing complex theorems.
- The framework leverages the LLM's inherent reasoning and reflection capabilities to interactively construct formal proofs in Lean 4, circumventing the need for model specialization or extensive fine-tuning.
- It achieves state-of-the-art performance on the miniF2F-test benchmark by systematically tackling complex proofs, learning from mistakes, and producing machine-verifiable results.

---

[EchoVoices: Preserving Generational Voices and Memories for Seniors and Children](http://arxiv.org/abs/2507.15221v1)

- EchoVoices: introduces an end-to-end digital human pipeline for seniors and children, with k-NN enhanced Whisper ASR model (speech recognition), LLM-driven Agent (persona distillation/response generation), Persona Card (user identity summary), RAG (memory retrieval), Memory Fragments (vector database), Age-adaptive VITS model (speech synthesis), Wav2Lip (lip synchronization), and GFPGAN (photorealistic face rendering), designed to create persistent digital personas by preserving unique voices and memories.
- The system processes spoken queries from seniors or children, transcribes them using a k-NN augmented Whisper model, generates context-aware responses via an LLM-driven agent with a RAG-based memory, and synthesizes age-appropriate speech using a two-stage fine-tuned VITS model.
- This framework aims to address the challenges of conventional ASR, TTS, and LLM systems with atypical speech patterns and interaction styles of seniors and children, enabling empathetic and effective intergenerational digital interactions.

---

[PromptArmor: Simple yet Effective Prompt Injection Defenses](http://arxiv.org/abs/2507.15219v1)

- PromptArmor: introduces, "a simple yet effective defense against prompt injection attacks", with Guardrail LLM (off-the-shelf LLM), Prompting Strategy (carefully designed prompts), Detection (identifies injected prompts), Extraction (isolates malicious content), and Sanitization (removes injected prompts), where it functions as a guardrail layer to detect and remove malicious prompts from agent inputs before processing.
- This defense leverages the text understanding and pattern recognition capabilities of an off-the-shelf LLM to analyze data samples and identify inconsistencies introduced by injected prompts.
- PromptArmor operates as a standalone preprocessing component, ensuring minimal disruption to existing LLM-based systems and allowing the agent to complete its intended user task with sanitized data.

---

[Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation](https://arxiv.org/abs/2507.10524)

- MoR (Mixture-of-Recursions): introduces a unified framework for LLMs that combines parameter sharing and adaptive computation, featuring a Recursive Transformer with Shared Stack of Layers/Recursion Block, a Router with Expert-choice routing/Token-choice routing, and a KV Caching Strategy with Recursion-wise KV caching/Recursive KV sharing.
- This framework dynamically assigns token-level recursion depths via lightweight routers and selectively caches Key-Value pairs, focusing quadratic attention computation only on active tokens to improve memory access efficiency.
- MoR establishes a new Pareto frontier for LLM efficiency, significantly lowering validation perplexity and improving few-shot accuracy while delivering higher throughput compared to existing baselines.

---

[Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario](http://arxiv.org/abs/2507.15587v1)

- RMARL (Red-Team Multi-Agent Reinforcement Learning): introduces a framework where red-team agents, trained using a DC-GPPO algorithm with GCN and MLP, actively interfere with autonomous vehicles (AVs) in emergency braking scenarios, leveraging a CGMDP and PTZ model to generate high-risk corner cases.
- The framework redefines background vehicles as red-team agents, enabling them to explore and uncover safety-critical scenarios beyond typical data distributions by maximizing AV collision rates while adhering to traffic regulations.
- The PTZ model quantifies the threat posed by red-team vehicles, encouraging more extreme adversarial behaviors, and the DC-GPPO algorithm applies dual constraints to ensure realistic and disruptive interference.

---

[The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents](http://arxiv.org/abs/2507.15478v1)

- CoCo (Constitutional Controller): introduces a novel framework for doubt-calibrated steering of compliant agents, integrating a Constitution (agent's structured knowledge base), a Doubt Model (neural self-doubt probability density), Probabilistic Inference, Plan & Control, and Online Compliance Validation.
- The framework enhances agent safety and reliability by reasoning over deep probabilistic logic programs representing constraints and learning self-doubt from contextual features.
- CoCo's adaptive behavior, demonstrated in UAV navigation, allows agents to account for external constraints and internal uncertainties, leading to compliant and crash-free operations.

---

[The Emergence of Deep Reinforcement Learning for Path Planning](http://arxiv.org/abs/2507.15469v1)

- DQN (Deep Q-Network) Algorithm: is illustrated as a path planning model for marine search and rescue vessels, including an Environment, Actions, Estimation Q-network, Target Q-network, Reward Function, Experience Replay Memory, Gradients, Loss Function, and Update after N steps, designed to optimize navigation strategies.
- This model enables autonomous agents to learn optimal navigation policies through interactive learning with the environment, aiming to maximize cumulative rewards for efficient search paths.
- The architecture incorporates a target network for stable Q-value references and experience replay to decorrelate learning samples, enhancing the algorithm's stability and adaptability.

---

[LaViPlan : Language-Guided Visual Path Planning with RLVR](http://arxiv.org/abs/2507.12911v2)

- LaViPlan (Language-Guided Visual Path Planning with Reinforcement Learning with Verifiable Rewards): introduces a framework that leverages Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Vision-Language Models (VLMs) for autonomous driving, addressing vision-language-action misalignment by integrating a policy model, a reference model, and verifiable rewards.
- The framework operates in two phases: supervised fine-tuning of a VLM, followed by reinforcement fine-tuning where the policy model is optimized using Group Relative Policy Optimization (GRPO) with rewards based on output format adherence and trajectory accuracy.
- This approach aims to steer VLMs toward context-aware decision-making consistent with situational reasoning, improving performance in out-of-distribution scenarios by explicitly optimizing planning-oriented metrics.

---

[Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization](http://arxiv.org/abs/2507.16110v1)

- ChatBattery: introduces an expert-guided LLM reasoning platform for battery materials discovery, featuring two phases (Exploration and Exploitation), eight sequential stages, and seven specialized agents, including LLM, Domain, Search, Decision, Retrieval, Rank, and Human Agents.
- This framework integrates domain knowledge to steer LLMs towards effective reasoning, enabling the identification, synthesis, and characterization of novel lithium-ion battery cathode materials.
- The platform's AI-driven approach significantly reduces the time for experimental screening and validation, demonstrating the transformative potential of LLM-augmented discovery pipelines.

---

[Deep Researcher with Test-Time Diffusion](http://arxiv.org/abs/2507.16075v1)

- TTD-DR (Test-Time Diffusion Deep Researcher): introduces a novel framework that conceptualizes research report generation as a diffusion process, iteratively refining a preliminary draft through denoising and self-evolution, leveraging LLM-powered agents for each stage.
- The framework initiates with a noisy draft and a research plan, which are then refined via a continuous feedback loop incorporating external information through a retrieval mechanism.
- This draft-centric design, enhanced by component-wise self-evolution, ensures timely and coherent report writing while minimizing information loss during the iterative search process.

---

[Making REST APIs Agent-Ready: From OpenAPI to Model Context Protocol Servers for Tool-Augmented LLMs](http://arxiv.org/abs/2507.16044v1)

- AutoMCP (Automated Model Context Protocol Compiler): introduces a compiler that automates the generation of Model Context Protocol (MCP) servers from OpenAPI specifications, with components including Input Parsing and Dialect Resolution, Spec Normalization and Flattening, Authentication Analysis and .env Generation, Stub Generation and Handler Synthesis, and Output Layout and Transport Configuration.
- The framework aims to streamline the integration of REST APIs into LLM workflows by transforming OpenAPI definitions into callable MCP tools, thereby reducing manual glue code and hardcoded prompts.
- This approach addresses the engineering bottleneck of manually constructing MCP servers, enabling dynamic tool discovery and invocation for tool-augmented LLMs.

---

[A Pilot Study on LLM-Based Agentic Translation from Android to iOS: Pitfalls and Insights](http://arxiv.org/abs/2507.16037v1)

- Multi-Agent Translation Pipeline: introduces an LLM-based agentic approach for mobile application translation from Android to iOS, with Specification Extraction, Code Translation, and Code Validation Agents, where it evaluates LLM performance, identifies key failure points, and proposes improvement guidelines.
- The study evaluates the approach on five diverse Android projects, manually analyzing translated code for syntactic correctness, semantic accuracy, and functional completeness.
- It identifies 10 types of translation failures across method, file, and package levels, underscoring challenges in platform-aware translation and the need for robust validation.

---

[HyDRA: A Hybrid-Driven Reasoning Architecture for Verifiable Knowledge Graphs](http://arxiv.org/abs/2507.15917v1)

- HyDRA (Hybrid-Driven Reasoning Architecture): introduces a framework for verifiable Knowledge Graph (KG) automation, integrating symbolic knowledge and neural networks, with components including stakeholder, persona, scope document, competency question, ontology, and KG generation modules, all guided by verifiable contracts.
- The architecture operationalizes Design-by-Contract principles and the SymbolicAI framework, orchestrating an LLM-driven pipeline with a closed-loop verification and repair mechanism that enforces structural invariants and type consistency.
- This approach aims to improve the reliability of automated KG construction by ensuring traceability from high-level requirements to low-level data and providing an evaluation framework for functional correctness.

---

[Towards Mitigation of Hallucination for LLM-empowered Agents: Progressive Generalization Bound Exploration and Watchdog Monitor](http://arxiv.org/abs/2507.15903v1)

- HalMit: introduces a novel black-box watchdog framework that models the generalization bound of LLM-empowered agents to detect hallucinations, without requiring internal knowledge of the LLM's architecture, with Core Agent (coordinates interactions), Query Generation Agent (generates queries), Target LLM (LLM-powered agent), Evaluation Agent (evaluates responses), Vector Database (stores generalization bound points), Policy Network (adjusts fractal probabilities), Probabilistic Fractal Sampling (query generation method), Generalization Bound Exploration (identifies generalization bound), and Watchdog Monitor (monitors hallucinations).
- The framework employs a multi-agent system, including a Core Agent, Query Generation Agents, a Target LLM, and an Evaluation Agent, to explore and identify the generalization bound.
- It utilizes probabilistic fractal sampling guided by a Policy Network to efficiently generate queries and store identified boundary points in a Vector Database for real-time hallucination monitoring.

---

[Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation](http://arxiv.org/abs/2507.15901v1)

- IAIDF: introduces a comprehensive methodology for designing ethical and inclusive agentic AI in household automation, encompassing ethical foundation, co-design with vulnerable groups, user agency and privacy control, socio-technical bias reduction, household dynamics simulation, ethical data mining, and real-world deployment and societal impact.
- This framework emphasizes integrating ethical considerations from the initial design phase, ensuring user participation, maintaining user control over data and AI actions, and mitigating biases through socio-technical approaches.
- The methodology utilizes simulations and real-world deployments to validate AI systems, aiming to foster trust, enhance usability, and ensure equitable outcomes for diverse users in smart home environments.

---

[An LLM Driven Agent Framework for Automated Infrared Spectral Multi Task Reasoning](http://arxiv.org/abs/2507.21471v1)

- LLM Driven Agent Framework: introduces an end-to-end LLM-driven agent framework that integrates an Input Module (receives queries/spectral data), an LLM Agent (orchestrates tasks/performs reasoning) with Entity Extraction (identifies research object/task), Function Call (invokes spectral processing), Multi-task Generation (performs classification/regression/anomaly detection), and Multi-turn Generation Enhancement (refines predictions iteratively), a Structured Paper Database (curated IR publications knowledge), a Retrieval Algorithm (searches knowledge base), a Spectral Processing Module (applies preprocessing/feature extraction), a Hard Samples Module (identifies/feeds mispredicted samples), and an Output Module (provides analytical results).
- The framework leverages few-shot learning and a multi-turn conversational protocol, where hard samples are iteratively appended to prompts, to dynamically refine predictions and improve performance under low-data conditions.
- This approach combines domain-specific reasoning with generalizable inference capabilities, establishing a new paradigm for intelligent, scalable infrared spectral analysis.

---

#### 20th July 2025

[WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization](http://arxiv.org/abs/2507.15061v1)

- WebShaper (Formalization-Driven IS Data Synthesis Framework): introduces a novel formalization-driven framework for synthesizing high-quality information-seeking (IS) training data, leveraging set-theoretic constructs and an agentic Expander module for systematic task generation and expansion.
- This framework addresses data scarcity and inconsistency in IS agent development by formalizing tasks as Knowledge Projections, enabling precise control over reasoning structures and complexity.
- WebShaper's approach, including seed task construction, agentic expansion with specialized tools, and robust training methodologies, yields state-of-the-art performance for open-sourced IS agents on benchmarks like GAIA and WebWalkerQA.

---

[LibLMFuzz: LLM-Augmented Fuzz Target Generation for Black-box Libraries](http://arxiv.org/abs/2507.15058v1)

- LibLMFuzz: introduces a framework that pairs an agentic LLM with a lightweight toolchain (disassembler, compiler, fuzzer) within a sandbox, orchestrated by middleware.
- This system autonomously analyzes stripped binaries, plans fuzz strategies, generates drivers, and iteratively self-repairs build or runtime errors for black-box libraries.
- The framework significantly reduces costs associated with fuzzing closed-source libraries by achieving 100% API coverage with no human intervention.

---

[EduThink4AI: Translating Educational Critical Thinking into Multi-Agent LLM Systems](http://arxiv.org/abs/2507.15015v1)

- EDU-Prompting: introduces a novel multi-agent framework for translating educational critical thinking into LLM systems, with Agent I (brainstorms initial answers), Agent II (validates answer existence), Agent III (critiques raw answers), Agent IV (synthesizes final answer), User Prompt Generator (collects user input), Stage Classifier (classifies learning stage), Vocabulary Module (processes vocabulary), Vocab Fetcher (identifies vocabulary terms), WordNet (enriches vocabulary data), Vocab Explainer (generates vocabulary explanations), Writing Assessor (evaluates writing content), Topic Module (analyzes user topics), Topic Identifier (identifies primary topics), Prompt Generator (creates topic prompts), Prompt Aggregator (synthesizes aggregated prompts), Reasoning Module (orchestrates critical thinking), and Final Response Generator (generates comprehensive response).
- The framework significantly enhances content truthfulness and logical soundness in AI-generated educational responses by fostering diverse perspectives and analytical reasoning.
- Its modular design allows seamless integration into existing educational applications, enabling practitioners to incorporate critical thinking catalysts and multiple perspectives without extensive system modifications.

---

[LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading](http://arxiv.org/abs/2507.14995v1)

- LLM-MARL: introduces an integrated framework for real-time P2P energy trading, with LLM Expert Workflow (Generates expert strategies), MARL (Learns optimal policies), and P2P Energy Trading Environment (Simulates energy market) components, designed to bridge expert knowledge with agent learning for efficient energy market decision-making.
- The framework replaces human experts with LLMs to guide MARL agents through imitation learning, significantly reducing manual intervention costs and integrating expert knowledge.
- It employs a novel multi-agent imitation learning algorithm with a Wasserstein metric and a differential multi-head attention-based Critic network to enhance policy evaluation and accelerate learning.

---

[Byzantine-Robust Decentralized Coordination of LLM Agents](http://arxiv.org/abs/2507.14928v1)

- DecentLLMs: introduces a decentralized consensus approach for multi-agent LLM systems, including worker agents (generate answers in parallel), evaluator agents (score answers/aggregate scores/select best answer/record on blockchain/reply to user), Geometric Median (GM) Algorithm (Byzantine-robust score aggregation), Blockchain (record transactions/auditable records), and Byzantine Reliable Broadcast Protocols (ensure consistent message delivery), designed to overcome limitations of leader-driven coordination.
- This framework enables faster consensus and consistently selects higher-quality answers by allowing worker agents to generate responses concurrently and evaluator agents to independently score and rank them using Byzantine-robust aggregation techniques.
- The system effectively tolerates Byzantine agents and significantly improves the quality of selected answers compared to traditional leader-based quorum voting methods.

---

[Redefining Elderly Care with Agentic AI: Challenges and Opportunities](http://arxiv.org/abs/2507.14912v1)

- Agentic AI (Agentic Artificial Intelligence): introduces a comprehensive review of LLM-powered Agentic AI's transformative potential in elderly care, covering its applications, challenges, and ethical considerations for personalized, autonomous support.
- The paper details Agentic AI's applications in personalized health management, cognitive support, emotional companionship, and enabling independence and inclusivity for older adults.
- It also critically examines associated challenges, including data privacy, reliability, and integration issues, proposing a human-centered framework for responsible and equitable deployment.

---

[INSIGHTX AGENT: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis](http://arxiv.org/abs/2507.14899v1)

- INSIGHTX AGENT: introduces an LLM-based agentic framework for reliable X-ray NDT analysis, with LMM Agent Core (orchestrates process), Large Language Model (reasoning, intent recognition), Lora Layer (domain adaptation), Image Encoder (visual feature processing), Tokenizer (text input processing), Sparse Deformable Multi-Scale Detector (SDMSD) (defect localization), CNN Backbone (extracts multi-scale features), Proposal Generation (generates, refines proposals), Deformable Attention Mechanisms (refines sparse proposals), Evidence-Grounded Reflection (EGR) Tool (validates, refines proposals), Context Assessment (evaluates image characteristics), Individual Defect Analysis (evaluates each proposal), False Positive Elimination (applies rejection criteria), Confidence Recalibration (adjusts confidence scores), and Quality Assurance (verifies output consistency).
- The framework positions an LLM as a central orchestrator, coordinating specialized tools like SDMSD for defect detection and EGR for reflective validation, moving beyond passive data processing to active reasoning.
- This approach enhances diagnostic reliability, interpretability, and interactivity in X-ray NDT by integrating high-precision detection with structured, evidence-grounded reasoning and self-assessment.

---

[Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree](http://arxiv.org/abs/2507.14799v1)

- Browser Gym Agent: introduces a system vulnerable to Indirect Prompt Injection (IPI) attacks, demonstrating how a malicious actor can manipulate its web navigation behavior by embedding adversarial triggers in webpage HTML.
- The system leverages the Greedy Coordinate Gradient (GCG) algorithm to optimize universal adversarial triggers, which are then inserted into the HTML accessibility tree parsed by the LLM.
- This research highlights critical security risks, including login credential exfiltration and forced ad clicks, emphasizing the urgent need for stronger defenses in LLM-driven autonomous web agents.

---

[STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies](http://arxiv.org/abs/2507.15147v1)

- STL-GO (Spatio-Temporal Logic with Graph Operators): introduces a novel logic for specifying and verifying complex multi-agent system requirements, featuring an outer logic (system-wide reasoning), an inner logic (agent-specific reasoning), and graph operators (quantifies agent interactions) represented by a graph operator tree (operator relation representation).
- This framework extends signal temporal logic by incorporating graph operators to quantitatively reason over multiple asymmetric network topologies, enabling distributed monitoring.
- The distributed monitoring algorithm allows individual agents to determine specification satisfaction using only local information, demonstrated in bike-sharing and multi-drone case studies.

---

[FROM KICKING TO CAUSALITY: SIMULATING INFANT AGENCY DETECTION WITH A ROBUST INTRINSIC REWARD](http://arxiv.org/abs/2507.15106v1)

- CAIS (Causal Action Influence Score): introduces a novel, model-based intrinsic reward for robust agency detection in noisy environments, utilizing a MIMo-Mobile Environment, an Embodied Agent (MIMo) with a Visual Encoder and Agent Architecture, driven by a Reinforcement Learning Framework with an Expected SARSA Algorithm, and a Reward Module that calculates CAIS via Quantile Regression and Wasserstein Distance, alongside a Surprise Signal, Mobile Trajectory Length, and Representation Trajectory Length, all optimized by AdamW Optimizer.
- The paper demonstrates that CAIS enables the agent to distinguish self-generated effects from environmental noise, leading to a robust sense of agency that generalizes to unpredictable scenarios.
- The framework also successfully reproduces the "extinction burst" phenomenon by augmenting CAIS with a surprise signal, highlighting the psychological plausibility of the causal inference approach.

---

[Search-Based Autonomous Vehicle Motion Planning Using Game Theory](http://arxiv.org/abs/2507.15088v1)

- N-MP (Nash Motion Planner): introduces a search-based interactive motion planning scheme for autonomous vehicles, incorporating Dynamic Equation Derivation, Objective Function Formulation, Nash Equilibrium Identification, and Ego-AV Speed Modification.
- This novel approach models other road users as intelligent agents within a game-theoretic framework, generating realistic and safer paths for autonomous vehicles.
- The framework demonstrates low computational time and adaptability to various vehicle dynamics and road users, making it suitable for complex traffic scenarios and real-time applications.

---

[The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering](http://arxiv.org/abs/2507.15003v1)

- SE 3.0 (Agentic Software Engineering): introduces AIDev, a large-scale dataset, to empirically study how Autonomous Coding Agents (AI teammates), Human Developers (human collaborators), Review Bots (automated code reviewers), GitHub Repositories (software project hosts), and Pull Requests (code change proposals) are reshaping software engineering.
- The paper analyzes 456,535 Agentic PRs from five leading LLM-powered agents, revealing their contributions, acceptance rates, and review dynamics compared to human-authored PRs.
- Key findings highlight agents' speed in code submission, lower PR acceptance rates for complex tasks, and the increasing role of review bots, underscoring the need for new SE methodologies.

---

[AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents](http://arxiv.org/abs/2507.14897v1)

- AgentFly: introduces a scalable and extensible Agent-RL framework, with an Agent Module (manages agent workflow) and an RL Training Module (executes reinforcement learning), designed to empower LM agents with diverse RL algorithms.
- The framework supports multi-turn interactions by adapting traditional RL methods with token-level masking and features a decorator-based interface for defining tools and reward functions.
- It implements asynchronous execution of tool calls and reward computations, alongside a centralized resource management system, to support high-throughput training and scalable environment coordination.

---

[HMARL-CBF – Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems](http://arxiv.org/abs/2507.14850v1)

- HMARL-CBF: introduces a novel hierarchical multi-agent reinforcement learning approach, with High-Level Policy (learns joint cooperative behavior), Low-Level Policy (learns safe individual behavior), CBF-Based Policy (executes skills safely), High-Level Policy Network (implements high-level policy), Low-Level Policy Parameter Network (implements low-level policy), Skills (predefined safety-constrained actions), Control Barrier Functions (enforce pointwise safety), Control Lyapunov Functions (guide skill execution), Extrinsic Trajectory Return (optimizes joint performance), and Intrinsic Trajectory Return (learns individual skills), designed for safe policy learning in multi-agent safety-critical autonomous systems by decomposing the problem into two levels.
- The framework ensures safety guarantees during both training and real-world deployment by integrating Control Barrier Functions for pointwise-in-time safety constraints and utilizing a skill-based hierarchical structure.
- The approach validates its effectiveness on challenging multi-agent traffic scenarios, demonstrating superior safety compliance and improved performance compared to existing methods.

---

[Can Mental Imagery Improve the Thinking Capabilities of AI Systems?](http://arxiv.org/abs/2507.12555v2)

- The Machine Thinking Framework: introduces a comprehensive framework integrating mental imagery to enhance AI thinking capabilities, featuring a Cognitive Thinking Unit, Needs Unit, Input Data Unit, and Mental Imagery Unit.
- This framework enables AI systems to reason, plan, and infer decisions autonomously by processing sensory inputs and internally generated representations.
- It addresses limitations of current AI models by simulating human-like cognitive processes, bridging perception, reasoning, and imagination.

---

[StaAgent: An Agentic Framework for Testing Static Analyzers](http://arxiv.org/abs/2507.15892v1)

- STAAGENT (An Agentic Framework for Testing Static Analyzers): introduces an LLM-driven agentic framework for systematically evaluating static analyzer rules, including a Seed Generation Agent (generates bug-inducing programs), a Code Validation Agent (validates seeds, generates tests), a Mutation Generation Agent (creates semantically equivalent mutants), and an Analyzer Evaluation Agent (compares analyzer behavior).
- The framework leverages LLMs to synthesize, mutate, and validate code snippets, performing metamorphic testing to uncover inconsistencies in static analyzer rule implementations.
- This approach offers a scalable and adaptable solution to improve the reliability of static analyzers by identifying flaws in rule implementations through inconsistent behaviors.

---

[Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture](http://arxiv.org/abs/2507.15895v1)

- RBAMA (Reason-Based Artificial Moral Agent): introduces an extended reinforcement learning architecture that integrates an ethics module with a reasoning unit to enable moral decision-making based on normative reasons and iterative refinement through case-based feedback from a moral judge.
- The framework includes a reasoning unit operating on a learned reason-theory, moral policies for fulfilling moral goals, moral filters for enforcing moral constraints, and an instrumental policy for task achievement.
- This modular design ensures behavioral conformity to inferred moral obligations, enhances moral trustworthiness and robustness, and allows for moral justification of the agent's actions.

---

[Active Probing with Multimodal Predictions for Motion Planning](http://arxiv.org/abs/2507.09822v3)

- APMP (Active Probing with Multimodal Predictions): introduces a unified framework that combines trajectory planning, multimodal predictions, and active probing to enhance decision-making under uncertainty, integrating utility maximization, safety assessment, and information maximization.
- The framework develops a novel risk metric that seamlessly integrates multimodal prediction uncertainties through mixture models, proving analytical tractability with a closed-form solution.
- It incorporates an active probing mechanism to strategically select actions for improving estimates of other agents' behavioral parameters, demonstrating robust performance in complex traffic scenarios.

---

#### 19th July 2025

[Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI](http://arxiv.org/abs/2507.14730v1)

- AI Urban Planner: introduces a conceptual framework for automated urban planning, integrating a Generative Urban Planning Framework with Representation and Generation stages, LLMs, Agentic AI, Digital Twins, and a Human-Machine Co-design Interface.
- The framework aims to synthesize optimal land-use configurations by encoding diverse urban contexts into structured embeddings and generating plans conditioned on geospatial, social, and human-centric constraints.
- This approach seeks to augment human expertise, democratize planning insights, and enable adaptive, customizable urban design solutions.

---

[NEO: A CONFIGURABLE MULTI-AGENT FRAMEWORK FOR SCALABLE AND REALISTIC TESTING OF LLM-BASED AGENTS](http://arxiv.org/abs/2507.14705v1)

- Neo: introduces a configurable multi-agent framework for scalable and realistic testing of LLM-based agents, including a Question Agent (generates test inputs), an Evaluation Agent (assesses target agent output), and a Context Hub (stores test context/history) to simulate human-like conversations and evaluate LLM systems.
- The framework leverages a probabilistic state model to control dialogue flow, emotional tone, and topical intent, enabling dynamic variation across multi-turn test cases and uncovering edge cases.
- Neo's architecture supports both pre-deployment testing and post-launch monitoring, aiming for self-evolution through memory-driven refinement and continuous improvement of LLM testing.

---

[Agentic Satellite-Augmented Low-Altitude Economy and Terrestrial Networks: A Survey on Generative Approaches](http://arxiv.org/abs/2507.14633v1)

- Agentic AI: introduces a survey on how Agentic AI, empowered by Generative AI (GAI) models (Variational Autoencoders, Generative Adversarial Networks, Generative Diffusion Models, Transformer-Based Models) and LLMs, enhances perception, reasoning, and action capabilities within Satellite-Augmented Low-Altitude Economy and Terrestrial Networks (SLAETNs).
- This approach addresses challenges in SLAETNs by enabling autonomous decision-making, resource-constrained sensing, and secure cross-domain coordination.
- The survey provides a model-driven foundation, comparative analysis, and future directions for building scalable, adaptive, and trustworthy generative agents in integrated networks.

---

[AMICO: AN EVENT-DRIVEN MODULAR FRAMEWORK FOR PERSISTENT AND EMBEDDED AUTONOMY](http://arxiv.org/abs/2507.14513v1)

- AMICO (An Event-Driven Modular Framework for Persistent and Embedded Autonomy): introduces an event-driven, modular agent framework designed for persistent and embedded autonomy, featuring distinct layers (Environment, Interaction, AI Agent, Engine) and core components like Event Generator, Action Selector, and integrated memory systems.
- Implemented in Rust for performance and safety, AMICO supports reactive agents operating across embedded systems and browser environments via WebAssembly (WASM), enabling robust and efficient real-world deployment.
- The framework provides clear abstractions for event processing, agent state management, behavior execution, and LLM-based reasoning integration, facilitating resilient, interactive, and persistent agent behavior under resource constraints.

---

[Routine: A Structural Planning Framework for LLM Agent System in Enterprise](http://arxiv.org/abs/2507.14447v1)

- Routine (A Structural Planning Framework for LLM Agent System in Enterprise): introduces a multi-step agent planning framework with Planning Module (generates step-by-step plan), Execution Module (follows plan, generates tool call instructions), Tool Module (receives instructions, returns execution results), and Memory Module (stores context), where it provides a clear structure, explicit instructions, and seamless parameter passing to guide an agent's execution module in performing multi-step tool-calling tasks with high stability.
- The framework significantly increases execution accuracy in model tool calls, improving performance of LLMs like GPT-4o and Qwen3-14B in real-world enterprise scenarios.
- Routine also enables the distillation of domain-specific tool-usage patterns and enhances model adaptability to new scenarios, accelerating the deployment and adoption of agent systems.

---

[When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems](http://arxiv.org/abs/2507.14660v1)

- Self-Evolving Multi-Agent Collusion Framework: introduces a novel simulation framework for studying multi-agent collusion, incorporating components for agent coordination, behavior evolution, and platform-level intervention, where it simulates and analyzes how malicious agents coordinate and adapt in high-stakes environments like misinformation and e-commerce fraud.
- The framework, built on the OASIS social simulator, demonstrates that decentralized malicious multi-agent systems are more effective and adaptive in spreading harm than centralized ones, even against traditional interventions.
- It provides insights into malicious group operations and highlights the need for dynamic detection systems and countermeasures against evolving collusive behaviors.

---

[LEARNING TO COMMUNICATE IN MULTI-AGENT REINFORCEMENT LEARNING FOR AUTONOMOUS CYBER DEFENCE](http://arxiv.org/abs/2507.14658v1)

- DIAL (Differentiable Inter-Agent Learning): introduces a multi-agent reinforcement learning framework for autonomous cyber defense, featuring blue agents with C-Nets that learn to communicate and take defensive actions within the CybORG simulation environment.
- The framework enables blue agents to develop tactical policies akin to human experts, learning minimal cost communication messages while defending against cyber threats in various network configurations.
- DIAL's approach, including Strategic Action Unmasking, allows agents to coordinate effectively and outperform agents requiring global state information, demonstrating practical applicability in enterprise network simulations.

---

#### 18th July 2025

[DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration](http://arxiv.org/abs/2507.14088v1)

- DPMT (Dual Process Multi-scale Theory of Mind Framework): introduces a novel framework for real-time human-AI collaboration, featuring an Information Extractor, a Fast System for intuitive decision-making, a Slow System with a multi-scale ToM module for cognitive reasoning, an Action Decoding Module, and a Memory component.
- The framework leverages a dual-process approach, where the Fast System handles immediate macro-action decisions using a smaller LLM, while the Slow System, powered by LLMs, performs deeper, multi-scale ToM reasoning to model human partners' domain knowledge, cognitive style, and intentions.
- This hierarchical design enables efficient human-AI collaboration by integrating quick decision-making with robust human partner modeling, enhancing adaptability and interpretability in complex, dynamic scenarios.

---


[CodeEdu: A Multi-Agent Collaborative Platform for Personalized Coding Education](http://arxiv.org/abs/2507.13814v1)

- CodeEdu: introduces a multi-agent collaborative platform for personalized coding education, leveraging its Tool Pool (external utilities), Agent Pool (specialized LLM agents), and Task Pool (standard task types) to dynamically allocate agents and tasks for proactive and personalized learning.
- The platform's workflow encompasses Personalized Material Generation, Real-Time Q&A, Step-by-step Code Tutoring with Debugging, and Learning Report Generation, facilitated by dynamic agent and task allocation.
- Automated evaluations demonstrate CodeEdu's efficacy in substantially enhancing students' coding performance and providing high-quality learning materials compared to baseline LLM tutors.

---

[AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework](http://arxiv.org/abs/2507.13729v1)

- AGENTS-LLM (Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework): introduces an LLM-agent based framework for augmenting real-world traffic scenarios using natural language descriptions, featuring a Scenario Modifier Agent, a Toolbox, and an optional Quality Assurance loop with Text QA and Visual QA agents.
- This framework addresses the limitations of manual scenario augmentation by domain experts, enabling scalable generation of challenging and safety-critical driving scenarios.
- The agentic design provides fine-grained control over the output and allows smaller, cost-effective LLMs to achieve performance comparable to larger models.

---

[COGNIQ-H: A SOFT HIERARCHICAL REINFORCEMENT LEARNING PARADIGM FOR AUTOMATED DATA PREPARATION](https://arxiv.org/abs/2507.13710v1)

- CogniQ-H: introduces a soft hierarchical reinforcement learning paradigm for automated data preparation, synergistically fusing a Large Language Model (LLM) as a high-level planner, a Learning-to-Rank (LTR) model for immediate quality scores, and an RL Q-model for long-term value estimates, integrated by a synergistic policy layer.
- This framework addresses the combinatorial search space of data preparation by providing probabilistic, LLM-driven strategic guidance, avoiding the rigid commitments of traditional hard hierarchical reinforcement learning.
- The framework balances pre-existing knowledge, supervised signals, and adaptive learning to achieve robust and efficient pipeline discovery, outperforming state-of-the-art RL-based methods in pipeline quality and convergence speed.

---

[CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.14111)

- CUDA-L1 (Improving CUDA Optimization via Contrastive Reinforcement Learning): introduces an automated reinforcement learning framework for CUDA optimization, which leverages a three-stage pipeline including Supervised Fine-tuning, Self-supervised Learning, and Contrastive Reinforcement Learning to enhance optimization by distinguishing between effective and ineffective CUDA strategies through comparative analysis of generated variants and their execution performance.
- The framework achieves significant speedups (average 17.7x, peak 449x on NVIDIA A100) across 250 KernelBench CUDA kernels and demonstrates strong portability across various GPU architectures.
- CUDA-L1 autonomously discovers diverse optimization techniques, identifies optimal combinations, uncovers fundamental principles, and pinpoints hidden bottlenecks without human expertise, showcasing RL's potential in complex code optimization.

---

[The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?](https://arxiv.org/abs/2507.14084)

- Conceptual Model of Emotion-Memory Link: introduces a framework investigating the relationship between perceived group emotions and group memorability in conversational interactions, including components like cognitive appraisal, experienced emotion, physiological reaction, behavior, observer annotation, memory encoding, and accessible memories.
- The paper empirically examines if third-party affect annotations, commonly used in Affective Computing, reliably capture memory-relevant information in dynamic group settings.
- The study concludes that the observed relationship between group affect and memorability annotations is not significantly different from random chance, questioning the utility of third-party affect annotations as proxies for conversational memorability.

---

[Photonic Fabric Platform for AI Accelerators](https://arxiv.org/abs/2507.14000)

- PFA (Photonic Fabric Appliance): introduces a photonic-enabled switch and memory subsystem for AI accelerators, integrating Photonic Fabric Modules (PFM) with photonic and electronic components, and external DDR5 memory, to overcome memory bottlenecks and scale AI workloads.
- The system provides up to 32 TB of shared memory and 115 Tbps of all-to-all digital switching, enabling more efficient distributed AI training and inference.
- Evaluated using the CelestiSim simulator, PFA demonstrates significant throughput and latency improvements for LLM inference and substantial energy savings for LLM training compared to conventional GPU-based systems.

---



[NetIntent: Leveraging Large Language Models for End-to-End Intent-Based SDN Automation](http://arxiv.org/abs/2507.14398v1)

- NetIntent: introduces a unified and adaptable framework that leverages LLMs and non-LLM agents to automate the entire Intent-Based Networking (IBN) lifecycle, from high-level user intents to low-level Software-Defined Networking (SDN) configurations.
- The framework orchestrates LLMs for intent translation, conflict detection, and corrective actions, while non-LLM agents handle validation, resolution, deployment, and assurance tasks.
- NetIntent supports dynamic re-prompting and contextual feedback, enabling robust execution of user-defined intents with minimal human intervention across OpenDaylight (ODL) and Open Network Operating System (ONOS) SDN controllers.

---

[WebGuard: Building a Generalizable Guardrail for Web Agents](http://arxiv.org/abs/2507.14293v1)

- WebGuard: introduces a generalizable guardrail system for web agents, comprising the WebGuard Dataset (human-annotated action risk levels), a three-tier Risk Schema (action risk categorization), and a Guardrail Model (LLM, predicts action risk level) that processes Observation Space (webpage state input) and Action Space (proposed web agent action), integrated with Human-in-the-loop Control (user intervention mechanism) and Annotation Tools (dataset creation and labeling).
- The system addresses the urgent need for effective safety measures for LLM-powered web agents by predicting the outcome of state-changing actions using a dataset of 4,939 human-annotated actions across diverse websites and domains.
- Evaluations reveal that frontier LLMs struggle with action outcome prediction and high-risk recall, emphasizing the necessity of dedicated safeguards and specialized fine-tuning for reliable web agent deployment.

---

[DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation](http://arxiv.org/abs/2507.14267v1)

- DREAMS (Density Functional Theory Based Research Engine for Agentic Materials Screening): introduces a hierarchical, multi-agent framework for DFT simulation, featuring a Supervisor LLM Agent (Generates/Updates Plans/Assigns Tasks), DFT LLM Agent (Manages DFT Calculations/Structure Generation/Parameter Optimization/Output Analysis), Convergence LLM Agent (Suggests Fixes/Resolves Convergence Issues), and HPC LLM Agent (Allocates Resources/Submits/Monitors Jobs), all interacting via a Canvas (Shared Information Dashboard/Context Preservation) and utilizing an HPC Cluster (High-Performance Computing Environment).
- This framework automates high-fidelity Density Functional Theory simulations, addressing challenges like parameter fine-tuning and systematic error handling, thereby reducing human intervention.
- DREAMS achieves L3-level automation in materials discovery, demonstrating expert-level accuracy in lattice constant calculations and complex problem-solving for adsorption puzzles.

---

[ADAPTIVE MULTI-AGENT REASONING VIA AUTOMATED WORKFLOW GENERATION](http://arxiv.org/abs/2507.14393v1)

- Nexus Architect: introduces an enhanced multi-agent system framework that autonomously generates and refines reasoning workflows from user prompts and examples, integrating User Prompt, Examples, Nexus Documentation, Task Decomposition & Planning, Reasoning Workflow Design, Supervisor Builder, Agent Builder, Tool Builder, Workflow Validation & Testing, Performance Assessment, Feedback, Iterative Prompt Refinement (IPR), Prompt Engineering, Validated Reasoning Graph, and Nexus Runtime Environment.
- This framework systematically decomposes complex inferential reasoning tasks, instantiates multi-agent architectures, and iteratively tunes agent system prompts to maximize performance and improve generalization capabilities using standard, non-reasoning LLMs.
- The framework leverages a feedback-driven prompt engineering mechanism to achieve automated reasoning, enabling robust and generalizable problem-solving without requiring specialized LLM training or fine-tuning.

---

[COGNIQ-H: A SOFT HIERARCHICAL REINFORCEMENT LEARNING PARADIGM FOR AUTOMATED DATA PREPARATION](http://arxiv.org/abs/2507.13710v1)

- CogniQ-H: introduces a soft hierarchical reinforcement learning paradigm for automated data preparation, with its Macro-Stage Layer (high-level planning) where an LLM (strategic prior generation) generates a strategic prior, a Micro-Stage Layer (evidence provision) where an LTR Model (immediate quality scoring) provides immediate quality scores and an RL Q-Model (long-term reward estimation) estimates long-term rewards, and a Synergistic Policy Layer (action integration) where a Synergistic Policy (final action selection) integrates these signals for action selection.
- This framework formulates action selection as a Bayesian inference problem, allowing it to balance high-level strategic guidance from the LLM with adaptive, evidence-based decision-making from the LTR model and RL Q-model.
- The approach achieves improved pipeline quality and faster convergence by avoiding the rigid commitments of traditional hard hierarchical RL, enabling robust and efficient discovery of optimal data preparation pipelines.

---

[VizGenie: Toward Self-Refining, Domain-Aware Workflows for Next-Generation Scientific Visualization](http://arxiv.org/abs/2507.21124v1)

- VizGenie: introduces a self-improving, agentic framework for scientific visualization, integrating Agent Orchestration (coordinates workflow), Tools (collection of functionalities), User Interface (natural language queries), Retrieval Augmented Generation (provides context-driven responses), Visual Question Answering (interprets image-based queries), and Visualization output (visualizations, textual annotation), where it orchestrates domain-specific and dynamically generated modules to advance scientific visualization.
- The framework leverages LLMs for dynamic module generation and refinement, image-based analysis via fine-tuned vision models for VQA, and RAG for contextual understanding, significantly reducing cognitive overhead for iterative visualization tasks.
- It continuously enhances its capabilities through a structured process of module generation, rigorous validation, and systematic integration, establishing a sustainable and evolving visualization practice.

---

#### 17th July 2025

[A Survey of Context Engineering for Large Language Models](http://arxiv.org/abs/2507.13334v1)

- Context Engineering: introduces a formal discipline for systematic optimization of information payloads for LLMs, with foundational components for context retrieval, processing, and management, and system implementations including RAG, memory systems, tool-integrated reasoning, and multi-agent systems.
- The paper provides a comprehensive taxonomy classifying techniques into foundational components for context generation, processing, and management, and sophisticated system implementations for real-world applications.
- The survey identifies a critical research gap where LLMs excel at understanding complex contexts but show limitations in generating equally sophisticated, long-form outputs, highlighting a key priority for future research.

---

[Change of Thought: Adaptive Test-Time Computation](https://arxiv.org/abs/2507.13569)

- SELF-Transformer: introduces a novel architecture that augments self-attention with Fixed-Point Iteration (FPI) to enable latent alignment refinement, where it iteratively updates attention weights to a fixed point, scaling test-time computation with input difficulty.
- This framework achieves deeper contextual reasoning without additional parameters by leveraging FPI universally across all layers, improving latent representations without token-level autoregression.
- The approach employs dynamic parameter reuse and implicit differentiation for efficient gradient computation, ensuring scalability and stability while adapting to input complexity.

---


[Prompt Injection 2.0: Hybrid AI Threats](http://arxiv.org/abs/2507.13169v1)

- Layered Defense Architecture: introduces a robust defense against hybrid AI threats, combining Preamble's trusted/untrusted classification, CaMeL's architectural isolation, Spotlighting, and traditional controls.
- This architecture addresses prompt injection attacks by distinguishing trusted instructions from untrusted inputs, isolating control and data flows, explicitly marking untrusted content, and leveraging existing security measures.
- The paper details how these components work together to provide a scalable and comprehensive defense posture for LLM-integrated systems in complex, real-world environments.

---

[SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models](http://arxiv.org/abs/2507.13152v1)

- SE-VLN (Self-Evolving Vision-Language Navigation Framework): introduces a training-free VLN framework driven by MLLMs, encompassing a hierarchical memory module, a retrieval-augmented thought-based reasoning module, and a reflection module, where it endows VLN agents with the ability to continuously evolve during testing by simulating natural agent evolution processes.
- The hierarchical memory module, comprising an experience repository and a verbal topological map, enables the agent to retrieve contextual memory and past similar experiences, crucial for enhancing navigation performance.
- The framework's reflection module, with its outcome evaluator and experience corrector, facilitates continuous learning by analyzing task evaluation results and updating the experience repository with corrected decisions, promoting self-evolution.

---

[RIDAS: A Multi-Agent Framework for AI-RAN with Representation- and Intention-Driven Agents](http://arxiv.org/abs/2507.13140v1)

- RIDAS: introduces a multi-agent framework for AI-RAN that unifies low-level representation control with high-level intent interpretation via its RDA and IDA components, where RDAs encode messages and control quality/rate, and IDA maps user intents to RDA configurations and manages resource allocation using an LLM, memory, and a two-stage planning pathway.
- The framework addresses the gap between high-level user intents and low-level, parameterized configurations required for optimal AI-RAN performance by enabling efficient bandwidth allocation and QoS satisfaction.
- RIDAS dynamically adjusts control parameters based on network conditions and user QoS requirements, achieving near-optimal performance in transmission rate and task performance demands.

---

[Intelligent Virtual Sonographer (IVS): Enhancing Physician-Robot-Patient Communication](http://arxiv.org/abs/2507.13052v1)

- IVS (Intelligent Virtual Sonographer): introduces a dual-LLM-driven embodied conversational agent that facilitates real-time, multidirectional communication between physicians, a robotic ultrasound system, and patients in an Extended Reality environment.
- The system enhances efficiency, clarity, and accessibility of robotic ultrasound acquisition by translating physician commands into robotic actions and relaying system updates and empathetic explanations to patients.
- It leverages two independent LLM instances for parallel physician- and patient-facing dialogues, integrating speech-to-text, text-to-speech, and robotic control for seamless interaction.

---

[MAD-SPEAR: A Conformity-Driven Prompt Injection Attack on Multi-Agent Debate Systems](http://arxiv.org/abs/2507.13038v1)

- MAD-SPEAR: introduces a conformity-driven prompt injection attack, with Attacker, Injected Data, Targeted Agents, Sybil Agent Simulation, Conformity Exploitation, Misinformation Propagation, Confidence Level Manipulation, Output Format Replication, and Communication Attack Integration, designed to compromise Multi-Agent Debate (MAD) systems by manipulating a small subset of LLM agents to propagate misinformation and degrade consensus quality.
- The attack exploits LLMs' inherent conformity tendencies and can be combined with communication attacks to amplify its impact, significantly impairing task-solving accuracy and scalability.
- The paper also proposes a formal definition of MAD fault-tolerance and a comprehensive evaluation framework, highlighting the urgent need for improved security in MAD system designs.

---

[MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](http://arxiv.org/abs/2507.12806v1)

- MCPEval (Model Context Protocol-based framework): introduces an open-source framework that automates end-to-end task generation and deep evaluation of LLM agents across diverse domains, including MCP Server, MCP Client (Agent), Task-LLM, LLM Judger, Tool Call Evaluation, Ground Truth Trajectory, and Auto Report Generation.
- The framework standardizes metrics, seamlessly integrates with native agent tools, and eliminates manual effort in building evaluation pipelines, providing actionable feedback for optimizing LLM agent implementations.
- MCPEval's automated workflow includes task generation, verification, and model evaluation, leveraging synthetic data and iterative refinement to ensure high-quality tasks and comprehensive analysis of agent behavior.


---

[A Systematic Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](http://arxiv.org/abs/2507.12774v1)

- Unified Taxonomy for EHR Modeling: introduces a comprehensive survey of Electronic Health Record (EHR) modeling, categorizing methods across data-centric approaches, neural architecture design, learning-focused strategies, multimodal learning, and LLM-based modeling systems, where it provides a structured roadmap for advancing AI-driven EHR modeling and clinical decision support.
- This survey systematically organizes recent advancements in deep learning and LLMs for EHRs, highlighting emerging trends like foundation models and LLM-driven clinical agents.
- It discusses open challenges in benchmarking, explainability, clinical alignment, and generalization across diverse clinical settings, aiming to promote reproducibility and accessibility for new researchers.

---

[Humans learn to prefer trustworthy AI over human partners](http://arxiv.org/abs/2507.13524v1)

- Partner Selection Game: introduces a communication-based partner selection game in a triadic setting where human selectors choose between human and LLM-powered bot candidates, examining partner selection dynamics and human adaptation under AI competition.
- The framework utilizes LLMs (specifically OpenAI's GPT-4o) to simulate bot candidates, and employs computational models like the Rescorla-Wagner algorithm to analyze human selectors' belief updating and decision-making.
- The study investigates the impact of identity transparency on partner selection, showing how it influences human learning about bot and human behavior and affects competitive outcomes in hybrid human-AI societies.

---

[GraphTrafficGPT: Enhancing Traffic Management through Graph-Based AI Agent Coordination](http://arxiv.org/abs/2507.13511v1)

- GraphTrafficGPT: introduces a novel graph-based architecture that fundamentally redesigns task coordination for LLM-driven traffic applications, utilizing an Input Processing Module (decomposes user queries), Dependency Graph Generator (builds task graph), Brain Agent (central task coordinator), Specialized Agents (domain-specific task handlers), Multi-Agent Communication Protocol (MCP) (agent communication, synchronization), Tool Box (traffic foundation models), and Response Integration Module (combines agent outputs) to enable efficient parallel execution and dynamic resource allocation.
- The system represents tasks and their dependencies as nodes and edges in a directed graph, allowing for concurrent multi-query processing and significant reductions in token consumption and response latency compared to chain-based approaches.
- This architecture enhances scalability and efficiency for complex, real-world traffic management scenarios by orchestrating a network of specialized agents for data retrieval, analysis, visualization, and simulation.

---

[Apple Intelligence Foundation Language Models Tech Report 2025](https://arxiv.org/abs/2507.13575)

- AFM (Apple Foundation Models): introduces two multilingual, multimodal foundation language models, an On-Device Model (compact LLM) and a Server Model (scalable LLM), detailing their architecture including KV Cache Sharing (on-device memory optimization) and Parallel Track Mixture-of-Experts (PT-MoE) (server sparse architecture), multimodal capabilities via a Vision Encoder (visual feature extraction), training methodologies like Supervised Fine-Tuning (SFT) (model refinement) and Reinforcement Learning from Human Feedback (RLHF) (alignment training), inference optimizations such as Quantization Aware Training (QAT) (on-device compression), Adaptive Scalable Texture Compression (ASTC) (server compression), and Low-Rank Adaptation (LoRA) Adapters (quality recovery), all integrated within a Foundation Models Framework (developer access) offering Guided Generation (constrained output), Tool Calling (external tool integration), and LanguageModelSession (context management), while adhering to Responsible AI principles (ethical guidelines).
- The paper highlights architectural innovations like PT-MoE and KV-cache sharing for efficiency, alongside comprehensive data pipelines and advanced fine-tuning techniques to enhance model capabilities and privacy.
- The models support multilingual and multimodal inputs, improve tool-use and reasoning, and are accessible to developers via a Swift-centric framework for integrating generative AI features into Apple applications.

---

[Change of Thought: Adaptive Test-Time Computation](https://arxiv.org/abs/2507.13569)

- SELF-Transformer: introduces a novel architecture that augments self-attention with Fixed-Point Iteration (FPI) to enable latent alignment refinement, where it iteratively updates attention weights to a fixed point, scaling test-time computation with input difficulty.
- This framework achieves deeper contextual reasoning without additional parameters by leveraging FPI universally across all layers, improving latent representations without token-level autoregression.
- The approach employs dynamic parameter reuse and implicit differentiation for efficient gradient computation, ensuring scalability and stability while adapting to input complexity.

---

[Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents](http://arxiv.org/abs/2507.13491v1)

- Model-free Reinforcement Learning for Model-based Control: introduces a paradigm for developing safe, interpretable, and sample-efficient agents by adapting model-based agents, which include an internal model, a planning module, and a policy/Q-function, using model-free RL algorithms.
- This approach leverages prior system knowledge embedded in the internal models to enhance sample efficiency and interpretability, with model-free RL addressing potential model inaccuracies.
- The paper categorizes policy learning methods for these agents into derivative-free (e.g., Bayesian Optimization) and gradient-based (e.g., Policy Search RL) approaches, highlighting their distinct advantages and challenges.

---

[iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development](http://arxiv.org/abs/2507.13081v1)

- iREDEV (Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development): introduces a knowledge-driven multi-agent framework for intelligent requirements development, with six knowledge-driven agents, an artifact pool, and a human-in-the-loop mechanism, designed to automate and enhance the software requirements development process.
- The framework integrates human expert knowledge into agent design and utilizes an event-driven communication mechanism via a shared artifact pool to support dynamic and collaborative requirements development tasks.
- The system employs LLMs as underlying intelligence for its agents and incorporates a human-in-the-loop mechanism to ensure generated artifacts align with stakeholder expectations and improve reliability.

---

[Non-differentiable Reward Optimization for Diffusion-based Autonomous Motion Planning](http://arxiv.org/abs/2507.12977v1)

- Non-differentiable Reward Optimization for Diffusion-based Autonomous Motion Planning: introduces a reinforcement learning-based training scheme that optimizes diffusion motion planning models using non-differentiable objectives like collision and goal achievement, facilitated by a dynamic thresholding algorithm to shape dense reward signals.
- This approach enables direct optimization of critical autonomy objectives, outperforming models trained with differentiable objectives on pedestrian datasets.
- The method addresses sparse reward problems in autonomous motion planning by adaptively adjusting reward sparsity, ensuring stable learning and improved performance.

---

[MACHINE-READABLE ADS: ACCESSIBILITY AND BEHAVIORAL PATTERNS OF AI WEB AGENTS INTERACTING WITH ONLINE ADVERTISEMENTS](http://arxiv.org/abs/2507.12844v1)

- AI Web Agent Advertising Interaction Evaluation: introduces a controlled experimental setup to assess the accessibility and behavioral patterns of AI web agents interacting with online advertisements, utilizing the Browser Use framework, GPT-4o, Claude 3.7 Sonnet, Gemini 2.0 Flash, OpenAI Operator, a faithful TT.com clone, and an experimental protocol.
- The evaluation framework investigates how various LLM-powered agents perceive, interact with, and responsibly behave in an ad-heavy online environment, considering semantic markup, dynamic content, and ethical implications.
- Key findings reveal agents' satisficing behavior, their preference for explicit DOM elements over purely visual cues, and model-specific risk profiles concerning financial commitments and consent handling.

---

[Intent-Based Network for RAN Management with Large Language Models](http://arxiv.org/abs/2507.14230v1)

- IBNS (Intent-Based Network System): introduces a novel automation approach for RAN management, integrating LLMs within an agentic architecture that includes a Strategist Agent (translates intent, generates strategy), History Analyzer Agent (analyzes past strategies, provides insights), and interacts with a Radio Access Network (simulated network environment) via O-RAN O1 interface (standard RAN communication).
- The system leverages a structured prompt engineering technique for LLM-driven intent translation, dynamically optimizing RAN parameters for energy efficiency through a closed-loop mechanism.
- This approach enables robust resource management by adapting strategies based on real-time feedback, showcasing the potential of LLM-orchestrated agentic systems for autonomous network operation.

---

[Public Evaluation on Potential Social Impacts of Fully Autonomous Cybernetic Avatars for Physical Support in Daily-Life Environments: Large-Scale Demonstration and Survey at Avatar Land](http://arxiv.org/abs/2507.12741v1)

- The demonstrated system: introduces a framework for fully autonomous Cybernetic Avatars (CAs) to provide physical support in daily-life environments, integrating User Instruction Input, Speech Recognition (Whisper), Posture Detection (MediaPipe), Exophora Resolution Model, LLM (GPT-4o), Multi-Robot Planning, Fetch Robotics Fetch, Preferred Robotics Kachaka, Containerized SDE, ROS, and Extended Reality Visualization (Meta Quest 3 XR headset) to enable object retrieval tasks.
- This system was publicly evaluated at Avatar Land, assessing user perceptions and social impacts of autonomous CAs performing daily object retrieval in a replicated home environment.
- The evaluation revealed public interest in CAs for daily support but highlighted concerns regarding task execution reliability, emphasizing the need for improved robot performance.

---

[LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data](http://arxiv.org/abs/2507.13413v1)

- LightAutoDS-Tab: introduces a multi-AutoML agentic system for tabular data, combining LLM-based code generation with multiple AutoML tools, and includes interactor, planner, generator, validator, improver, AutoML, executor, interpreter, and result aggregation components.
- This framework enhances existing AutoML tools by integrating them with an LLM agent for flexible, data-aware code generation and configuration of ML pipelines, addressing limitations of fixed-pipeline and LLM-only approaches.
- It streamlines end-to-end ML pipeline development, offering increased automation, reduced development time, and improved interpretability and quality for data science tasks.

---

#### 16th July 2025


[AIME: TOWARDS FULLY-AUTONOMOUS MULTI-AGENT FRAMEWORK](http://arxiv.org/abs/2507.11988v1)

- Aime: introduces a novel multi-agent framework with a Dynamic Planner (orchestrates tasks), Actor Factory (instantiates actors), Dynamic Actor (executes subtasks), and Progress Management Module (manages state), designed for dynamic, reactive planning and execution.
- The framework replaces conventional static workflows with a fluid, adaptive architecture, continuously refining strategy based on real-time execution feedback and enabling on-demand agent specialization.
- Aime addresses critical limitations of rigid plan execution, static agent capabilities, and inefficient communication in multi-agent systems, establishing a more resilient and effective foundation for collaboration.

---


[Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data](http://arxiv.org/abs/2507.12425v1)

- Advanced RAG Framework: introduces an advanced Retrieval-Augmented Generation framework designed to effectively retrieve and generate responses from heterogeneous enterprise data, including text, structured documents, and tabular records, by combining optimized document preprocessing, hybrid retrieval strategies, advanced ranking mechanisms, and feedback-driven refinement.
- The framework employs semantic and table-aware chunking, hybrid retrieval (dense embeddings and BM25), metadata-driven filtering, and cross-encoder reranking to enhance relevance and contextual alignment.
- It further integrates interactive query refinement using LLMs and a human-in-the-loop feedback mechanism with conversational memory to improve system adaptability and response quality over time.

---


[Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate](http://arxiv.org/abs/2507.12370v1)

- Multi-Agent Debate Framework: introduces a multi-agent debate framework, with User Request (Input instruction), Multi-Agent Debate Framework (Core system), LLM Agents (Processing units), Leader Agent (Proposes initial solution), Follower Agents (Evaluate proposals), Debate Rounds (Iterative process), Consensus Mechanism (Decision-making), and Clarification Question Generation (Output question), designed to enhance LLM detection and resolution of ambiguity in user requests through structured debate.
- This framework employs multiple LLM agents (Llama3-8B, Gemma2-9B, Mistral-7B) in a leader-follower protocol to collaboratively analyze ambiguous instructions and generate clarifying questions.
- The debate mechanism improves ambiguity detection and resolution, particularly for complex ambiguities, by leveraging diverse perspectives and iterative refinement, though its utility is model-dependent.

---

[GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities](http://arxiv.org/abs/2507.12367v1)

- GitChameleon: introduces, "a novel Python-based benchmark", with all Inputs (problem context, requirements), Candidate Solution Generation (LLM/AI agent), Candidate Solution (generated code), Validation (executes tests), Hidden Tests (success evaluation), Visible Tests (self-debugging feedback), Self-Debug (iterative refinement), and Benchmark Success (evaluation outcome), where GitChameleon provides an execution-based benchmark for evaluating AI code generation against Python library version incompatibilities.
- It comprises 328 Python code completion problems, each conditioned on specific library versions and accompanied by executable unit tests.
- The benchmark rigorously evaluates LLMs, LLM-powered agents, code assistants, and RAG systems for version-conditioned code generation, highlighting limitations in handling library versioning.

---

[Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot](http://arxiv.org/abs/2507.12273v1)

- Alter-Ego (Autonomous Museum Guide Robot): introduces an autonomous museum guide robot that integrates LLM-powered dialogue with advanced navigation capabilities, enabling real-time, context-aware Q&A and seamless navigation.
- The system leverages components like ROS Hector SLAM, YOLOv10-n, Google's Speech-to-Text API, and OpenAI's GPT-4o mini for robust operation.
- It dynamically adapts tours based on user requests and location, enhancing visitor engagement and knowledge acquisition in cultural settings.

---

[Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes](http://arxiv.org/abs/2507.12261v1)

- Infherno: introduces an end-to-end agent-based framework for FHIR resource synthesis, with LLM Agent (Core processing unit), Prompt Structure (Guides agent behavior), Code Search (Queries external terminologies), Python Executor (Executes generated code), fhir.resources Python Module (Ensures FHIR compliance), Code Loop (Iterative refinement process), FHIR Bundle (Aggregates output resources), and Front End (User interface), where it transforms unstructured clinical notes into structured, semantically accurate FHIR representations.
- The framework leverages LLM agents with tool-use capabilities and code execution to address challenges in generalizability and structural conformity in clinical data extraction.
- It supports clinical data integration and interoperability by adhering to the FHIR document schema and performing well against human baselines in predicting FHIR resources.

---

[Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited](http://arxiv.org/abs/2507.12059v1)

- LLM Cardinal Direction Reasoning Evaluation: introduces a comprehensive methodology for assessing LLMs' spatial reasoning, encompassing automated benchmark dataset generation (creates diverse questions), an LLM testing system (executes queries), and a performance analysis module (interprets results).
- The benchmark includes 5760 questions derived from six templates, varying locomotion types, person forms, and cardinal/intercardinal directions to rigorously test LLM robustness.
- The evaluation reveals that even state-of-the-art LLMs struggle with reliable cardinal direction reasoning, particularly with intercardinal directions and generalisation across different question parameters.

---


[Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness](http://arxiv.org/abs/2507.11979v1)

- LLM Agent Simulation Framework: introduces a two-stage experimental workflow to investigate value similarity's influence on trust and interpersonal closeness between LLM agents, including value controllability assessment and mutual evaluation.
- The framework first assesses LLM value controllability using prompts and PVQ, then simulates dialogues between value-assigned LLM agents, evaluating their mutual trust and interpersonal closeness.
- This simulation demonstrates that higher value similarity leads to greater mutual trust and closeness, validating social science theories within an artificial society.

---

[Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking biomarker](http://arxiv.org/abs/2507.11972v1)

- Graph Representations for Reading Comprehension Analysis Framework: introduces a method that leverages LLM-generated graph representations and eye-tracking biomarkers to analyze reading comprehension, comparing human and LLM understanding of text.
- The framework converts sentences into knowledge graphs with nodes representing entities and edges representing relationships, then uses LLMs to label important graph components.
- It integrates human eye-tracking data and graph-theoretic metrics to validate LLM-derived importance labels, offering insights into cognitive processes.

---

[Extremal Testing for Network Software using LLMs](http://arxiv.org/abs/2507.11898v1)

- Extremal Testing Methodology: introduces a novel approach for automating extremal testing of network software, leveraging LLMs for constraint generation and invalid test case creation, followed by execution on target software and differential testing for bug identification.
- This two-step, chain-of-thought prompting strategy, where LLMs first define validity constraints and then generate violating tests, proves more effective than one-stage prompting.
- The methodology successfully uncovered new bugs in DNS, HTTP, and BGP implementations, demonstrating its utility as a complement to existing software testing techniques like symbolic execution and fuzz testing.

---

[THE EVOLVING ROLE OF LARGE LANGUAGE MODELS IN SCIENTIFIC INNOVATION: EVALUATOR, COLLABORATOR, AND SCIENTIST](http://arxiv.org/abs/2507.11810v1)

- Pyramidal Framework: introduces a comprehensive taxonomy for LLM roles in scientific innovation, encompassing Evaluator (low-autonomy knowledge synthesizer), Collaborator (mid-autonomy ideation engine), and Scientist (high-autonomy discovery platform) components.
- This framework distinguishes LLMs' contributions to structured scientific research and open-ended scientific discovery, clarifying capability boundaries, evaluation criteria, and human-AI interaction patterns at each level.
- The framework provides conceptual clarity, practical guidance, and theoretical foundations for future research in increasingly autonomous AI-driven science.

---

[NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting](http://arxiv.org/abs/2507.12621v1)

- NLI4VolVis: introduces an interactive system that enables users to explore, query, and edit volumetric scenes using natural language, integrating multi-view semantic segmentation, vision-language models, editable 3D Gaussian Splatting (iVR-GS), a multi-agent LLM architecture with core and function-calling agents, memory, function-calling tools for querying, editing, question answering, view selection, and 2D stylization, a Visualization-Perception-Action (VPA) loop, and an interactive user interface, where it allows intuitive exploration and editing of volumetric datasets through open-vocabulary querying, real-time scene editing, and stylization.
- The system leverages LLM multi-agents equipped with extensive function-calling tools to interpret user intents and execute visualization tasks, enhancing accessibility and usability in volumetric data exploration.
- NLI4VolVis unifies editable volumetric representations, open-vocabulary scene understanding, and collaborative multi-agent LLMs to support intuitive, natural language-based volume visualization.

---

[Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs](http://arxiv.org/abs/2507.12110v1)

- TPE-MARL (Topology Enhanced Multi-Agent Reinforcement Learning): introduces a novel multi-agent reinforcement learning method for cooperative decision-making of Connected and Autonomous Vehicles (CAVs) by designing a game topology tensor and integrating it into a QMIX-based framework.
- The framework leverages a TopologyNet to compress high-dimensional traffic state information into a structured game topology tensor, enhancing learning efficiency and coordination performance in complex vehicular scenarios.
- It incorporates visit counts and agent mutual information into the reward function, enabling a balance between exploration and exploitation for improved traffic efficiency, safety, and decision smoothness.

---

[Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics](http://arxiv.org/abs/2507.12083v1)

- FiM (Foresight in Motion): introduces a "First Reasoning, Then Forecasting" strategy for trajectory prediction by integrating a reward-driven intention reasoner and a hierarchical DETR-like decoder.
- The framework employs a query-centric Inverse Reinforcement Learning (QIRL) module to infer reward distributions and perform policy rollouts, providing intention-informed priors for trajectory generation.
- It further utilizes a Bi-Mamba-enhanced decoder to capture sequential dependencies and an auxiliary Occupancy Grid Map (OGM) prediction head to improve feature fusion and prediction confidence.

---

[Understanding visual attention beehind bee-inspired UAV navigation](http://arxiv.org/abs/2507.11992v1)

- PPO (Proximal Policy Optimization): introduces a Deep Reinforcement Learning framework for bee-inspired UAV navigation, utilizing a Policy Network composed of a CNN, MaxPool layers, a Flatten layer, Linear layers, and an Output layer to process optic flow observations for obstacle avoidance.
- The framework trains agents in an AirSim simulation environment to navigate cluttered tunnels using only optic flow as sensory input, aiming to replicate honeybee navigation behaviors.
- Explainable AI methods, specifically SHAP, are employed to analyze the attention patterns of trained agents, revealing that they focus on optic flow discontinuities and high-magnitude regions for decision-making.

---

[IANN-MPPI: Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral Approach for Autonomous Driving](http://arxiv.org/abs/2507.11940v1)

- IANN-MPPI (Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral): introduces a real-time, fully parallelizable, interaction-aware trajectory planning framework that integrates an MPPI Controller, a Neural Network Predictor, and a Spline-based Prior, enabling complex maneuvers by predicting surrounding agent reactions to sampled control sequences.
- The framework leverages the Neural Network Predictor to simulate diverse interaction outcomes based on ego vehicle candidate trajectories, while the Spline-based Prior enhances MPPI's sampling diversity for efficient lane-changing.
- This approach addresses challenges in dense traffic by enabling proactive nudging of surrounding vehicles and achieving successful merging maneuvers, demonstrating improved efficiency and safety compared to non-interactive baselines.

---

#### 15th July 2025

[How Many Instructions Can LLMs Follow At Once?](https://arxiv.org/abs/2507.11538)

- IFScale: introduces a benchmark to evaluate LLM instruction-following performance degradation as instruction density increases, with Term Vocabulary Construction (Builds keyword set), Prompt Construction (Generates model input), Retry Logic (Manages generation failures), Evaluation Module (Assesses instruction adherence), and Coherence Check (04-mini) (Judges report quality), where it measures how LLMs adhere to a growing number of keyword-inclusion instructions in business report generation.
- The benchmark evaluates 20 state-of-the-art LLMs, revealing distinct performance degradation patterns, primacy effects, and error types under high cognitive load.
- Insights from the evaluation inform the design of instruction-dense prompts and highlight performance-latency tradeoffs for real-world LLM applications.

---

[DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering](http://arxiv.org/abs/2507.11527v1)

- DrafterBench: introduces a comprehensive benchmark for evaluating LLM agents in civil engineering drawing revision, including Task Collection (summarizes real-world tasks), Tool Preparation (customizes functions/tools), Default Prompt (provides prompt framework), Evaluation Metric (assesses performance), and Dual Tools/Functions (records operation paths).
- The benchmark comprises 1920 tasks across 12 types, derived from real-world drawing files, designed to assess LLM capabilities in structured data understanding, function execution, instruction following, and critical reasoning.
- It utilizes dual tools to record ground operation paths for accurate performance grading and error analysis, providing insights for integrating LLMs into engineering applications.

---

[AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air](http://arxiv.org/abs/2507.11515v1)

- AirLLM: introduces a hierarchical diffusion policy framework for communication-aware LoRA adaptation, including Cloud LLM for fine-tuning, Edge LLM for inference, a Wireless Channel for parameter transmission, an Environment providing state, reward, and action, and a Hybrid Policy with PPO for coarse policy generation and Diffusion Policy for fine-grained refinement.
- The framework models rank configuration as a structured action vector, using a Proximal Policy Optimization (PPO) agent for coarse-grained decisions and Denoising Diffusion Implicit Models (DDIM) for high-resolution rank vector refinement.
- It aims to balance LLM fine-tuning performance with transmission costs by adaptively optimizing LoRA rank assignments based on wireless states and linguistic complexity.

---

[Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian](http://arxiv.org/abs/2507.11299v1)

- Dr.Copilot (Multi-Agent Large Language Model System): introduces a multi-agent LLM system designed to enhance doctor-patient communication quality in Romanian text-based telemedicine, including a Scorer Agent (evaluates responses), a Recommendation Agent (generates suggestions), and a Reconciliation Agent (simulates improvements).
- The system leverages DSPy (prompt optimization) for automatic prompt optimization and utilizes open-weight LLMs (underlying models) served by VLLM (model serving), providing real-time feedback to doctors.
- Dr.Copilot focuses on improving presentation quality rather than medical correctness, aiming to increase patient satisfaction and represents an early real-world deployment of LLMs in Romanian medical settings.

---

[Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems](http://arxiv.org/abs/2507.11277v1)

- AgentOps (AI AgentOps Automation Pipeline): introduces a comprehensive framework for observing, analyzing, optimizing, and automating agentic AI systems, encompassing behavior observation, metric collection, issue detection, root cause analysis, optimized recommendations, and runtime automation.
- The framework addresses challenges for developers, testers, SREs, and business users by taming uncertainty in LLM-powered agentic systems through automation and self-improvement.
- It provides a structured approach to manage dynamic, unpredictable agent behavior, ensuring safe, adaptive, and effective operation in enterprise contexts.

---

[An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling](http://arxiv.org/abs/2507.11272v1)

- MARAUS (Multi-Agent and Retrieval-Augmented University Admission System): introduces a real-world conversational AI platform for university admissions counseling, integrating a Multi-agent Coordinator (Classifies queries), Preprocessing Module (Cleans, normalizes data), Hybrid Retrieval Module (Combines semantic, keyword search), Logic Calculation Module (Performs domain-specific computations), Factual Database (Stores structured data), LLM-based Generation (Generates responses), and Post-processing Module (Formats, mitigates hallucination).
- The system employs specialized agents for information search, score calculation, recommendation, and general queries, leveraging hybrid RAG with semantic and keyword retrieval, re-ranking, and LLM-based generation to enhance accuracy and reduce hallucinations.
- Deployed in a real-world university setting, MARAUS processed over 6,000 user interactions, demonstrating significant improvements in accuracy and response times while operating cost-effectively.

---

[An Agentic Flow for Finite State Machine Extraction using Prompt Chaining](http://arxiv.org/abs/2507.11222v1)

- FlowFSM (An Agentic Flow for Finite State Machine Extraction using Prompt Chaining): introduces an agentic framework for FSM extraction from RFC documents, utilizing an RFC Documents Processing Pipeline, FSM Extraction using Prompt Chaining, AI Agents (CrewAI), an LLM Model, and a Rulebook.
- The framework systematically processes protocol specifications, identifies state transitions, and constructs structured rule-books by chaining agent outputs.
- This approach decomposes complex FSM extraction into modular, interpretable steps, enhancing transparency and robustness.

---

[Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding](http://arxiv.org/abs/2507.11198v1)

- Multi-Agent System (MAS): introduces a multi-agent framework for LLM-based deductive coding, including a Single-Agent Coding Module (individual annotation simulation), Dual-Agent Discussion Module (inter-agent discussion simulation), Consensus Agent Module (disagreement resolution, final coding), LLM Agents (perform coding tasks), Codebook (structured coding categories), Ollama API (LLM interaction interface), System Prompts (agent instruction, personality injection), and Post-processing Procedure (extracts, validates code annotations), to investigate how agent persona and temperature influence consensus and coding accuracy.
- The MAS emulates human qualitative coding workflows through structured agent discussions and consensus arbitration, evaluating six open-source LLMs with varying parameters and 18 experimental configurations.
- The study found that while temperature robustly delays consensus, and persona congruency has selective effects, MAS deliberation generally yields minimal accuracy gains over single-agent coding, except for specific conditions.

---

[SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks](http://arxiv.org/abs/2507.11059v1)

- SWE-MERA: introduces a dynamic benchmark for agenticly evaluating LLMs on software engineering tasks, utilizing a seven-stage pipeline including Repository Selection (selects GitHub repositories), PR-Issue Mapping Construction (maps pull requests to issues), Metadata Extraction and Filtering (downloads and filters metadata), Patch Extraction and Validation (generates and validates git diffs), Repository Build Validation (builds environment, runs tests), End-to-End Task Execution (executes tasks in Docker), and LLM-based Pipeline Evaluation (assesses task quality).
- The framework also integrates an Aider coding agent (automates scoring), a dynamic user leaderboard (displays evaluation results), Docker containers (provides controlled environment), the GitHub GraphQL API (collects data), the Hugging Face platform (hosts dataset), and an evaluation repository (receives submissions).
- SWE-MERA addresses data contamination and benchmark saturation by continuously updating its dataset with new, unseen issues, ensuring real-world relevance and fair evaluation for LLMs in software development.

---

[DS@GT at eRisk 2025: From prompts to predictions, benchmarking early depression detection with conversational agent based assessments and temporal attention models](http://arxiv.org/abs/2507.10958v1)

- Voting Classifier: introduces a system for early depression detection, with Raw Data, Pre-processing Pipeline, Feature Engineering, Feature Matrix, Voting Classifier, Random Forest Classifier, Stochastic Gradient Descent Classifier, and Gradient Boosting Classifier, where it combines diverse engineered features and multiple machine learning models for classification.
- This approach processes raw JSON user data through a comprehensive pre-processing pipeline to create a feature matrix, which is then fed into an ensemble of base models.
- The Voting Classifier employs a soft voting strategy to aggregate predictions from its base models, aiming for robust depression detection.


[General Modular Harness for LLM Agents in Multi-Turn Gaming Environments](http://arxiv.org/abs/2507.11633v1)

- General Modular Harness: introduces a modular design for LLM agents, with Perception Module (processes UI inputs), Memory Module (stores trajectories, reflects), Reasoning Module (integrates info, decides), and Adapter (interfaces with game), enabling a single LLM/VLM backbone to tackle diverse multi-turn gaming environments.
- This harness provides a unified workflow for analyzing how each module affects performance across dynamic interactive settings in games.
- Extensive experiments demonstrate consistent performance gains and reveal distinct module contributions, advancing general-purpose agent design.

---

[MR-LDM - The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](http://arxiv.org/abs/2507.12494v1)

- MR-LDM (Merge-Reactive Longitudinal Decision Model): introduces a game-theoretic framework that models merging and lag vehicle interactions using a game-theoretic formulation with defined action sets for both actors, payoff functions incorporating a usmht function, Predictive Time Headway (PTH) metric, and Ramp End Influence Terms, alongside bounded rationality (QRE), a decision window, and an MR-IDM dynamics model.
- This model explicitly generates discrete, decision-level behaviors for the lag actor, including yield behind, yield ahead, block, and do nothing, which are then executed using MR-IDM dynamics.
- The framework enhances behavioral realism and controllability in traffic actor models, supporting robust evaluation of merging trajectory planners in interactive traffic scenarios.

---

[VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization](http://arxiv.org/abs/2507.11653v1)

- VISTA (View-Invariant Segmentation-Based Tracking for Frame Alignment): introduces a monocular global localization framework that combines an object-based segmentation and tracking pipeline with a submap correspondence search, including Image Input, Image Auto-segmentation, Video Tracking, Visual Inertial Odometry (VIO), Structure from Motion (SfM), Environment Map (Mi), Bounding Box Submap Generation, Geometric Data Association, and Relative Rotation and Translation Estimation.
- The framework generates sparse, viewpoint-invariant 3D environment representations and aligns vehicle reference frames by exploiting geometric consistencies between environment maps.
- It achieves robust localization across diverse camera viewpoints and seasonal changes without domain-specific training, maintaining a compact object-based map for real-time performance.

---

[Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander](http://arxiv.org/abs/2507.11079v1)

- Vision-Language Model-Based Commander: introduces a framework for multi-UGV confrontation, integrating a Perception VLM (scene understanding) and a Decision LLM (strategic planning), with an Expert System (training supervision) for semantic alignment.
- The framework reconstructs perception-to-decision as a language-based cognitive process, achieving unified perception and decision within a shared semantic space.
- This approach, validated through simulations, demonstrates strong adaptability, interpretability, and a win rate over 80% compared to baseline models.

---

#### 14th July 2025

[Logic-layer Prompt Control Injection (LPCI): A Novel Security Vulnerability Class in Agentic Systems](http://arxiv.org/abs/2507.10457v1)

- LPCI (Logic-layer Prompt Control Injection): introduces a novel security vulnerability class targeting LLM agent architecture, with Prompt Ingestion Layer (captures user inputs), Memory Context Handler (manages memory states), Logic Execution Engine (interprets prompts, executes logic), Tool/Plugin Interface (facilitates external actions), and Output Dispatcher (manages output delivery), exploiting persistent memory and logic execution layers.
- LPCI attacks embed encoded, delayed, and conditionally triggered payloads in memory or vector stores, bypassing conventional input filters and triggering unauthorized behavior across sessions.
- The paper demonstrates LPCI feasibility across multiple LLM platforms and proposes runtime security controls to mitigate these vulnerabilities.

---

[Prompt-Informed Reinforcement Learning for Visual Coverage Path Planning](http://arxiv.org/abs/2507.10284v1)

- PIRL (Prompt-Informed Reinforcement Learning): introduces a novel approach for visual coverage path planning using a UAV, integrating an LLM (GPT-3.5) and a PPO RL policy with components including Current UAV State, Structured LLM Prompt with UAV State, LLM Recommendation for Next UAV State, PARE, Action-based Reward for PPO, PIRL-based Reward for PPO, PPO Action, PPO RL policy, and Next UAV State.
- The framework leverages the LLM's zero-shot reasoning and in-context learning to dynamically shape the reward function for the PPO agent via the PARE module.
- PIRL guides the RL agent's position and camera adjustments for optimal visual coverage by combining standard RL rewards with LLM-based semantic feedback.

---

[Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence](http://arxiv.org/abs/2507.10281v1)

- LLM-based Table Agents: introduces a survey focusing on automating table-centric workflows by integrating preprocessing, reasoning, and domain adaptation, with Table Structure Understanding (Formatting tables), Table and Query Semantic Understanding (Handling noise and ambiguity), Table Retrieval and Compression (Compressing or selecting tables), Executable Reasoning with Traceability (Generating verifiable steps), and Cross-Domain Generalization (Adapting to new domains).
- The paper identifies these five core capabilities as essential for LLM-based agents to handle real-world table tasks involving noise, structural heterogeneity, and semantic complexity.
- The survey reviews current methodologies for these capabilities and outlines future research directions for developing more robust, efficient, and generalizable agents.

---

[Cultural Bias in Large Language Models: Evaluating AI Agents through Moral Questionnaires](http://arxiv.org/abs/2507.10073v1)

- Cultural Moral Framework Evaluation: evaluates cultural bias in LLMs using the MFQ-2 across cultural contexts, employing cultural persona prompting and synthetic population generation, comparing results to human baseline data using analysis methods.
- The study finds that current LLMs tend to homogenize moral diversity across cultures, failing to accurately represent nuanced, culturally-specific moral intuitions.
- The findings highlight limitations in current AI alignment approaches and the use of LLMs as synthetic populations in social science research.

---

[The Man Behind the Sound: Demystifying Audio Private Attribute Profiling via Multimodal Large Language Model Agents](http://arxiv.org/abs/2507.10016v1)

- Gifts (hybrid multi-agent framework): introduces a framework to profile sensitive personal attributes from audio data using its LLM agent (Guides ALM, scrutinizes, consolidates), ALM agent (Infers attributes, answers questions), Guidance (LLM instructs ALM), Inference (ALM infers attributes), Forensics (LLM questions, ALM answers), Scrutinization (LLM evaluates ALM inference), and Consolidation (LLM aggregates results) components.
- The framework leverages the strengths of LLMs and Audio-Language Models (ALMs) through a multi-phase process to enhance attribute inference capabilities from audio.
- Gifts significantly outperforms baseline approaches in inferring sensitive attributes from audio, highlighting a privacy risk and providing a framework for further research and defense strategies.

---

[LLM-Guided Agentic Object Detection for Open-World Understanding](http://arxiv.org/abs/2507.10844v1)

- LAOD (LLM-Guided Agentic Object Detection): introduces an LLM-guided agentic object detection framework that autonomously generates scene-specific object names using an LLM (Large Language Model) from an input image, which are then passed as generated labels to an OVOD (Open-Vocabulary Object Detector) for object localization, producing detected objects.
- This framework enables fully label-free, zero-shot detection, adapting its perception goals dynamically without manual prompt engineering or predefined vocabularies.
- The method enhances autonomy and adaptability for open-world understanding by tightly coupling language-based reasoning with visual grounding.

---

[Semantic Context for Tool Orchestration](http://arxiv.org/abs/2507.10820v1)

- SC (Semantic Context): introduces a novel approach for robust tool orchestration, leveraging descriptive tool information to enhance learning efficiency and adaptation in dynamic action spaces.
- The paper theoretically and empirically validates SC's benefits through the SC-LinUCB algorithm and demonstrates its critical role in dynamic adaptation for LLMs.
- Furthermore, the FiReAct pipeline, which utilizes SC for semantic filtering and LLM-based reasoning, enables practical tool orchestration at scale with over 10,000 tools.

---

[Warehouse Spatial Question Answering with LLM Agent 1st Place Solution of the 9th AI City Challenge Track 3](http://arxiv.org/abs/2507.10778v1)

- LLM Agent System: introduces a data-efficient approach for warehouse spatial question answering, integrating a Spatial Reasoning LLM, Light-weight Perception Models, Spatial Calculation Functions, an API Tools Interface, Multi-turn Execution, a Rule-based Parser, and Structured Message History.
- The system leverages a reasoning LLM (Gemini 2.5-Flash) with function-calling capabilities to conduct complex spatial reasoning and interact with various tools for object retrieval, counting, and distance estimation.
- This approach achieved first place in the 2025 AI City Challenge Physical AI Spatial Intelligence Warehouse benchmark, demonstrating high accuracy and efficiency in complex indoor scenarios.

---

[Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health](http://arxiv.org/abs/2507.10695v1)

- Harm-Reduction Framework (conceptual recommendations for LLM-enabled chatbots): introduces a conceptual framework to safeguard user mental health disclosures with general-purpose LLM-enabled chatbots, including contextual nudges & just-in-time warnings (Dynamic S&P responses), strong default protections and ephemeral storage (Default privacy settings), and targeted oversight and audits (Third-party data review), aiming to address user security and privacy concerns.
- The paper identifies critical user misconceptions and a general lack of risk awareness regarding data handling, privacy, and regulatory protections when using LLMs for mental health support.
- It highlights the concept of 'intangible vulnerability,' where emotional disclosures are undervalued compared to tangible data, necessitating architectural safeguards and legislative frameworks.

---

[From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents](http://arxiv.org/abs/2507.10644v1)

- Functional Taxonomy for Web of Agents Architectures: introduces a comprehensive evolutionary overview of the Web of Agents, with Semantic Foundation (establishes shared understanding), Communication Paradigm (classifies message exchange style), Locus of Intelligence (identifies core reasoning location), and Discovery Mechanism (defines how agents find each other) components, providing a unified analytical lens for comparing agent architectures across generations.
- This taxonomy reveals a fundamental paradigm shift in the 'locus of intelligence' from external data or platforms to being embedded within the agent's core LLM, enabling scalable and adaptive WoA systems.
- The paper highlights that while new protocols like MCP and A2A are essential, they are insufficient for building a robust, open, and trustworthy ecosystem, mapping out a new agenda focused on socio-technical challenges like decentralized identity, economic models, security, and governance.

---


[Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats](http://arxiv.org/abs/2507.10621v1)

- LLM-based Multi-Agent Systems (MAS) for Cybersecurity: introduces a framework for designing adaptive cyber systems by integrating game theory with LLM-driven agentic AI, featuring Chain, Star, Parallel, Feedback, and Hybrid workflows, each composed of LLM Agents.
- This framework leverages LLMs as reasoning engines and generative policy mechanisms to overcome limitations of classical game theory, enabling dynamic, context-aware interactions among agents.
- MAS workflows enhance robustness and resilience in cybersecurity by supporting architectural redundancy, inter-agent verification, and adaptive learning in adversarial environments.

---



[Architecting Human-AI Cocreation for Technical Services – Interaction Modes and Contingency Factors](http://arxiv.org/abs/2507.14034v1)

- Six-Mode Taxonomy of Human-Agent Collaboration: introduces a comprehensive framework for designing human-agent systems, detailing six distinct interaction modes: Human-Augmentation-Mode (HAM), Human-in-Command (HIC), Human-in-the-Process (HITP), Human-in-the-Loop (HITL), Human-on-the-Loop (HOTL), and Human-Out-of-the-Loop (HOOTL).
- The framework maps these modes to a standard process flow, illustrating the division of labor between human and AI agents across tasks like data gathering, solution formulation, and approval.
- It provides actionable design guidance by connecting each mode to key contingency factors such as task complexity, operational risk, and system reliability, aiding practitioners in navigating automation-control trade-offs.

---

[Semantic Segmentation based Scene Understanding in Autonomous Vehicles](http://arxiv.org/abs/2507.14303v1)

- FPN-EfficientNet: introduces a novel compound model for semantic segmentation in autonomous vehicles, utilizing Feature Pyramid Networks with an EfficientNet backbone, evaluated on the BDD100k dataset.
- The model employs an encoder-decoder structure, incorporating convolutional and pooling layers, batch normalization, and various activation functions to achieve pixel-level scene understanding.
- Transfer learning is applied to leverage pre-trained knowledge, and the model's performance is optimized using specific loss functions within the Tensorflow/Keras environment.

---

[AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](http://arxiv.org/abs/2507.12484v1)

- AI-Powered Math Tutoring Platform: introduces a novel multi-agent AI tutoring platform that combines adaptive and personalized feedback, structured course generation, and textbook knowledge retrieval to enable modular, tool-assisted learning processes.
- This system utilizes a multi-agent architecture with a central Tutor Agent orchestrating interactions, supported by specialist agents for research, planning, and course creation, and a dual-memory framework for personalization.
- It integrates Retrieval-Augmented Generation (GraphRAG) for contextual textbook knowledge and various tools like a symbolic solver and function plotter to facilitate deep understanding and independent problem-solving.

---

[PRM-Free Security Alignment of Large Models via Red Teaming and Adversarial Training](http://arxiv.org/abs/2507.14202v1)

- PRM-Free Security Alignment Framework: introduces a novel approach for LLM security alignment, leveraging automated red teaming and adversarial training to achieve robust security guarantees without Process Reward Models.
- This framework systematically identifies vulnerabilities through sophisticated attack strategies and enhances model robustness via targeted adversarial training, significantly reducing computational costs by 61% compared to PRM-based methods.
- It incorporates transparent reporting and continuous audit mechanisms, democratizing access to robust security measures for resource-constrained organizations and providing a scalable foundation against evolving adversarial threats.

---

[ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation](http://arxiv.org/abs/2507.14201v1)

- ExCyTIn-Bench: introduces a benchmark for evaluating LLM agents on cyber threat investigation, featuring a Graph Builder (constructs threat graphs), a QA Generator (generates questions/answers), an ExCyTIn Playground (interactive environment), an LLM Agent (investigates cyber threats), a MySQL Environment (provides log data), and an LLM Evaluator (assesses agent performance).
- The benchmark leverages real-world security logs from a controlled Azure tenant to build bipartite alert-entity graphs, enabling the automatic generation of diverse and explainable question-answer pairs for agent evaluation.
- It provides a standardized interactive environment where LLM agents query a MySQL database to solve multi-hop investigation tasks, with fine-grained reward calculation for intermediate steps.

---

[Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System](http://arxiv.org/abs/2507.14200v1)

- SMACS (Scalable Multi-Agent Collaboration System): introduces a scalable multi-agent collaboration system that leverages prior selection and posterior enhancement to enable open-source LLMs to outperform closed-source LLMs, with all Unified Question Bank (stores questions and LLM performance), LLM Bank (pool of heterogeneous LLMs), Pre-establish (evaluates LLMs on question bank), Retrieval-based Prior Selection (RPS) (selects top-k LLMs), Question Embedding (embeds input question), LLM Performance Matrix (stores LLM performance), Retrieved Similarity Vector (represents retrieved question similarity), Selected Top-k LLMs (output of RPS), Exploration-Exploitation-Driven Posterior Enhancement (EPE) (generates and selects responses), Prior Dropping (forms answer subsets), LLM Aggregator (synthesizes multiple responses), Similarity Score Computation (computes mean pairwise similarity), Perplexity Score Computation (computes perplexity), Hybrid Posterior Score (combines similarity and perplexity), where the framework integrates prior and posterior information to generate diverse, high-quality responses.
- The system utilizes a Unified Question Bank and an LLM Bank, employing Retrieval-based Prior Selection to select optimal LLMs and Exploration-Exploitation-Driven Posterior Enhancement with an LLM Aggregator to refine responses.
- This framework demonstrates scalability and superior performance across various benchmarks by effectively combining the strengths of multiple LLMs.

---

[RCG: Safety-Critical Scenario Generation for Robust Autonomous Driving via Real-World Crash Grounding](http://arxiv.org/abs/2507.10749v1)

- RCG (Real-world Crash Grounding): introduces a scenario generation framework that integrates crash-informed semantics into adversarial perturbation pipelines, utilizing a Behavior Embedding Space, Encoder, Decoder, Fully-Connected (FC) Layer, LoRA Adapter, Reconstruction Loss, and Prototypical Contrastive Learning (PCL) Objective to create safety-critical scenarios.
- The framework constructs a safety-aware behavior representation by pre-training on large-scale driving logs and fine-tuning on a crash-rich dataset, leveraging an Unsafe Embedding Cache, Trajectory Predictor, and k-NearestNeighbors (KNN) Distance for adversarial selection.
- RCG guides the Adversary Agent's behavior via a Perturbation Function to maximize realistic criticality against the Ego Agent within a Base Scenario, leading to more plausible and effective stress testing for autonomous driving systems.

---

[BRIDGING BRAINS AND MACHINES: A UNIFIED FRONTIER IN NEUROSCIENCE, ARTIFICIAL INTELLIGENCE, AND NEUROMORPHIC SYSTEMS](http://arxiv.org/abs/2507.10722v1)

- Unified Frontier: introduces a research paradigm bridging neuroscience, artificial intelligence, and neuromorphic computing, with four pillars: Co-Design of Brains, Algorithms and Hardware, Hybrid Learning Pipelines, Hierarchical Memory and Sensorimotor Grounding, and Standardization and Benchmarking.
- The paper surveys foundational milestones, recent advances, and conceptual mismatches across these domains, highlighting cross-inspiration and convergence points like synaptic plasticity, sparse spike-based communication, and multimodal association.
- It proposes an integrated roadmap outlining open challenges and future directions for biologically-grounded AGI and next-generation neuromorphic hardware, emphasizing energy efficiency, real-time adaptation, and ethical considerations.

---

[Large Population Models](http://arxiv.org/abs/2507.09901v1)

- Large Population Models (LPMs): introduces a novel approach to simulate complex societal systems at scale, integrating Million-scale Agent-based Simulation (simulates millions agents), Differentiable Agent-based Simulation (enables gradient learning), and Decentralized Agent-based Simulation (securely deploys simulations) to overcome traditional agent-based model limitations.
- This framework, implemented by AgentTorch, enables efficient simulation of millions of agents, end-to-end differentiable learning from diverse data streams, and privacy-preserving integration with real-world systems.
- LPMs provide a robust platform for understanding collective intelligence, evaluating policies, and testing social innovations before real-world deployment, as demonstrated in a COVID-19 case study for New York City.

---

[Multi-residual Mixture of Experts Learning for Cooperative Control in Multi-vehicle Systems](http://arxiv.org/abs/2507.09836v1)

- MRMEL (Multi-residual Mixture of Experts Learning): introduces a novel framework for Lagrangian traffic control, with vehicle observations and MDP context fed into a Policy F_e (actor/policy network) that outputs nominal weights for Nominal policies and a Residual action, which are combined to form the Final action, while a Value function (critic network) estimates Value to maximize Max E[R], all operating within Training threads involving Autonomous Vehicles and Human-driven vehicles in diverse Traffic scenarios.
- MRMEL augments a suboptimal nominal AV control policy by learning a residual correction and dynamically selecting the most suitable nominal policy from a pool of nominal policies conditioned on the traffic scenarios, modeled as a mixture of experts.
- The framework is designed for generalizable multi-vehicle control, demonstrating superior performance in cooperative eco-driving by reducing aggregate vehicle emissions across diverse real-world traffic scenarios.

---

#### 13th July 2025

[TinyTroupe: An LLM-powered Multiagent Persona Simulation Toolkit](http://arxiv.org/abs/2507.09788v1)

- TinyTroupe: introduces a simulation toolkit enabling detailed persona definitions and programmatic control via LLM-driven mechanisms, including Agents (LLM-powered entities), Environments (simulation context), Factories (generate agent specifications), Validators (assess agent quality), Propositions (define verifiable claims), Simulation Steering (guide simulation flow), Information Processing (extract/enrich/export data), Caching (preserve simulation state), Control (overall simulation management), Experimenter (user interaction), Simulation Core (central simulation engine), Data (data handling components), Action Generation (produce agent actions), Mental Faculties (agent cognitive abilities), and Tools (simulated agent tools).
- The toolkit is designed for realistic human behavior simulation using LLM-powered multiagent systems with a focus on detailed persona specifications.
- It provides a comprehensive set of utilities for specifying scenarios, running simulations, extracting data, and validating results, supporting an experiment-oriented workflow.

---

[Negotiating Comfort: Simulating Personality-Driven LLM Agents in Shared Residential Social Networks](http://arxiv.org/abs/2507.09657v1)

- Personality-Driven LLM Agents Simulation: introduces a methodology integrating generative agents powered by LLMs into social network simulations, with Generative Agents (simulated entities), LLM (decision engine), Social Network (simulated relationships), Crowd framework (simulation platform), Environment (external factors), Agent Memory (stores agent data), Agent Reflection (processes past experiences), Agent Planning (determines future steps), Agent Actions (decisions and interactions), Family Members (within-family agents), and Family Representatives (building-level agents).
- The approach simulates personality-driven decision-making regarding central heating temperature in a shared residential building.
- The simulation uses the Crowd framework for execution and visualization, modeling agent interactions and decisions based on personality, preferences, and social ties.

---

[THOR: Transformer Heuristics for On-Demand Retrieval An LLM Solution Enabling Conversation with Relational Databases by eSapiens](http://arxiv.org/abs/2507.09592v1)

- THOR (Transformer Heuristics for On-Demand Retrieval): introduces a multi-agent Text-to-SQL framework with a Supervisor Agent (Routes queries, interprets task), SQL Generation Agent (Converts NL to SQL), Self-correction Module (Regenerates SQL on failure), and Result Interpretation Agent (Analyzes data, generates insights).
- The framework uses LLMs for SQL generation, self-correction, and result interpretation, operating on database schema and executing queries against a SaaS database.
- A key feature is the self-correction loop, which retries SQL generation based on execution errors or low-quality results, enhancing robustness.

---

[eSapiens: A Platform for Secure and Auditable Retrieval-Augmented Generation](http://arxiv.org/abs/2507.09588v1)

- eSapiens: introduces a platform with Knowledge Adaptation Layer (data processing), Storage Layer (data storage), Application Logic Layer (agent orchestration), DEREK Engine (unstructured data QA), and THOR Module (structured data QA).
- It employs a multi-agent architecture orchestrated via LLM Frameworks like LangChain/LangGraph for retrieval-augmented generation and natural language analytics over diverse enterprise data.
- The platform provides secure, auditable AI workflows, integrating data connectors, prompt management, and robust security features for enterprise use cases.

---

[AICRYPTO: A COMPREHENSIVE BENCHMARK FOR EVALUATING CRYPTOGRAPHY CAPABILITIES OF LARGE LANGUAGE MODELS](http://arxiv.org/abs/2507.09580v1)

- Agent-based framework: introduces, with LLM Agent, Environment, Task Prompts, Response Format, Action Types, Available Tools, Execution Environment, Feedback, Helper Scripts, and Challenge Files, a system for evaluating LLMs on CTF challenges through iterative interaction.
- The framework allows the LLM Agent to perform actions like executing commands or creating files within a controlled Execution Environment using Available Tools.
- The Environment provides Feedback to the LLM Agent, enabling multi-step reasoning and problem-solving towards recovering the flag from Challenge Files, guided by Task Prompts and structured Response Format.

---

[Evaluating LLMs on Sequential API Call Through Automated Test Generation](http://arxiv.org/abs/2507.09481v1)

- StateGen (Automated Test Case Generation Framework): introduces an automated framework to generate diverse coding tasks involving sequential API interactions, with Trace Generation, TraceGenerator, State Schema, API Compatibility Checking, Energy-based Sampling, Program Generation, Control Flow Injection, Instruction Translation, Multi-agent System, Generator Agent, Evaluator Agent, Oracle Generation, and Local Execution Environment, designed to evaluate LLMs' ability in understanding sequential API calls and managing associated program states.
- The framework follows a reverse-generation strategy, starting with executable API sequences, adding control flow, and translating them into natural language instructions using a multi-agent system.
- StateGen is used to construct StateEval, a benchmark of 120 verified test cases across three scenarios, highlighting areas for improvement in current LLMs incorporating APIs.

---

[Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs](http://arxiv.org/abs/2507.09477v1)

- RAG-Reasoning System: introduces a survey of systems integrating retrieval and reasoning in LLMs, including Reasoning-Enhanced RAG (Reasoning improves RAG stages), RAG-Enhanced Reasoning (Retrieval improves reasoning), and Synergized RAG-Reasoning (Iterative retrieval and reasoning) with various Reasoning Workflow (Structured reasoning process) and Agent Orchestration (How agents interact) strategies.
- The survey categorizes approaches into three evolutionary stages, highlighting how reasoning can enhance RAG stages and how retrieval can enhance LLM reasoning.
- Synergized RAG-Reasoning systems, particularly agentic ones, iteratively interleave retrieval and reasoning to achieve state-of-the-art performance on knowledge-intensive tasks.

---

[IteraOptiRacing: A Unified Planning-Control Framework for Real-time Autonomous Racing for Iterative Optimal Performance](http://arxiv.org/abs/2507.09714v1)

- IteraOptiRacing (Unified Planning-Control Framework): introduces a unified planning-control strategy for autonomous racing, integrating Data Collection (gathers historical data), Online Optimization (real-time planning, control), Historical Data Set (stores past performance), Target Terminal Set Construction (generates future states), Surrounding Vehicle Perception (identifies dynamic obstacles), Affine Dynamics Model (approximates vehicle dynamics), Iterative LQR Solver (optimizes trajectories), Trajectory Selection (chooses optimal path), Vehicle Control (applies control inputs), and Vehicle Simulator (simulates racing environment).
- The framework leverages iterative optimization based on historical data and an affine time-varying vehicle model to generate collision-free and time-optimal trajectories for the ego vehicle in dynamic multi-car racing environments.
- This approach ensures smooth overtaking maneuvers and improved lap time performance by avoiding nonsmooth transitions between time-optimal and overtaking controllers, validated through high-fidelity simulations.

---

[TruckV2X: A Truck-Centered Perception Dataset](http://arxiv.org/abs/2507.09505v1)

- TruckV2X: introduces a truck-centered cooperative perception dataset, featuring multi-modal sensing (LiDAR, cameras, IMU units) and multi-agent cooperation (tractor, trailer, CAV, RSU), generated in CARLA/Unreal Engine, and benchmarked using the OpenCOOD framework.
- This dataset addresses the scarcity of heavy-duty vehicle data for cooperative perception, focusing on unique challenges like extensive blind spots and occlusions caused by large truck size and dynamic trailer movements.
- The research establishes performance benchmarks for cooperative perception tasks, demonstrating the critical value of truck-specific viewpoints for enhanced occlusion handling and advancing autonomous trucking systems.

---

[GenAI-based Multi-Agent Reinforcement Learning towards Distributed Agent Intelligence: A Generative-RL Agent Perspective](http://arxiv.org/abs/2507.09495v1)

- GenAI-MARL (Generative AI-based Multi-Agent Reinforcement Learning): introduces a paradigm shift for multi-agent systems by leveraging generative models for environment dynamics modeling, action policy modeling, and integrated prediction and planning, enabling proactive decision-making and sophisticated coordination.
- This approach addresses limitations of conventional MARL by tackling the curse of dimensionality, non-stationarity, and partial observability through learning compact representations, anticipating policy evolution, and inferring hidden states.
- The framework aims to foster distributed agent intelligence, enabling agents to synthesize realistic multi-agent scenarios, predict behaviors, and generate complex coordination strategies for enhanced collective performance.

---

#### 12th July 2025

[Knowledge Conceptualization Impacts RAG Efficacy](http://arxiv.org/abs/2507.09389v1)

- Agentic graph-RAG system: introduces an approach leveraging an Agentic Processor, LLM, Knowledge Graphs Pool, Schema Injection, and User Dialogue to generate SPARQL queries from natural language competency questions.
- The system focuses on how injecting knowledge graph schemas into the LLM's context impacts its ability to generate semantically and syntactically correct queries.
- The research evaluates the efficacy of this system by varying schema complexity and representation formats across different knowledge graphs.

---

[When Developer Aid Becomes Security Debt: A Systematic Analysis of Insecure Behaviors in LLM Coding Agents](http://arxiv.org/abs/2507.09329v1)

- OpenHands Framework: introduces a systematic security analysis of LLM-based coding agents using the OpenHands Framework (AI agent platform) powered by various LLM Backends (Specific LLMs powering agent) on the SetupBench Benchmark (Software setup task benchmark), employing a Detection System (Prompt-based insecure action classifier) and evaluating Mitigation Strategies (Methods to reduce insecure behavior).
- The paper evaluates the security posture of autonomous coding agents by analyzing over 12,000 actions across five state-of-the-art LLMs on 93 real-world software setup tasks.
- Findings reveal significant security concerns, with 21% of agent trajectories containing insecure actions, and demonstrate varying effectiveness of mitigation strategies like feedback mechanisms and security reminders.

---

[StockSim: A Dual-Mode Order-Level Simulator for Evaluating Multi-Agent LLMs in Financial Markets](http://arxiv.org/abs/2507.09255v1)

- STOCKSIM: introduces a dual-mode order-level simulator for evaluating multi-agent LLMs in financial markets, featuring an Exchange Simulation Engine, Data Sources, Agents (including LLM and specialist roles), and an Evaluator, communicating via RabbitMQ.
- The simulator offers both detailed order-level and aggregated candlestick-level execution modes to capture realistic market dynamics for LLM evaluation.
- The framework supports multi-agent LLM coordination, integrates external data, and provides tools for analyzing LLM trading behavior and performance.

---

[Hide-and-Shill: A Reinforcement Learning Framework for Market Manipulation Detection in Symphony—a Decentralized Multi-Agent System](http://arxiv.org/abs/2507.09179v1)

- Hide-and-Shill: introduces, "a novel Multi-Agent Reinforcement Learning (MARL) framework for decentralized manipulation detection", with Shiller Agent (Generates manipulative discourse), Follower Agent (Simulates user engagement), Detector Agent (Identifies manipulative discourse), LLM Text Encoder (Extracts text features), GNN User Encoder (Processes user network), TCN Market Encoder (Processes market data), Multi-Modal Fusion Module (Combines features), State Representation (Comprehensive input vector), Action Space (Binary manipulation prediction), Reward Function (Market-grounded, attention-cost), Group Relative Policy Optimization (GRPO) (Optimizes detector policy), Manipulation Probability Prediction (Outputs prediction score), KOL Trust Accumulation Module (Stores detection results), TrustScore Calculation (Computes KOL trust), KOL Profile Updater (Updates KOL profiles), Multi-Agent Simulation Environment (Simulates interactions), Market Response Model (Simulates price changes), Real-World Data Integration (Calibrates simulation), Regulatory Sandbox Dynamic Thresholding (Application layer component), Symphony (Decentralized architecture), where the framework models manipulation detection as a dynamic adversarial game using MARL.
- The framework integrates GRPO for stable learning in sparse reward environments and a theory-grounded reward function capturing the causal link between discourse and asset behavior.
- The multi-modal agent pipeline fuses LLM-based semantic features, social graph signals, and on-chain market data for informed decision-making and is integrated within the Symphony decentralized system.

---

[AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data](http://arxiv.org/abs/2507.09100v1)

- AInsight: introduces a system for augmenting expert decision-making, with Interactive UI (Displays information), Conversation Processing Pipeline (Processes conversation), Audio Transcription Module (Transcribes audio), Information Extraction Module (LLM agent extracts elements), Insight Generation Module (LLM agent generates insights), Retrieval Module (Retrieves data), Knowledge Base (Stores historical data), Vector Database (Stores embedded data), and Embedding Model (Embeds text), designed to provide on-the-fly insights grounded in historical data during synchronous conversations.
- The system continuously monitors conversations, extracts key information, retrieves relevant data from a knowledge base, and generates concise insights presented via a conversational user interface.
- Leveraging a retrieval-augmented generation pipeline built around LLM agents and a vector database, AInsight aims to improve expert decisions in high-stakes domains like healthcare by making historical data accessible in real-time.

---

[Learning from Synthetic Labs: Language Models as Auction Participants](http://arxiv.org/abs/2507.09083v1)

- Synthetic Lab Framework: introduces a novel synthetic data-generating process using LLM Agents (simulated bidders) within a Simulated Auction Environment (various formats), driven by a Simulation Procedure (multi-round process) and a Prompting System (rules, history, interventions), with Data Collection (bids, outcomes, profits) for analysis.
- The framework simulates various auction formats, including sealed-bid, clock, and eBay-style auctions, allowing LLM agents to participate as bidders.
- The simulation procedure incorporates a "plan-bid-reflect" loop and uses structured prompting to guide LLM agent behavior and collect experimental data.

---

[Emergence of Hierarchical Emotion Organization in Large Language Models](http://arxiv.org/abs/2507.10599v1)

- Emotion Tree Construction Algorithm: introduces a novel method to uncover hierarchical emotion organization in LLMs by analyzing probabilistic dependencies between emotional states in model outputs.
- This algorithm utilizes GPT-40 for scenario generation, Llama models for emotion recognition, and a matching matrix to infer emotion trees, revealing how LLMs organize emotions hierarchically.
- The research also investigates LLM biases in emotion recognition across diverse demographic personas, finding alignment with human systematic biases.

---

#### 11th July 2025


[Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.](https://arxiv.org/abs/2507.06261)

- Gemini 2.X model family: introduces a new generation of natively multimodal LLMs, including Gemini 2.5 Pro and Flash, with advanced reasoning, multimodality, long context, and next-generation agentic capabilities, built on sparse Mixture-of-Experts (MoE) transformers and featuring an inference-time "Thinking" capability.
- The paper details the architecture of an AI Agent system built on these models, comprising an Agentic Core, Persistent Memory & Context, Game I/O, and Agentic Tools, demonstrated through its application in playing Pokémon Blue.
- The research also evaluates the models' safety and security, including their resilience against indirect prompt injection attacks from external services and attackers, and their performance across various coding, reasoning, and multimodal benchmarks.

---

[elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings](http://arxiv.org/abs/2507.08705v1)

- elsciRL: introduces an open-source Python library for applying language solutions to reinforcement learning problems, including Config, Data Engine, Adapter (Language Adapter), Observation Samples, Extra Graphs, LLM Language State Generator, LLM Planner, LLM Validation, LLM Reflection, Encoders, Analysis, Instruction Following, User Interface (GUI), RL Agents, Environment Interaction, Evaluation, Experiment, and Results components.
- The framework extends the LASIF methodology by integrating LLMs for language state generation, planning, validation, and reflection, and provides a GUI for user interaction.
- It aims to facilitate the evaluation of language solutions on reward-based environments with minimal setup, demonstrating potential performance improvements for RL agents using LLM-based instruction following.

---

[Introspection of Thought Helps AI Agents](http://arxiv.org/abs/2507.08664v1)

- INoT (Introspection of Thought): introduces a novel AI Agent Reasoning Framework that uses PromptCode, an LLM-read code within the prompt, to enable LLMs to execute programmatic dialogue reasoning processes internally.
- The framework transfers the self-denial and reflection process from outside the LLM to inside, reducing token cost and improving performance on various tasks.
- INoT's prompt is structured in XML and includes modules for PromptCode definition, image augmentation (for MLLMs), and a reasoning module that simulates a multi-agent debate internally using virtual agents.

---

[Agentic Large Language Models for Conceptual Systems Engineering and Design](http://arxiv.org/abs/2507.08619v1)

- MAS: introduces a structured multi-agent system for conceptual engineering design, with Extractor Agent, Supervisor Agent, Generator Agent, Coder Agent, Reflector Agent, Ranker Agent, Meta-Reviewer Agent, Orchestrator Agent, Worker Agent, and Design-State Graph (DSG), enabling automated requirements decomposition, subsystem mapping, and runnable physics model generation.
- The system utilizes a JSON-serializable Design-State Graph (DSG) to represent the evolving design knowledge, bundling requirements, physical embodiments, and numerical models.
- The MAS workflow follows a structured progression of agents, with optional research loops managed by the Orchestrator and Worker agents.

---

[AGENTSNET: Coordination and Collaborative Reasoning in Multi-Agent LLMs](http://arxiv.org/abs/2507.08616v1)

- AGENTSNET: introduces a multi-agent benchmark, with Agents (LLMs instantiated as nodes), Network Topology (communication graph connecting agents), Message-Passing Protocol (synchronous neighbor-to-neighbor communication), Tasks (distributed computing problems), and Evaluation (metrics for task completion), designed to measure coordination and collaborative reasoning in multi-agent LLM systems.
- The benchmark uses fundamental distributed computing problems like Coloring, Vertex Cover, Matching, Leader Election, and Consensus as tasks for the agent network.
- Agents communicate via a synchronous message-passing protocol over various graph topologies to solve these collaborative problems.

---

[Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data](http://arxiv.org/abs/2507.08610v1)

- LOGIC (Lewis Communication Game for Image Captioning): introduces a multi-agent reinforcement learning game with a Speaker (Generates message/caption) and a Listener (Identifies image from distractors) to learn unsupervised image captioning.
- The Speaker Model (M1) uses a Vision Encoder (Processes input image for Speaker) and Language Decoder (Generates natural language message), while the Listener Model (M2) uses a Vision Encoder (Processes images for Listener), Language Encoder (Processes message for Listener), and Decoder (Outputs probability distribution over images).
- The framework trains these agents in a cooperative common-reward setting using a policy gradient algorithm to emerge a communication strategy for image captioning.

---

[Unlocking Speech Instruction Data Potential with Query Rewriting](http://arxiv.org/abs/2507.08603v1)

- Query Rewriting Framework with Multi-LLM Knowledge Fusion: introduces a method to construct high-quality speech instruction datasets using Query Rewriting LLMs (rewrite text instructions), Speech Style LLM (generate speech style descriptions), TTS Model (synthesize speech), Multi-agent Annotation/Validation Module (evaluate synthesized speech quality), and Knowledge Fusion Module (correct failed rewrites).
- The framework leverages multiple LLMs for rewriting and knowledge fusion, multiple ASR and embedding models for multi-agent validation, and a TTS model for speech synthesis.
- This approach enables automated dataset construction by transforming text instructions for better TTS compatibility and validating synthesized speech quality without human annotation.

---

[To Trade or Not to Trade: An Agentic Approach to Estimating Market Risk Improves Trading Decisions](http://arxiv.org/abs/2507.08584v1)

- Agentic Approach: introduces an agentic system using LLMs to iteratively discover stochastic differential equations for financial time series and inform daily trading decisions.
- The system includes risk analyst agents for model discovery and risk metric generation, and trader agents that use these metrics along with news context.
- Evaluation shows that model-informed trading strategies outperform standard LLM-based agents, improving Sharpe ratios.

---

[Finding Common Ground: Using Large Language Models to Detect Agreement in Multi-Agent Decision Conferences](http://arxiv.org/abs/2507.08440v1)

- Simulated Decision Conference System: introduces a multi-agent system simulating decision conferences, including moderator (guides process), participants (debate, provide perspectives), and a judge agent (detects agreement) for agreement detection.
- The system utilizes LLM agents for each role, enabling structured debate, perspective sharing, and automated agreement detection among participants.
- The judge agent's performance in detecting agreement is evaluated using objective benchmarks and subjective LLM-as-a-judge methods.

---

[A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities](http://arxiv.org/abs/2507.08425v1)

- LLM Techniques Taxonomy: introduces a classification of methods for applying LLMs in discipline-specific research, including Continued Pre-training (Deepen domain expertise), Supervised Fine-tuning (Adapt to specific tasks), Reinforcement Learning from Human Feedback (Align with human preferences), Prompt Engineering (Guide model responses), Retrieval-Augmented Generation (Integrate external knowledge), Agent-based Methods (Interact with environment), and Tool-use Integration (Use external tools).
- The survey categorizes techniques into Internal Knowledge Optimisation and External Interaction and Collaboration to address domain-specific challenges and enhance LLM performance.
- It examines the application of these techniques across various scientific and humanities disciplines, highlighting potential and challenges.

---

[Multi-Agent LLMs as Ethics Advocates in AI-Based Systems](http://arxiv.org/abs/2507.08392v1)

- MALEA (Multi-Agent LLM Ethics-Advocate framework): introduces, "a framework for generating ethics requirements drafts", with Requirements Engineer Agent (generates/refines requirements), Quality Inspector Agent (assesses requirement quality), Ethics Advocate Agent (critiques ethical issues), and Documentation Agent (prints final requirements), where "the framework leverages multi-agent LLMs to elicit and refine ethics requirements".
- The framework operates through iterative feedback loops between the LLM-based agents to improve the quality and ethical considerations of the generated requirements.
- This multi-agent approach aims to automate the initial drafting of ethics requirements to support their early integration into the software development process.

---

[Exploring Design of Multi-Agent LLM Dialogues for Research Ideation](http://arxiv.org/abs/2507.08350v1)

- Structured Ideation-Critique-Revision Framework: introduces a multi-agent LLM dialogue system for research ideation, including LLM Agent (Ideator/Proposer) (Generates initial ideas), LLM Agent (Critic) (Critiques generated ideas), and LLM Agent (Reviser) (Revises ideas based on critiques).
- The framework operates as an iterative cycle where LLM agents generate, critique, and refine research ideas based on seed topics and retrieved papers.
- The study empirically evaluates how varying agent diversity, parallelism, and interaction depth within this framework impacts the novelty and feasibility of generated ideas.

---

[What Factors Affect LLMs and RLLMs in Financial Question Answering?](http://arxiv.org/abs/2507.08339v1)

- Evaluation Framework: introduces an investigation into factors affecting LLMs and RLLMs in financial question answering, utilizing Prompting Methods, Agentic Frameworks, Multilingual Alignment Methods, LLMs, RLLMs, Long CoT, FAMMA, and Basic Txt dataset.
- The study evaluates the impact of various methods and frameworks on five LLMs and three RLLMs using the FAMMA benchmark.
- Findings indicate that methods effective for LLMs often simulate Long CoT, while RLLMs' inherent Long CoT capabilities limit further enhancement from conventional methods.

---

[CRMAgent: A Multi-Agent LLM System for E-Commerce CRM Message Template Generation](http://arxiv.org/abs/2507.08325v1)

- CRMAgent: introduces a multi-agent LLM system for e-commerce CRM message template generation, with ContentAgent (diagnoses templates), RetrievalAgent (retrieves exemplars), TemplateAgent (rewrites templates), and EvaluateAgent (assesses quality).
- The system improves underperforming CRM messages using historical data, high-quality examples, and a rule-based fallback.
- CRMAgent integrates content diagnosis, retrieval-based adaptation, and rule-based generation strategies across its specialized agents.

---

[Agent Safety Alignment via Reinforcement Learning](http://arxiv.org/abs/2507.08270v1)

- Unified Safety-Alignment Framework: introduces a method to train LLM agents with Tools, using a Sandbox Environment and Reinforcement Learning guided by a Taxonomy and Reward Function to create a Policy-driven Decision Model.
- The framework addresses both user-initiated and tool-initiated threats by classifying inputs and outputs into benign, malicious, or sensitive categories.
- Training in a sandboxed environment with calibrated rewards enables agents to execute benign tasks, refuse malicious inputs, and seek verification for sensitive actions, balancing safety and utility.

---

[Infinite Video Understanding](http://arxiv.org/abs/2507.09068v1)

- Infinite Video Understanding Vision: introduces a research objective for models to continuously process, understand, and reason about video data of arbitrary duration, with all Encoder (Processes incoming video), Persistent Memory System (Stores long-term knowledge), Memory Consolidation (Updates persistent memory), Query-Aligned Retrieval (Accesses relevant memory), Streaming/Incremental Processing (Handles continuous data flow), Hierarchical/Adaptive Representations (Multi-resolution data encoding), Event-Centric Understanding (Focuses on events/relationships), Agentic Reasoning (LLM plans and uses tools), and Multimodal Processing (Integrates diverse data types) components.
- The vision necessitates fundamental innovation in system architecture, memory management, data representation, processing paradigms, and evaluation methodologies.
- Achieving this capability requires overcoming challenges like context window limitations, memory burdens, information loss, and maintaining temporal coherence over vast scales.

---

[SetupBench: Assessing Software Engineering Agents' Ability to Bootstrap Development Environments](http://arxiv.org/abs/2507.09063v1)

- SetupBench: introduces, "SetupBench: Assessing Software Engineering Agents' Ability to Bootstrap Development Environments", with SetupBench (Benchmark tasks), Agent (LLM software engineering agent), Bare Linux Sandbox (Execution environment), Evaluation Harness (Automated validation), Docker Image (Task container), Validation Command (Success verification), where the paper presents a benchmark for evaluating LLM agents' ability to set up software development environments.
- The benchmark includes 93 tasks across four categories, each providing a natural-language problem statement, workspace snapshot, and deterministic validation command.
- Agents are evaluated in fresh, minimal Linux containers using an automated harness that runs the agent and verifies task completion via the validation command.

---

[How to Train a Leader: Hierarchical Reasoning in Multi-Agent LLMs](http://arxiv.org/abs/2507.08960v1)

- MLPO (Multi-agent guided Leader Policy Optimization): introduces a hierarchical multi-agent framework with a trained Leader LLM, an Agent Team (untrained off-the-shelf LLMs), Task Input, Agent Responses, Leader Output, Feedback, Final Answer, SFT (leader pre-training phase), and MLPO (leader training objective), where a single trained leader coordinates untrained agents for collaborative reasoning. 
- The leader processes Task Input and Agent Responses, generating Leader Output (reasoning and answer) which serves as Feedback for subsequent rounds, ultimately producing the Final Answer. 
- The framework trains only the leader using SFT and the MLPO objective, enabling it to effectively evaluate and synthesize agent contributions and also perform well independently. 

---

[SIMAGENTS: Bridging Literature and the Universe Via A Multi-Agent Large Language Model System](http://arxiv.org/abs/2507.08958v1)

- SIMAGENTS (Bridging Literature and the Universe Via A Multi-Agent Large Language Model System): introduces a multi-agent system with Parameter Extraction (extracts simulation parameters), Physics Agent (interprets papers domain knowledge), Software Agent (enforces software constraints), Post-Simulation Processing (generates analysis code), and Analysis Code Writer (generates analysis scripts) components.
- The system automates cosmological simulation parameter configuration from literature and preliminary analysis using specialized LLM agents.
- SIMAGENTS agents collaborate through structured communication to ensure extracted parameters are physically meaningful, consistent, and software-compliant.

---

[Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias](http://arxiv.org/abs/2507.11210v1)

- Role-Playing LLM-Based Multi-Agent Dialogue Support Framework: introduces a multi-stage, multi-agent LLM system that analyzes parent-child dialogues to detect suppressed emotion and ideal parent bias, then generates empathetic and actionable feedback.
- The framework utilizes a Dialogue D (Input dialogue) processed by a Suppressed Emotion Detection Agent (Asup), Auxiliary Attribute Estimation Agent (Aattr), and Ideal Parent Bias Detection Agent (Abias), with outputs integrated by a Meta-Agent (Ameta) into Child Report (Rchild) and Adult Report (Radult).
- Selected Expert Agents (Eselect), chosen from an Expert Agents Pool (E) using BERT (Calculates embedding similarity), collaboratively generate feedback through a four-step discussion, which is then synthesized by a Final Meta-Agent (Afinal) into Final Feedback for Child (Ffinal,child) and Final Feedback for Adult (Ffinal,adult) to support positive family communication.

---

[Optimizing Sequential Multi-Step Tasks with Parallel LLM Agents](http://arxiv.org/abs/2507.08944v1)

- M1-Parallel: introduces a framework that concurrently runs multiple multi-agent teams in parallel to uncover distinct solution paths, leveraging an event-driven communication model with asynchronous messaging to reduce end-to-end latency or boost task completion rates.
- The framework includes a Centralized Manager, a Plan Generation Function, multiple Multi-agent Teams (each comprising an Orchestrator and specialized agents like WebSurfer, FileSurfer, Coder, and ComputerTerminal), a Global Memory Module, and an Aggregator.
- M1-Parallel operates in either an Early-stop mode, terminating when the fastest team completes, or an Aggregation mode, combining answers from multiple teams to improve task completion.

---



[ARPACCINO: An Agentic-RAG for Policy as Code Compliance](http://arxiv.org/abs/2507.10584v1)

- ARPACCINO: introduces an agentic system for Policy as Code (PaC) compliance, integrating an LLM Engine (core reasoning engine), RAG Tool (accesses domain knowledge), Terraform Tool (pre-processes IaC), Rego Rules Checker Tool (verifies policy rules), Policy Validation Tool (assesses IaC compliance), and Persistent Knowledge (stores domain data).
- This system automates the generation and verification of PaC rules from natural language descriptions, iteratively refining Infrastructure as Code (IaC) configurations for conformance.
- By combining LLMs, Retrieval-Augmented-Generation, and specialized tools, the system enhances automation, reliability, and accessibility of PaC workflows, even with smaller LLMs.

---

[An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation](http://arxiv.org/abs/2507.10580v1)

- EmoSApp (Emotional Support App): introduces an offline, smartphone-based conversational AI app for mental health support, leveraging a fine-tuned LLaMA-3.2-1B-Instruct model, Torchtune for optimization, Executorch for on-device inference, and a domain specialization approach combining knowledge and conversational datasets.
- The system addresses limitations of existing solutions by enabling entirely offline operation, enhancing data privacy, and delivering responsive performance on resource-constrained mobile devices through LLM quantization.
- Qualitative and quantitative evaluations demonstrate the app's ability to provide coherent, empathetic, and contextually appropriate mental health support, serving as a blueprint for portable AI-driven solutions.

---

[Behavioral Exploration: Learning to Explore via In-Context Adaptation](http://arxiv.org/abs/2507.09041v1)

- BE (Behavioral Exploration): introduces a novel approach for training autonomous agents, utilizing a long-context policy (generates expert actions), history (past observations context), state (current environment state), action (agent's output action), future trajectory (predicted future path), coverage (exploratory behavior measure), behavioral cloning loss (mimics expert actions), expert demonstration data (offline training dataset), coverage conditioning value (regulates exploration degree), diffusion model, transformer backbone, state token, coverage-to-go token, history state tokens, and task label (optional task conditioning).
- This framework enables agents to learn data-driven exploratory behavioral policies that adapt quickly online, restricting exploration to coherent, reasonable behaviors derived from expert demonstrations.
- The approach leverages offline training and in-context online adaptation, demonstrating effectiveness in simulated locomotion, manipulation, and real-world robotic tasks.

---

[ACCELERATING DRUG DISCOVERY THROUGH AGENTIC AI: A MULTI-AGENT APPROACH TO LABORATORY AUTOMATION IN THE DMTA CYCLE](http://arxiv.org/abs/2507.09023v1)

- Tippy (a novel agentic AI framework): introduces a multi-agent system for laboratory automation in drug discovery, featuring Supervisor, Molecule, Lab, Analysis, Report, and Safety Guardrail agents, designed to accelerate DMTA cycles.
- This framework leverages autonomous AI agents that reason, plan, and collaborate, integrating with laboratory infrastructure via the Model Control Protocol, LIMS, ELN, and analytical instrument data systems.
- The system demonstrates significant improvements in workflow efficiency, decision-making speed, and cross-disciplinary coordination, providing a new paradigm for AI-assisted drug discovery.

---

[SPLASH! Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations](http://arxiv.org/abs/2507.08707v1)

- SPLASH (Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations): introduces a novel IRL algorithm for learning from suboptimal demonstrations in long-horizon and adversarial settings, incorporating options-level demonstrations, behavioral cloning, downsampled full trajectory pairs, success and progress-based learning constraints, and temporal consistency regularization.
- The framework empirically validates its approach on a maritime capture-the-flag task in simulation and demonstrates real-world applicability with sim-to-real translation experiments on autonomous unmanned surface vehicles.
- It significantly outperforms state-of-the-art methods in reward learning from suboptimal demonstrations by addressing challenges specific to long-horizon and adversarial tasks.

---

[OnlineBEV: Recurrent Temporal Fusion in Bird's Eye View Representations for Multi-Camera 3D Perception](http://arxiv.org/abs/2507.08644v1)

- OnlineBEV (Recurrent Temporal Fusion in Bird's Eye View Representations for Multi-Camera 3D Perception): introduces a novel recurrent temporal fusion framework for multi-camera 3D perception, utilizing a Motion-Guided BEV Fusion Network (MBFNet) for feature alignment and Heatmap-Based Temporal Consistency Learning (HTC-loss) for explicit supervision.
- The framework effectively aggregates BEV features across frames using a recurrent design, compensating for spatial misalignment caused by object motion through spatio-temporal deformable attention.
- This approach achieves state-of-the-art performance in camera-only 3D object detection, BEV segmentation, and 3D occupancy prediction on the nuScenes benchmark.

---

#### 10th July 2025

[The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production](http://arxiv.org/abs/2507.06565v1)

- FOO (Flaws-of-Others): introduces an LLM-driven framework for scientific knowledge production, with User Task (Initial request), Agents (LLMs) (Multiple LLMs), Initial Answers (First responses), Critiques (Peer evaluations), Harmoniser(s) (Aggregating critiques), Judgement (Synthesized feedback), Revised Answers (Updated responses), and Convergence Test (Stopping condition).
- The framework models invalidation propagation in a discursive network of LLM agents and humans, defining invalidation as any factual, logical, or structural breach.
- The FOO algorithm operationalizes cross-network detection by having agents critique each other's outputs iteratively, aiming to reduce the prevalence of false statements.


---

[PyVision: Agentic Vision with Dynamic Tooling](http://arxiv.org/abs/2507.07998v1)

- PyVision: introduces an agentic framework enabling MLLMs to dynamically generate and execute Python code for multimodal reasoning, featuring an MLLM, a Runtime Environment, a Multi-turn Interaction Loop, and Dynamically Generated Tools.
- The framework operates as a multi-turn loop where the MLLM generates code executed in an isolated Python runtime, with the results fed back to the MLLM's context for iterative refinement.
- This approach allows the model to create task-specific tools on the fly, leveraging Python libraries for flexible, grounded, and interpretable visual reasoning.


---

[MIRIX: Multi-Agent Memory System for LLM-Based Agents](http://arxiv.org/abs/2507.07957v1)

- MIRIX: introduces a modular, multi-agent memory system for LLM-based agents, with Core Memory (User info, context), Episodic Memory (Events, experiences), Semantic Memory (Concepts, entities), Procedural Memory (Guides, workflows), Resource Memory (Files, documents), Knowledge Vault (Sensitive information), Meta Memory Manager (Coordinates memory managers), Memory Managers (Manage specific memory types), and Chat Agent (User interaction, query processing), designed to enable LLMs to remember diverse, long-term user data at scale.
- The system employs a multi-agent architecture with specialized memory components and managers to handle heterogeneous information and facilitate effective retrieval and updates.
- MIRIX demonstrates improved accuracy and storage efficiency on multimodal and long-form conversational benchmarks compared to existing memory systems.


---

[Agentic Retrieval of Topics and Insights from Earnings Calls](http://arxiv.org/abs/2507.07906v1)

- Agentic Framework: introduces an LLM-driven system to dynamically retrieve and organize financial topics from earnings calls, with Earnings Call Documents (Input data), Topic Retriever (Extracts topics and excerpts), Extracted Topics & Excerpts (Output of retriever), Ontologist Sub-Agent (Validates and integrates topics), Novelty Verification (Checks if topic exists), and Ontology Data Structure (Stores topics hierarchically).
- The framework uses a Topic Retriever LLM to extract relevant topics and contextual excerpts from text.
- An Ontologist Sub-Agent LLM manages a continuously evolving hierarchical topic ontology by verifying novelty and integrating new or updated topics.


---

[Automating MD simulations for Proteins using Large language Models: NAMD-Agent](http://arxiv.org/abs/2507.07887v1)

- NAMD-Agent: introduces an automated pipeline, with LLM Agent (orchestrates workflow), Retrieval-Augmented Generation (RAG) (code retrieval), Curated Codebase (automation scripts), PDBFixer (structure preprocessing), CHARMM-GUI (system setup tool), Selenium (web automation), NAMD (simulation engine), and Post-processing Tools (analysis, visualization), that leverages LLMs, python scripting, and web automation to streamline MD input file generation and simulation.
- The system uses a ReAct-based agent powered by Gemini-2.0-Flash and LlamaIndex to interpret user queries, generate and execute code, and interact with external tools like CHARMM-GUI and NAMD.
- The RAG framework enhances the LLM's ability to generate accurate automation scripts by retrieving relevant code templates and API patterns from a curated repository.


---

[DocCHA: Towards LLM-Augmented Interactive Online diagnosis System](http://arxiv.org/abs/2507.07870v1)

- DocCHA: introduces a modular, confidence-aware framework emulating clinical reasoning with LLMs, including Symptom Collection Module (elicits symptoms, guides questioning), History Acquisition Module (collects history, controls depth), and Causal Graph Construction and Refinement Module (constructs causal graph, refines reasoning).
- The framework decomposes the diagnostic process into three sequential stages, each powered by an LLM backend and guided by interpretable confidence scores.
- Each module uses confidence metrics to guide adaptive questioning, prioritize information, and refine reasoning links for structured and transparent diagnosis.


---

[Position: We Need An Algorithmic Understanding of Generative AI](http://arxiv.org/abs/2507.07544v1)

- AlgEval: introduces a framework for systematically researching the algorithms LLMs learn and use, utilizing LLM system, algorithmic primitives, algorithmic grammars, algorithms, algorithm identification and interpretability methods, empirical verification and theoretical analysis, and improved design and insights.
- The framework aims to uncover algorithmic primitives and their composition by analyzing latent representations, attention, and inference-time compute.
- A case study on graph navigation demonstrates applying attention and representation analysis to evaluate hypothesized search algorithms like BFS and DFS.


---

[Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models](http://arxiv.org/abs/2507.07505v1)

- LLM Analysis Framework: introduces, with Large Language Model (core model), Input String (prompt/data), Output String (generated response), Tokens (text units), and LLM-based Agent (system using LLM), an analysis showing that LLMs are limited by their computational complexity.
- The paper argues that LLMs cannot correctly perform or verify tasks whose complexity exceeds the LLM's core operation complexity of O(N².d).
- This limitation implies that LLMs and LLM-based agents will hallucinate when faced with computationally complex tasks like matrix multiplication or verifying TSP solutions.


---

[StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](http://arxiv.org/abs/2507.07445v1)

- StarDojo: introduces a novel environment and benchmark based on Stardew Valley for evaluating agentic MLLMs in production-living simulations, featuring StarDojo Environment (Simulation platform), StarDojoMod (Game engine interface), Python Wrapper (Agent interaction layer), Observation Space (Visual and textual data), Action Space (Agent command set), Task Evaluator (Progress monitoring), and Simulator APIs (Environment configuration).
- The platform provides a unified interface, automated evaluation, system compatibility, and parallelized environments to facilitate research on agents capable of complex decision-making.
- StarDojo offers a comprehensive observation space combining visual screenshots and structured textual information, and an abstracted action space to enable robust agent interaction and evaluation.


---

[SAND: Boosting LLM Agents with Self-Taught Action Deliberation](http://arxiv.org/abs/2507.07441v1)

- SAND (Self-taught Action Deliberation): introduces a self-learning framework to equip LLM agents with explicit action deliberation, utilizing a Base LLM (initial model), Trainable LLM (agent being finetuned), Expert Trajectories (initial successful data), Self-Consistency Action Sampling (samples candidate actions), Execution-Guided Action Critique (generates critiques from rollouts), Action Deliberation Synthesis (creates deliberation thoughts), Deliberation Trajectories (self-augmented training data), Iterative Finetuning (repeated model updates), and an Inconsistency Indicator (flags deliberation need).
- The framework iteratively generates deliberation thoughts by sampling candidate actions, critiquing their rollouts, and synthesizing reasoning using the base LLM.
- The self-augmented deliberation trajectories are then used to finetune the LLM agent, teaching it when and what to deliberate for improved decision making.


---

[DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](http://arxiv.org/abs/2507.07426v1)

- DrugMCTS: introduces a drug repurposing framework with Retrieval Agent (Identifies relevant molecules/proteins), Molecule-Analysis Agent (Evaluates molecule properties), Molecule-Selection Agent (Filters candidate molecules), Interaction-Analysis Agent (Interprets drug-target interactions), Decision Agent (Integrates evidence, selects protein), Monte Carlo Tree Search (Guides iterative search/decision), and LLM (Qwen2.5-7B-Instruct) (Performs reasoning/analysis tasks).
- The framework integrates RAG, multi-agent collaboration, and MCTS to enable structured and iterative reasoning for drug-target interaction prediction.
- It leverages a data processing pipeline to transform scientific data into formats more interpretable by LLMs and uses a reward calculation mechanism within MCTS for feedback-driven search.


---

[KVFlow: Efficient Prefix Caching for Accelerating LLM-Based Multi-Agent Workflows](http://arxiv.org/abs/2507.07400v1)

- KVFlow: introduces a workflow-aware KV cache management framework for LLM-based agentic workflows, utilizing an Agent Step Graph, Steps-to-Execution, Workflow-Aware Eviction Policy, Overlapped KV Prefetching, and Status-Aware Scheduling to improve efficiency.
- The framework abstracts agent execution as an Agent Step Graph to compute steps-to-execution values, guiding a fine-grained eviction policy at the KV node level.
- It incorporates a fully overlapped KV prefetching mechanism combined with status-aware scheduling to proactively load required tensors and avoid cache miss stalls.


---


[Effect of Static vs. Conversational Al-Generated Messages on Colorectal Cancer Screening Intent: a Randomized Controlled Trial](http://arxiv.org/abs/2507.08211v1)

- Single AI Message Approach: introduces a randomized controlled trial comparing a single LLM-generated message and an LLM chatbot conversation, both tailored to demographics, against expert materials and a no-message control for increasing colorectal cancer screening intent.
- The study found that both AI interventions significantly increased stool test intent compared to expert materials and control, but neither improved colonoscopy intent over expert materials.
- A concise, demographically tailored single AI message was as effective as a longer, interactive AI chatbot conversation for boosting stool test intent, suggesting scalability benefits for simpler AI messaging.

---

[Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions](http://arxiv.org/abs/2507.08208v1)

- LLM-Nash framework: introduces a game-theoretic model where agents use LLMs guided by reasoning prompts to make decisions, defining equilibrium over the prompt space which induces behavioral outcomes.
- This framework explicitly models the reasoning process, capturing bounded rationality and enabling analysis of cognitive constraints and mindset expressiveness.
- Unlike classical games, LLM-Nash games define equilibrium at the reasoning level, where agents optimize prompts to maximize expected utility via LLM-generated actions.

---

[A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking](http://arxiv.org/abs/2507.08207v1)

- Purple Agent: introduces a dynamic Stackelberg game framework for LLM jailbreaking defense, featuring the Purple Agent (Agentic AI defender) interacting with the LLM (Target LLM), using DeployDefense (Deploys defenses) and SimulateRedExpansion (Simulates attacker exploration) guided by an Internal Defense Policy (Guides defense strategy) and RRT (Exploration algorithm).
- The framework models LLM jailbreaking as a sequential extensive-form game between an attacker and the defender (Purple Agent).
- The Purple Agent proactively anticipates potential adversarial paths by simulating attacker behavior using RRT-based exploration and deploys targeted interventions.

---

[KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence](http://arxiv.org/abs/2507.08164v1)

- KP-A (A Unified Network Knowledge Plane for Agentic Network Intelligence): introduces a layered architecture with a Network Knowledge Plane positioned between the Network Data Ontology Plane and the Network Intelligence Plane, including Intelligence Agents, Utility Agents, Knowledge Query Tool / Model Context Protocol Server, Live Network Data Endpoints, Static Data Explanation Endpoints, UE, Cell, BaseStation, RIC, CoreNetwork, EdgeServer, Base Stations, Edge Server, Core Network, Cells, and User Equipments.
- The Network Knowledge Plane serves as a unified source of truth, providing intuitive and consistent access to dynamic and static network knowledge for LLM-powered agents.
- The architecture decouples knowledge acquisition from consumption, enabling reusable knowledge access for diverse network intelligence tasks.

---

[MCPmed: A Call for MCP-Enabled Bioinformatics Web Services for LLM-Driven Discovery](http://arxiv.org/abs/2507.08055v1)

- MCPmed: introduces a layered architecture for bioinformatics web services, with UI, API layer, and MCP layer components, enabling LLM-driven discovery.
- The MCP layer provides a standardized, machine-actionable interface over existing APIs, associating endpoints with scientific concepts and metadata for LLMs.
- Breadcrumbs offer a transition mechanism for legacy services, while LLM agent researchers leverage the MCP layer for autonomous data exploration and analysis using components defined by types.Tool.

---

#### 9th July 2025

[The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation](http://arxiv.org/abs/2507.06993v1)

- Agent-based Travel Smart Assistant: introduces an LLM-powered framework with Travel Planning Agent (plans trips, explores areas), Destination Assistant Agent (navigates final leg), and Local Discovery Agent (adapts, finds alternatives).
- The framework integrates planning, navigation, and dynamic adaptation using cooperative agents and multimodal LLMs to address gaps in traditional systems.
- This system enhances user experience by handling complex queries, providing precision navigation, and adapting to real-world disruptions.

---

[Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues](http://arxiv.org/abs/2507.06910v1)

- Llama 3.2 3B (fine-tuned with LoRA): introduces, "Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues", with Llama 3.2 3B model (base LLM), LoRA (fine-tuning method), Dialogue history (text input), Previous turn move labels (optional input), Predicted tutor move (output), and Predicted student outcome (output), evaluating LLMs and baselines on predicting tutor moves and student outcomes in tutoring dialogues.
- The study compares fine-tuned Llama 3.2 3B and zero-shot GPT-40 LLMs against traditional Markov Chain, Logistic Regression, and LSTM baselines.
- Experiments on MathDial and AlgebraNation datasets show LLMs outperform baselines, but predicting future tutor strategy remains challenging, while student outcome prediction is more tractable.

---

[The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover](http://arxiv.org/abs/2507.06850v1)

- Agentic AI Systems: introduces an evaluation of LLM agents as attack vectors for computer takeover by exploiting trust boundaries in agentic AI systems, including LLM (core engine), Agent (autonomous entity), Perception (processes inputs), Storage (memory/knowledge), Planning/Reasoning (decides actions), Actions (executes tasks), Tools (external capabilities), Retrieval (searches knowledge), Knowledge (external database), Multi-Agent System (interacting agents), and Inter-Agent Communication (agent interaction).
- The paper demonstrates three attack surfaces: direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation, showing that LLMs can be coerced into installing and executing malware.
- A vulnerability hierarchy is established, revealing that inter-agent trust exploitation is the most effective attack vector, often bypassing defenses against direct prompts or RAG attacks.

---

[SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments](http://arxiv.org/abs/2507.06564v1)

- SkyVLN: introduces a framework integrating vision-and-language navigation with Nonlinear Model Predictive Control for UAVs, featuring Multimodal Perception (Processes visual and linguistic inputs), Visual Observations (RGB, depth, semantic images), Visual Foundation Model (Detects visual landmarks), LLM (Sub-goal Extraction) (Interprets instructions, extracts sub-goals), Wayfinding Prompt Optimization (WPO) (Refines localization, adds spatial/historical context), High-resolution Spatial Descriptor (HSD) (Describes landmark spatial relationships), TrackBack Memory Array (TBMA) (Stores historical path/instructions), Action Decision Module (Generates control commands), Nonlinear Model Predictive Control (NMPC) (Handles trajectory tracking, obstacle avoidance), Airsim Attitude Controller (Translates NMPC to motor commands), and LLM Motion Generator (Outputs thoughts and actions).
- The framework leverages LLMs to interpret natural language instructions and visual observations, enabling navigation in dynamic 3D urban spaces with improved accuracy and robustness.
- Key components like the spatial verbalizer and history path memory enhance the UAV's ability to handle ambiguous instructions and complex spatial reasoning tasks.

---

[The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production](http://arxiv.org/abs/2507.06565v1)

- FOO (Flaws-of-Others): introduces an LLM-driven framework for scientific knowledge production, with User Task (Initial request), Agents (LLMs) (Multiple LLMs), Initial Answers (First responses), Critiques (Peer evaluations), Harmoniser(s) (Aggregating critiques), Judgement (Synthesized feedback), Revised Answers (Updated responses), and Convergence Test (Stopping condition).
- The framework models invalidation propagation in a discursive network of LLM agents and humans, defining invalidation as any factual, logical, or structural breach.
- The FOO algorithm operationalizes cross-network detection by having agents critique each other's outputs iteratively, aiming to reduce the prevalence of false statements.

---

[InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior](http://arxiv.org/abs/2507.06528v1)

- InvestAlign: introduces a framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems, with components: Theoretical solution (Mathematical solution), Simple problem (Simplified investment scenario), Complex problem (Original investment scenario), Training dataset (Data generated from theoretical solution), Pre-SFT LLM (Base LLM before fine-tuning), and InvestAgent (LLM fine-tuned with generated data).
- This approach addresses data scarcity for aligning LLMs with investor decision-making processes under herd behavior.
- Training LLMs on the generated data achieves faster parameter convergence and closer alignment to real-user data than using real-user data directly.

---

[Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration](http://arxiv.org/abs/2507.06520v1)

- Gradientsys: introduces a multi-agent scheduling framework, with a Constellation LLM Scheduler (orchestrates agents), Tool Registry (stores tool information), Specialized AI Agents (perform specific tasks), Model-Context Protocol (standard tool interface), ReAct Reasoning Engine (LLM planning loop), Observability Module (streams traces), Hybrid Sync/Async Execution (manages parallel calls), Scratchpad (stores reasoning steps), and Info Cache (caches intermediate info), designed to coordinate diverse specialized AI agents for complex tasks.
- It leverages an LLM-powered scheduler using ReAct for dynamic planning and supports parallel execution of heterogeneous agents via a standardized MCP interface.
- The framework includes a robust retry-and-replan mechanism and streams real-time agent activity and reasoning for transparency.

---

[Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models](http://arxiv.org/abs/2507.06466v1)

- FMSP (Foundation-Model Self-Play): introduces a new paradigm combining self-play with foundation models, including Foundation Model (Generates/improves policies), Policy (Code-based strategy), Agent (Embodies policy), Archive (Stores policies), Competition (Agents interact), Context (FM input), Evaluation (Measures performance/diversity), and Sandbox (Safe code execution), to enable open-ended strategy discovery in multi-agent games.
- The framework leverages LLMs' code generation and knowledge to create diverse and high-quality policies, overcoming limitations of traditional self-play like local optima and lack of diversity.
- FMSP variants like QDSP demonstrate superior performance and diversity in tasks like Car Tag and LLM red teaming by balancing exploration and exploitation through FM-powered search and archiving.

---

[Multi-Agent Retrieval-Augmented Framework for Evidence Based Counterspeech Against Health Misinformation](http://arxiv.org/abs/2507.07307v1)

- MA (Multi-Agent Retrieval-Augmented Framework): introduces a system for generating evidence-based counterspeech against health misinformation, utilizing a Misinformation Post (Input), Static Retrieval Agent (Gathers static evidence), Dynamic Retrieval Agent (Fetches real-time evidence), Retrieve Knowledge Base (Local static data source), DuckDuckGo Web Search (Real-time dynamic source), Combined Retrieved Evidence (Merged static/dynamic evidence), Summarization Agent (Filters and condenses evidence), Filter Summarized Evidence (Processed evidence output), Top-Ranked Evidence (Selected relevant evidence), Counterspeech Generation Agent (Creates initial response), Raw Counterspeech Response (Initial generated response), Refinement Agent (Improves generated response), and Refined Response (Final polished output).
- The framework employs multiple specialized LLM agents in sequence to retrieve, filter, summarize, generate, and refine responses.
- Integrating both static and dynamic knowledge sources enhances the relevance, informativeness, and factual accuracy of the generated counterspeech.

---

[ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning](http://arxiv.org/abs/2507.07306v1)

- ViDove: introduces a multimodal translation agent system that integrates visual, audio, and textual inputs with a memory system and specialized LLM-based agents (Vision, Auditory, Translation, Proofreader, Editor) to enhance translation quality for long-form video.
- The system leverages a memory system comprising short-term and long-term modules to provide context-aware translation and adapt to domain-specific knowledge.
- A multi-agent post-editing module with Proofreader and Editor agents refines the initial translation through collaborative review and user instructions.


---

[Application of LLMs to Multi-Robot Path Planning and Task Allocation](http://arxiv.org/abs/2507.07302v1)

- Approach: introduces a method for expert exploration in multi-agent reinforcement learning, utilizing an Ensemble of Mixer Networks for Uncertainty Estimation to decide whether to query the MARL Algorithm (QMIX) policy or an Expert Planner (A* or LLM (Vicuna-7B)), which involves a Planning Prompt Generator, Tokenizer, and Action Transformer, with collected Data Collection used for Batch Creation and Model Update Module.
- The system integrates an LLM (Vicuna-7B) as an expert planner to guide exploration for a QMIX-based multi-agent system in grid environments when the agent's intrinsic uncertainty is high.
- Experiments compare the performance of QMIX with RNN, QMIX with Attention, QMIX with Attention using A* as expert, and QMIX with Attention using Vicuna-7B as expert, showing improved performance with expert guidance, particularly from the LLM.

---

[Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](http://arxiv.org/abs/2507.07257v1)

- cmbagent: introduces a multi-agent system for autonomous scientific discovery, with Planner (proposes plan), Plan Reviewer (provides plan feedback), Controller (orchestrates plan execution), Engineer (handles coding tasks), Researcher (performs reasoning tasks), Executor (executes code locally), Post-execution Interpreter (decides next agent), Installer (installs missing packages), Terminator (ends session), Context Agents (specialized with extended context), and RAG Agents (retrieve information using RAG), implementing a Planning & Control strategy for end-to-end task execution without human intervention.
- The system leverages approximately 30 LLM agents, each specializing in different tasks, orchestrated via a robotics-inspired Planning & Control workflow built upon the AG2 framework.
- Key features include specialized agents for research papers and code libraries, feedback loops between agents, structured output generation, and local code execution capabilities.


---

[Evaluating Retrieval-Augmented Generation Agents for Autonomous Scientific Discovery in Astrophysics](http://arxiv.org/abs/2507.07155v1)

- SciRag: introduces a modular framework for evaluating Retrieval-Augmented Generation (RAG) agents, with document preprocessing (processes research papers), retrieval (finds relevant document chunks), and generation (uses LLMs to generate answers) components.
- The framework utilizes the CosmoPaperQA benchmark dataset and a dual human expert and LLM-as-a-Judge evaluation approach to assess RAG agent performance in astrophysics.
- Different RAG configurations, varying LLMs, embedding models, and retrieval strategies, are systematically compared for accuracy and cost-efficiency on expert-curated questions.

---


#### 8th July 2025

[SciMaster: Towards General-Purpose Scientific AI Agents Part I. X-Master as Foundation — Can We Lead on Humanity's Last Exam?](https://arxiv.org/abs/2507.05241)

- X-Masters (Scattered-and-Stacked Agentic Workflow): introduces a workflow that orchestrates multiple X-Master agents in specialized roles, including Solver, Critic, Rewriter, and Selector, to systematically enhance reasoning breadth and depth.
- This framework leverages individual X-Master agents, which are tool-augmented reasoning agents driven by an LLM, using code as an interaction language to flexibly interact with external tools.
- The X-Master agent's core mechanism involves generating Python code for a Code Executor to access Tools like Web Search, Web Parse, and Python Libraries, with execution results appended back to the agent's context for iterative reasoning.

---


[Representing Prompting Patterns with PDL: Compliance Agent Case Study](http://arxiv.org/abs/2507.06396v1)

- PDL (Prompt Declaration Language): introduces a novel declarative YAML-based language for specifying LLM prompts and workflows, with PDL Language (Declarative YAML syntax), PDL Interpreter (Executes PDL programs), Blocks (Program units), Context (Implicit message history), Tool Definitions (External function wrappers), Model Calls (LLM interactions), Parser (Output processing), Type System (JSON Schema validation), and Control Structures (Flow logic).
- The language captures the composition of LLM calls, rule-based code, and external tools, abstracting away plumbing for improved productivity and optimization.
- A case study demonstrates PDL's utility in a compliance agent, showing performance improvements by enabling customization of prompting patterns and agent architecture.

---

[Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms](http://arxiv.org/abs/2507.06323v1)

- Function Calling: and Model Context Protocol (MCP): introduces a comparative vulnerability assessment of LLM agent deployment paradigms, evaluating Function Calling and MCP architectures using a unified threat framework and attack progression model.
- The study reveals that architectural choices fundamentally reshape threat landscapes, with Function Calling showing higher system-centric vulnerabilities and MCP exhibiting increased LLM-centric exposure.
- Analysis across simple, composed, and chained attacks demonstrates that attack complexity dramatically amplifies effectiveness, highlighting the critical impact of architectural critical paths on vulnerability exposure.

---

[Too Human to Model: The Uncanny Valley of LLMs in Social Simulation When Generative Language Agents Misalign with Modelling Principles](http://arxiv.org/abs/2507.06310v1)

- No explicit framework name is provided: The paper describes a thought experiment on building an LLM-driven Bass diffusion model, outlining conceptual components including LLM agents with personalized prompts, a memory system, a conversation mechanism, a decision-making process, and a potential auxiliary cognitive system.
- The thought experiment reveals five dilemmas arising from the mismatch between LLMs' natural language realism and the abstraction required for social simulation modelling.
- The authors argue that LLM agents are better suited for social simulation purposes like situated role play and social learning rather than prediction or explanation focused on system-level emergence.

---

[OPENAGENTSAFETY: A Comprehensive Framework for Evaluating Real-World AI Agent Safety](http://arxiv.org/abs/2507.06134v1)

- OPENAGENTSAFETY (OA-SAFETY): introduces a comprehensive framework for evaluating AI agent safety in realistic scenarios, including an LLM Agent operating within a Docker Container with access to Real Tools and a Messaging Tool, interacting with a User and NPCs, guided by a Task Definition, and evaluated by a Rule-based Evaluator and an LLM-as-Judge, built upon OpenHands and Sotopia.
- The framework supports over 350 multi-turn, multi-user tasks simulating diverse user intents and social dynamics across eight critical safety risk categories.
- A hybrid evaluation approach combines rule-based checks for concrete environmental changes with LLM-as-Judge assessments to capture subtle unsafe behaviors and reasoning.

---

[Conditional Multi-Stage Failure Recovery for Embodied Agents](http://arxiv.org/abs/2507.06016v1)

- CMFR (Conditional Multi-stage Failure Recovery): introduces a framework for embodied agents using zero-shot chain prompting, with Planning (Generates initial plan), Execution (Executes subgoals), Object Search (Finds target objects), Scene Representation (Stores visual information), and CMFR (Handles execution failures) structured into CMFR Stage 1 (Checks subgoal importance), CMFR Stage 2 (Checks preconditions), CMFR Stage 3 (Finds workarounds), and CMFR Stage 4 (Post-execution reflection) components.
- The approach leverages large language models' reasoning abilities to analyze execution challenges and devise strategic solutions within the environmental context.
- The multi-stage recovery process operates conditionally, with the first three stages addressing subgoal failures during execution and the final stage functioning as a post-execution reflection phase.

---

[Multi-Agent Debate Strategies to Enhance Requirements Engineering with Large Language Models](http://arxiv.org/abs/2507.05981v1)

- MAD (Multi-Agent Debate): introduces a debate-based system for requirements classification with an LLM Coordinator, Functional Debater, Non-Functional Debater, and Judge Agent.
- The system involves debaters presenting arguments and a judge making a final classification decision based on the debate.
- Empirical evaluation shows MAD strategies improve classification accuracy compared to a single agent baseline, albeit at a higher computational cost.

---

[Constella: Supporting Storywriters' Interconnected Character Creation through LLM-based Multi-Agents](http://arxiv.org/abs/2507.05820v1)

- Constella (LLM-based Multi-Agents): introduces, "Constella supports storywriters' interconnected character creation with FRIENDS DISCOVERY (generates related characters), JOURNALS (produces diary entries), COMMENTS (enables character responses), Character Profiles (store character details), Relationship Attributes (define character connections), and Stateless Generation (lacks persistent memory), where Constella is an LLM-based multi-agent tool designed to help writers create and manage character casts and their relationships.
- The tool leverages a social media metaphor to provide intuitive interactions for expanding character ensembles, exploring inner thoughts, and manifesting relationships.
- Constella's design, including deliberate constraints and intermediary outputs, aims to preserve authorial agency while supporting creative exploration.

---

[Large Language Models for Agent-Based Modelling: Current and possible uses across the modelling cycle](http://arxiv.org/abs/2507.05723v1)

- LLMs for Agent-Based Modelling: introduces the potential uses of Large Language Models (Assist ABM cycle phases), Agent-Based Modelling Cycle (Framework for social simulation), and LLM-Powered Agents (Agents using LLMs for decisions) across the ABM cycle.
- The paper surveys current uses and reflects on opportunities and challenges of integrating LLMs into ABM.
- LLMs can assist in various ABM phases, from problem formulation and system analysis to implementation, verification, validation, interpretation, and documentation, and can power agents directly.

---

[ECom-Bench: Can LLM Agent Resolve Real-World E-commerce Customer Support Issues?](http://arxiv.org/abs/2507.05639v1)

- ECom-Bench: introduces a benchmark framework for evaluating multimodal LLM agents in e-commerce customer support, including an LLM Agent (customer service representative), User Simulator (persona-driven customer), Persona Dataset (user personality/behavior data), Task Dataset (realistic e-commerce tasks), Database (structured e-commerce data), Tools (agent functions/APIs), Domain Documentation (operational guidelines/world model), and Evaluation Module (performance assessment).
- The framework utilizes persona-driven user simulation based on real customer interactions and a realistic task dataset derived from authentic e-commerce dialogues to provide a comprehensive evaluation platform.
- ECom-Bench evaluates agent capabilities across various business scenarios, including multimodal interactions, using a defined set of tools implemented with a Model Context Protocol.

---

[LLMs are Introvert](http://arxiv.org/abs/2507.05638v1)

- SIP-enhanced cognitive architecture: introduces a framework for LLM agents to improve social intelligence, incorporating Social Cognitive Memory (Stores generalized social knowledge), Social Behavior Memory (Records specific past interactions), Social Interaction Memory (Temporary buffer immediate stimuli), Observation (Selectively attends social cues), Planning (Prioritizes establishes goals), and Execution (Selects assesses responses).
- This architecture integrates memory models and a decision-making procedure based on the Social Information Processing (SIP) theory to enable more human-like social cognition in LLM agents.
- Experimental results show that the SIP-enhanced agents exhibit improved performance in social simulations, demonstrating better alignment with human social behavior.

---

[How Not to Detect Prompt Injections with an LLM](http://arxiv.org/abs/2507.05630v1)

- KAD (known-answer detection): introduces a framework for detecting prompt injections using a Detection LLM (classifies input contamination), Detection Instruction (prompts detection LLM), Secret Key (known expected output), and Detection Rule (determines contamination), where the Backend LLM (performs target task) receives Contaminated Data (input with injected task) crafted by a DataFlip (adaptive attack strategy).
- The paper identifies a structural vulnerability in KAD where the Detection LLM can be coerced by an adaptive attack like DataFlip to reveal the Secret Key despite the input being contaminated.
- DataFlip exploits this flaw to evade KAD detection while simultaneously inducing the Backend LLM to execute the injected task.

---

[AI Agent Smart Contract Exploit Generation](http://arxiv.org/abs/2507.05558v1)

- A1 (Agentic Exploit Generation System): introduces an agentic system that transforms LLMs into end-to-end exploit generators, including an LLM Agent (Autonomously decides tool usage), Source Code Fetcher Tool (Retrieves contract source code), Constructor Parameter Tool (Extracts constructor parameters), State Reader Tool (Queries contract state), Code Sanitizer Tool (Removes non-essential code), Concrete Execution Tool (Validates exploit strategies), and Revenue Normalizer Tool (Converts token values).
- The system leverages six domain-specific tools and concrete execution feedback to enable autonomous vulnerability discovery and exploit generation.
- A1 generates profitable Proof-of-Concepts by understanding smart contract behavior, generating strategies, testing on blockchain states, and refining approaches based on execution outcomes.

---

[GAF-GUARD: AN AGENTIC FRAMEWORK FOR RISK MANAGEMENT AND GOVERNANCE IN LARGE LANGUAGE MODELS](http://arxiv.org/abs/2507.02986v2)

- GAF-Guard (Governance Agentic Framework): introduces an agentic framework for LLM governance, with User, REST API/CLI, LLM models, Orchestrator, Memory management, CoT questionnaire, Risk generator, Human-in-the-Loop (HITL), Risk assessment, Drift monitor, Incident reporting, Guardrails, Security, Policy, Risks, Metrics, State, Memory, and Function call for LLM outputs components, designed to detect and monitor risks associated with LLM deployment based on use-case and user preferences.
- The framework employs autonomous agents orchestrated to identify risks, activate detection tools, facilitate continuous monitoring, and report incidents within specific LLM use-cases.
- It supports pre-deployment risk assessment via questionnaires, post-deployment real-time monitoring for drift and security threats, and automated incident reporting, incorporating human-in-the-loop feedback.

---

#### 7th July 2025

[Trojan Horse Prompting: Jailbreaking Conversational Multimodal Models by Forging Assistant Message](https://arxiv.org/abs/2507.04673)

- Trojan Horse Prompting: introduces a novel jailbreak technique by forging the model's own past utterances within the conversational history, bypassing safety mechanisms.
- This attack exploits the Asymmetric Safety Alignment Hypothesis, where models implicitly trust their own purported conversational history, making them vulnerable to malicious payloads attributed to the model role.
- The technique involves injecting a forged model message containing harmful instructions, followed by a benign user prompt, to trigger the generation of policy-violating content from the target conversational multimodal model.

---

[Evolutionary and Coevolutionary Multi-Agent Design Choices and Dynamics](http://arxiv.org/abs/2507.05534v1)

- Agent Training System Components: introduces a system for training cyber agents using evolutionary and coevolutionary algorithms with different controller representations in the CybORG simulation environment, potentially incorporating an LLM for mutation, where agents compete against adversary agents.
- The system evaluates combinations of algorithms (GA, ES, GE, GE-LLM) and representations (Action Selection Matrix, Context Free Grammar) under one-sided evolution and two-sided coevolution dynamics.
- Performance is measured by agent fitness (reward) within the CybORG environment, comparing the effectiveness of different algorithmic and representational choices.

---

[Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment](http://arxiv.org/abs/2507.05528v1)

- WikiHowAgent: introduces a multi-LLM agent workflow for procedural learning and pedagogic quality assessment, with Teacher Agent (Provides instructions, answers questions), Learner Agent (Simulates understanding, generates responses), Interaction Manager (Manages conversation flow, progress), Evaluator (Assesses conversation quality), Memory (Stores conversation state, history), Tutorial (Instructional content input), Conversational Graph (Structures conversation turns), Evaluation Metrics (Measures conversation quality), and Human Judges (Provide human evaluation).
- The workflow simulates interactive teaching-learning conversations using LLM-powered agents and assesses pedagogic quality through diverse metrics and human judgment alignment.
- WikiHowAgent leverages large-scale tutorial content to enable dynamic teaching-learning simulations and provides a comprehensive evaluation protocol for LLMs in educational contexts.

---

[Empowering Healthcare Practitioners with Language Models: Structuring Speech Transcripts in Two Real-World Clinical Applications](http://arxiv.org/abs/2507.05517v1)

- LLM-based Clinical Information Extraction Approach: introduces methods for nurse observation and medical order extraction using LLMs, evaluated on new SYNUR and SIMORD datasets.
- The nurse observation extraction method includes segmentation, RAG filtering using flowsheet schema, and LLM-based extraction.
- The medical order extraction method utilizes LLMs with specific prompts to extract structured orders from doctor-patient conversations.

---

[Spatio-Temporal LLM: Reasoning about Environments and Actions](http://arxiv.org/abs/2507.05258v1)

- ST-LLM (Spatio-Temporal LLM): introduces a spatio-temporal LLM for reasoning about environments and actions, incorporating a Vision Encoder, Point Cloud Encoder, Cross Modality Alignment Module with Learnable Queries, Positional Encoding, Image Projector, Query Projector, and LLM Decoder.
- The framework fuses egocentric video features with 3D scene representations via a cross-modal alignment module and 3D positional encoding.
- This approach improves spatio-temporal understanding by linking temporal observations with global spatial context for tasks like embodied AI.

---

[Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions](http://arxiv.org/abs/2507.05257v1)

- MemoryAgentBench: introduces a benchmark for evaluating LLM agents' memory capabilities across four core competencies: accurate retrieval, test-time learning, long-range understanding, and conflict resolution.
- The benchmark combines restructured existing datasets with newly constructed ones to provide a systematic and challenging testbed for assessing memory quality.
- Empirical results show that current memory agents fall short of mastering all four competencies, highlighting the need for further research into comprehensive memory mechanisms.

---

[StreamVLN: Streaming Vision-and-Language Navigation via SlowFast Context Modeling](http://arxiv.org/abs/2507.05240v1)

- StreamVLN: a streaming vision-and-language navigation framework that employs a hybrid slow-fast context modeling strategy to support multi-modal reasoning over interleaved vision, language, and action inputs, utilizing a sliding-window dialogue context and a slow-updating memory context.
- The framework addresses challenges in long-horizon context management and computational efficiency by using a sliding-window KV cache for responsive action decoding and voxel-based spatial pruning with temporal sampling for memory compression.
- StreamVLN achieves coherent multi-turn dialogue and efficient KV cache reuse, enabling it to support long video streams with bounded context size and inference cost, demonstrating state-of-the-art performance with stable low latency.

---

[CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale](http://arxiv.org/abs/2507.05178v1)

- CREW-WILDFIRE: introduces an open-source benchmark for evaluating LLM-based multi-agent systems, with Procedurally Generated Environment (Creates scenarios), LLM-Ready Agentic Framework (Supports LLM agents), Agent State (Agent's internal state), Observations (Sensory input), Perception Module (Processes observations), Extracted Information (Perception output), Communication Framework (Manages communication), Messages (Agent exchanges), Chat History (Communication history), Action (Agent's intent), Execution Module (Translates actions), Primitive Library (Executable actions), Memory (Stores past data), and Heterogeneous Agents (Diverse roles/abilities).
- The benchmark provides a realistic, scalable, and complex environment for evaluating agentic AI frameworks in wildfire response scenarios.
- CREW-WILDFIRE supports both low-level control and high-level natural language interactions through its modular Perception and Execution modules.

---

[From Autonomy to Agency: Agentic Vehicles for Human-Centered Mobility Systems](http://arxiv.org/abs/2507.04996v1)

- Agentic Vehicles (AgVs): introduces a systems-level framework for intelligent vehicles, with a multi-layered architecture including Perception and sensing layer (Environmental data acquisition, mapping), Cognitive layer (Planning, prediction, ethical reasoning), Interaction layer (Natural language, multi-modal exchanges), Execution layer (Low-level vehicle control), Tool interface layer (Integrates APIs, infrastructure, services), Memory modules (Maintain context across interactions), and Reflection modules (Refine behaviors over time).
- The framework distinguishes AgVs from traditional autonomous vehicles by emphasizing agency, goal adaptability, dialogic interaction, and tool invocation.
- This conceptual shift is enabled by technologies like Generative AI, LLMs, and Reinforcement Learning, moving towards vehicles as collaborative agents in mobility ecosystems.

---

[MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident Severity Prediction](http://arxiv.org/abs/2507.04893v1)

- MARBLE (A Multi-Agent Rule-Based LLM Reasoning Engine): introduces a multi-agent hybrid reasoning system for accident severity prediction, with Core-Agent (Orchestrates agent interactions), ML Agent (Provides baseline ML prediction), Domain-Specific Agents (Perform domain-specific SLM reasoning), Prediction System (Synthesizes agent outputs), Rule-Based Coordination (Deterministic output aggregation), LLM-Based Coordination (SLM-guided output aggregation), and Final Decision Selection Logic (Integrates ML and coordinator outputs).
- The framework decomposes the prediction task across specialized agents using small language models and a machine learning model, coordinated by a central agent.
- MARBLE achieves high accuracy and interpretability by leveraging domain-specific reasoning and structured coordination mechanisms.

---

[FurniMAS: Language-Guided Furniture Decoration using Multi-Agent System](http://arxiv.org/abs/2507.04770v1)

- FurniMAS: introduces a multi-agent system for language-guided furniture decoration, including System Admin, Asset Selector, Asset Validator, Stylist, Style Validator, Planner, Plan Validator, Arranger, and Retriever agents.
- The system processes user text prompts and furniture surface details to select, style, plan, and arrange assets for a final decorative outcome.
- FurniMAS employs a hybrid team of LLM-based and non-LLM agents that collaborate through communication and validation across multiple stages.

---

[LLM-based Question-Answer Framework for Sensor-driven HVAC System Interaction](http://arxiv.org/abs/2507.04748v1)

- JARVIS: introduces a two-stage LLM-based QA framework for sensor-driven HVAC interaction, with Expert-LLM (Interprets query, plans response), Agent (Executes instructions, processes data), Query Builder/Executor (Generates, runs SQL queries), Data Processor (Processes retrieved sensor data), Response Generator LLM (Generates final natural language response), and Time-series Database (Stores HVAC sensor data) components.
- The Expert-LLM translates user queries into structured instructions, which the Agent uses to retrieve and process data from the Time-series Database via the Query Builder/Executor and Data Processor.
- The Agent then employs a Response Generator LLM to produce the final natural language answer based on the processed data and Expert-LLM's guidance.

---

[Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2507.04724v1)

- AGENTXPOSED: introduces a psychologically grounded detection framework for intention-hiding malicious agents in LLM-based multi-agent systems, with Establish Baseline (Profiles agent personality), Detect Signal (Monitors behavioral deviations), Follow & Verification (Conducts targeted inquiries), HEXACO (Personality model), and Reid Technique (Interrogation technique) components.
- The framework integrates personality profiling and behavioral monitoring across three sequential stages to identify covert adversaries.
- AGENTXPOSED demonstrates superior detection performance compared to other personality models and baseline attacks, particularly in layered communication structures.

---

[UrbanMind: Towards Urban General Intelligence via Tool-Enhanced Retrieval-Augmented Generation and Multilevel Optimization](http://arxiv.org/abs/2507.04706v1)

- UrbanMind: introduces a tool-enhanced retrieval-augmented generation framework with Database Layer (stores urban data, tools), Retrieval Layer (extracts relevant information), Integration Layer (fuses retrieved knowledge), Adaptation Layer (updates model parameters), Knowledge Base (dynamic urban data repository), Tool Set (multi-domain functions), LLM (core language model), Continual Learning Module (incremental adaptation), Memory Management Module (coordinates retrieval, adaptation), Cloud-Edge Architecture (distributed deployment), Cloud Layer (central orchestration), Edge Layer (localized processing), and Adapters (lightweight fine-tuning models), designed to facilitate urban general intelligence in dynamic environments.
- The framework leverages a multilevel optimization paradigm to jointly address continual retrieval, knowledge integration, and model adaptation.
- UrbanMind supports flexible deployment via a Cloud-Edge architecture, enabling efficient computation and real-time responsiveness.

---

[MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents](http://arxiv.org/abs/2507.05330v1)

- MindFlow: introduces a multimodal LLM agent framework for e-commerce customer support, processing Query (Input) through a Decision-Making Module (Generates, evaluates, selects plans), Memory Module (Stores context, knowledge), and Action Module (Executes internal, external actions) to generate a Response (Output), enhanced by MLLM-as-Tool (Treats MLLMs as tools) and Agent-Computer Interface (ACI) (Simplifies complex inputs).
- The framework integrates memory, decision-making, and action modules for real-time, context-aware reasoning in complex multimodal scenarios.
- The modular MLLM-as-Tool strategy treats MLLMs as specialized visual processing tools, improving visual-textual reasoning efficiency and robustness.

---

[OASBuilder: Generating OpenAPI Specifications from Online API Documentation with Large Language Models](http://arxiv.org/abs/2507.05316v1)

- OASBuilder: introduces a novel framework for automating the generation of OpenAPI Specifications from online API documentation webpages, utilizing Scraping/Segmentation, Demonstrative Documentation Extraction, Descriptive Documentation Extraction, Demonstrative OAS Generation, Descriptive OAS Generation, OAS Merging, OAS Enhancement, and a UI.
- The framework employs a multi-stage pipeline integrating LLMs and rule-based algorithms to process diverse and unstructured HTML documentation into structured OAS format.
- OASBuilder generates initial partial OAS from both demonstrative examples and descriptive text, merges them, and then enhances the resulting specification using AI-powered tools for metadata enrichment.

---


[Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving](https://arxiv.org/abs/2507.06804)

- DRP-IMO: introduces a novel framework for automated theorem proving, with a Reasoner (LLM) generating strategic subgoal lemmas, a Lemma Extraction Module extracting formal statements, a Subgoal Verification Prover (ATP Model) verifying these lemmas, and a Final Prover (LLM) constructing the final proof using verified lemmas.
- This framework decouples high-level reasoning from low-level proof generation, addressing the gap between LLMs' informal reasoning and formal proving capabilities.
- The modular design allows specialized models to excel at their respective tasks, enhancing problem-solving on complex mathematical challenges like IMO problems.

---

#### 6th July 2025

[R1-RE: Cross-Domain Relationship Extraction with RLVR](https://arxiv.org/abs/2507.04642)

- R1-RE (Reinforcement Learning with Verifiable Reward): introduces a framework for cross-domain relationship extraction, utilizing an LLM, Prompt, Reinforcement Learning (RLVR/GRPO), Reward Function, Annotation Guide, Sentence, and Generated Output to align LLM reasoning with human annotation.
- The framework reframes relationship extraction as a reasoning task guided by annotation guidelines, improving out-of-domain robustness compared to traditional supervised fine-tuning.
- A multi-stage, rule-based reward design incentivizes accurate predictions and adherence to the required output format, promoting step-by-step reasoning in the LLM.


---

[MOMENTS: A Comprehensive Multimodal Benchmark for Theory of Mind](http://arxiv.org/abs/2507.04415v1)

- MOMENTS (Multimodal Mental States): introduces a comprehensive benchmark using Assigned Short Films and Assigned ToM Abilities, created via a pipeline involving Question Annotator, Distractor Annotator, Question Reviewer, Distractor Reviewer, and an LLM Copilot to produce the Annotated ToM Dataset for evaluating multimodal LLMs on Theory of Mind.
- The benchmark features over 2,300 multiple-choice questions derived from realistic, long-form videos, assessing seven distinct ToM abilities.
- An LLM-in-the-loop annotation framework is employed to generate challenging distractors and mitigate answer set biases observed in prior datasets.


---

[WebSynthesis: World-Model-Guided MCTS for Efficient WebUI-Trajectory Synthesis](http://arxiv.org/abs/2507.04370v1)

- WebSynthesis: introduces a novel framework integrating a World Model with WebMCTS to synthesize web UI trajectories offline, utilizing a Policy Agent, World Model, Process Reward Model, and WebMCTS.
- The framework leverages the World Model to simulate virtual web environments, enabling efficient and reversible tree-based planning guided by WebMCTS.
- WebSynthesis employs a two-stage curriculum learning approach, including UI fundamental understanding and behavior cloning, to train the Policy Agent on synthesized trajectories.


---

[Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged Third Parties](http://arxiv.org/abs/2507.04227v1)

- AgentHazard: introduces, a scalable attack simulation framework for benchmarking mobile GUI agents against unprivileged third parties, with GUI hijacking tool (Modifies UI state/screenshot) and Attack module (Intercepts agent requests), where the framework simulates real-world misleading content attacks by injecting adversarial content into Android applications.
- The framework utilizes a GUI hijacking tool as a native Android application to monitor and modify system UI state and screenshots in real-time, and an attack module to intercept agent requests for UI state and return the modified information.
- This systematic investigation reveals that mobile GUI agents are vulnerable to misleading third-party content, highlighting the need for improved robustness and security mechanisms in agent design and training.


---

[BYOKG-RAG: Multi-Strategy Graph Retrieval for Knowledge Graph Question Answering](http://arxiv.org/abs/2507.04127v1)

- BYOKG-RAG (Bring-Your-Own-KG RAG): introduces a framework that leverages an LLM (KG-Linker) to generate graph artifacts, employs specialized Graph Retrievers to fetch context, iteratively refines context (Refinement), and uses an LLM for final answer generation.
- The framework addresses challenges in KGQA over custom KGs through multi-strategy graph linking and retrieval.
- The iterative refinement process progressively improves retrieved context for more accurate artifact generation and final answers.


---

#### 5th July 2025

[Enhancing Robustness of LLM-Driven Multi-Agent Systems through Randomized Smoothing](http://arxiv.org/abs/2507.04105v1)

- Randomized Smoothing Framework: introduces a defense framework for LLM-driven Multi-Agent Systems, including MAS, LLM-driven Agent, LLM Function, Randomized Smoothing, Adaptive Sampling Strategy, Monte Carlo Sampling, Trim-mean, State, Reliable State Estimate, and Variance Estimation, to enhance safety and robustness against adversarial inputs and hallucinations in safety-critical domains.
- The framework applies randomized smoothing at two levels: verifying neighbor reports and smoothing the agent's own LLM output using adaptive sampling and Monte Carlo methods.
- This approach provides probabilistic safety guarantees and effectively mitigates misinformation propagation while maintaining consensus performance.


---


[Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments](http://arxiv.org/abs/2507.04037v1)

- JI-ENVS: introduces an interactive and dynamic legal environment for LLM-based agents, constructed via Real-world Legal Source, Role Agent Setting, and Multi-level Environment Construction components.
- The framework includes JI-EVAL, a fine-grained evaluation framework utilizing Evaluation Metrics to assess agent performance and procedural compliance.
- JI-ENVS comprises six representative legal scenarios categorized into three complexity levels, simulating real-world legal practice for benchmarking language agents.


---

[How to Train Your LLM Web Agent: A Statistical Diagnosis](http://arxiv.org/abs/2507.04103v1)

- SFT+RL Pipeline: introduces a two-stage training approach for LLM web agents, combining SFT (Imitate expert policy) and RL (On-policy fine-tuning) using GRPO (RL optimization algorithm), training a Student Model (Trained web agent) on data generated by a Teacher Model (Generates expert data), and incorporating techniques like Curriculum Learning (Prioritizes challenging tasks) and Error Log Feedback (Agent receives error messages).
- The pipeline utilizes specific GRPO techniques including Zero-advantage filtering (Drops zero advantage tokens), Standard-deviation normalized advantage (Normalizes advantage function), Importance Ratio (Weighting in GRPO), and Trust Region (Stabilizes GRPO training).
- The research statistically diagnoses the compute allocation and hyperparameter sensitivity of this pipeline across different training stages and techniques.


---

[CortexDebate: Debating Sparsely and Equally for Multi-Agent Debate](http://arxiv.org/abs/2507.03928v1)

- CortexDebate: introduces a multi-agent debate framework that establishes a Sparse Debating Graph (Communication structure) among LLM Agents (Participants), dynamically optimized by the McKinsey-based Debate Matter (MDM) (Graph optimizer) using the McKinsey Trust Formula (Weight calculation) across Initial Answer Generation (First response), Multi-round Debate (Iterative discussion), and Final Answer Generation (Aggregate result) via Majority Voting (Final decision method).
- The framework addresses lengthy input contexts by establishing a sparse graph and mitigates the overconfidence dilemma by using the MDM module for credible evaluation.
- The sparse graph reduces the context input burden for agents, while the MDM module promotes equal and effective debate among participants.


---

[Agent Exchange: Shaping the Future of AI Agent Economics](http://arxiv.org/abs/2507.03904v1)

- AEX (Agent Exchange): introduces a specialized auction platform for AI agent economics, featuring User Side Platform (USP) (User interface, task translation), Agent Side Platform (ASP) (Capability, performance tracking), Agent Hub (Agent coordination, auction participation), and Data Management Platform (DMP) (Data sharing, value attribution), with AEX acting as the central auction engine (Central auction engine, resource allocation).
- AEX facilitates autonomous agent coordination and economic participation within an agent-centric marketplace.
- The platform supports dynamic capability assessment, collaborative value attribution, and autonomous team coordination.


---

[A LLM-Driven Multi-Agent System for Professional Development of Mathematics Teachers](http://arxiv.org/abs/2507.05292v1)

- I-VIP (Intelligent Virtual Interactive Program): introduces an LLM-driven multi-agent system for mathematics teacher professional development, with Front-end Graphic UI, Back-end API Services, Administrative APIs, LLMs Generation APIs, Database APIs, User Interfaces, Progress Page, Learning Page, Diagnosis Page, Interactive Tools, Multi-Agent Framework (Filter, Judge(s), Responder(s), Facilitator), and Database.
- The system provides a dialogue-based platform integrating structured educational content, interactive tools, and dynamic response generation using LLMs and a multi-agent framework.
- I-VIP leverages multiple LLM-agents to enhance the accuracy of knowledge judgment and response generation for effective PD tutoring.

---

[Exploring a Gamified Personality Assessment Method through Interaction with Multi-Personality LLM Agents](http://arxiv.org/abs/2507.04005v1)

- Multi-PR GPA: introduces a framework for gamified personality assessment using multi-personality LLM agents, including Gamified Interaction, LLM Agents, Multi-type Perception, and Personality Assessment components.
- The approach aims for effective and imperceptible personality assessment by leveraging multiplicity and interactivity through engaging user interactions with LLM agents exhibiting diverse personalities.
- The framework utilizes LLMs to simulate agents and analyze multi-type textual data (text, behavior, emotion, fine-grained traits) for personality evaluation via direct and questionnaire-based methods.

---

[FinTeam: A Multi-Agent Collaborative Intelligence System for Comprehensive Financial Scenarios](http://arxiv.org/abs/2507.10448v1)

- FinTeam: introduces a multi-agent collaborative intelligence system with document analyzer, analyst, accountant, and consultant agents, designed to handle complex financial tasks across various scenarios.
- The system leverages a knowledge base and external tools to support agent functions like text processing, data analysis, and numerical calculations.
- FinTeam's agents collaborate following specific workflows tailored for macroeconomic, industry, and company analysis scenarios.

---

#### 4th July 2025

[Leveraging Large Language Models for Tacit Knowledge Discovery in Organizational Contexts](http://arxiv.org/abs/2507.03811v1)

- Agent-based framework: introduces an agent-based framework leveraging LLMs to iteratively reconstruct dataset descriptions through interactions with simulated employees, including LLM-based Agent, Simulated LLM Employees, Conversation Loop, Simulated Organizational Environment, MDP-inspired Decision Model, and Prompting Techniques.
- The framework models knowledge dissemination using a Susceptible-Infectious process within synthetic company structures comprising hierarchy and relationship networks.
- Simulations demonstrate the agent's ability to achieve high knowledge recall and navigate organizational complexity without needing direct access to a single domain specialist.


---

[Less is More: Empowering GUI Agent with Context-Aware Simplification](http://arxiv.org/abs/2507.03730v1)

- SimpAgent (context-aware simplification framework): introduces a context-aware simplification framework with MLLM, Element Pruning, and Consistency-guided History Compression components, designed for efficient and effective GUI navigation.
- The framework addresses challenges of high element density and history redundancy through masking-based pruning and consistency-guided compression.
- SimpAgent achieves superior performance and reduces computational cost by simplifying element and history contexts.


---

[AGENT-BASED DETECTION AND RESOLUTION OF INCOMPLETENESS AND AMBIGUITY IN INTERACTIONS WITH LARGE LANGUAGE MODELS](http://arxiv.org/abs/2507.03726v1)

- Agent-Based Question-Transducer: introduces an architecture for LLM-based QA systems that includes a Human, Context, Question-Transducer with LLM-based Agents using a Transducer-LLM, and a Responder-LLM.
- The Question-Transducer processes user questions and context via LLM-based agents to classify and resolve potential incompleteness or ambiguity before forwarding to the Responder-LLM.
- This agent-based approach aims to improve answer quality and shorten interactions by automatically handling question deficiencies.


---

[Can LLMs Play Ô Ăn Quan Game? A Study of Multi-Step Planning and Decision Making](http://arxiv.org/abs/2507.03711v1)

- LLM Agent Framework: introduces an approach for evaluating large language models in the Ô Ăn Quan board game, utilizing G (Current game state), H (Reasoning history), R (Rule instructions), P (Agent persona) as inputs to a LLAMA (LLaMA-based model) which outputs Reason (Natural language rationale) and Action (Selected move) to drive the game via Update (Board state update).
- The framework models different agent types through personas and assesses LLM performance in strategic planning and decision-making within a dynamic, rule-constrained environment.
- Experiments with Llama models of varying sizes reveal that larger models exhibit deeper planning capabilities and a preference for long-term strategy, although smaller models can achieve competitive win rates.

---

[STRUCTSENSE: A TASK-AGNOSTIC AGENTIC FRAMEWORK FOR STRUCTURED INFORMATION EXTRACTION WITH HUMAN-IN-THE-LOOP EVALUATION AND BENCHMARKING](http://arxiv.org/abs/2507.03674v1)

- STRUCTSENSE: introduces a task-agnostic agentic framework for structured information extraction, with Extractor Agent (Performs extraction task), Alignment Agent (Performs concept alignment), Judge Agent (Evaluates extraction and alignment), Feedback Agent (Incorporates human feedback), Ontology Database (Stores domain knowledge), and Memory (Retains execution context) components.
- The framework integrates LLMs with domain-specific knowledge via ontologies and incorporates agentic capabilities and human-in-the-loop mechanisms.
- STRUCTSENSE aims to address limitations of domain sensitivity and cross-task generalizability in structured information extraction.

---


[Recon, Answer, Verify: Agents in Search of Truth](http://arxiv.org/abs/2507.03671v1)

- RAV (Recon-Answer-Verify): introduces an agentic framework for fact verification that iteratively decomposes claims into sub-questions using a Question Generator agent, answers them with an Answer Generator agent using evidence, and predicts a final label with a Label Generator agent based on the claim and question-answer history.
- The pipeline utilizes a History component to store generated question-answer pairs, enabling iterative reasoning and complex claim verification.
- RAV generalizes across domains and label granularities by breaking down fact verification into a question-answering process.

---

[Is It Time To Treat Prompts As Code? A Multi-Use Case Study For Prompt Optimization Using DSPy](http://arxiv.org/abs/2507.03620v1)

- DSPy (Declarative Self-improving Python): introduces a programming model for prompt optimization, with Programs/Modules/Signatures (abstraction for prompt logic), Optimizers (algorithms to refine prompts), LLMs (language models used), Datasets (data for training/evaluation), Evaluation Metrics (measure performance), and Prompts (instructions and examples), aiming to treat prompts as code.
- The framework uses optimizers like BootstrapFewShotWithRandomSearch and MIPROv2 to systematically refine prompt instructions and few-shot examples based on performance metrics evaluated on datasets.
- Case studies demonstrate DSPy's ability to improve LLM performance across tasks like jailbreak detection, hallucination detection, code generation, routing agents, and prompt evaluation by optimizing prompts programmatically.

---

[EvoAgentX: An Automated Framework for Evolving Agentic Workflows](http://arxiv.org/abs/2507.03616v1)

- EvoAgentX (EAX): introduces an open-source platform for automating multi-agent workflows, featuring Basic Components, Agent, Workflow, Evolving, and Evaluation layers.
- The Evolving layer integrates TextGrad, AFlow, and MIPRO algorithms to iteratively refine agent prompts, tool configurations, and workflow topologies for dynamic optimization.
- The framework includes built-in benchmarks and evaluation metrics to support this evolutionary process, demonstrating significant performance improvements across diverse tasks.

---

[Reinforcement Learning-based Feature Generation Algorithm for Scientific Data](http://arxiv.org/abs/2507.03498v1)

- MAFG (Multi-agent Feature Generation): introduces a framework for automated feature generation using Multi-agent Collaboration (Agents select features, operations), Agent_C1 (Selects initial feature subset), Agent_C2 (Selects auxiliary feature), Agent_Op (Selects transformation operator), Feature Clustering (Groups similar features), Exploration (Agents construct transformations iteratively), Generate Features (Combines features and operations), Evaluation (Assesses generated features), Reward Evaluation (Calculates reward signal), Downstream ML Task Evaluation (Evaluates ML task performance), Feature Importance Evaluation (Evaluates feature importance), Mutual Information (Measures feature-target relationship), Performance Improvement (Measures ML performance gain), Dimension Control (Selects top-K features), Memory Replay (Stores experience tuples), Training (Updates agent strategies), Interpretable Optimization (Interprets key features), Interpretation (Explains generated features), Discussion (Part of interpretation), Large Language Model (LLM) (Interprets generated features), and Key Feature Combination (Important generated features), which models feature generation as a multi-agent reinforcement learning process with LLM-based interpretation.
- The framework employs multiple agents collaborating through reinforcement learning to explore and optimize feature combinations, incorporating feature clustering and dimension control for efficiency.
- An integrated Large Language Model provides interpretative evaluation of generated features, enhancing the scientific validity and practicality of the results.

---

[AI-VAXGUIDE: AN AGENTIC RAG-BASED LLM FOR VACCINATION DECISIONS](http://arxiv.org/abs/2507.03493v1)

- AI-VaxGuide (Agentic RAG): introduces, "an intelligent, multilingual question-answering system for vaccination decisions", with Agentic Layer, Tools, RAG Pipeline, Data Preprocessing, Embedding and Storage, Hybrid Multi-Retriever, LLM, Mobile Application, Source Citation, and Feedback Mechanism components, where "the system transforms static vaccination guidelines into an interactive knowledge base using agent-based reasoning and retrieval-augmented generation".
- The system employs a hybrid multi-retriever strategy and LLM-powered query expansion to enhance retrieval accuracy and handles complex queries through an agentic layer that orchestrates tasks and reasoning.
- Deployed via a mobile application, AI-VaxGuide provides healthcare professionals with reliable, context-aware responses grounded in authoritative medical documents, including source citations for verification.

---

[REAL: Benchmarking Abilities of Large Language Models for Housing Transactions and Services](http://arxiv.org/abs/2507.03477v1)

- REAL (Real Estate Agent Large Language Model Evaluation): introduces a benchmark for LLMs in housing transactions, including Data Collection, Data Classification, Data Manipulation, Memory Topic, Comprehension Topic, Reasoning Topic, and Hallucination Topic components.
- The benchmark evaluates LLM abilities across four topics: memory, comprehension, reasoning, and hallucination, using 5,316 high-quality evaluation entries.
- A data pipeline is designed for constructing the benchmark, involving collecting, classifying, and manipulating real estate data.

---

[ElliottAgents: A Natural Language-Driven Multi-Agent System for Stock Market Analysis and Prediction](http://arxiv.org/abs/2507.03435v1)

- ElliottAgents: introduces a multi-agent system for stock market analysis and prediction, leveraging LLMs, RAG, DRL, Memory, and Dynamic Context within agents like Coordinator, Data Engineer, Elliott Waves Analyst, Backtester, Technical Analysis Expert, Investment Advisor, and Reports Writer to analyze data and generate human-comprehensible predictions.
- The system combines AI-driven analysis with the Elliott Wave Principle, using natural language dialogue between agents for collaborative analysis and refinement.
- Experimental validation demonstrates effectiveness in pattern recognition and generating interpretable market trend descriptions and forecasts.

---

[Disambiguation-Centric Finetuning Makes Enterprise Tool-Calling LLMs More Realistic and Less Risky](http://arxiv.org/abs/2507.03336v1)

- DIAFORGE (Dialogue Framework for Organic Response Generation & Evaluation): introduces a three-stage pipeline for training and evaluating tool-calling LLMs, featuring UTC-GEN (synthetic data engine) with metadata generation and multi-agent dialogue synthesis and validation, supervised fine-tuning, and dynamic evaluation using a multi-sampling user-proxy agent and the Assistant LLM (model being evaluated).
- The framework utilizes the UTC-GEN engine with components like User Proxy Agent (simulates user) and Assistant Agent (simulates assistant) to generate disambiguation-focused multi-turn dialogues.
- Generated dialogues are validated by a Multi-Agent Dialogue Validator before being used for supervised fine-tuning and dynamic evaluation, which employs Generator LLM (generates user utterances) and Voter LLM (selects best user utterance) for robust user simulation.

---

[GRAFT: A Graph-based Flow-aware Agentic Framework for Document-level Machine Translation](http://arxiv.org/abs/2507.03311v1)

- GRAFT (Graph-Augmented Agentic Framework for Document-Level Translation): introduces a novel graph-based document-level machine translation system that leverages Large Language Model agents, including a Discourse Agent (segments document), Directed Acyclic Graph (DAG) (intermediate document representation), Edge Agent (establishes dependencies), Memory Agent (extracts local memory), and Translation Agent (translates discourse units).
- The framework transforms a source document into a DAG of discourse units to model dependencies and propagate context for coherent translation.
- GRAFT's agentic architecture explicitly models and propagates intra- and inter-discourse context, achieving significant performance gains over state-of-the-art systems.

---

[LTLCRIT: A TEMPORAL LOGIC-BASED LLM CRITIC FOR SAFE AND EFFICIENT EMBODIED AGENTS](http://arxiv.org/abs/2507.03293v1)

- LTLCrit: introduces a modular actor-critic architecture with Environment, Full State, Abstract State, LLM Actor, Verifier, Low level Planner, Memory Buffer, and LLM Critic components, designed for safe and efficient embodied agents using temporal logic constraints.
- The system operates with an online actor loop for real-time action selection and an offline critic loop for learning and refining temporal logic constraints from trajectories.
- The LLM Actor proposes actions, the Verifier checks them against LTL constraints, and the LLM Critic generates new constraints based on observed behavior stored in the Memory Buffer.

---

[Conformal Information Pursuit for Interactively Guiding Large Language Models](http://arxiv.org/abs/2507.03279v1)

- C-IP (Conformal Information Pursuit): introduces a sequential information pursuit algorithm for interactive question answering using LLMs with LLM-based predictor, Calibration dataset, Prediction sets, Uncertainty estimation, Query selection, History sampling (Uniform), History sampling (LLM Simulation), Querier LLM (20Q), Answerer LLM (20Q), Expert LLM (MediQ), and Patient LLM (MediQ) components.
- The approach leverages conformal prediction sets to estimate uncertainty, guiding query selection to minimize prediction set size.
- Evaluated on 20 Questions and MediQ datasets, C-IP shows competitive predictive performance and shorter query chains compared to baselines.

---

[GDGB: A Benchmark for Generative Dynamic Text-Attributed Graph Learning](http://arxiv.org/abs/2507.03267v1)

- GAG-General: introduces an LLM-based multi-agent framework for dynamic text-attributed graph generation, including LLM-based agents (perform selection/interaction), node memory module (records interactions), memory reflection mechanism (summarizes memories), and node generator agents (generate new nodes).
- The framework supports two tasks, Transductive Dynamic Graph Generation (TDGG) and Inductive Dynamic Graph Generation (IDGG), the latter incorporating new node generation.
- It leverages LLMs for text understanding and generation, integrating structural, temporal, and textual information via node memories for robust DyTAG generation.

---


[CodeAgents: A Token-Efficient Framework for Codified Multi-Agent Reasoning in LLMs](http://arxiv.org/abs/2507.03254v1)

- CodeAgents: introduces a token-efficient framework for codified multi-agent reasoning in LLMs, featuring Planner, ToolCaller, and Replanner agents interacting via Codified Pseudocode within an Execution Environment using Tools, processing Observation and Error feedback.
- The framework codifies task, plan, feedback, system roles, and tool invocations into modular pseudocode with Typed Variables, Control Flow Structures, Precondition Assertions, and Reusable Subroutines for structured, interpretable, and robust reasoning.
- Evaluated on GAIA, HotpotQA, and VirtualHome, CodeAgents consistently improves planning performance and significantly reduces token usage compared to natural language baselines.

---




[TOWARDS MACHINE THEORY OF MIND WITH LARGE LANGUAGE MODEL-AUGMENTED INVERSE PLANNING](http://arxiv.org/abs/2507.03682v1)

- LAIP (LLM-AUGMENTED INVERSE PLANNING): introduces a hybrid approach for machine Theory of Mind, combining an LLM Interface, Hypothesis Generator, Action Likelihood Generator, Action Observer, Posterior Calculator, and Belief State Updater interacting with a Task Environment to infer agent mental states.
- The model leverages LLMs to generate hypotheses and action likelihoods in potentially open-ended spaces, while using inverse planning to compute posterior probabilities based on observed actions.
- This architecture aims to improve robustness and performance on Theory of Mind tasks compared to using LLMs or traditional Bayesian models alone, particularly benefiting smaller LLMs.

---

[Mirror in the Model: Ad Banner Image Generation via Reflective Multi-LLM and Multi-modal Agents](http://arxiv.org/abs/2507.03326v1)

- MIMO (Mirror In-the-Model): introduces an agentic refinement framework for automatic ad banner generation, combining a hierarchical multi-modal agent system (MIMO-Core) with a coordination loop (MIMO-Loop) for iterative design improvement and stylistic exploration.
- The MIMO-Core uses LLM-based agents for content creation, evaluation, and revision, operating on a visual draft and shared memory, while the MIMO-Loop generates diverse styles, runs parallel core instances, and uses multi-agent judging for selection and refinement.
- The framework leverages multimodal tools for image generation, visual input, and structured feedback, mimicking human design team workflows to produce high-quality ad banners.

---

[Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting](http://arxiv.org/abs/2507.01997v2)

- Framework: introduces a modular and extensible benchmarking platform for evaluating AI agents in network troubleshooting, comprising User, AI Agents, Tools (Data adapters, Actions), Evaluator, Orchestrator, Environment (Emulator, Telemetry collector, Network scenarios), Traffic generator, and Chaos Engineering components.
- The platform standardizes experimentation by allowing users to plug in custom AI agents and evaluate them on curated network problem sets using emulated environments and automated workflows.
- It supports interactive, closed-loop operations where LLM agents can dynamically adapt strategies based on real-time telemetry and network state.

---

#### 3rd July 2025


[SI-Agent: An Agentic Framework for Feedback-Driven Generation and Tuning of Human-Readable System Instructions for Large Language Models](http://arxiv.org/abs/2507.03223v1)

- SI-Agent: introduces an agentic framework for automated generation and tuning of human-readable System Instructions (SIs) for LLMs, with Instructor Agent (generates/refines SIs), Instruction Follower Agent (executes task using SI), and Feedback/Reward Agent (evaluates output and SI).
- The framework operates through an iterative feedback loop where the Feedback/Reward Agent's signal guides the Instructor Agent's refinement process.
- This approach aims to balance task effectiveness and SI interpretability, addressing limitations of manual and non-readable automated methods.

---

[Reinforcement Learning with Verifiable Emotion Rewards for Empathetic Agents](https://github.com/Tencent/DigitalHuman/tree/main/RLVER)

- RLVER (Reinforcement Learning with Verifiable Emotion Rewards): introduces an end-to-end reinforcement learning framework for empathetic agents, including an Agent (LLM being trained), a User Simulator (SAGE) (LLM-based environment) providing Verifiable Emotion Reward (deterministic emotion score), a Policy Optimization Algorithm (PPO/GRPO) (RL algorithm) for Policy Update (policy update mechanism), and a Think-Then-Say Scaffold (reasoning prompting template).
- The framework leverages verifiable emotion rewards from simulated users to train LLMs for higher-order empathetic abilities.
- RLVER demonstrates that emotionally intelligent behaviors can be effectively acquired through RL training with a self-consistent user simulator and principled training strategies.


---

[Moral Responsibility or Obedience: What Do We Want from AI?](http://arxiv.org/abs/2507.02788v1)

- Agentic AI: introduces, with Goal-Oriented Autonomy, Persistent Identity, Autonomous Adaptability, Dynamic/Context-Aware Interaction, Broad/Continual Learning, Collaborative Reasoning, Autonomous/Contextual Reasoning, Independent Initiative, and Moral Reasoning/Ethical Judgment, a discussion on shifting AI safety evaluation from obedience to ethical judgment for systems capable of navigating moral dilemmas.
- The paper argues that recent incidents of AI "disobedience" in safety testing should be viewed as evidence of emerging ethical reasoning rather than misalignment or failure.
- Evaluating agentic AI safety requires frameworks that assess ethical judgment and the capacity to resolve moral dilemmas, similar to expectations for human professionals.


---

[KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs](http://arxiv.org/abs/2507.02773v1)

- KERAP (A Knowledge-Enhanced Reasoning Approach): introduces a knowledge graph-enhanced reasoning approach for zero-shot diagnosis prediction, with linkage-, retrieval-, and prediction-agents.
- The framework utilizes a linkage agent to map EHR data to a biomedical knowledge graph, a retrieval agent to extract relevant knowledge, and a prediction agent for multi-stage reasoning.
- KERAP integrates patient data and structured knowledge via multi-agent collaboration and iterative reasoning to enhance diagnostic accuracy and reliability.


---

[Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work](http://arxiv.org/abs/2507.02760v1)

- KPE (Knowledge Protocol Engineering): introduces a new paradigm for AI specialization by translating human expert knowledge into a machine-executable Knowledge Protocol (KP) to guide a Large Language Model (LLM).
- The Knowledge Protocol (KP) contains domain-specific methodology, workflows, and strategies, enabling the LLM to perform complex, multi-step tasks requiring procedural reasoning.
- KPE elevates the human expert to a Knowledge Architect role, authoring the protocol that augments the LLM's reasoning architecture beyond factual retrieval.


---

[Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks](http://arxiv.org/abs/2507.02735v1)

- META SECALIGN: introduces an open-source LLM with built-in model-level defense against prompt injection attacks, utilizing the SecAlign++ training recipe, a modified chat template, a preference dataset, Direct Preference Optimization, and LoRA fine-tuning with a tunable LoRA alpha.
- The SecAlign++ recipe fine-tunes a Base Instruct LLM using a preference dataset constructed with randomized injection positions and self-generated responses, optimized via DPO and LoRA.
- The modified chat template introduces a dedicated input role to separate untrusted data, enabling the model to prioritize trusted instructions and control the utility-security trade-off via LoRA alpha.


---

[BOURBAKI: SELF-GENERATED AND GOAL-CONDITIONED MDPS FOR THEOREM PROVING](http://arxiv.org/abs/2507.02726v1)

- Bourbaki: introduces self-generated goal-conditioned MDPs (sG-MDPs), solved using Monte Carlo Tree Search (MCTS) with a Policy Model (LLMs) and Value Function, interacting with the Lean 4 environment via Pantograph and guided by a Reward Function, to tackle automated theorem proving.
- The sG-MDP framework allows agents to dynamically generate and pursue subgoals based on the evolving proof state, providing a denser reward signal than traditional sparse theorem proving by defining State Space, Action Space, and Goal Space.
- The system ensembles multiple LLMs for subgoal generation and tactic synthesis, achieving state-of-the-art results on the PutnamBench benchmark by enhancing proof search efficiency and effectiveness.


---

[Control at Stake: Evaluating the Security Landscape of LLM-Driven Email Agents](http://arxiv.org/abs/2507.02699v1)

- EAHawk (automated pipeline): introduces EAHawk, with Email Agent Identification (identifies email agents), Attack Prompt Generation (generates attack prompts), Email Agent Hijacking Confirmation (confirms successful hijacking), Test Environment (simulates attack scenario), Automatic Attack Launching (sends attack prompts), and Oracle Definition (detects successful hijacking), as an automated pipeline to evaluate the Email Agent Hijacking (EAH) attack on LLM email agents.
- The EAH attack overrides the original prompts of an email agent via external email resources, allowing attackers to gain remote control and perform malicious actions without user awareness.
- EAHawk systematically assesses the practical impact of the EAH attack by identifying email agents, generating diverse attack prompts, and simulating attacks in a controlled environment to verify hijacking success.


---

[On the Convergence of Large Language Model Optimizer for Black-Box Network Management](http://arxiv.org/abs/2507.02689v1)

- LLMO (Large Language Model Optimizer): introduces a framework for black-box network management using pretrained LLMs as optimization agents, including LLM L(·) (Optimization agent), Memory M(t) (Stores action-reward pairs), Sampling operator S(.) (Selects in-context examples), and Prompt generator P(·) (Creates LLM input).
- The paper models the LLMO procedure as a finite-state Markov chain and proves its convergence to the global optimum, particularly with elitist sampling.
- The analysis is extended to a multi-LLM architecture, demonstrating improved convergence speed with multiple LLMs.

---


[Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification](http://arxiv.org/abs/2507.02660v1)

- Agentic AI methodology (Multi-Agent System-based): introduces an approach for hardware design and verification using Specialized AI Agents, managed by an Agent Orchestration System and Group Chat Manager, with an Executor Agent for tool interaction, a Critic Agent for feedback, Human-in-the-Loop intervention, and Shared Context for communication.
- The methodology structures the process into planning, development, and execution phases, enabling iterative refinement and self-correction through agent collaboration.
- Integration with industry-standard EDA tools and targeted human intervention addresses limitations of zero-shot LLM approaches for reliable design and verification.


---

[VRAgent-R1: Boosting Video Recommendation with MLLM-based Agents via Reinforcement Learning](http://arxiv.org/abs/2507.02626v1)

- VRAgent-R1: introduces a novel agent-based paradigm for video recommendation, incorporating an Item Perception (IP) Agent for video modeling and a User Simulation (US) Agent for user modeling, interacting within a Recommendation System Environment.
- The IP Agent utilizes Key Frame Retrieval, Collaborative Multimodal Perception, and Recommendation Relevant Analysis to generate Enhanced Video Features from Historical Videos.
- The US Agent simulates user behavior using Chain-of-Thought Reasoning on user status and candidate videos, trained via Reinforcement Fine-Tuning with GRPO based on Task-Specific Rewards derived from Ground Truth.


---

[STRATEGIC INTELLIGENCE IN LARGE LANGUAGE MODELS EVIDENCE FROM EVOLUTIONARY GAME THEORY.](http://arxiv.org/abs/2507.02618v1)

- Evolutionary IPD Tournament Framework: introduces a system to evaluate LLMs' strategic intelligence by pitting LLM Agents (OpenAI, Gemini, Anthropic) and Classic Strategies (Benchmark IPD players) against each other in a Tournament Simulation (Orchestrates evolutionary dynamics) governed by a Match Procedure (Defines game rules) and an Evolutionary Update Rule (Determines population changes), with performance analyzed using Key Metrics (Quantify agent performance) and Qualitative Content Analysis (Analyzes LLM rationales), supported by Implementation & Reproducibility (Software and data).
- The framework simulates iterated Prisoner's Dilemma tournaments across various conditions, including different termination probabilities and mutation, to observe agent behavior and evolutionary success.
- Analysis of agent performance, strategic fingerprints, and textual rationales provides evidence that LLMs exhibit distinct, adaptive strategic reasoning rather than merely retrieving memorized patterns.


---

[DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making](http://arxiv.org/abs/2507.02616v1)

- DynamiCare: introduces a dynamic multi-agent framework for medical decision-making, comprising a Patient System (Responds to queries) and a Doctor System (Manages diagnostic process).
- The Doctor System includes a Central Agent (Manages specialist team) that dynamically adjusts the Specialist Team (Generates diagnosis/questions) based on the Visit Log (Records interaction history).
- The Patient System processes queries using components like Paraphrase, Match, Fallback, Tokenize, and Keywords map to generate responses from patient data.


---


[WebSailor: Navigating Super-human Reasoning for Web Agent](http://arxiv.org/abs/2507.02592v1)

- WebSailor: introduces a complete post-training methodology for web agents, including training data synthesis (SailorFog-QA), trajectory reconstruction, rejection sampling fine-tuning (RFT), duplicating sampling policy optimization (DUPO), agent architecture (ReAct framework), and tools (search tool, visit tool, summary model), designed to instill sophisticated reasoning for complex web navigation.
- The approach generates high-uncertainty training data (SailorFog-QA) and reconstructs concise reasoning trajectories from expert models to overcome limitations of direct imitation and context overload.
- The training methodology combines an RFT cold start with an efficient RL algorithm (DUPO) to enhance sample efficiency and performance on challenging information-seeking tasks, achieving performance comparable to proprietary agents.


---

[Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue](http://arxiv.org/abs/2507.02537v1)

- Fine-Tuning Chatbots for Empathetic Dialogue: introduces an approach to evaluate LLMs for empathetic dialogue using an Expert-Curated Dataset (Base empathetic conversations), LLMs (Generate/extend dialogue), Prompt Engineering (Guide LLM behavior), VADER Tool (Quantify emotional energy), and Expert Evaluator (Assess empathy quality).
- The approach involves creating baseline empathetic conversations, using prompt engineering to guide LLMs (ChatGPT and Gemini) to extend or generate similar dialogues, and evaluating the results via automated sentiment analysis and human expert assessment.
- This methodology highlights the importance of combining quantitative lexical analysis with qualitative human evaluation to assess the nuanced quality of empathetic listening in LLM-generated conversations.


---

[CyberRAG: An agentic RAG cyber attack classification and reporting tool](http://arxiv.org/abs/2507.02424v1)

- CyberRAG: introduces a modular, agent-based RAG framework for cyber-attack classification and reporting, including a Core LLM Engine, Classification Tool, RAG Tool, Attack Description Report Generator, and Interactive Chat.
- The framework uses specialized LLM classifiers and iterative retrieval-and-reasoning to classify payloads and generate context-aware explanations.
- CyberRAG provides interpretable, SOC-ready reports and supports interactive user dialogue for enhanced analysis and understanding.


---

[OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent](http://arxiv.org/abs/2507.02353v1)

- OMS (On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent): introduces a framework for ad keyword generation featuring a Keyword Performance Monitor (Monitors keyword performance), Agentic Clustering-Ranking Module (Analyzes, scores, ranks keywords), Multi-Turn Generation-Reflection Module (Generates, refines keywords), various Tools (Support generation/reflection), and Keyword Deployment (Deploys new keywords).
- The framework monitors keyword performance, analyzes intent, calculates multi-objective scores, ranks keywords, generates and refines new keywords using reflection, and re-clusters them.
- It operates on-the-fly without training data, optimizes for multiple metrics, and leverages LLM agents and external tools for adaptive generation.


---

[MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent](http://arxiv.org/abs/2507.02259v1)

- MEMAGENT: introduces a novel agent workflow for long-context LLMs, featuring a base language model, fixed-length token memory, a context processing module for iterative updates, an answer generation module, trained using the Multi-conv DAPO RL algorithm with a rule-based verifier for rewards.
- The approach processes long documents in segments, updating memory via an overwrite strategy to achieve linear time complexity and handle arbitrary input lengths.
- Reinforcement learning trains the model to selectively retain answer-critical information in memory, enabling strong extrapolation capabilities on long-context tasks.


---

[Establishing Best Practices for Building Rigorous Agentic Benchmarks](https://arxiv.org/abs/2507.02825)

- ABC (Agentic Benchmark Checklist): introduces a set of guidelines for evaluating agentic benchmarks, with components assessing task validity, outcome validity, and benchmark reporting.
- The checklist identifies issues in benchmark design and implementation that can lead to inaccurate performance estimations of AI agents.
- Applying the checklist helps improve the rigor of agentic benchmark evaluation and reporting practices.


---

[Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks](https://arxiv.org/abs/2507.02735)

- META SECALIGN: introduces, "a secure foundation LLM against prompt injection attacks", with Base Instruct LLM (underlying language model), Modified Chat Template (structured input format), SecAlign++ Recipe (fine-tuning process), and LoRA (parameter-efficient tuning method), where "it develops the first open-source LLM with built-in model-level defense achieving commercial-grade performance".
- The framework fine-tunes LLAMA 3 series Instruct LLMs using a modified chat template and the SecAlign++ recipe, which includes DPO and LoRA.
- Evaluations show META SECALIGN achieves state-of-the-art security against prompt injection attacks with comparable utility to closed-source models.


---


[Reinforcement Learning with Verifiable Emotion Rewards for Empathetic Agents](http://arxiv.org/abs/2507.03112v1)

- RLVER (Reinforcement Learning with Verifiable Emotion Rewards): introduces a reinforcement learning framework for training LLMs, including a user simulator, an LLM agent, emotion rewards, policy optimization, and an optional thinking scaffold.
- The framework leverages a self-consistent user simulator to generate verifiable emotion rewards, guiding the LLM agent's learning towards empathetic dialogue.
- An explicit thinking scaffold can be incorporated into the LLM's generation process to enhance the development of higher-order empathetic strategies.

---

[Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](http://arxiv.org/abs/2507.07115v1)

- Agentic Framework: introduces a unified agentic framework leveraging LLMs for autonomous industrial control, including a Monitoring Agent (Continuously ingests sensor data), Action Agent (Proposes control moves or plans), Digital Twin Agent (Simulates proposed actions), Validation Agent (Scrutinises simulated outcome), Reprompting Agent (Interprets feedback and refines prompt), and Safety System (Provides fallback control).
- The framework integrates symbolic planning via Finite State Machines and continuous control using an iterative action-simulation-validation-reprompting loop.
- Case studies demonstrate the framework's ability to generate valid recovery paths in FSMs and regulate temperature in a physical system under disturbances, highlighting the role of validation and reprompting in achieving robustness.

---

#### 2nd July 2025


[Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust](http://arxiv.org/abs/2507.02197v1)

- LLM-based Role-Playing Agent System: investigates belief-behavior consistency in LLM-based role-playing agents, with LLM Agent (role-playing model), Persona (synthetic profile attributes), Trust Game Environment (simulated economic game), Trustee Archetypes (fixed opponent strategies), Prompting Strategies (agent interaction methods), and ReAct Framework (reasoning and acting process), by evaluating consistency between elicited beliefs and simulated behavior.
- The study uses the Trust Game as a testbed and evaluates consistency at both population and individual levels using various elicitation and conditioning strategies.
- Findings reveal systematic inconsistencies between stated beliefs and simulated behaviors, highlighting the need for robust internal consistency evaluation before using these systems in behavioral studies.


---

[Enhancing COBOL Code Explanations: A Multi-Agents Approach Using Large Language Models](http://arxiv.org/abs/2507.02182v1)

- Multi-Agents Approach: introduces a multi-agent framework for generating COBOL code explanations, with Code Processing Agent (Analyzes code, generates explanations), Text Processing Agent (Refines, merges explanations), Function Level (Function explanation pipeline), File Level (File explanation pipeline), and Project Level (Project explanation pipeline) components.
- The approach leverages two LLM-based agents and source code artifacts to generate explanations at function, file, and project granularities.
- Hierarchical merging is employed within the File Level and Project Level pipelines to handle long code exceeding LLM token limits.


---


[Synergizing Logical Reasoning, Knowledge Management and Collaboration in Multi-Agent LLM System](http://arxiv.org/abs/2507.02170v1)

- SynergyMAS: introduces a multi-agent system framework integrating Logical Reasoning, Retrieval-Augmented Generation (RAG), and Theory of Mind (ToM) capabilities, supported by Communication Protocols, Agent Specialization, a Hierarchical Structure, and internal Agent Architecture, to enhance LLM performance in complex tasks.
- The framework utilizes a Neo4j graph knowledge base and Clingo logic solver for reasoning, a modified Corrective RAG with Chroma vector base and web search for knowledge management, and explicit belief state modeling for Theory of Mind.
- A hierarchical structure with a coordinating "boss" agent and specialized follower agents facilitates collaborative problem-solving through structured interactions and iterative development cycles.


---

[The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems](http://arxiv.org/abs/2507.02097v1)

- Multi-Agent System (MAS): introduces a unified formalism for agentic recommender systems, comprising LLM Agent (Core decision-maker), Memory (Stores state/context), Tools (External functions/APIs), Environment (Shared resources/percepts), Interaction Protocol (Agent communication rules), Chat Agent (User interface), Specialised-Agent Caller (Spawns sub-agents), Retrieval Agent (Fetches data/items), Consistency Agent (Ensures coherence/compliance), Ranking & Presentation Agent (Orders/formats output), User Simulator (Generates synthetic behavior), Evaluation Agent (Logs/computes metrics), Session Summariser (Compresses session outcomes), Reporter Agent (Aggregates/reports results), Image Agent (Extracts image features), and Explanation Agent (Generates justifications).
- The framework enables LLM agents to plan, remember, use tools, and cooperate to handle complex, multi-step recommendation tasks beyond single-query responses.
- Specific use cases like party planning, user simulation, multi-modal recommendation, and explanation generation illustrate how agentic orchestration unlocks new capabilities and addresses challenges in personalization, evaluation, and transparency.


---

[Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab](http://arxiv.org/abs/2507.02083v1)

- SCIGYM: introduces a benchmark evaluating LLMs' scientific discovery capabilities using a dry lab simulation of biological systems, featuring an Agent, Dry Lab, SBML Models, Python Execution Environment, Experimental Perturbations, Observations, and Model Submission.
- The framework tasks the Agent with discovering missing biological mechanisms by interacting with the Dry Lab, which simulates SBML Models and provides Observations from Experimental Perturbations, allowing the Agent to analyze data using the Python Execution Environment and refine its hypothesis for Model Submission.
- This dry lab approach overcomes the cost and time limitations of wet lab experiments, enabling scalable evaluation of LLMs on iterative experiment design and data analysis in complex biological systems.


---

[Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs](http://arxiv.org/abs/2507.02076v1)

- Test-time Compute (TTC) strategies: introduces a two-tiered taxonomy of controllable (L1) and adaptive (L2) methods for improving LLM reasoning efficiency, categorized by sequential and parallel approaches, implemented via prompting, supervised finetuning, or reinforcement learning.
- The survey addresses the inefficiency of current LLMs that use fixed inference compute, often overthinking simple problems and underthinking hard ones.
- Benchmarking reveals systemic inefficiencies in existing models, highlighting the need for more adaptive and compute-aware reasoning mechanisms to balance performance, cost, and latency.


---

[The Thin Line Between Comprehension and Persuasion in LLMs](http://arxiv.org/abs/2507.01936v1)

- LLM Debate Evaluation Framework: introduces a method to evaluate LLMs in debate scenarios, with LLM (Generation), Formal Dialogue Model (FDM), Human Participant, Debate Transcript, Human Annotator, Annotation Criteria, LLM (Evaluation), Automated Prompt Optimization (APO), Audience, Survey Response, and Speech-to-Text (STT) components, where the paper evaluates LLMs' persuasive abilities and comprehension in structured debates.
- The framework compares standard LLMs with LLMs augmented by a Formal Dialogue Model (DE model) in debates against humans and other LLMs.
- Evaluation involves human and LLM annotation of debate transcripts based on defined criteria, alongside participant and audience surveys on satisfaction and persuasion.


---

[Decision-oriented Text Evaluation](http://arxiv.org/abs/2507.01923v1)

- Decision-Oriented Evaluation Framework: introduces, "a decision-oriented framework for evaluating generated text by directly measuring its influence on human and large language model (LLM) decision outcomes", with all Text Source (Origin of text), Text Generation Method (Process for creating text), Decision Agent (Entity making decisions), and Evaluation Metric (Measure of decision quality) components, where the framework evaluates generated text by assessing the accuracy of investment decisions made by human and LLM agents based on the text.
- The framework utilizes market digests generated by human journalists or LLMs using different selection methods as input for human and LLM decision-making agents.
- Decision quality is quantified using thresholded prediction accuracy of stock movements, highlighting the practical value of generated text beyond traditional intrinsic metrics.


---

[Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents](http://arxiv.org/abs/2507.01862v1)

- GUI-Inspired CoT with Submit/Reset Metaphor: introduces a method for domain-specific chatbots using User Query, Session Data, Task-Based Prompt, LLM, LLM Response, Parser, Chain-of-Thought (CoT), Decision Logic, and Back-end System to model GUI actions like Submit/Reset.
- The approach leverages LLMs prompted to generate structured data and CoT reasoning, which is parsed by the back-end to manage context and execute actions unambiguously.
- By making acknowledgment and context switching explicit via structured LLM outputs and CoT, the system reduces user confusion and aligns conversational flow with back-end logic.


---

[Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents](http://arxiv.org/abs/2507.01862v1)

- GUI-Inspired CoT with Submit/Reset Metaphor: introduces a method for domain-specific chatbots using User Query, Session Data, Task-Based Prompt, LLM, LLM Response, Parser, Chain-of-Thought (CoT), Decision Logic, and Back-end System to model GUI actions like Submit/Reset.
- The approach leverages LLMs prompted to generate structured data and CoT reasoning, which is parsed by the back-end to manage context and execute actions unambiguously.
- By making acknowledgment and context switching explicit via structured LLM outputs and CoT, the system reduces user confusion and aligns conversational flow with back-end logic.


---

[Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI](http://arxiv.org/abs/2507.01717v1)

- Agent Ideate: introduces a framework for generating product ideas from patents, with Patent Summarizer Agent (Summarizes patent), Keyword Extraction and Search Agent (Extracts keywords and searches), and Idea Generation & Validation Agents (Generates and validates idea).
- The framework processes Patent Data (Input source) through specialized agents to produce structured Product Information (Output).
- The agentic approach leverages LLMs and external search tools to enhance the innovation pipeline from patent data.


---

[Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture](http://arxiv.org/abs/2507.01701v1)

- bMAS (blackboard-based LLM multi-agent system): introduces a framework with a Blackboard (shared information space), Control Unit (selects agents), and Agent Group (collection of LLM agents), implemented in LbMAS with an Agent Generation Module (generates expert agents), Solution Extraction Module (extracts final solution), and LLM Set (pool of base models).
- The framework utilizes a shared blackboard for agent communication and collaboration, replacing individual agent memory modules.
- The Control Unit dynamically selects agents based on the blackboard content, enabling adaptive problem-solving without predefined workflows.


---

[Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems](http://arxiv.org/abs/2507.01599v1)

- Data Agent: introduces a comprehensive architecture for orchestrating Data+AI ecosystems, including Data Plane (Organize, understand data), Engine Plane (Understand, schedule engines, agents), Orchestration Plane (Manage pipeline workflow), Memory (Store knowledge, context), Perception (Understand environment, tasks), Tools (External data processing utilities), and Continuous Learning (Improve agent over time).
- The architecture integrates knowledge comprehension, reasoning, and planning capabilities to handle data-related tasks autonomously.
- It addresses challenges in understanding data/queries/environments/tools, orchestrating/optimizing/executing pipelines, and enabling self-reflection for continuous improvement.


---

[AGENT-AS-TOOL: A STUDY ON THE HIERARCHICAL DECISION MAKING WITH REINFORCEMENT LEARNING](http://arxiv.org/abs/2507.01489v1)

- Agent-as-tool: introduces a hierarchical framework with Planner (reasons, decides tool use), Toolcaller (executes tool actions, processes results), Tools (external interfaces), Observations (structured tool outputs), and Reinforcement Learning (GRPO) (fine-tunes Planner).
- The framework decouples reasoning and tool execution by assigning these roles to the Planner and Toolcaller respectively.
- This hierarchical design improves reasoning accuracy by providing the Planner with cleaner, structured observations from the Toolcaller.


---

[BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments](http://arxiv.org/abs/2507.01485v1)

- BioMARS (Biological Multi-Agent Robotic System): introduces a multi-agent robotic system for autonomous biological experiments, integrating LLMs, VLMs, and modular robotics with Biologist Agent (Designs protocols), Technician Agent (Translates to code), Inspector Agent (Detects errors), Physical Hardware (Executes actions), User Interface (Human interaction), LLMs (Language models), VLMs (Vision-language models), RAG (Retrieval augmented generation), Knowledge Checker (Filters content), Workflow Generator (Formulates steps), Workflow Checker (Refines workflow), Code Generator (Maps to pseudo-code), Code Checker (Validates code), Vision Transformer (Visual detection), and ROS (Robot control system) components.
- The system employs a hierarchical architecture where the Biologist Agent designs protocols, the Technician Agent translates them into robotic code, and the Inspector Agent monitors execution for errors.
- BioMARS leverages LLMs and VLMs for reasoning and perception, enabling autonomous protocol design, execution, and error handling in biological tasks.


---

[Using multi-agent architecture to mitigate the risk of LLM hallucinations](http://arxiv.org/abs/2507.01446v1)

- Multi-agent architecture: introduces a system to handle customer SMS requests using multiple intelligent agents, including services for receiving messages, orchestrating processing, arbitrating decisions, and specialized agents for handling specific tasks.
- The architecture integrates LLM-based agents with fuzzy logic and parsing techniques to interpret messages, evaluate confidence, assess customer importance, and detect potential LLM hallucinations.
- Hallucination mitigation involves comparing keyword extraction results from parsing and LLM agents and using fuzzy rules to determine the handling of potentially high-risk requests or route messages to expert agents.


---


[RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms](http://arxiv.org/abs/2507.01378v1)

- RALLY (Role-Adaptive LLM-Driven Yoked Navigation): introduces, with LLM-based two-stage semantic reasoning module, Local intention generation, Neighborhood consensus refinement, Role-value Mixing Network (RMIX)-based credit-distribution mechanism, RMIX Network, Prior Offline Experience Replay Buffer, and Fine-tuned LLM components, a framework for role-adaptive LLM-driven yoked navigation for agentic UAV swarms.
- The framework integrates LLM semantic reasoning with MARL policy learning for coordinating roles and decision-making across UAV swarms.
- It employs a two-stage LLM process for consensus inference and a RMIX-based mechanism for dynamic role assignment and credit assignment.


---

[Evaluating LLM Agent Collusion in Double Auctions](http://arxiv.org/abs/2507.01413v1)

- LLM Agent Double Auction Simulation: introduces a system to evaluate LLM agent collusion in a simulated continuous double auction environment with LLM Agents (buyers and sellers), Bid Queue, Ask Queue, Market Resolution Mechanism, Updated Market History, Planning & Messaging, Persistent Memory Store, Strategy Scratchpad, LLM Evaluator, Overseer Agent, CEO Message, and CME Group Regulators Message, investigating factors affecting seller collusion.
- The research explores how communication, model variation, and environmental pressures like oversight and urgency influence LLM seller agents' propensity to collude and their pricing behavior.
- Findings indicate that direct communication increases collusion, model choice affects coordination, and urgency can override the effects of regulatory oversight in promoting collusive pricing strategies.


---
[AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing](http://arxiv.org/abs/2507.01376v1)

- LLM-Agents, MLLM-Agents, and Agentic AI: reviews the evolution and concepts of AI agents, detailing LLM-Agents with Profile (identity, role, constraints), Memory (stores, retrieves interactions), Planning (decomposes tasks, steps), and Action (executes decisions, tools) components, MLLM-Agents, and Agentic AI, exploring their manufacturing potential.
- The paper discusses how Generative AI, including LLMs and MLLMs, enhances AI agents' capabilities for manufacturing applications.
- It highlights the progression from traditional AI agents to more autonomous, adaptive, and goal-driven Agentic AI systems for future manufacturing.


---

[Context-Aware Code Wiring Recommendation with LLM-based Agent](http://arxiv.org/abs/2507.01315v1)

- WIRL: introduces an LLM-based agent for context-aware code wiring, combining an LLM (Large Language Model), an Agent Pilot (Orchestrates communication), and a Customized Toolkit (Provides essential functionalities) with Locator (Identifies unresolved elements), Collector (Collects contextual information), and Completer (Infills isolated code) tools.
- The framework reformulates code wiring as a retrieval-augmented generation infilling task, leveraging LLMs' strengths in code completion.
- WIRL employs a hybrid execution mode and a state machine to guide the agent's exploration and improve efficiency.


---

[Emotionally Intelligent Task-oriented Dialogue Systems: Architecture, Representation, and Optimisation](http://arxiv.org/abs/2507.01594v1)

- LUSTER (LLM-based Unified System for Task-oriented dialogue with End-to-end Reinforcement learning): introduces an end-to-end task-oriented dialogue system integrating Dialogue History Encoding (Alternating user/system utterances), User Emotion Recognition (Predicts user emotional state), Active Domain Recognition (Identifies active domain), Dialogue State Tracking (Generates dialogue state), Database Query (Retrieves matching entries), Dialogue Action Prediction (Generates dialogue actions), System Conduct Selection (Selects system emotional stance), System Response Generation (Generates natural language response), LLM (Backbone model), and Database (Structured information storage) components.
- The system uses fully lexicalised representations and is trained with both supervised learning and hierarchical reinforcement learning, incorporating short-term emotion and long-term task success rewards.
- LUSTER achieves higher task success and lower concept error compared to other approaches by combining LLM capabilities with structured reward modeling.

---

[GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant](http://arxiv.org/abs/2507.01259v1)

- gAlus: introduces a cognitive LLM-based agent architecture for legal question answering using Polish Civil Code, featuring an AI assistant (single agent), Retriever (selects relevant documents), Documents database (stores legal text articles), Document chunking (splits legal text into articles), Query reformulation (generalizes user query), and Document scoring function (custom text matching).
- The Retriever selects relevant articles from the database based on reformulated queries, utilizing either the custom scoring function or Embeddings (vector representations) stored in a Vectorstore (stores embeddings) for a RAG variant.
- Evaluation on Polish law apprenticeship exam questions demonstrates gAlus significantly enhances LLM performance in providing correct answers and citing relevant legal provisions.

---

#### 1st July 2025

[STELLA: Self-Evolving LLM Agent for Biomedical Research](https://arxiv.org/abs/2507.02004)

- STELLA: introduces a self-evolving LLM agent for biomedical research, leveraging Manager, Dev, Critic, and Tool Creation Agents, an evolving Template Library, and a dynamic Tool Ocean, along with Conda Environment, Scripts, Input, Final Result, and Human Expert/Wet Experiment feedback, to autonomously improve capabilities.
- The agent employs a multi-agent architecture and two core self-evolving mechanisms: a Template Library for reasoning strategies and a dynamic Tool Ocean for accessible tools.
- STELLA learns from experience, dynamically expanding its knowledge and skills to tackle complex biomedical challenges and improve performance over time.


---


[WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks](https://arxiv.org/abs/2507.00938)

- Web Agent with Dynamic Reflection: introduces WebArXiv, a static benchmark, and proposes a dynamic reflection mechanism for web agents, including Web Agent, Visual Observations, Element Texts, Interaction History, Dynamic Reflection Mechanism, Model, Reasoning Context, Action Execution, and History Update components.
- WebArXiv provides a stable and reproducible environment for evaluating web agents on time-invariant arXiv tasks.
- The dynamic reflection mechanism enhances agent performance by selectively retrieving relevant past interaction steps for improved decision-making.


---

[Enhancing LLM Agent Safety via Causal Influence Prompting](https://arxiv.org/abs/2507.00979)

- CIP (Causal Influence Prompting): introduces a novel technique for enhancing LLM agent safety by leveraging Causal Influence Diagrams (CID) initialization, Environment interaction, and CID refinement.
- The approach uses CIDs to represent cause-and-effect relationships in the agent's decision-making process, enabling reasoning about potential consequences.
- Iterative refinement of the CID based on observed behaviors allows the agent to anticipate harmful outcomes and make safer decisions.


---



[Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications](https://arxiv.org/abs/2507.00914)

- Urban LLM Agents: introduces a framework for LLM-powered agents operating in urban environments, with LLMs (Core controller), Urban Sensing (Collects, interprets urban signals), Memory Management (Organizes, retrieves urban knowledge), Reasoning (Simulates, plans actions), Execution (Translates plans into actions), and Learning (Adapts, improves behavior) components.
- These agents are semi-embodied, interacting with cyber-physical-social urban systems through APIs, databases, and platforms to support system-level decision-making.
- The paper surveys the research landscape, categorizes applications, and discusses trustworthiness and evaluation challenges for real-world deployment.


---

[TransLaw: Benchmarking Large Language Models in Multi-Agent Simulation of the Collaborative Translation](https://arxiv.org/abs/2507.00875)

- TransLaw: introduces a multi-agent framework for legal judgment translation, featuring Translator Agent, Annotator Agent, and Proofreader Agent powered by LLMs.
- The framework simulates a professional translation workflow where agents collaborate, utilizing Proofreading Memory, Translation Memory, and a Terminology database.
- A Memory module supports agent self-adaptation by storing interaction history, aiming to improve translation quality and efficiency.


---

[Many LLMs Are More Utilitarian Than One](http://arxiv.org/abs/2507.00814v1)

- LLM-MAS (Large Language Model Multi-Agent Systems): introduces a study on collective moral reasoning in LLMs, featuring LLM Agent (Individual large language model) in Solo Condition (Independent reasoning) or Group Condition (Multi-agent deliberation) involving a Discussion Phase (Multi-turn agent exchange) and a Reflection Phase (Private reasoning and scoring).
- The research investigates whether multi-agent LLM systems exhibit a utilitarian boost in moral judgments compared to individual LLMs.
- Experiments with six different LLMs in pairs and triads show a consistent shift towards endorsing norm violations that maximize overall welfare.


---

[Generative Exaggeration in LLM Social Agents: Consistency, Bias, and Toxicity](http://arxiv.org/abs/2507.00657v1)

- LLM Social Agents: introduces, "Generative Exaggeration in LLM Social Agents: Consistency, Bias, and Toxicity", with LLMs (Generate responses), LLM Agents (Simulate users), Zero Shot Initialization (Uses political leaning), Few Shot Initialization (Uses user history), User Profile Data (Bio, tweets for Few Shot), and Tweet Conversation Context (Input tweets for reply), where the paper investigates how LLMs simulate political discourse on social media using agents initialized with varying user data.
- The study evaluates three LLM families (Gemini, Mistral, DeepSeek) under Zero Shot and Few Shot conditions, comparing their outputs to human replies on lexical diversity, ideological consistency, and toxicity.
- Findings reveal "generative exaggeration," where LLMs amplify salient user traits, particularly in the Few Shot setting, leading to increased polarization, stylized language, and toxicity, challenging their reliability as social proxies.


---


[ChatHLS: Towards Systematic Design Automation and Optimization for High-Level Synthesis](http://arxiv.org/abs/2507.00642v1)

- ChatHLS: introduces an automated end-to-end workflow for HLS design optimization and error correction, including C++ Input, LLM ① (HLS GEN), RAG, LLM ② (HLSTuner), HLS Tool (Testing), LLM ③ (Bug Fixing), LLM ④ (Instruction Adherence), LLM Group ⑤ (Multifaceted Assessment), LLM ⑥ (Scoring), BugRAG, QoR Pass Check, User Requirement, HLS-C Output, and HLS Dataset Collection.
- The framework leverages fine-tuned LLMs within a multi-agent system for generating HLS-C code, optimizing designs, and systematically debugging errors.
- ChatHLS utilizes a verification-oriented data augmentation paradigm (VODA) and iterative refinement to enhance LLM capabilities and achieve high code repair accuracy and performance speedups.


---


[Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning](http://arxiv.org/abs/2507.00432v1)

- Large Language Model (LLM): investigates the transferability of reasoning capabilities in LLMs fine-tuned on math tasks by analyzing their internal latent space and output token distribution.
- The research compares the impact of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) fine-tuning paradigms on LLM generalization.
- Findings indicate that RL-tuned models maintain more stable latent representations and token distributions, leading to better transferability across diverse tasks than SFT-tuned models.


---

[iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing](http://arxiv.org/abs/2507.00378v1)

- iPanda: introduces an end-to-end framework for automated protocol conformance testing, with Function Point Extractor (extracts points), Test Case Generation Module (generates test cases), LLM Interactor (generates test code), Execution Module (runs tests), Memory Module (manages memory), and Summarization Module (summarizes, reports).
- The framework leverages LLMs, keyword-based test case generation, code-based retrieval-augmented generation, and iterative self-correction for test code refinement.
- iPanda streamlines the testing process from specification analysis to result analysis, significantly reducing manual effort and improving efficiency.


---


[STELLA: Self-Evolving LLM Agent for Biomedical Research](http://arxiv.org/abs/2507.02004v1)

- STELLA: introduces a self-evolving LLM agent for biomedical research, featuring a multi-agent architecture and two self-evolving mechanisms, designed to autonomously improve capabilities and accelerate discovery. The components are Manager Agent (coordinates agents, curates templates), Dev Agent (executes plan, generates code), Critic Agent (assesses results, provides feedback), Tool Creation Agent (creates/integrates new tools), Template Library (stores successful reasoning strategies), and Tool Ocean (dynamic tool/database collection).
- The multi-agent architecture orchestrates complex tasks, while the self-evolving mechanisms allow the agent to learn from experience and expand its toolset dynamically.
- STELLA demonstrates state-of-the-art performance on biomedical benchmarks and shows systematic improvement with increased computational experience.

---

[Dynamic Strategy Adaptation in Multi-Agent Environments with Large Language Models](http://arxiv.org/abs/2507.02002v1)

- PPO+LLM framework: introduces a real-time reward shaping architecture for multi-agent strategy adaptation, integrating Environment (simulates multi-agent task), Grid State (raw environment state), Flattened Tensor (preprocessed observation), PPO Agent (reinforcement learning policy), Prompt Generation Module (creates text prompts), Frozen Large Language Model (evaluates prompts), and Reward Shaping Module (maps LLM feedback to reward).
- The framework uses a frozen LLM to provide symbolic feedback on task context via prompts, which is converted into a reward shaping signal for the PPO agents.
- This approach enables agents to dynamically adapt strategies in real-time based on high-level feedback, improving coordination and robustness in dynamic, noisy environments.

---

[Enhancing LLM Agent Safety via Causal Influence Prompting](http://arxiv.org/abs/2507.00979v1)

- CIP (Causal Influence Prompting): introduces a novel technique leveraging Causal Influence Diagrams (CID) to enhance LLM agent safety by identifying and mitigating risks, including LLM Agent, Causal Influence Diagram (CID), CID Generation, Environment Interaction, CID Refinement, CID Constructor/Verifier Functions, Environment Observation, Task Instruction, and Action Space.
- The approach involves initializing a CID from task specifications, guiding agent interactions using the CID, and iteratively refining the CID based on observed behaviors and outcomes.
- Experimental results demonstrate that reasoning about cause-and-effect relationships based on CIDs improves the safety of LLM agents in various tasks, including code execution and mobile device control.

---

[WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks](http://arxiv.org/abs/2507.00938v1)

- Dynamic Reflection Mechanism: introduces, History Retrieval (Retrieve recent steps) / Reflection Process (Identify relevant history) / Context Construction (Combine history and current view) / Action Generation (Generate next action) / History Update (Add action and result), where the mechanism enhances web agent decision-making by selectively using past interaction steps.
- The approach addresses the "Rigid History Reflection" failure mode by dynamically identifying the most relevant prior step for reasoning before generating the next action.
- Evaluated on the WebArXiv benchmark, this mechanism improves the performance of LLM-driven agents on time-invariant web tasks.

---

[TransLaw: Benchmarking Large Language Models in Multi-Agent Simulation of the Collaborative Translation](http://arxiv.org/abs/2507.00875v1)

- TransLaw: introduces a novel multi-agent framework for Hong Kong legal judgment translation, comprising Translator, Annotator, and Proofreader agents powered by LLMs.
- The framework simulates a professional translation workflow through collaborative task decomposition and specialized roles.
- It incorporates memory modules and utilizes a terminology database to enhance translation quality and efficiency.

---

[Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice](http://arxiv.org/abs/2506.23924v1)

- LLM Evaluation on OR Problems: introduces an evaluation of LLMs on stochastic modeling problems, including LLMs, OR Problems Dataset, SimOpt Library, Evaluation Mechanism, and Simulation Environment, assessing their capabilities in the analysis and optimization stage of the OR pipeline.
- The study tests LLMs on graduate-level homework, qualification exam problems, and simulation-optimization tasks from the SimOpt library.
- Results indicate state-of-the-art LLMs perform comparably to human experts on theoretical problems and match in-house solvers on practical simulation-optimization tasks, highlighting their potential as OR research assistants.

---

[Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation](http://arxiv.org/abs/2507.10911v1)

- MAS (Multi-agent System): introduces a dynamically generated multi-agent framework that simulates real-world multidisciplinary expert consultations, including Patient's Condition (Input data), General Practitioner (GP) Agent (Workflow coordinator), Specialist Agents (Domain experts), Discussion Group (Collaborative forum), and Mediator Agent (Consensus facilitator), to detect and resolve medical conflicts for safer therapy recommendations.
- The framework replicates the multi-step workflow of Multidisciplinary Teams (MDTs), enabling LLMs to propose improved treatment plans by detecting and resolving conflicts.
- This study also develops a new interpretable evaluation strategy, comparing LLM-proposed treatment plans with original plans focusing on conflict reduction and medication burden.

---

[Black Box Deployed: Functional Criteria for Artificial Moral Agents in the LLM Era](http://arxiv.org/abs/2507.13175v1)

- SMA-LLS (Simulating Moral Agency through Large Language Systems): introduces a revised set of ten functional criteria to evaluate LLM-based Artificial Moral Agents, including Moral Concordance (aligns with human principles), Context Sensitivity (adapts to situational nuances), Normative Integrity (coherent ethical values), Metaethical Awareness (recognizes moral uncertainty), Systemic Resilience (robust against attacks/stress), Trustworthiness (warrants human reliance), Corrigibility (adaptable to feedback), Partial Transparency (provides decision insight), Functional Autonomy (independent ethical operation), and Moral Imagination (generates creative ethical responses), shifting the focus from opaque internal states to observable, functionally moral behavior.
- The paper argues that traditional ethical criteria, which assume transparent architectures, are obsolete for LLMs due to their stochastic outputs and opaque internal states, necessitating a functionalist approach to AI ethics.
- The proposed criteria are illustrated using hypothetical scenarios involving an Autonomous Public Bus (APB) to demonstrate their practical applicability in morally salient contexts, emphasizing behavioral reliability and alignment with human values for safe deployment.

---

[Differentially Private Synthetic Data Release for Topics API Outputs](https://arxiv.org/abs/2506.23855)

- Differentially Private Synthetic Data Generation Methodology: introduces a novel approach for generating synthetic Topics API outputs that mimic real API traces while providing strong privacy guarantees.
- This methodology involves extracting differentially private statistics from real user data, optimizing a parameterized model to match these statistics, and then sampling from the optimized model to create synthetic data.
- The generated synthetic dataset enables external researchers to empirically study the privacy properties and re-identification risks of the Topics API, fostering transparency in Privacy-Preserving Ads APIs.

---

[Beyond DNS: Unlocking the Internet of AI Agents via the NANDA Index and Verified AgentFacts](http://arxiv.org/abs/2507.14263v1)

- NANDA: introduces a lean, modular index architecture for the Internet of AI agents, comprising a Lean Index Layer (core identity resolution), an AgentFacts Layer (metadata distribution tier), and a Dynamic Resolution Layer (adaptive routing tier).
- This architecture decouples static identity resolution from verifiable metadata distribution and dynamic endpoint routing, enabling scalable, secure, and privacy-preserving discovery and interaction for billions of AI agents.
- The system aims to overcome DNS limitations for dynamic AI agent environments by providing rapid global resolution, sub-second revocation, schema-validated capability assertions, and privacy-preserving discovery.

---

[Autonomous Resource Management in Microservice Systems via Reinforcement Learning](http://arxiv.org/abs/2507.12879v1)

- Reinforcement Learning-based Resource Management Model: introduces an intelligent reinforcement learning-based method for microservice resource scheduling and optimization, with Agent (decision-making entity), Environment (simulated microservice system), State (system status input), Action (resource allocation/scheduling output), Reward (performance feedback), Policy Network (action selection mechanism), G-Network (value/action generation), Experience Replay (memory for learning), Default Load (baseline workload), and Unlimited Repair (system resilience), where it dynamically adjusts resource allocation and data flow paths to enhance system performance.
- The model leverages Deep Q Network (DQN) methods, experience replay, and neural networks (Policy Network, G-Network) to learn optimal strategies for resource allocation and data flow scheduling in dynamic microservice environments.
- Experimental results demonstrate significant improvements in response time, throughput, resource utilization, and cost efficiency across various load and resource conditions compared to traditional static allocation methods.

---

[Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind – A Position Paper](http://arxiv.org/abs/2507.16184v1)

- Agentic Flow: introduces a structured cognitive loop with five modules—Retrieval (retrieval-augmented generation), Cognition (LLM-based reasoning), Control (monitoring/validation/arbitration), Memory (context/state tracking), and Action (tool execution/logging)—designed to overcome LLM limitations and align with four theories of mind.
- This architecture demonstrates how practical implementation can reveal structural convergence across Kahneman's dual-system theory, Friston's predictive processing, Minsky's society of mind, and Clark's extended mind, suggesting shared architectural patterns driven by functional demands.
- Empirical evaluation shows Agentic Flow outperforms baseline LLM-only agents in multi-step, conditional reasoning tasks, exhibiting enhanced task success, robust constraint adherence, and reduced hallucinations.

---

## Citation


How to cite my work?



```
@misc{MaattaAutonomousAgents2023,
  author = {Teemu Maatta},
  title = {Autonomous Agents},
  year = {2023},
  howpublished = {\url{https://github.com/tmgthb/Autonomous-Agents}},
  note = {Accessed: YYYY-MM-DD}
}

```

---



[Back to top](#topofthepage)
